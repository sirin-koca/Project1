[
    {
        "id": "http://arxiv.org/abs/2205.05739v3",
        "title": "Learning to Retrieve Videos by Asking Questions",
        "abstract": "  The majority of traditional text-to-video retrieval systems operate in static\nenvironments, i.e., there is no interaction between the user and the agent\nbeyond the initial textual query provided by the user. This can be sub-optimal\nif the initial query has ambiguities, which would lead to many falsely\nretrieved videos. To overcome this limitation, we propose a novel framework for\nVideo Retrieval using Dialog (ViReD), which enables the user to interact with\nan AI agent via multiple rounds of dialog, where the user refines retrieved\nresults by answering questions generated by an AI agent. Our novel multimodal\nquestion generator learns to ask questions that maximize the subsequent video\nretrieval performance using (i) the video candidates retrieved during the last\nround of interaction with the user and (ii) the text-based dialog history\ndocumenting all previous interactions, to generate questions that incorporate\nboth visual and linguistic cues relevant to video retrieval. Furthermore, to\ngenerate maximally informative questions, we propose an Information-Guided\nSupervision (IGS), which guides the question generator to ask questions that\nwould boost subsequent video retrieval accuracy. We validate the effectiveness\nof our interactive ViReD framework on the AVSD dataset, showing that our\ninteractive method performs significantly better than traditional\nnon-interactive video retrieval systems. We also demonstrate that our proposed\napproach generalizes to the real-world settings that involve interactions with\nreal humans, thus, demonstrating the robustness and generality of our framework\n",
        "published": "2022",
        "authors": [
            "Avinash Madasu",
            "Junier Oliva",
            "Gedas Bertasius"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1603.08474v1",
        "title": "Deep Embedding for Spatial Role Labeling",
        "abstract": "  This paper introduces the visually informed embedding of word (VIEW), a\ncontinuous vector representation for a word extracted from a deep neural model\ntrained using the Microsoft COCO data set to forecast the spatial arrangements\nbetween visual objects, given a textual description. The model is composed of a\ndeep multilayer perceptron (MLP) stacked on the top of a Long Short Term Memory\n(LSTM) network, the latter being preceded by an embedding layer. The VIEW is\napplied to transferring multimodal background knowledge to Spatial Role\nLabeling (SpRL) algorithms, which recognize spatial relations between objects\nmentioned in the text. This work also contributes with a new method to select\ncomplementary features and a fine-tuning method for MLP that improves the $F1$\nmeasure in classifying the words into spatial roles. The VIEW is evaluated with\nthe Task 3 of SemEval-2013 benchmark data set, SpaceEval.\n",
        "published": "2016",
        "authors": [
            "Oswaldo Ludwig",
            "Xiao Liu",
            "Parisa Kordjamshidi",
            "Marie-Francine Moens"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2109.00020v1",
        "title": "Working Memory Connections for LSTM",
        "abstract": "  Recurrent Neural Networks with Long Short-Term Memory (LSTM) make use of\ngating mechanisms to mitigate exploding and vanishing gradients when learning\nlong-term dependencies. For this reason, LSTMs and other gated RNNs are widely\nadopted, being the standard de facto for many sequence modeling tasks. Although\nthe memory cell inside the LSTM contains essential information, it is not\nallowed to influence the gating mechanism directly. In this work, we improve\nthe gate potential by including information coming from the internal cell\nstate. The proposed modification, named Working Memory Connection, consists in\nadding a learnable nonlinear projection of the cell content into the network\ngates. This modification can fit into the classical LSTM gates without any\nassumption on the underlying task, being particularly effective when dealing\nwith longer sequences. Previous research effort in this direction, which goes\nback to the early 2000s, could not bring a consistent improvement over vanilla\nLSTM. As part of this paper, we identify a key issue tied to previous\nconnections that heavily limits their effectiveness, hence preventing a\nsuccessful integration of the knowledge coming from the internal cell state. We\nshow through extensive experimental evaluation that Working Memory Connections\nconstantly improve the performance of LSTMs on a variety of tasks. Numerical\nresults suggest that the cell state contains useful information that is worth\nincluding in the gate structure.\n",
        "published": "2021",
        "authors": [
            "Federico Landi",
            "Lorenzo Baraldi",
            "Marcella Cornia",
            "Rita Cucchiara"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1506.00333v2",
        "title": "Learning to Answer Questions From Image Using Convolutional Neural\n  Network",
        "abstract": "  In this paper, we propose to employ the convolutional neural network (CNN)\nfor the image question answering (QA). Our proposed CNN provides an end-to-end\nframework with convolutional architectures for learning not only the image and\nquestion representations, but also their inter-modal interactions to produce\nthe answer. More specifically, our model consists of three CNNs: one image CNN\nto encode the image content, one sentence CNN to compose the words of the\nquestion, and one multimodal convolution layer to learn their joint\nrepresentation for the classification in the space of candidate answer words.\nWe demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QA\ndatasets, which are two benchmark datasets for the image QA, with the\nperformances significantly outperforming the state-of-the-art.\n",
        "published": "2015",
        "authors": [
            "Lin Ma",
            "Zhengdong Lu",
            "Hang Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1507.01053v1",
        "title": "Describing Multimedia Content using Attention-based Encoder--Decoder\n  Networks",
        "abstract": "  Whereas deep neural networks were first mostly used for classification tasks,\nthey are rapidly expanding in the realm of structured output problems, where\nthe observed target is composed of multiple random variables that have a rich\njoint distribution, given the input. We focus in this paper on the case where\nthe input also has a rich structure and the input and output structures are\nsomehow related. We describe systems that learn to attend to different places\nin the input, for each element of the output, for a variety of tasks: machine\ntranslation, image caption generation, video clip description and speech\nrecognition. All these systems are based on a shared set of building blocks:\ngated recurrent neural networks and convolutional neural networks, along with\ntrained attention mechanisms. We report on experimental results with these\nsystems, showing impressively good performance and the advantage of the\nattention mechanism.\n",
        "published": "2015",
        "authors": [
            "Kyunghyun Cho",
            "Aaron Courville",
            "Yoshua Bengio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1510.04709v2",
        "title": "Multilingual Image Description with Neural Sequence Models",
        "abstract": "  In this paper we present an approach to multi-language image description\nbringing together insights from neural machine translation and neural image\ndescription. To create a description of an image for a given target language,\nour sequence generation models condition on feature vectors from the image, the\ndescription from the source language, and/or a multimodal vector computed over\nthe image and a description in the source language. In image description\nexperiments on the IAPR-TC12 dataset of images aligned with English and German\nsentences, we find significant and substantial improvements in BLEU4 and Meteor\nscores for models trained over multiple languages, compared to a monolingual\nbaseline.\n",
        "published": "2015",
        "authors": [
            "Desmond Elliott",
            "Stella Frank",
            "Eva Hasler"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1609.04938v2",
        "title": "Image-to-Markup Generation with Coarse-to-Fine Attention",
        "abstract": "  We present a neural encoder-decoder model to convert images into\npresentational markup based on a scalable coarse-to-fine attention mechanism.\nOur method is evaluated in the context of image-to-LaTeX generation, and we\nintroduce a new dataset of real-world rendered mathematical expressions paired\nwith LaTeX markup. We show that unlike neural OCR techniques using CTC-based\nmodels, attention-based approaches can tackle this non-standard OCR task. Our\napproach outperforms classical mathematical OCR systems by a large margin on\nin-domain rendered data, and, with pretraining, also performs well on\nout-of-domain handwritten data. To reduce the inference complexity associated\nwith the attention-based approaches, we introduce a new coarse-to-fine\nattention layer that selects a support region before applying attention.\n",
        "published": "2016",
        "authors": [
            "Yuntian Deng",
            "Anssi Kanervisto",
            "Jeffrey Ling",
            "Alexander M. Rush"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.05300v4",
        "title": "Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe\n  Noise",
        "abstract": "  The growing importance of massive datasets used for deep learning makes\nrobustness to label noise a critical property for classifiers to have. Sources\nof label noise include automatic labeling, non-expert labeling, and label\ncorruption by data poisoning adversaries. Numerous previous works assume that\nno source of labels can be trusted. We relax this assumption and assume that a\nsmall subset of the training data is trusted. This enables substantial label\ncorruption robustness performance gains. In addition, particularly severe label\nnoise can be combated by using a set of trusted data with clean labels. We\nutilize trusted data by proposing a loss correction technique that utilizes\ntrusted examples in a data-efficient manner to mitigate the effects of label\nnoise on deep neural network classifiers. Across vision and natural language\nprocessing tasks, we experiment with various label noises at several strengths,\nand show that our method significantly outperforms existing methods.\n",
        "published": "2018",
        "authors": [
            "Dan Hendrycks",
            "Mantas Mazeika",
            "Duncan Wilson",
            "Kevin Gimpel"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.05415v2",
        "title": "Teaching Machines to Code: Neural Markup Generation with Visual\n  Attention",
        "abstract": "  We present a neural transducer model with visual attention that learns to\ngenerate LaTeX markup of a real-world math formula given its image. Applying\nsequence modeling and transduction techniques that have been very successful\nacross modalities such as natural language, image, handwriting, speech and\naudio; we construct an image-to-markup model that learns to produce\nsyntactically and semantically correct LaTeX markup code over 150 words long\nand achieves a BLEU score of 89%; improving upon the previous state-of-art for\nthe Im2Latex problem. We also demonstrate with heat-map visualization how\nattention helps in interpreting the model and can pinpoint (detect and\nlocalize) symbols on the image accurately despite having been trained without\nany bounding box data.\n",
        "published": "2018",
        "authors": [
            "Sumeet S. Singh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1511.02274v2",
        "title": "Stacked Attention Networks for Image Question Answering",
        "abstract": "  This paper presents stacked attention networks (SANs) that learn to answer\nnatural language questions from images. SANs use semantic representation of a\nquestion as query to search for the regions in an image that are related to the\nanswer. We argue that image question answering (QA) often requires multiple\nsteps of reasoning. Thus, we develop a multiple-layer SAN in which we query an\nimage multiple times to infer the answer progressively. Experiments conducted\non four image QA data sets demonstrate that the proposed SANs significantly\noutperform previous state-of-the-art approaches. The visualization of the\nattention layers illustrates the progress that the SAN locates the relevant\nvisual clues that lead to the answer of the question layer-by-layer.\n",
        "published": "2015",
        "authors": [
            "Zichao Yang",
            "Xiaodong He",
            "Jianfeng Gao",
            "Li Deng",
            "Alex Smola"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1511.02799v4",
        "title": "Neural Module Networks",
        "abstract": "  Visual question answering is fundamentally compositional in nature---a\nquestion like \"where is the dog?\" shares substructure with questions like \"what\ncolor is the dog?\" and \"where is the cat?\" This paper seeks to simultaneously\nexploit the representational capacity of deep networks and the compositional\nlinguistic structure of questions. We describe a procedure for constructing and\nlearning *neural module networks*, which compose collections of jointly-trained\nneural \"modules\" into deep networks for question answering. Our approach\ndecomposes questions into their linguistic substructures, and uses these\nstructures to dynamically instantiate modular networks (with reusable\ncomponents for recognizing dogs, classifying colors, etc.). The resulting\ncompound networks are jointly trained. We evaluate our approach on two\nchallenging datasets for visual question answering, achieving state-of-the-art\nresults on both the VQA natural image dataset and a new dataset of complex\nquestions about abstract shapes.\n",
        "published": "2015",
        "authors": [
            "Jacob Andreas",
            "Marcus Rohrbach",
            "Trevor Darrell",
            "Dan Klein"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1511.04401v5",
        "title": "Symbol Grounding Association in Multimodal Sequences with Missing\n  Elements",
        "abstract": "  In this paper, we extend a symbolic association framework for being able to\nhandle missing elements in multimodal sequences. The general scope of the work\nis the symbolic associations of object-word mappings as it happens in language\ndevelopment in infants. In other words, two different representations of the\nsame abstract concepts can associate in both directions. This scenario has been\nlong interested in Artificial Intelligence, Psychology, and Neuroscience. In\nthis work, we extend a recent approach for multimodal sequences (visual and\naudio) to also cope with missing elements in one or both modalities. Our method\nuses two parallel Long Short-Term Memories (LSTMs) with a learning rule based\non EM-algorithm. It aligns both LSTM outputs via Dynamic Time Warping (DTW). We\npropose to include an extra step for the combination with the max operation for\nexploiting the common elements between both sequences. The motivation behind is\nthat the combination acts as a condition selector for choosing the best\nrepresentation from both LSTMs. We evaluated the proposed extension in the\nfollowing scenarios: missing elements in one modality (visual or audio) and\nmissing elements in both modalities (visual and sound). The performance of our\nextension reaches better results than the original model and similar results to\nindividual LSTM trained in each modality.\n",
        "published": "2015",
        "authors": [
            "Federico Raue",
            "Andreas Dengel",
            "Thomas M. Breuel",
            "Marcus Liwicki"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.08799v1",
        "title": "Chargrid: Towards Understanding 2D Documents",
        "abstract": "  We introduce a novel type of text representation that preserves the 2D layout\nof a document. This is achieved by encoding each document page as a\ntwo-dimensional grid of characters. Based on this representation, we present a\ngeneric document understanding pipeline for structured documents. This pipeline\nmakes use of a fully convolutional encoder-decoder network that predicts a\nsegmentation mask and bounding boxes. We demonstrate its capabilities on an\ninformation extraction task from invoices and show that it significantly\noutperforms approaches based on sequential text or document images.\n",
        "published": "2018",
        "authors": [
            "Anoop Raveendra Katti",
            "Christian Reisswig",
            "Cordula Guder",
            "Sebastian Brarda",
            "Steffen Bickel",
            "Johannes H\u00f6hne",
            "Jean Baptiste Faddoul"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.03063v1",
        "title": "Weak Supervision helps Emergence of Word-Object Alignment and improves\n  Vision-Language Tasks",
        "abstract": "  The large adoption of the self-attention (i.e. transformer model) and\nBERT-like training principles has recently resulted in a number of high\nperforming models on a large panoply of vision-and-language problems (such as\nVisual Question Answering (VQA), image retrieval, etc.). In this paper we claim\nthat these State-Of-The-Art (SOTA) approaches perform reasonably well in\nstructuring information inside a single modality but, despite their impressive\nperformances , they tend to struggle to identify fine-grained inter-modality\nrelationships. Indeed, such relations are frequently assumed to be implicitly\nlearned during training from application-specific losses, mostly cross-entropy\nfor classification. While most recent works provide inductive bias for\ninter-modality relationships via cross attention modules, in this work, we\ndemonstrate (1) that the latter assumption does not hold, i.e. modality\nalignment does not necessarily emerge automatically, and (2) that adding weak\nsupervision for alignment between visual objects and words improves the quality\nof the learned models on tasks requiring reasoning. In particular , we\nintegrate an object-word alignment loss into SOTA vision-language reasoning\nmodels and evaluate it on two tasks VQA and Language-driven Comparison of\nImages. We show that the proposed fine-grained inter-modality supervision\nsignificantly improves performance on both tasks. In particular, this new\nlearning signal allows obtaining SOTA-level performances on GQA dataset (VQA\ntask) with pre-trained models without finetuning on the task, and a new SOTA on\nNLVR2 dataset (Language-driven Comparison of Images). Finally, we also\nillustrate the impact of the contribution on the models reasoning by\nvisualizing attention distributions.\n",
        "published": "2019",
        "authors": [
            "Corentin Kervadec",
            "Grigory Antipov",
            "Moez Baccouche",
            "Christian Wolf"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2002.06701v1",
        "title": "Gaussian Smoothen Semantic Features (GSSF) -- Exploring the Linguistic\n  Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO\n  Framework",
        "abstract": "  In this work, we have introduced Gaussian Smoothen Semantic Features (GSSF)\nfor Better Semantic Selection for Indian regional language-based image\ncaptioning and introduced a procedure where we used the existing translation\nand English crowd-sourced sentences for training. We have shown that this\narchitecture is a promising alternative source, where there is a crunch in\nresources. Our main contribution of this work is the development of deep\nlearning architectures for the Bengali language (is the fifth widely spoken\nlanguage in the world) with a completely different grammar and language\nattributes. We have shown that these are working well for complex applications\nlike language generation from image contexts and can diversify the\nrepresentation through introducing constraints, more extensive features, and\nunique feature spaces. We also established that we could achieve absolute\nprecision and diversity when we use smoothened semantic tensor with the\ntraditional LSTM and feature decomposition networks. With better learning\narchitecture, we succeeded in establishing an automated algorithm and\nassessment procedure that can help in the evaluation of competent applications\nwithout the requirement for expertise and human intervention.\n",
        "published": "2020",
        "authors": [
            "Chiranjib Sur"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.13867v1",
        "title": "Learning Various Length Dependence by Dual Recurrent Neural Networks",
        "abstract": "  Recurrent neural networks (RNNs) are widely used as a memory model for\nsequence-related problems. Many variants of RNN have been proposed to solve the\ngradient problems of training RNNs and process long sequences. Although some\nclassical models have been proposed, capturing long-term dependence while\nresponding to short-term changes remains a challenge. To this problem, we\npropose a new model named Dual Recurrent Neural Networks (DuRNN). The DuRNN\nconsists of two parts to learn the short-term dependence and progressively\nlearn the long-term dependence. The first part is a recurrent neural network\nwith constrained full recurrent connections to deal with short-term dependence\nin sequence and generate short-term memory. Another part is a recurrent neural\nnetwork with independent recurrent connections which helps to learn long-term\ndependence and generate long-term memory. A selection mechanism is added\nbetween two parts to help the needed long-term information transfer to the\nindependent neurons. Multiple modules can be stacked to form a multi-layer\nmodel for better performance. Our contributions are: 1) a new recurrent model\ndeveloped based on the divide-and-conquer strategy to learn long and short-term\ndependence separately, and 2) a selection mechanism to enhance the separating\nand learning of different temporal scales of dependence. Both theoretical\nanalysis and extensive experiments are conducted to validate the performance of\nour model, and we also conduct simple visualization experiments and ablation\nanalyses for the model interpretability. Experimental results indicate that the\nproposed DuRNN model can handle not only very long sequences (over 5000 time\nsteps), but also short sequences very well. Compared with many state-of-the-art\nRNN models, our model has demonstrated efficient and better performance.\n",
        "published": "2020",
        "authors": [
            "Chenpeng Zhang",
            "Shuai Li",
            "Mao Ye",
            "Ce Zhu",
            "Xue Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2011.14901v1",
        "title": "Language-Driven Region Pointer Advancement for Controllable Image\n  Captioning",
        "abstract": "  Controllable Image Captioning is a recent sub-field in the multi-modal task\nof Image Captioning wherein constraints are placed on which regions in an image\nshould be described in the generated natural language caption. This puts a\nstronger focus on producing more detailed descriptions, and opens the door for\nmore end-user control over results. A vital component of the Controllable Image\nCaptioning architecture is the mechanism that decides the timing of attending\nto each region through the advancement of a region pointer. In this paper, we\npropose a novel method for predicting the timing of region pointer advancement\nby treating the advancement step as a natural part of the language structure\nvia a NEXT-token, motivated by a strong correlation to the sentence structure\nin the training data. We find that our timing agrees with the ground-truth\ntiming in the Flickr30k Entities test data with a precision of 86.55% and a\nrecall of 97.92%. Our model implementing this technique improves the\nstate-of-the-art on standard captioning metrics while additionally\ndemonstrating a considerably larger effective vocabulary size.\n",
        "published": "2020",
        "authors": [
            "Annika Lindh",
            "Robert J. Ross",
            "John D. Kelleher"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2209.09004v3",
        "title": "EcoFormer: Energy-Saving Attention with Linear Complexity",
        "abstract": "  Transformer is a transformative framework that models sequential data and has\nachieved remarkable performance on a wide range of tasks, but with high\ncomputational and energy cost. To improve its efficiency, a popular choice is\nto compress the models via binarization which constrains the floating-point\nvalues into binary ones to save resource consumption owing to cheap bitwise\noperations significantly. However, existing binarization methods only aim at\nminimizing the information loss for the input distribution statistically, while\nignoring the pairwise similarity modeling at the core of the attention. To this\nend, we propose a new binarization paradigm customized to high-dimensional\nsoftmax attention via kernelized hashing, called EcoFormer, to map the original\nqueries and keys into low-dimensional binary codes in Hamming space. The\nkernelized hash functions are learned to match the ground-truth similarity\nrelations extracted from the attention map in a self-supervised way. Based on\nthe equivalence between the inner product of binary codes and the Hamming\ndistance as well as the associative property of matrix multiplication, we can\napproximate the attention in linear complexity by expressing it as a\ndot-product of binary codes. Moreover, the compact binary representations of\nqueries and keys enable us to replace most of the expensive multiply-accumulate\noperations in attention with simple accumulations to save considerable on-chip\nenergy footprint on edge devices. Extensive experiments on both vision and\nlanguage tasks show that EcoFormer consistently achieves comparable performance\nwith standard attentions while consuming much fewer resources. For example,\nbased on PVTv2-B0 and ImageNet-1K, Ecoformer achieves a 73% on-chip energy\nfootprint reduction with only a 0.33% performance drop compared to the standard\nattention. Code is available at https://github.com/ziplab/EcoFormer.\n",
        "published": "2022",
        "authors": [
            "Jing Liu",
            "Zizheng Pan",
            "Haoyu He",
            "Jianfei Cai",
            "Bohan Zhuang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2212.08330v2",
        "title": "Convolution-enhanced Evolving Attention Networks",
        "abstract": "  Attention-based neural networks, such as Transformers, have become ubiquitous\nin numerous applications, including computer vision, natural language\nprocessing, and time-series analysis. In all kinds of attention networks, the\nattention maps are crucial as they encode semantic dependencies between input\ntokens. However, most existing attention networks perform modeling or reasoning\nbased on representations , wherein the attention maps of different layers are\nlearned separately without explicit interactions. In this paper, we propose a\nnovel and generic evolving attention mechanism, which directly models the\nevolution of inter-token relationships through a chain of residual\nconvolutional modules. The major motivations are twofold. On the one hand, the\nattention maps in different layers share transferable knowledge, thus adding a\nresidual connection can facilitate the information flow of inter-token\nrelationships across layers. On the other hand, there is naturally an\nevolutionary trend among attention maps at different abstraction levels, so it\nis beneficial to exploit a dedicated convolution-based module to capture this\nprocess. Equipped with the proposed mechanism, the convolution-enhanced\nevolving attention networks achieve superior performance in various\napplications, including time-series representation, natural language\nunderstanding, machine translation, and image classification. Especially on\ntime-series representation tasks, Evolving Attention-enhanced Dilated\nConvolutional (EA-DC-) Transformer outperforms state-of-the-art models\nsignificantly, achieving an average of 17% improvement compared to the best\nSOTA. To the best of our knowledge, this is the first work that explicitly\nmodels the layer-wise evolution of attention maps. Our implementation is\navailable at https://github.com/pkuyym/EvolvingAttention.\n",
        "published": "2022",
        "authors": [
            "Yujing Wang",
            "Yaming Yang",
            "Zhuo Li",
            "Jiangang Bai",
            "Mingliang Zhang",
            "Xiangtai Li",
            "Jing Yu",
            "Ce Zhang",
            "Gao Huang",
            "Yunhai Tong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2308.04832v1",
        "title": "TSSR: A Truncated and Signed Square Root Activation Function for Neural\n  Networks",
        "abstract": "  Activation functions are essential components of neural networks. In this\npaper, we introduce a new activation function called the Truncated and Signed\nSquare Root (TSSR) function. This function is distinctive because it is odd,\nnonlinear, monotone and differentiable. Its gradient is continuous and always\npositive. Thanks to these properties, it has the potential to improve the\nnumerical stability of neural networks. Several experiments confirm that the\nproposed TSSR has better performance than other stat-of-the-art activation\nfunctions. The proposed function has significant implications for the\ndevelopment of neural network models and can be applied to a wide range of\napplications in fields such as computer vision, natural language processing,\nand speech recognition.\n",
        "published": "2023",
        "authors": [
            "Yuanhao Gong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.06488v2",
        "title": "SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural\n  Network",
        "abstract": "  Spiking neural networks (SNNs) have demonstrated the capability to achieve\ncomparable performance to deep neural networks (DNNs) in both visual and\nlinguistic domains while offering the advantages of improved energy efficiency\nand adherence to biological plausibility. However, the extension of such\nsingle-modality SNNs into the realm of multimodal scenarios remains an\nunexplored territory. Drawing inspiration from the concept of contrastive\nlanguage-image pre-training (CLIP), we introduce a novel framework, named\nSpikeCLIP, to address the gap between two modalities within the context of\nspike-based computing through a two-step recipe involving ``Alignment\nPre-training + Dual-Loss Fine-tuning\". Extensive experiments demonstrate that\nSNNs achieve comparable results to their DNN counterparts while significantly\nreducing energy consumption across a variety of datasets commonly used for\nmultimodal model evaluation. Furthermore, SpikeCLIP maintains robust\nperformance in image classification tasks that involve class labels not\npredefined within specific categories.\n",
        "published": "2023",
        "authors": [
            "Tianlong Li",
            "Wenhao Liu",
            "Changze Lv",
            "Jianhan Xu",
            "Cenyuan Zhang",
            "Muling Wu",
            "Xiaoqing Zheng",
            "Xuanjing Huang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.02671v1",
        "title": "Grounding Natural Language Commands to StarCraft II Game States for\n  Narration-Guided Reinforcement Learning",
        "abstract": "  While deep reinforcement learning techniques have led to agents that are\nsuccessfully able to learn to perform a number of tasks that had been\npreviously unlearnable, these techniques are still susceptible to the\nlongstanding problem of {\\em reward sparsity}. This is especially true for\ntasks such as training an agent to play StarCraft II, a real-time strategy game\nwhere reward is only given at the end of a game which is usually very long.\nWhile this problem can be addressed through reward shaping, such approaches\ntypically require a human expert with specialized knowledge. Inspired by the\nvision of enabling reward shaping through the more-accessible paradigm of\nnatural-language narration, we investigate to what extent we can contextualize\nthese narrations by grounding them to the goal-specific states. We present a\nmutual-embedding model using a multi-input deep-neural network that projects a\nsequence of natural language commands into the same high-dimensional\nrepresentation space as corresponding goal states. We show that using this\nmodel we can learn an embedding space with separable and distinct clusters that\naccurately maps natural-language commands to corresponding game states . We\nalso discuss how this model can allow for the use of narrations as a robust\nform of reward shaping to improve RL performance and efficiency.\n",
        "published": "2019",
        "authors": [
            "Nicholas Waytowich",
            "Sean L. Barton",
            "Vernon Lawhern",
            "Ethan Stump",
            "Garrett Warnell"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.00489v1",
        "title": "SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Planning\n  and Control",
        "abstract": "  In this work, we present an approach to deep visuomotor control using\nstructured deep dynamics models. Our deep dynamics model, a variant of\nSE3-Nets, learns a low-dimensional pose embedding for visuomotor control via an\nencoder-decoder structure. Unlike prior work, our dynamics model is structured:\ngiven an input scene, our network explicitly learns to segment salient parts\nand predict their pose-embedding along with their motion modeled as a change in\nthe pose space due to the applied actions. We train our model using a pair of\npoint clouds separated by an action and show that given supervision only in the\nform of point-wise data associations between the frames our network is able to\nlearn a meaningful segmentation of the scene along with consistent poses. We\nfurther show that our model can be used for closed-loop control directly in the\nlearned low-dimensional pose space, where the actions are computed by\nminimizing error in the pose space using gradient-based methods, similar to\ntraditional model-based control. We present results on controlling a Baxter\nrobot from raw depth data in simulation and in the real world and compare\nagainst two baseline deep networks. Our method runs in real-time, achieves good\nprediction of scene dynamics and outperforms the baseline methods on multiple\ncontrol runs. Video results can be found at:\nhttps://rse-lab.cs.washington.edu/se3-structured-deep-ctrl/\n",
        "published": "2017",
        "authors": [
            "Arunkumar Byravan",
            "Felix Leeb",
            "Franziska Meier",
            "Dieter Fox"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.11483v2",
        "title": "Constructing Parsimonious Analytic Models for Dynamic Systems via\n  Symbolic Regression",
        "abstract": "  Developing mathematical models of dynamic systems is central to many\ndisciplines of engineering and science. Models facilitate simulations, analysis\nof the system's behavior, decision making and design of automatic control\nalgorithms. Even inherently model-free control techniques such as reinforcement\nlearning (RL) have been shown to benefit from the use of models, typically\nlearned online. Any model construction method must address the tradeoff between\nthe accuracy of the model and its complexity, which is difficult to strike. In\nthis paper, we propose to employ symbolic regression (SR) to construct\nparsimonious process models described by analytic equations. We have equipped\nour method with two different state-of-the-art SR algorithms which\nautomatically search for equations that fit the measured data: Single Node\nGenetic Programming (SNGP) and Multi-Gene Genetic Programming (MGGP). In\naddition to the standard problem formulation in the state-space domain, we show\nhow the method can also be applied to input-output models of the NARX\n(nonlinear autoregressive with exogenous input) type. We present the approach\non three simulated examples with up to 14-dimensional state space: an inverted\npendulum, a mobile robot, and a bipedal walking robot. A comparison with deep\nneural networks and local linear regression shows that SR in most cases\noutperforms these commonly used alternative methods. We demonstrate on a real\npendulum system that the analytic model found enables a RL controller to\nsuccessfully perform the swing-up task, based on a model constructed from only\n100 data samples.\n",
        "published": "2019",
        "authors": [
            "Erik Derner",
            "Ji\u0159\u00ed Kubal\u00edk",
            "Nicola Ancona",
            "Robert Babu\u0161ka"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1312.1909v1",
        "title": "From Maxout to Channel-Out: Encoding Information on Sparse Pathways",
        "abstract": "  Motivated by an important insight from neural science, we propose a new\nframework for understanding the success of the recently proposed \"maxout\"\nnetworks. The framework is based on encoding information on sparse pathways and\nrecognizing the correct pathway at inference time. Elaborating further on this\ninsight, we propose a novel deep network architecture, called \"channel-out\"\nnetwork, which takes a much better advantage of sparse pathway encoding. In\nchannel-out networks, pathways are not only formed a posteriori, but they are\nalso actively selected according to the inference outputs from the lower\nlayers. From a mathematical perspective, channel-out networks can represent a\nwider class of piece-wise continuous functions, thereby endowing the network\nwith more expressive power than that of maxout networks. We test our\nchannel-out networks on several well-known image classification benchmarks,\nsetting new state-of-the-art performance on CIFAR-100 and STL-10, which\nrepresent some of the \"harder\" image classification benchmarks.\n",
        "published": "2013",
        "authors": [
            "Qi Wang",
            "Joseph JaJa"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1312.5845v7",
        "title": "Competitive Learning with Feedforward Supervisory Signal for Pre-trained\n  Multilayered Networks",
        "abstract": "  We propose a novel learning method for multilayered neural networks which\nuses feedforward supervisory signal and associates classification of a new\ninput with that of pre-trained input. The proposed method effectively uses rich\ninput information in the earlier layer for robust leaning and revising internal\nrepresentation in a multilayer neural network.\n",
        "published": "2013",
        "authors": [
            "Takashi Shinozaki",
            "Yasushi Naruse"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1402.3337v5",
        "title": "Zero-bias autoencoders and the benefits of co-adapting features",
        "abstract": "  Regularized training of an autoencoder typically results in hidden unit\nbiases that take on large negative values. We show that negative biases are a\nnatural result of using a hidden layer whose responsibility is to both\nrepresent the input data and act as a selection mechanism that ensures sparsity\nof the representation. We then show that negative biases impede the learning of\ndata distributions whose intrinsic dimensionality is high. We also propose a\nnew activation function that decouples the two roles of the hidden layer and\nthat allows us to learn representations on data with very high intrinsic\ndimensionality, where standard autoencoders typically fail. Since the decoupled\nactivation function acts like an implicit regularizer, the model can be trained\nby minimizing the reconstruction error of training data, without requiring any\nadditional regularization.\n",
        "published": "2014",
        "authors": [
            "Kishore Konda",
            "Roland Memisevic",
            "David Krueger"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1409.5185v2",
        "title": "Deeply-Supervised Nets",
        "abstract": "  Our proposed deeply-supervised nets (DSN) method simultaneously minimizes\nclassification error while making the learning process of hidden layers direct\nand transparent. We make an attempt to boost the classification performance by\nstudying a new formulation in deep networks. Three aspects in convolutional\nneural networks (CNN) style architectures are being looked at: (1) transparency\nof the intermediate layers to the overall classification; (2)\ndiscriminativeness and robustness of learned features, especially in the early\nlayers; (3) effectiveness in training due to the presence of the exploding and\nvanishing gradients. We introduce \"companion objective\" to the individual\nhidden layers, in addition to the overall objective at the output layer (a\ndifferent strategy to layer-wise pre-training). We extend techniques from\nstochastic gradient methods to analyze our algorithm. The advantage of our\nmethod is evident and our experimental result on benchmark datasets shows\nsignificant performance gain over existing methods (e.g. all state-of-the-art\nresults on MNIST, CIFAR-10, CIFAR-100, and SVHN).\n",
        "published": "2014",
        "authors": [
            "Chen-Yu Lee",
            "Saining Xie",
            "Patrick Gallagher",
            "Zhengyou Zhang",
            "Zhuowen Tu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1412.6563v2",
        "title": "Self-informed neural network structure learning",
        "abstract": "  We study the problem of large scale, multi-label visual recognition with a\nlarge number of possible classes. We propose a method for augmenting a trained\nneural network classifier with auxiliary capacity in a manner designed to\nsignificantly improve upon an already well-performing model, while minimally\nimpacting its computational footprint. Using the predictions of the network\nitself as a descriptor for assessing visual similarity, we define a\npartitioning of the label space into groups of visually similar entities. We\nthen augment the network with auxilliary hidden layer pathways with\nconnectivity only to these groups of label units. We report a significant\nimprovement in mean average precision on a large-scale object recognition task\nwith the augmented model, while increasing the number of multiply-adds by less\nthan 3%.\n",
        "published": "2014",
        "authors": [
            "David Warde-Farley",
            "Andrew Rabinovich",
            "Dragomir Anguelov"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1412.6830v3",
        "title": "Learning Activation Functions to Improve Deep Neural Networks",
        "abstract": "  Artificial neural networks typically have a fixed, non-linear activation\nfunction at each neuron. We have designed a novel form of piecewise linear\nactivation function that is learned independently for each neuron using\ngradient descent. With this adaptive activation function, we are able to\nimprove upon deep neural network architectures composed of static rectified\nlinear units, achieving state-of-the-art performance on CIFAR-10 (7.51%),\nCIFAR-100 (30.83%), and a benchmark from high-energy physics involving Higgs\nboson decay modes.\n",
        "published": "2014",
        "authors": [
            "Forest Agostinelli",
            "Matthew Hoffman",
            "Peter Sadowski",
            "Pierre Baldi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1412.7210v4",
        "title": "Denoising autoencoder with modulated lateral connections learns\n  invariant representations of natural images",
        "abstract": "  Suitable lateral connections between encoder and decoder are shown to allow\nhigher layers of a denoising autoencoder (dAE) to focus on invariant\nrepresentations. In regular autoencoders, detailed information needs to be\ncarried through the highest layers but lateral connections from encoder to\ndecoder relieve this pressure. It is shown that abstract invariant features can\nbe translated to detailed reconstructions when invariant features are allowed\nto modulate the strength of the lateral connection. Three dAE structures with\nmodulated and additive lateral connections, and without lateral connections\nwere compared in experiments using real-world images. The experiments verify\nthat adding modulated lateral connections to the model 1) improves the accuracy\nof the probability model for inputs, as measured by denoising performance; 2)\nresults in representations whose degree of invariance grows faster towards the\nhigher layers; and 3) supports the formation of diverse invariant poolings.\n",
        "published": "2014",
        "authors": [
            "Antti Rasmus",
            "Tapani Raiko",
            "Harri Valpola"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1502.06464v2",
        "title": "Rectified Factor Networks",
        "abstract": "  We propose rectified factor networks (RFNs) to efficiently construct very\nsparse, non-linear, high-dimensional representations of the input. RFN models\nidentify rare and small events in the input, have a low interference between\ncode units, have a small reconstruction error, and explain the data covariance\nstructure. RFN learning is a generalized alternating minimization algorithm\nderived from the posterior regularization method which enforces non-negative\nand normalized posterior means. We proof convergence and correctness of the RFN\nlearning algorithm. On benchmarks, RFNs are compared to other unsupervised\nmethods like autoencoders, RBMs, factor analysis, ICA, and PCA. In contrast to\nprevious sparse coding methods, RFNs yield sparser codes, capture the data's\ncovariance structure more precisely, and have a significantly smaller\nreconstruction error. We test RFNs as pretraining technique for deep networks\non different vision datasets, where RFNs were superior to RBMs and\nautoencoders. On gene expression data from two pharmaceutical drug discovery\nstudies, RFNs detected small and rare gene modules that revealed highly\nrelevant new biological insights which were so far missed by other unsupervised\nmethods.\n",
        "published": "2015",
        "authors": [
            "Djork-Arn\u00e9 Clevert",
            "Andreas Mayr",
            "Thomas Unterthiner",
            "Sepp Hochreiter"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1506.02617v1",
        "title": "Path-SGD: Path-Normalized Optimization in Deep Neural Networks",
        "abstract": "  We revisit the choice of SGD for training deep neural networks by\nreconsidering the appropriate geometry in which to optimize the weights. We\nargue for a geometry invariant to rescaling of weights that does not affect the\noutput of the network, and suggest Path-SGD, which is an approximate steepest\ndescent method with respect to a path-wise regularizer related to max-norm\nregularization. Path-SGD is easy and efficient to implement and leads to\nempirical gains over SGD and AdaGrad.\n",
        "published": "2015",
        "authors": [
            "Behnam Neyshabur",
            "Ruslan Salakhutdinov",
            "Nathan Srebro"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1508.00451v4",
        "title": "Integrated Inference and Learning of Neural Factors in Structural\n  Support Vector Machines",
        "abstract": "  Tackling pattern recognition problems in areas such as computer vision,\nbioinformatics, speech or text recognition is often done best by taking into\naccount task-specific statistical relations between output variables. In\nstructured prediction, this internal structure is used to predict multiple\noutputs simultaneously, leading to more accurate and coherent predictions.\nStructural support vector machines (SSVMs) are nonprobabilistic models that\noptimize a joint input-output function through margin-based learning. Because\nSSVMs generally disregard the interplay between unary and interaction factors\nduring the training phase, final parameters are suboptimal. Moreover, its\nfactors are often restricted to linear combinations of input features, limiting\nits generalization power. To improve prediction accuracy, this paper proposes:\n(i) Joint inference and learning by integration of back-propagation and\nloss-augmented inference in SSVM subgradient descent; (ii) Extending SSVM\nfactors to neural networks that form highly nonlinear functions of input\nfeatures. Image segmentation benchmark results demonstrate improvements over\nconventional SSVM training methods in terms of accuracy, highlighting the\nfeasibility of end-to-end SSVM training with neural factors.\n",
        "published": "2015",
        "authors": [
            "Rein Houthooft",
            "Filip De Turck"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1509.04612v2",
        "title": "Adapting Resilient Propagation for Deep Learning",
        "abstract": "  The Resilient Propagation (Rprop) algorithm has been very popular for\nbackpropagation training of multilayer feed-forward neural networks in various\napplications. The standard Rprop however encounters difficulties in the context\nof deep neural networks as typically happens with gradient-based learning\nalgorithms. In this paper, we propose a modification of the Rprop that combines\nstandard Rprop steps with a special drop out technique. We apply the method for\ntraining Deep Neural Networks as standalone components and in ensemble\nformulations. Results on the MNIST dataset show that the proposed modification\nalleviates standard Rprop's problems demonstrating improved learning speed and\naccuracy.\n",
        "published": "2015",
        "authors": [
            "Alan Mosca",
            "George D. Magoulas"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1603.08029v1",
        "title": "Resnet in Resnet: Generalizing Residual Architectures",
        "abstract": "  Residual networks (ResNets) have recently achieved state-of-the-art on\nchallenging computer vision tasks. We introduce Resnet in Resnet (RiR): a deep\ndual-stream architecture that generalizes ResNets and standard CNNs and is\neasily implemented with no computational overhead. RiR consistently improves\nperformance over ResNets, outperforms architectures with similar amounts of\naugmentation on CIFAR-10, and establishes a new state-of-the-art on CIFAR-100.\n",
        "published": "2016",
        "authors": [
            "Sasha Targ",
            "Diogo Almeida",
            "Kevin Lyman"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1605.06457v1",
        "title": "Virtual Worlds as Proxy for Multi-Object Tracking Analysis",
        "abstract": "  Modern computer vision algorithms typically require expensive data\nacquisition and accurate manual labeling. In this work, we instead leverage the\nrecent progress in computer graphics to generate fully labeled, dynamic, and\nphoto-realistic proxy virtual worlds. We propose an efficient real-to-virtual\nworld cloning method, and validate our approach by building and publicly\nreleasing a new video dataset, called Virtual KITTI (see\nhttp://www.xrce.xerox.com/Research-Development/Computer-Vision/Proxy-Virtual-Worlds),\nautomatically labeled with accurate ground truth for object detection,\ntracking, scene and instance segmentation, depth, and optical flow. We provide\nquantitative experimental evidence suggesting that (i) modern deep learning\nalgorithms pre-trained on real data behave similarly in real and virtual\nworlds, and (ii) pre-training on virtual data improves performance. As the gap\nbetween real and virtual worlds is small, virtual worlds enable measuring the\nimpact of various weather and imaging conditions on recognition performance,\nall other things being equal. We show these factors may affect drastically\notherwise high-performing deep models for tracking.\n",
        "published": "2016",
        "authors": [
            "Adrien Gaidon",
            "Qiao Wang",
            "Yohann Cabon",
            "Eleonora Vig"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1608.00218v1",
        "title": "Hyperparameter Transfer Learning through Surrogate Alignment for\n  Efficient Deep Neural Network Training",
        "abstract": "  Recently, several optimization methods have been successfully applied to the\nhyperparameter optimization of deep neural networks (DNNs). The methods work by\nmodeling the joint distribution of hyperparameter values and corresponding\nerror. Those methods become less practical when applied to modern DNNs whose\ntraining may take a few days and thus one cannot collect sufficient\nobservations to accurately model the distribution. To address this challenging\nissue, we propose a method that learns to transfer optimal hyperparameter\nvalues for a small source dataset to hyperparameter values with comparable\nperformance on a dataset of interest. As opposed to existing transfer learning\nmethods, our proposed method does not use hand-designed features. Instead, it\nuses surrogates to model the hyperparameter-error distributions of the two\ndatasets and trains a neural network to learn the transfer function. Extensive\nexperiments on three CV benchmark datasets clearly demonstrate the efficiency\nof our method.\n",
        "published": "2016",
        "authors": [
            "Ilija Ilievski",
            "Jiashi Feng"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1608.06884v2",
        "title": "Towards Bayesian Deep Learning: A Framework and Some Existing Methods",
        "abstract": "  While perception tasks such as visual object recognition and text\nunderstanding play an important role in human intelligence, the subsequent\ntasks that involve inference, reasoning and planning require an even higher\nlevel of intelligence. The past few years have seen major advances in many\nperception tasks using deep learning models. For higher-level inference,\nhowever, probabilistic graphical models with their Bayesian nature are still\nmore powerful and flexible. To achieve integrated intelligence that involves\nboth perception and inference, it is naturally desirable to tightly integrate\ndeep learning and Bayesian models within a principled probabilistic framework,\nwhich we call Bayesian deep learning. In this unified framework, the perception\nof text or images using deep learning can boost the performance of higher-level\ninference and in return, the feedback from the inference process is able to\nenhance the perception of text or images. This paper proposes a general\nframework for Bayesian deep learning and reviews its recent applications on\nrecommender systems, topic models, and control. In this paper, we also discuss\nthe relationship and differences between Bayesian deep learning and other\nrelated topics like Bayesian treatment of neural networks.\n",
        "published": "2016",
        "authors": [
            "Hao Wang",
            "Dit-Yan Yeung"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1609.01360v2",
        "title": "Evolutionary Synthesis of Deep Neural Networks via Synaptic\n  Cluster-driven Genetic Encoding",
        "abstract": "  There has been significant recent interest towards achieving highly efficient\ndeep neural network architectures. A promising paradigm for achieving this is\nthe concept of evolutionary deep intelligence, which attempts to mimic\nbiological evolution processes to synthesize highly-efficient deep neural\nnetworks over successive generations. An important aspect of evolutionary deep\nintelligence is the genetic encoding scheme used to mimic heredity, which can\nhave a significant impact on the quality of offspring deep neural networks.\nMotivated by the neurobiological phenomenon of synaptic clustering, we\nintroduce a new genetic encoding scheme where synaptic probability is driven\ntowards the formation of a highly sparse set of synaptic clusters. Experimental\nresults for the task of image classification demonstrated that the synthesized\noffspring networks using this synaptic cluster-driven genetic encoding scheme\ncan achieve state-of-the-art performance while having network architectures\nthat are not only significantly more efficient (with a ~125-fold decrease in\nsynapses for MNIST) compared to the original ancestor network, but also\ntailored for GPU-accelerated machine learning applications.\n",
        "published": "2016",
        "authors": [
            "Mohammad Javad Shafiee",
            "Alexander Wong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1609.07093v3",
        "title": "Neural Photo Editing with Introspective Adversarial Networks",
        "abstract": "  The increasingly photorealistic sample quality of generative image models\nsuggests their feasibility in applications beyond image generation. We present\nthe Neural Photo Editor, an interface that leverages the power of generative\nneural networks to make large, semantically coherent changes to existing\nimages. To tackle the challenge of achieving accurate reconstructions without\nloss of feature quality, we introduce the Introspective Adversarial Network, a\nnovel hybridization of the VAE and GAN. Our model efficiently captures\nlong-range dependencies through use of a computational block based on\nweight-shared dilated convolutions, and improves generalization performance\nwith Orthogonal Regularization, a novel weight regularization method. We\nvalidate our contributions on CelebA, SVHN, and CIFAR-100, and produce samples\nand reconstructions with high visual fidelity.\n",
        "published": "2016",
        "authors": [
            "Andrew Brock",
            "Theodore Lim",
            "J. M. Ritchie",
            "Nick Weston"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1702.07811v2",
        "title": "Adaptive Neural Networks for Efficient Inference",
        "abstract": "  We present an approach to adaptively utilize deep neural networks in order to\nreduce the evaluation time on new examples without loss of accuracy. Rather\nthan attempting to redesign or approximate existing networks, we propose two\nschemes that adaptively utilize networks. We first pose an adaptive network\nevaluation scheme, where we learn a system to adaptively choose the components\nof a deep network to be evaluated for each example. By allowing examples\ncorrectly classified using early layers of the system to exit, we avoid the\ncomputational time associated with full evaluation of the network. We extend\nthis to learn a network selection system that adaptively selects the network to\nbe evaluated for each example. We show that computational time can be\ndramatically reduced by exploiting the fact that many examples can be correctly\nclassified using relatively efficient networks and that complex,\ncomputationally costly networks are only necessary for a small fraction of\nexamples. We pose a global objective for learning an adaptive early exit or\nnetwork selection policy and solve it by reducing the policy learning problem\nto a layer-by-layer weighted binary classification problem. Empirically, these\napproaches yield dramatic reductions in computational cost, with up to a 2.8x\nspeedup on state-of-the-art networks from the ImageNet image recognition\nchallenge with minimal (<1%) loss of top5 accuracy.\n",
        "published": "2017",
        "authors": [
            "Tolga Bolukbasi",
            "Joseph Wang",
            "Ofer Dekel",
            "Venkatesh Saligrama"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1703.06217v2",
        "title": "Deciding How to Decide: Dynamic Routing in Artificial Neural Networks",
        "abstract": "  We propose and systematically evaluate three strategies for training\ndynamically-routed artificial neural networks: graphs of learned\ntransformations through which different input signals may take different paths.\nThough some approaches have advantages over others, the resulting networks are\noften qualitatively similar. We find that, in dynamically-routed networks\ntrained to classify images, layers and branches become specialized to process\ndistinct categories of images. Additionally, given a fixed computational\nbudget, dynamically-routed networks tend to perform better than comparable\nstatically-routed networks.\n",
        "published": "2017",
        "authors": [
            "Mason McGill",
            "Pietro Perona"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1705.06820v4",
        "title": "Pixel Deconvolutional Networks",
        "abstract": "  Deconvolutional layers have been widely used in a variety of deep models for\nup-sampling, including encoder-decoder networks for semantic segmentation and\ndeep generative models for unsupervised learning. One of the key limitations of\ndeconvolutional operations is that they result in the so-called checkerboard\nproblem. This is caused by the fact that no direct relationship exists among\nadjacent pixels on the output feature map. To address this problem, we propose\nthe pixel deconvolutional layer (PixelDCL) to establish direct relationships\namong adjacent pixels on the up-sampled feature map. Our method is based on a\nfresh interpretation of the regular deconvolution operation. The resulting\nPixelDCL can be used to replace any deconvolutional layer in a plug-and-play\nmanner without compromising the fully trainable capabilities of original\nmodels. The proposed PixelDCL may result in slight decrease in efficiency, but\nthis can be overcome by an implementation trick. Experimental results on\nsemantic segmentation demonstrate that PixelDCL can consider spatial features\nsuch as edges and shapes and yields more accurate segmentation outputs than\ndeconvolutional layers. When used in image generation tasks, our PixelDCL can\nlargely overcome the checkerboard problem suffered by regular deconvolution\noperations.\n",
        "published": "2017",
        "authors": [
            "Hongyang Gao",
            "Hao Yuan",
            "Zhengyang Wang",
            "Shuiwang Ji"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1705.06821v2",
        "title": "Spatial Variational Auto-Encoding via Matrix-Variate Normal\n  Distributions",
        "abstract": "  The key idea of variational auto-encoders (VAEs) resembles that of\ntraditional auto-encoder models in which spatial information is supposed to be\nexplicitly encoded in the latent space. However, the latent variables in VAEs\nare vectors, which can be interpreted as multiple feature maps of size 1x1.\nSuch representations can only convey spatial information implicitly when\ncoupled with powerful decoders. In this work, we propose spatial VAEs that use\nfeature maps of larger size as latent variables to explicitly capture spatial\ninformation. This is achieved by allowing the latent variables to be sampled\nfrom matrix-variate normal (MVN) distributions whose parameters are computed\nfrom the encoder network. To increase dependencies among locations on latent\nfeature maps and reduce the number of parameters, we further propose spatial\nVAEs via low-rank MVN distributions. Experimental results show that the\nproposed spatial VAEs outperform original VAEs in capturing rich structural and\nspatial information.\n",
        "published": "2017",
        "authors": [
            "Zhengyang Wang",
            "Hao Yuan",
            "Shuiwang Ji"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1705.08881v2",
        "title": "Dense Transformer Networks",
        "abstract": "  The key idea of current deep learning methods for dense prediction is to\napply a model on a regular patch centered on each pixel to make pixel-wise\npredictions. These methods are limited in the sense that the patches are\ndetermined by network architecture instead of learned from data. In this work,\nwe propose the dense transformer networks, which can learn the shapes and sizes\nof patches from data. The dense transformer networks employ an encoder-decoder\narchitecture, and a pair of dense transformer modules are inserted into each of\nthe encoder and decoder paths. The novelty of this work is that we provide\ntechnical solutions for learning the shapes and sizes of patches from data and\nefficiently restoring the spatial correspondence required for dense prediction.\nThe proposed dense transformer modules are differentiable, thus the entire\nnetwork can be trained. We apply the proposed networks on natural and\nbiological image segmentation tasks and show superior performance is achieved\nin comparison to baseline methods.\n",
        "published": "2017",
        "authors": [
            "Jun Li",
            "Yongjun Chen",
            "Lei Cai",
            "Ian Davidson",
            "Shuiwang Ji"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.00436v2",
        "title": "Hierarchical Representations for Efficient Architecture Search",
        "abstract": "  We explore efficient neural architecture search methods and show that a\nsimple yet powerful evolutionary algorithm can discover new architectures with\nexcellent performance. Our approach combines a novel hierarchical genetic\nrepresentation scheme that imitates the modularized design pattern commonly\nadopted by human experts, and an expressive search space that supports complex\ntopologies. Our algorithm efficiently discovers architectures that outperform a\nlarge number of manually designed models for image classification, obtaining\ntop-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, which\nis competitive with the best existing neural architecture search approaches. We\nalso present results using random search, achieving 0.3% less top-1 accuracy on\nCIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36\nhours down to 1 hour.\n",
        "published": "2017",
        "authors": [
            "Hanxiao Liu",
            "Karen Simonyan",
            "Oriol Vinyals",
            "Chrisantha Fernando",
            "Koray Kavukcuoglu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.00970v7",
        "title": "A Classification-Based Study of Covariate Shift in GAN Distributions",
        "abstract": "  A basic, and still largely unanswered, question in the context of Generative\nAdversarial Networks (GANs) is whether they are truly able to capture all the\nfundamental characteristics of the distributions they are trained on. In\nparticular, evaluating the diversity of GAN distributions is challenging and\nexisting methods provide only a partial understanding of this issue. In this\npaper, we develop quantitative and scalable tools for assessing the diversity\nof GAN distributions. Specifically, we take a classification-based perspective\nand view loss of diversity as a form of covariate shift introduced by GANs. We\nexamine two specific forms of such shift: mode collapse and boundary\ndistortion. In contrast to prior work, our methods need only minimal human\nsupervision and can be readily applied to state-of-the-art GANs on large,\ncanonical datasets. Examining popular GANs using our tools indicates that these\nGANs have significant problems in reproducing the more distributional\nproperties of their training dataset.\n",
        "published": "2017",
        "authors": [
            "Shibani Santurkar",
            "Ludwig Schmidt",
            "Aleksander M\u0105dry"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.04340v3",
        "title": "Data Augmentation Generative Adversarial Networks",
        "abstract": "  Effective training of neural networks requires much data. In the low-data\nregime, parameters are underdetermined, and learnt networks generalise poorly.\nData Augmentation alleviates this by using existing data more effectively.\nHowever standard data augmentation produces only limited plausible alternative\ndata. Given there is potential to generate a much broader set of augmentations,\nwe design and train a generative model to do data augmentation. The model,\nbased on image conditional Generative Adversarial Networks, takes data from a\nsource domain and learns to take any data item and generalise it to generate\nother within-class data items. As this generative process does not depend on\nthe classes themselves, it can be applied to novel unseen classes of data. We\nshow that a Data Augmentation Generative Adversarial Network (DAGAN) augments\nstandard vanilla classifiers well. We also show a DAGAN can enhance few-shot\nlearning systems such as Matching Networks. We demonstrate these approaches on\nOmniglot, on EMNIST having learnt the DAGAN on Omniglot, and VGG-Face data. In\nour experiments we can see over 13% increase in accuracy in the low-data regime\nexperiments in Omniglot (from 69% to 82%), EMNIST (73.9% to 76%) and VGG-Face\n(4.5% to 12%); in Matching Networks for Omniglot we observe an increase of 0.5%\n(from 96.9% to 97.4%) and an increase of 1.8% in EMNIST (from 59.5% to 61.3%).\n",
        "published": "2017",
        "authors": [
            "Antreas Antoniou",
            "Amos Storkey",
            "Harrison Edwards"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.08762v1",
        "title": "DNN-Buddies: A Deep Neural Network-Based Estimation Metric for the\n  Jigsaw Puzzle Problem",
        "abstract": "  This paper introduces the first deep neural network-based estimation metric\nfor the jigsaw puzzle problem. Given two puzzle piece edges, the neural network\npredicts whether or not they should be adjacent in the correct assembly of the\npuzzle, using nothing but the pixels of each piece. The proposed metric\nexhibits an extremely high precision even though no manual feature extraction\nis performed. When incorporated into an existing puzzle solver, the solution's\naccuracy increases significantly, achieving thereby a new state-of-the-art\nstandard.\n",
        "published": "2017",
        "authors": [
            "Dror Sholomon",
            "Eli David",
            "Nathan S. Netanyahu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.08763v1",
        "title": "DeepPainter: Painter Classification Using Deep Convolutional\n  Autoencoders",
        "abstract": "  In this paper we describe the problem of painter classification, and propose\na novel approach based on deep convolutional autoencoder neural networks. While\nprevious approaches relied on image processing and manual feature extraction\nfrom paintings, our approach operates on the raw pixel level, without any\npreprocessing or manual feature extraction. We first train a deep convolutional\nautoencoder on a dataset of paintings, and subsequently use it to initialize a\nsupervised convolutional neural network for the classification phase.\n  The proposed approach substantially outperforms previous methods, improving\nthe previous state-of-the-art for the 3-painter classification problem from\n90.44% accuracy (previous state-of-the-art) to 96.52% accuracy, i.e., a 63%\nreduction in error rate.\n",
        "published": "2017",
        "authors": [
            "Eli David",
            "Nathan S. Netanyahu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.09663v1",
        "title": "DeepBrain: Functional Representation of Neural In-Situ Hybridization\n  Images for Gene Ontology Classification Using Deep Convolutional Autoencoders",
        "abstract": "  This paper presents a novel deep learning-based method for learning a\nfunctional representation of mammalian neural images. The method uses a deep\nconvolutional denoising autoencoder (CDAE) for generating an invariant, compact\nrepresentation of in situ hybridization (ISH) images. While most existing\nmethods for bio-imaging analysis were not developed to handle images with\nhighly complex anatomical structures, the results presented in this paper show\nthat functional representation extracted by CDAE can help learn features of\nfunctional gene ontology categories for their classification in a highly\naccurate manner. Using this CDAE representation, our method outperforms the\nprevious state-of-the-art classification rate, by improving the average AUC\nfrom 0.92 to 0.98, i.e., achieving 75% reduction in error. The method operates\non input images that were downsampled significantly with respect to the\noriginal ones to make it computationally feasible.\n",
        "published": "2017",
        "authors": [
            "Ido Cohen",
            "Eli David",
            "Nathan S. Netanyahu",
            "Noa Liscovitch",
            "Gal Chechik"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.07008v1",
        "title": "Segmentation hi\u00e9rarchique faiblement supervis\u00e9e",
        "abstract": "  Image segmentation is the process of partitioning an image into a set of\nmeaningful regions according to some criteria. Hierarchical segmentation has\nemerged as a major trend in this regard as it favors the emergence of important\nregions at different scales. On the other hand, many methods allow us to have\nprior information on the position of structures of interest in the images. In\nthis paper, we present a versatile hierarchical segmentation method that takes\ninto account any prior spatial information and outputs a hierarchical\nsegmentation that emphasizes the contours or regions of interest while\npreserving the important structures in the image. An application of this method\nto the weakly-supervised segmentation problem is presented.\n",
        "published": "2018",
        "authors": [
            "Amin Fehri",
            "Santiago Velasco-Forero",
            "Fernand Meyer"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.08530v1",
        "title": "Training wide residual networks for deployment using a single bit for\n  each weight",
        "abstract": "  For fast and energy-efficient deployment of trained deep neural networks on\nresource-constrained embedded hardware, each learned weight parameter should\nideally be represented and stored using a single bit. Error-rates usually\nincrease when this requirement is imposed. Here, we report large improvements\nin error rates on multiple datasets, for deep convolutional neural networks\ndeployed with 1-bit-per-weight. Using wide residual networks as our main\nbaseline, our approach simplifies existing methods that binarize weights by\napplying the sign function in training; we apply scaling factors for each layer\nwith constant unlearned values equal to the layer-specific standard deviations\nused for initialization. For CIFAR-10, CIFAR-100 and ImageNet, and models with\n1-bit-per-weight requiring less than 10 MB of parameter memory, we achieve\nerror rates of 3.9%, 18.5% and 26.0% / 8.5% (Top-1 / Top-5) respectively. We\nalso considered MNIST, SVHN and ImageNet32, achieving 1-bit-per-weight test\nresults of 0.27%, 1.9%, and 41.3% / 19.1% respectively. For CIFAR, our error\nrates halve previously reported values, and are within about 1% of our\nerror-rates for the same network with full-precision weights. For networks that\noverfit, we also show significant improvements in error rate by not learning\nbatch normalization scale and offset parameters. This applies to both full\nprecision and 1-bit-per-weight networks. Using a warm-restart learning-rate\nschedule, we found that training for 1-bit-per-weight is just as fast as\nfull-precision networks, with better accuracy than standard schedules, and\nachieved about 98%-99% of peak performance in just 62 training epochs for\nCIFAR-10/100. For full training code and trained models in MATLAB, Keras and\nPyTorch see https://github.com/McDonnell-Lab/1-bit-per-weight/ .\n",
        "published": "2018",
        "authors": [
            "Mark D. McDonnell"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1803.08375v2",
        "title": "Deep Learning using Rectified Linear Units (ReLU)",
        "abstract": "  We introduce the use of rectified linear units (ReLU) as the classification\nfunction in a deep neural network (DNN). Conventionally, ReLU is used as an\nactivation function in DNNs, with Softmax function as their classification\nfunction. However, there have been several studies on using a classification\nfunction other than Softmax, and this study is an addition to those. We\naccomplish this by taking the activation of the penultimate layer $h_{n - 1}$\nin a neural network, then multiply it by weight parameters $\\theta$ to get the\nraw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$,\ni.e. $f(o) = \\max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide\nclass predictions $\\hat{y}$ through argmax function, i.e. argmax $f(x)$.\n",
        "published": "2018",
        "authors": [
            "Abien Fred Agarap"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1803.09820v2",
        "title": "A disciplined approach to neural network hyper-parameters: Part 1 --\n  learning rate, batch size, momentum, and weight decay",
        "abstract": "  Although deep learning has produced dazzling successes for applications of\nimage, speech, and video processing in the past few years, most trainings are\nwith suboptimal hyper-parameters, requiring unnecessarily long training times.\nSetting the hyper-parameters remains a black art that requires years of\nexperience to acquire. This report proposes several efficient ways to set the\nhyper-parameters that significantly reduce training time and improves\nperformance. Specifically, this report shows how to examine the training\nvalidation/test loss function for subtle clues of underfitting and overfitting\nand suggests guidelines for moving toward the optimal balance point. Then it\ndiscusses how to increase/decrease the learning rate/momentum to speed up\ntraining. Our experiments show that it is crucial to balance every manner of\nregularization for each dataset and architecture. Weight decay is used as a\nsample regularizer to show how its optimal value is tightly coupled with the\nlearning rates and momentums. Files to help replicate the results reported here\nare available.\n",
        "published": "2018",
        "authors": [
            "Leslie N. Smith"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1803.10560v1",
        "title": "Normalization of Neural Networks using Analytic Variance Propagation",
        "abstract": "  We address the problem of estimating statistics of hidden units in a neural\nnetwork using a method of analytic moment propagation. These statistics are\nuseful for approximate whitening of the inputs in front of saturating\nnon-linearities such as a sigmoid function. This is important for\ninitialization of training and for reducing the accumulated scale and bias\ndependencies (compensating covariate shift), which presumably eases the\nlearning. In batch normalization, which is currently a very widely applied\ntechnique, sample estimates of statistics of hidden units over a batch are\nused. The proposed estimation uses an analytic propagation of mean and variance\nof the training set through the network. The result depends on the network\nstructure and its current weights but not on the specific batch input. The\nestimates are suitable for initialization and normalization, efficient to\ncompute and independent of the batch size. The experimental verification well\nsupports these claims. However, the method does not share the generalization\nproperties of BN, to which our experiments give some additional insight.\n",
        "published": "2018",
        "authors": [
            "Alexander Shekhovtsov",
            "Boris Flach"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1803.10590v2",
        "title": "Feed-forward Uncertainty Propagation in Belief and Neural Networks",
        "abstract": "  We propose a feed-forward inference method applicable to belief and neural\nnetworks. In a belief network, the method estimates an approximate factorized\nposterior of all hidden units given the input. In neural networks the method\npropagates uncertainty of the input through all the layers. In neural networks\nwith injected noise, the method analytically takes into account uncertainties\nresulting from this noise. Such feed-forward analytic propagation is\ndifferentiable in parameters and can be trained end-to-end. Compared to\nstandard NN, which can be viewed as propagating only the means, we propagate\nthe mean and variance. The method can be useful in all scenarios that require\nknowledge of the neuron statistics, e.g. when dealing with uncertain inputs,\nconsidering sigmoid activations as probabilities of Bernoulli units, training\nthe models regularized by injected noise (dropout) or estimating activation\nstatistics over the dataset (as needed for normalization methods). In the\nexperiments we show the possible utility of the method in all these tasks as\nwell as its current limitations.\n",
        "published": "2018",
        "authors": [
            "Alexander Shekhovtsov",
            "Boris Flach",
            "Michal Busta"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1803.11395v1",
        "title": "Contrast-Oriented Deep Neural Networks for Salient Object Detection",
        "abstract": "  Deep convolutional neural networks have become a key element in the recent\nbreakthrough of salient object detection. However, existing CNN-based methods\nare based on either patch-wise (region-wise) training and inference or fully\nconvolutional networks. Methods in the former category are generally\ntime-consuming due to severe storage and computational redundancies among\noverlapping patches. To overcome this deficiency, methods in the second\ncategory attempt to directly map a raw input image to a predicted dense\nsaliency map in a single network forward pass. Though being very efficient, it\nis arduous for these methods to detect salient objects of different scales or\nsalient regions with weak semantic information. In this paper, we develop\nhybrid contrast-oriented deep neural networks to overcome the aforementioned\nlimitations. Each of our deep networks is composed of two complementary\ncomponents, including a fully convolutional stream for dense prediction and a\nsegment-level spatial pooling stream for sparse saliency inference. We further\npropose an attentional module that learns weight maps for fusing the two\nsaliency predictions from these two streams. A tailored alternate scheme is\ndesigned to train these deep networks by fine-tuning pre-trained baseline\nmodels. Finally, a customized fully connected CRF model incorporating a salient\ncontour feature embedding can be optionally applied as a post-processing step\nto improve spatial coherence and contour positioning in the fused result from\nthese two streams. Extensive experiments on six benchmark datasets demonstrate\nthat our proposed model can significantly outperform the state of the art in\nterms of all popular evaluation metrics.\n",
        "published": "2018",
        "authors": [
            "Guanbin Li",
            "Yizhou Yu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1803.11410v3",
        "title": "The Resistance to Label Noise in K-NN and DNN Depends on its\n  Concentration",
        "abstract": "  We investigate the classification performance of K-nearest neighbors (K-NN)\nand deep neural networks (DNNs) in the presence of label noise. We first show\nempirically that a DNN's prediction for a given test example depends on the\nlabels of the training examples in its local neighborhood. This motivates us to\nderive a realizable analytic expression that approximates the multi-class K-NN\nclassification error in the presence of label noise, which is of independent\nimportance. We then suggest that the expression for K-NN may serve as a\nfirst-order approximation for the DNN error. Finally, we demonstrate\nempirically the proximity of the developed expression to the observed\nperformance of K-NN and DNN classifiers. Our result may explain the already\nobserved surprising resistance of DNN to some types of label noise. It also\ncharacterizes an important factor of it showing that the more concentrated the\nnoise the greater is the degradation in performance.\n",
        "published": "2018",
        "authors": [
            "Amnon Drory",
            "Oria Ratzon",
            "Shai Avidan",
            "Raja Giryes"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.02003v1",
        "title": "Deep Algorithms: designs for networks",
        "abstract": "  A new design methodology for neural networks that is guided by traditional\nalgorithm design is presented. To prove our point, we present two heuristics\nand demonstrate an algorithmic technique for incorporating additional weights\nin their signal-flow graphs. We show that with training the performance of\nthese networks can not only exceed the performance of the initial network, but\ncan match the performance of more-traditional neural network architectures. A\nkey feature of our approach is that these networks are initialized with\nparameters that provide a known performance threshold for the architecture on a\ngiven task.\n",
        "published": "2018",
        "authors": [
            "Abhejit Rajagopal",
            "Shivkumar Chandrasekaran",
            "Hrushikesh N. Mhaskar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.02679v2",
        "title": "Semi-Supervised Learning via Compact Latent Space Clustering",
        "abstract": "  We present a novel cost function for semi-supervised learning of neural\nnetworks that encourages compact clustering of the latent space to facilitate\nseparation. The key idea is to dynamically create a graph over embeddings of\nlabeled and unlabeled samples of a training batch to capture underlying\nstructure in feature space, and use label propagation to estimate its high and\nlow density regions. We then devise a cost function based on Markov chains on\nthe graph that regularizes the latent space to form a single compact cluster\nper class, while avoiding to disturb existing clusters during optimization. We\nevaluate our approach on three benchmarks and compare to state-of-the art with\npromising results. Our approach combines the benefits of graph-based\nregularization with efficient, inductive inference, does not require\nmodifications to a network architecture, and can thus be easily applied to\nexisting networks to enable an effective use of unlabeled data.\n",
        "published": "2018",
        "authors": [
            "Konstantinos Kamnitsas",
            "Daniel C. Castro",
            "Loic Le Folgoc",
            "Ian Walker",
            "Ryutaro Tanno",
            "Daniel Rueckert",
            "Ben Glocker",
            "Antonio Criminisi",
            "Aditya Nori"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.03796v4",
        "title": "Generative Adversarial Network Architectures For Image Synthesis Using\n  Capsule Networks",
        "abstract": "  In this paper, we propose Generative Adversarial Network (GAN) architectures\nthat use Capsule Networks for image-synthesis. Based on the principal of\npositional-equivariance of features, Capsule Network's ability to encode\nspatial relationships between the features of the image helps it become a more\npowerful critic in comparison to Convolutional Neural Networks (CNNs) used in\ncurrent architectures for image synthesis. Our proposed GAN architectures learn\nthe data manifold much faster and therefore, synthesize visually accurate\nimages in significantly lesser number of training samples and training epochs\nin comparison to GANs and its variants that use CNNs. Apart from analyzing the\nquantitative results corresponding the images generated by different\narchitectures, we also explore the reasons for the lower coverage and diversity\nexplored by the GAN architectures that use CNN critics.\n",
        "published": "2018",
        "authors": [
            "Yash Upadhyay",
            "Paul Schrater"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.05034v4",
        "title": "A Probabilistic U-Net for Segmentation of Ambiguous Images",
        "abstract": "  Many real-world vision problems suffer from inherent ambiguities. In clinical\napplications for example, it might not be clear from a CT scan alone which\nparticular region is cancer tissue. Therefore a group of graders typically\nproduces a set of diverse but plausible segmentations. We consider the task of\nlearning a distribution over segmentations given an input. To this end we\npropose a generative segmentation model based on a combination of a U-Net with\na conditional variational autoencoder that is capable of efficiently producing\nan unlimited number of plausible hypotheses. We show on a lung abnormalities\nsegmentation task and on a Cityscapes segmentation task that our model\nreproduces the possible segmentation variants as well as the frequencies with\nwhich they occur, doing so significantly better than published approaches.\nThese models could have a high impact in real-world applications, such as being\nused as clinical decision-making algorithms accounting for multiple plausible\nsemantic segmentation hypotheses to provide possible diagnoses and recommend\nfurther actions to resolve the present ambiguities.\n",
        "published": "2018",
        "authors": [
            "Simon A. A. Kohl",
            "Bernardino Romera-Paredes",
            "Clemens Meyer",
            "Jeffrey De Fauw",
            "Joseph R. Ledsam",
            "Klaus H. Maier-Hein",
            "S. M. Ali Eslami",
            "Danilo Jimenez Rezende",
            "Olaf Ronneberger"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.05978v6",
        "title": "Uncertainty Estimations by Softplus normalization in Bayesian\n  Convolutional Neural Networks with Variational Inference",
        "abstract": "  We introduce a novel uncertainty estimation for classification tasks for\nBayesian convolutional neural networks with variational inference. By\nnormalizing the output of a Softplus function in the final layer, we estimate\naleatoric and epistemic uncertainty in a coherent manner. The intractable\nposterior probability distributions over weights are inferred by Bayes by\nBackprop. Firstly, we demonstrate how this reliable variational inference\nmethod can serve as a fundamental construct for various network architectures.\nOn multiple datasets in supervised learning settings (MNIST, CIFAR-10,\nCIFAR-100), this variational inference method achieves performances equivalent\nto frequentist inference in identical architectures, while the two desiderata,\na measure for uncertainty and regularization are incorporated naturally.\nSecondly, we examine how our proposed measure for aleatoric and epistemic\nuncertainties is derived and validate it on the aforementioned datasets.\n",
        "published": "2018",
        "authors": [
            "Kumar Shridhar",
            "Felix Laumann",
            "Marcus Liwicki"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.06296v1",
        "title": "Right for the Right Reason: Training Agnostic Networks",
        "abstract": "  We consider the problem of a neural network being requested to classify\nimages (or other inputs) without making implicit use of a \"protected concept\",\nthat is a concept that should not play any role in the decision of the network.\nTypically these concepts include information such as gender or race, or other\ncontextual information such as image backgrounds that might be implicitly\nreflected in unknown correlations with other variables, making it insufficient\nto simply remove them from the input features. In other words, making accurate\npredictions is not good enough if those predictions rely on information that\nshould not be used: predictive performance is not the only important metric for\nlearning systems. We apply a method developed in the context of domain\nadaptation to address this problem of \"being right for the right reason\", where\nwe request a classifier to make a decision in a way that is entirely 'agnostic'\nto a given protected concept (e.g. gender, race, background etc.), even if this\ncould be implicitly reflected in other attributes via unknown correlations.\nAfter defining the concept of an 'agnostic model', we demonstrate how the\nDomain-Adversarial Neural Network can remove unwanted information from a model\nusing a gradient reversal layer.\n",
        "published": "2018",
        "authors": [
            "Sen Jia",
            "Thomas Lansdall-Welfare",
            "Nello Cristianini"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.06926v1",
        "title": "Understanding Patch-Based Learning by Explaining Predictions",
        "abstract": "  Deep networks are able to learn highly predictive models of video data. Due\nto video length, a common strategy is to train them on small video snippets. We\napply the deep Taylor / LRP technique to understand the deep network's\nclassification decisions, and identify a \"border effect\": a tendency of the\nclassifier to look mainly at the bordering frames of the input. This effect\nrelates to the step size used to build the video snippet, which we can then\ntune in order to improve the classifier's accuracy without retraining the\nmodel. To our knowledge, this is the the first work to apply the deep Taylor /\nLRP technique on any video analyzing neural network.\n",
        "published": "2018",
        "authors": [
            "Christopher Anders",
            "Gr\u00e9goire Montavon",
            "Wojciech Samek",
            "Klaus-Robert M\u00fcller"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.01430v1",
        "title": "SGAD: Soft-Guided Adaptively-Dropped Neural Network",
        "abstract": "  Deep neural networks (DNNs) have been proven to have many redundancies.\nHence, many efforts have been made to compress DNNs. However, the existing\nmodel compression methods treat all the input samples equally while ignoring\nthe fact that the difficulties of various input samples being correctly\nclassified are different. To address this problem, DNNs with adaptive dropping\nmechanism are well explored in this work. To inform the DNNs how difficult the\ninput samples can be classified, a guideline that contains the information of\ninput samples is introduced to improve the performance. Based on the developed\nguideline and adaptive dropping mechanism, an innovative soft-guided\nadaptively-dropped (SGAD) neural network is proposed in this paper. Compared\nwith the 32 layers residual neural networks, the presented SGAD can reduce the\nFLOPs by 77% with less than 1% drop in accuracy on CIFAR-10.\n",
        "published": "2018",
        "authors": [
            "Zhisheng Wang",
            "Fangxuan Sun",
            "Jun Lin",
            "Zhongfeng Wang",
            "Bo Yuan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.03165v1",
        "title": "Sparse Deep Neural Network Exact Solutions",
        "abstract": "  Deep neural networks (DNNs) have emerged as key enablers of machine learning.\nApplying larger DNNs to more diverse applications is an important challenge.\nThe computations performed during DNN training and inference are dominated by\noperations on the weight matrices describing the DNN. As DNNs incorporate more\nlayers and more neurons per layers, these weight matrices may be required to be\nsparse because of memory limitations. Sparse DNNs are one possible approach,\nbut the underlying theory is in the early stages of development and presents a\nnumber of challenges, including determining the accuracy of inference and\nselecting nonzero weights for training. Associative array algebra has been\ndeveloped by the big data community to combine and extend database, matrix, and\ngraph/network concepts for use in large, sparse data problems. Applying this\nmathematics to DNNs simplifies the formulation of DNN mathematics and reveals\nthat DNNs are linear over oscillating semirings. This work uses associative\narray DNNs to construct exact solutions and corresponding perturbation models\nto the rectified linear unit (ReLU) DNN equations that can be used to construct\ntest vectors for sparse DNN implementations over various precisions. These\nsolutions can be used for DNN verification, theoretical explorations of DNN\nproperties, and a starting point for the challenge of sparse training.\n",
        "published": "2018",
        "authors": [
            "Jeremy Kepner",
            "Vijay Gadepally",
            "Hayden Jananthan",
            "Lauren Milechin",
            "Sid Samsi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.06699v5",
        "title": "Adaptive Neural Trees",
        "abstract": "  Deep neural networks and decision trees operate on largely separate\nparadigms; typically, the former performs representation learning with\npre-specified architectures, while the latter is characterised by learning\nhierarchies over pre-specified features with data-driven architectures. We\nunite the two via adaptive neural trees (ANTs) that incorporates representation\nlearning into edges, routing functions and leaf nodes of a decision tree, along\nwith a backpropagation-based training algorithm that adaptively grows the\narchitecture from primitive modules (e.g., convolutional layers). We\ndemonstrate that, whilst achieving competitive performance on classification\nand regression datasets, ANTs benefit from (i) lightweight inference via\nconditional computation, (ii) hierarchical separation of features useful to the\ntask e.g. learning meaningful class associations, such as separating natural\nvs. man-made objects, and (iii) a mechanism to adapt the architecture to the\nsize and complexity of the training dataset.\n",
        "published": "2018",
        "authors": [
            "Ryutaro Tanno",
            "Kai Arulkumaran",
            "Daniel C. Alexander",
            "Antonio Criminisi",
            "Aditya Nori"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.09946v1",
        "title": "Computationally Efficient Measures of Internal Neuron Importance",
        "abstract": "  The challenge of assigning importance to individual neurons in a network is\nof interest when interpreting deep learning models. In recent work, Dhamdhere\net al. proposed Total Conductance, a \"natural refinement of Integrated\nGradients\" for attributing importance to internal neurons. Unfortunately, the\nauthors found that calculating conductance in tensorflow required the addition\nof several custom gradient operators and did not scale well. In this work, we\nshow that the formula for Total Conductance is mathematically equivalent to\nPath Integrated Gradients computed on a hidden layer in the network. We provide\na scalable implementation of Total Conductance using standard tensorflow\ngradient operators that we call Neuron Integrated Gradients. We compare Neuron\nIntegrated Gradients to DeepLIFT, a pre-existing computationally efficient\napproach that is applicable to calculating internal neuron importance. We find\nthat DeepLIFT produces strong empirical results and is faster to compute, but\nbecause it lacks the theoretical properties of Neuron Integrated Gradients, it\nmay not always be preferred in practice. Colab notebook reproducing results:\nhttp://bit.ly/neuronintegratedgradients\n",
        "published": "2018",
        "authors": [
            "Avanti Shrikumar",
            "Jocelin Su",
            "Anshul Kundaje"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.03305v2",
        "title": "BAR: Bayesian Activity Recognition using variational inference",
        "abstract": "  Uncertainty estimation in deep neural networks is essential for designing\nreliable and robust AI systems. Applications such as video surveillance for\nidentifying suspicious activities are designed with deep neural networks\n(DNNs), but DNNs do not provide uncertainty estimates. Capturing reliable\nuncertainty estimates in safety and security critical applications will help to\nestablish trust in the AI system. Our contribution is to apply Bayesian deep\nlearning framework to visual activity recognition application and quantify\nmodel uncertainty along with principled confidence. We utilize the stochastic\nvariational inference technique while training the Bayesian DNNs to infer the\napproximate posterior distribution around model parameters and perform Monte\nCarlo sampling on the posterior of model parameters to obtain the predictive\ndistribution. We show that the Bayesian inference applied to DNNs provide\nreliable confidence measures for visual activity recognition task as compared\nto conventional DNNs. We also show that our method improves the visual activity\nrecognition precision-recall AUC by 6.2% compared to non-Bayesian baseline. We\nevaluate our models on Moments-In-Time (MiT) activity recognition dataset by\nselecting a subset of in- and out-of-distribution video samples.\n",
        "published": "2018",
        "authors": [
            "Ranganath Krishnan",
            "Mahesh Subedar",
            "Omesh Tickoo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.03403v1",
        "title": "ExGate: Externally Controlled Gating for Feature-based Attention in\n  Artificial Neural Networks",
        "abstract": "  Perceptual capabilities of artificial systems have come a long way since the\nadvent of deep learning. These methods have proven to be effective, however\nthey are not as efficient as their biological counterparts. Visual attention is\na set of mechanisms that are employed in biological visual systems to ease\ncomputational load by only processing pertinent parts of the stimuli. This\npaper addresses the implementation of top-down, feature-based attention in an\nartificial neural network by use of externally controlled neuron gating. Our\nresults showed a 5% increase in classification accuracy on the CIFAR-10 dataset\nversus a non-gated version, while adding very few parameters. Our gated model\nalso produces more reasonable errors in predictions by drastically reducing\nprediction of classes that belong to a different category to the true class.\n",
        "published": "2018",
        "authors": [
            "Jarryd Son",
            "Amit Mishra"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1901.00109v4",
        "title": "Morphological Network: How Far Can We Go with Morphological Neurons?",
        "abstract": "  Morphological neurons, that is morphological operators such as dilation and\nerosion with learnable structuring elements, have intrigued researchers for\nquite some time because of the power these operators bring to the table despite\ntheir simplicity. These operators are known to be powerful nonlinear tools, but\nfor a given problem coming up with a sequence of operations and their\nstructuring element is a non-trivial task. So, the existing works have mainly\nfocused on this part of the problem without delving deep into their\napplicability as generic operators. A few works have tried to utilize\nmorphological neurons as a part of classification (and regression) networks\nwhen the input is a feature vector. However, these methods mainly focus on a\nspecific problem, without going into generic theoretical analysis. In this\nwork, we have theoretically analyzed morphological neurons and have shown that\nthese are far more powerful than previously anticipated. Our proposed\nmorphological block, containing dilation and erosion followed by their linear\ncombination, represents a sum of hinge functions. Existing works show that\nhinge functions perform quite well in classification and regression problems.\nTwo morphological blocks can even approximate any continuous function. However,\nto facilitate the theoretical analysis that we have done in this paper, we have\nrestricted ourselves to the 1D version of the operators, where the structuring\nelement operates on the whole input. Experimental evaluations also indicate the\neffectiveness of networks built with morphological neurons, over similarly\nstructured neural networks.\n",
        "published": "2019",
        "authors": [
            "Ranjan Mondal",
            "Sanchayan Santra",
            "Soumendu Sundar Mukherjee",
            "Bhabatosh Chanda"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1901.08296v1",
        "title": "Deep Learning on Attributed Graphs: A Journey from Graphs to Their\n  Embeddings and Back",
        "abstract": "  A graph is a powerful concept for representation of relations between pairs\nof entities. Data with underlying graph structure can be found across many\ndisciplines and there is a natural desire for understanding such data better.\nDeep learning (DL) has achieved significant breakthroughs in a variety of\nmachine learning tasks in recent years, especially where data is structured on\na grid, such as in text, speech, or image understanding. However, surprisingly\nlittle has been done to explore the applicability of DL on arbitrary\ngraph-structured data directly.\n  The goal of this thesis is to investigate architectures for DL on graphs and\nstudy how to transfer, adapt or generalize concepts that work well on\nsequential and image data to this domain. We concentrate on two important\nprimitives: embedding graphs or their nodes into a continuous vector space\nrepresentation (encoding) and, conversely, generating graphs from such vectors\nback (decoding). To that end, we make the following contributions.\n  First, we introduce Edge-Conditioned Convolutions (ECC), a convolution-like\noperation on graphs performed in the spatial domain where filters are\ndynamically generated based on edge attributes. The method is used to encode\ngraphs with arbitrary and varying structure.\n  Second, we propose SuperPoint Graph, an intermediate point cloud\nrepresentation with rich edge attributes encoding the contextual relationship\nbetween object parts. Based on this representation, ECC is employed to segment\nlarge-scale point clouds without major sacrifice in fine details.\n  Third, we present GraphVAE, a graph generator allowing us to decode graphs\nwith variable but upper-bounded number of nodes making use of approximate graph\nmatching for aligning the predictions of an autoencoder with its inputs. The\nmethod is applied to the task of molecule generation.\n",
        "published": "2019",
        "authors": [
            "Martin Simonovsky"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1901.10277v3",
        "title": "High-Quality Self-Supervised Deep Image Denoising",
        "abstract": "  We describe a novel method for training high-quality image denoising models\nbased on unorganized collections of corrupted images. The training does not\nneed access to clean reference images, or explicit pairs of corrupted images,\nand can thus be applied in situations where such data is unacceptably expensive\nor impossible to acquire. We build on a recent technique that removes the need\nfor reference data by employing networks with a \"blind spot\" in the receptive\nfield, and significantly improve two key aspects: image quality and training\nefficiency. Our result quality is on par with state-of-the-art neural network\ndenoisers in the case of i.i.d. additive Gaussian noise, and not far behind\nwith Poisson and impulse noise. We also successfully handle cases where\nparameters of the noise model are variable and/or unknown in both training and\nevaluation data.\n",
        "published": "2019",
        "authors": [
            "Samuli Laine",
            "Tero Karras",
            "Jaakko Lehtinen",
            "Timo Aila"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.03871v5",
        "title": "Learning V1 Simple Cells with Vector Representation of Local Content and\n  Matrix Representation of Local Motion",
        "abstract": "  This paper proposes a representational model for image pairs such as\nconsecutive video frames that are related by local pixel displacements, in the\nhope that the model may shed light on motion perception in primary visual\ncortex (V1). The model couples the following two components: (1) the vector\nrepresentations of local contents of images and (2) the matrix representations\nof local pixel displacements caused by the relative motions between the agent\nand the objects in the 3D scene. When the image frame undergoes changes due to\nlocal pixel displacements, the vectors are multiplied by the matrices that\nrepresent the local displacements. Thus the vector representation is\nequivariant as it varies according to the local displacements. Our experiments\nshow that our model can learn Gabor-like filter pairs of quadrature phases. The\nprofiles of the learned filters match those of simple cells in Macaque V1.\nMoreover, we demonstrate that the model can learn to infer local motions in\neither a supervised or unsupervised manner. With such a simple model, we\nachieve competitive results on optical flow estimation.\n",
        "published": "2019",
        "authors": [
            "Ruiqi Gao",
            "Jianwen Xie",
            "Siyuan Huang",
            "Yufan Ren",
            "Song-Chun Zhu",
            "Ying Nian Wu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.04615v3",
        "title": "Gauge Equivariant Convolutional Networks and the Icosahedral CNN",
        "abstract": "  The principle of equivariance to symmetry transformations enables a\ntheoretically grounded approach to neural network architecture design.\nEquivariant networks have shown excellent performance and data efficiency on\nvision and medical imaging problems that exhibit symmetries. Here we show how\nthis principle can be extended beyond global symmetries to local gauge\ntransformations. This enables the development of a very general class of\nconvolutional neural networks on manifolds that depend only on the intrinsic\ngeometry, and which includes many popular methods from equivariant and\ngeometric deep learning. We implement gauge equivariant CNNs for signals\ndefined on the surface of the icosahedron, which provides a reasonable\napproximation of the sphere. By choosing to work with this very regular\nmanifold, we are able to implement the gauge equivariant convolution using a\nsingle conv2d call, making it a highly scalable and practical alternative to\nSpherical CNNs. Using this method, we demonstrate substantial improvements over\nprevious methods on the task of segmenting omnidirectional images and global\nclimate patterns.\n",
        "published": "2019",
        "authors": [
            "Taco S. Cohen",
            "Maurice Weiler",
            "Berkay Kicanaoglu",
            "Max Welling"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.00370v2",
        "title": "Sub-Architecture Ensemble Pruning in Neural Architecture Search",
        "abstract": "  Neural architecture search (NAS) is gaining more and more attention in recent\nyears due to its flexibility and remarkable capability to reduce the burden of\nneural network design. To achieve better performance, however, the searching\nprocess usually costs massive computations that might not be affordable for\nresearchers and practitioners. While recent attempts have employed ensemble\nlearning methods to mitigate the enormous computational cost, however, they\nneglect a key property of ensemble methods, namely diversity, which leads to\ncollecting more similar sub-architectures with potential redundancy in the\nfinal design. To tackle this problem, we propose a pruning method for NAS\nensembles called \"Sub-Architecture Ensemble Pruning in Neural Architecture\nSearch (SAEP).\" It targets to leverage diversity and to achieve sub-ensemble\narchitectures at a smaller size with comparable performance to ensemble\narchitectures that are not pruned. Three possible solutions are proposed to\ndecide which sub-architectures to prune during the searching process.\nExperimental results exhibit the effectiveness of the proposed method by\nlargely reducing the number of sub-architectures without degrading the\nperformance.\n",
        "published": "2019",
        "authors": [
            "Yijun Bian",
            "Qingquan Song",
            "Mengnan Du",
            "Jun Yao",
            "Huanhuan Chen",
            "Xia Hu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.05448v1",
        "title": "Neural Memory Plasticity for Anomaly Detection",
        "abstract": "  In the domain of machine learning, Neural Memory Networks (NMNs) have\nrecently achieved impressive results in a variety of application areas\nincluding visual question answering, trajectory prediction, object tracking,\nand language modelling. However, we observe that the attention based knowledge\nretrieval mechanisms used in current NMNs restricts them from achieving their\nfull potential as the attention process retrieves information based on a set of\nstatic connection weights. This is suboptimal in a setting where there are vast\ndifferences among samples in the data domain; such as anomaly detection where\nthere is no consistent criteria for what constitutes an anomaly. In this paper,\nwe propose a plastic neural memory access mechanism which exploits both static\nand dynamic connection weights in the memory read, write and output generation\nprocedures. We demonstrate the effectiveness and flexibility of the proposed\nmemory model in three challenging anomaly detection tasks in the medical\ndomain: abnormal EEG identification, MRI tumour type classification and\nschizophrenia risk detection in children. In all settings, the proposed\napproach outperforms the current state-of-the-art. Furthermore, we perform an\nin-depth analysis demonstrating the utility of neural plasticity for the\nknowledge retrieval process and provide evidence on how the proposed memory\nmodel generates sparse yet informative memory outputs.\n",
        "published": "2019",
        "authors": [
            "Tharindu Fernando",
            "Simon Denman",
            "David Ahmedt-Aristizabal",
            "Sridha Sridharan",
            "Kristin Laurens",
            "Patrick Johnston",
            "Clinton Fookes"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.12827v5",
        "title": "Entity Abstraction in Visual Model-Based Reinforcement Learning",
        "abstract": "  This paper tests the hypothesis that modeling a scene in terms of entities\nand their local interactions, as opposed to modeling the scene globally,\nprovides a significant benefit in generalizing to physical tasks in a\ncombinatorial space the learner has not encountered before. We present\nobject-centric perception, prediction, and planning (OP3), which to the best of\nour knowledge is the first fully probabilistic entity-centric dynamic latent\nvariable framework for model-based reinforcement learning that acquires entity\nrepresentations from raw visual observations without supervision and uses them\nto predict and plan. OP3 enforces entity-abstraction -- symmetric processing of\neach entity representation with the same locally-scoped function -- which\nenables it to scale to model different numbers and configurations of objects\nfrom those in training. Our approach to solving the key technical challenge of\ngrounding these entity representations to actual objects in the environment is\nto frame this variable binding problem as an inference problem, and we develop\nan interactive inference algorithm that uses temporal continuity and\ninteractive feedback to bind information about object properties to the entity\nvariables. On block-stacking tasks, OP3 generalizes to novel block\nconfigurations and more objects than observed during training, outperforming an\noracle model that assumes access to object supervision and achieving two to\nthree times better accuracy than a state-of-the-art video prediction model that\ndoes not exhibit entity abstraction.\n",
        "published": "2019",
        "authors": [
            "Rishi Veerapaneni",
            "John D. Co-Reyes",
            "Michael Chang",
            "Michael Janner",
            "Chelsea Finn",
            "Jiajun Wu",
            "Joshua B. Tenenbaum",
            "Sergey Levine"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.14594v2",
        "title": "Deep Learning for 2D and 3D Rotatable Data: An Overview of Methods",
        "abstract": "  Convolutional networks are successful due to their equivariance/invariance\nunder translations. However, rotatable data such as images, volumes, shapes, or\npoint clouds require processing with equivariance/invariance under rotations in\ncases where the rotational orientation of the coordinate system does not affect\nthe meaning of the data (e.g. object classification). On the other hand,\nestimation/processing of rotations is necessary in cases where rotations are\nimportant (e.g. motion estimation). There has been recent progress in methods\nand theory in all these regards. Here we provide an overview of existing\nmethods, both for 2D and 3D rotations (and translations), and identify\ncommonalities and links between them.\n",
        "published": "2019",
        "authors": [
            "Luca Della Libera",
            "Vladimir Golkov",
            "Yue Zhu",
            "Arman Mielke",
            "Daniel Cremers"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.01181v2",
        "title": "GraphChallenge.org Sparse Deep Neural Network Performance",
        "abstract": "  The MIT/IEEE/Amazon GraphChallenge.org encourages community approaches to\ndeveloping new solutions for analyzing graphs and sparse data. Sparse AI\nanalytics present unique scalability difficulties. The Sparse Deep Neural\nNetwork (DNN) Challenge draws upon prior challenges from machine learning, high\nperformance computing, and visual analytics to create a challenge that is\nreflective of emerging sparse AI systems. The sparse DNN challenge is based on\na mathematically well-defined DNN inference computation and can be implemented\nin any programming environment. In 2019 several sparse DNN challenge\nsubmissions were received from a wide range of authors and organizations. This\npaper presents a performance analysis of the best performers of these\nsubmissions. These submissions show that their state-of-the-art sparse DNN\nexecution time, $T_{\\rm DNN}$, is a strong function of the number of DNN\noperations performed, $N_{\\rm op}$. The sparse DNN challenge provides a clear\npicture of current sparse DNN systems and underscores the need for new\ninnovations to achieve high performance on very large sparse DNNs.\n",
        "published": "2020",
        "authors": [
            "Jeremy Kepner",
            "Simon Alford",
            "Vijay Gadepally",
            "Michael Jones",
            "Lauren Milechin",
            "Albert Reuther",
            "Ryan Robinett",
            "Sid Samsi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.02755v1",
        "title": "Detection and skeletonization of single neurons and tracer injections\n  using topological methods",
        "abstract": "  Neuroscientific data analysis has traditionally relied on linear algebra and\nstochastic process theory. However, the tree-like shapes of neurons cannot be\ndescribed easily as points in a vector space (the subtraction of two neuronal\nshapes is not a meaningful operation), and methods from computational topology\nare better suited to their analysis. Here we introduce methods from Discrete\nMorse (DM) Theory to extract the tree-skeletons of individual neurons from\nvolumetric brain image data, and to summarize collections of neurons labelled\nby tracer injections. Since individual neurons are topologically trees, it is\nsensible to summarize the collection of neurons using a consensus tree-shape\nthat provides a richer information summary than the traditional regional\n'connectivity matrix' approach. The conceptually elegant DM approach lacks\nhand-tuned parameters and captures global properties of the data as opposed to\nprevious approaches which are inherently local. For individual skeletonization\nof sparsely labelled neurons we obtain substantial performance gains over\nstate-of-the-art non-topological methods (over 10% improvements in precision\nand faster proofreading). The consensus-tree summary of tracer injections\nincorporates the regional connectivity matrix information, but in addition\ncaptures the collective collateral branching patterns of the set of neurons\nconnected to the injection site, and provides a bridge between single-neuron\nmorphology and tracer-injection data.\n",
        "published": "2020",
        "authors": [
            "Dingkang Wang",
            "Lucas Magee",
            "Bing-Xing Huo",
            "Samik Banerjee",
            "Xu Li",
            "Jaikishan Jayakumar",
            "Meng Kuan Lin",
            "Keerthi Ram",
            "Suyi Wang",
            "Yusu Wang",
            "Partha P. Mitra"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.02967v5",
        "title": "Evolving Normalization-Activation Layers",
        "abstract": "  Normalization layers and activation functions are fundamental components in\ndeep networks and typically co-locate with each other. Here we propose to\ndesign them using an automated approach. Instead of designing them separately,\nwe unify them into a single tensor-to-tensor computation graph, and evolve its\nstructure starting from basic mathematical functions. Examples of such\nmathematical functions are addition, multiplication and statistical moments.\nThe use of low-level mathematical functions, in contrast to the use of\nhigh-level modules in mainstream NAS, leads to a highly sparse and large search\nspace which can be challenging for search methods. To address the challenge, we\ndevelop efficient rejection protocols to quickly filter out candidate layers\nthat do not work well. We also use multi-objective evolution to optimize each\nlayer's performance across many architectures to prevent overfitting. Our\nmethod leads to the discovery of EvoNorms, a set of new\nnormalization-activation layers with novel, and sometimes surprising structures\nthat go beyond existing design patterns. For example, some EvoNorms do not\nassume that normalization and activation functions must be applied\nsequentially, nor need to center the feature maps, nor require explicit\nactivation functions. Our experiments show that EvoNorms work well on image\nclassification models including ResNets, MobileNets and EfficientNets but also\ntransfer well to Mask R-CNN with FPN/SpineNet for instance segmentation and to\nBigGAN for image synthesis, outperforming BatchNorm and GroupNorm based layers\nin many cases.\n",
        "published": "2020",
        "authors": [
            "Hanxiao Liu",
            "Andrew Brock",
            "Karen Simonyan",
            "Quoc V. Le"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.04249v2",
        "title": "GeneCAI: Genetic Evolution for Acquiring Compact AI",
        "abstract": "  In the contemporary big data realm, Deep Neural Networks (DNNs) are evolving\ntowards more complex architectures to achieve higher inference accuracy. Model\ncompression techniques can be leveraged to efficiently deploy such\ncompute-intensive architectures on resource-limited mobile devices. Such\nmethods comprise various hyper-parameters that require per-layer customization\nto ensure high accuracy. Choosing such hyper-parameters is cumbersome as the\npertinent search space grows exponentially with model layers. This paper\nintroduces GeneCAI, a novel optimization method that automatically learns how\nto tune per-layer compression hyper-parameters. We devise a bijective\ntranslation scheme that encodes compressed DNNs to the genotype space. The\noptimality of each genotype is measured using a multi-objective score based on\naccuracy and number of floating point operations. We develop customized genetic\noperations to iteratively evolve the non-dominated solutions towards the\noptimal Pareto front, thus, capturing the optimal trade-off between model\naccuracy and complexity. GeneCAI optimization method is highly scalable and can\nachieve a near-linear performance boost on distributed multi-GPU platforms. Our\nextensive evaluations demonstrate that GeneCAI outperforms existing rule-based\nand reinforcement learning methods in DNN compression by finding models that\nlie on a better accuracy-complexity Pareto curve.\n",
        "published": "2020",
        "authors": [
            "Mojan Javaheripi",
            "Mohammad Samragh",
            "Tara Javidi",
            "Farinaz Koushanfar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.11545v1",
        "title": "Dropout as an Implicit Gating Mechanism For Continual Learning",
        "abstract": "  In recent years, neural networks have demonstrated an outstanding ability to\nachieve complex learning tasks across various domains. However, they suffer\nfrom the \"catastrophic forgetting\" problem when they face a sequence of\nlearning tasks, where they forget the old ones as they learn new tasks. This\nproblem is also highly related to the \"stability-plasticity dilemma\". The more\nplastic the network, the easier it can learn new tasks, but the faster it also\nforgets previous ones. Conversely, a stable network cannot learn new tasks as\nfast as a very plastic network. However, it is more reliable to preserve the\nknowledge it has learned from the previous tasks. Several solutions have been\nproposed to overcome the forgetting problem by making the neural network\nparameters more stable, and some of them have mentioned the significance of\ndropout in continual learning. However, their relationship has not been\nsufficiently studied yet. In this paper, we investigate this relationship and\nshow that a stable network with dropout learns a gating mechanism such that for\ndifferent tasks, different paths of the network are active. Our experiments\nshow that the stability achieved by this implicit gating plays a very critical\nrole in leading to performance comparable to or better than other involved\ncontinual learning algorithms to overcome catastrophic forgetting.\n",
        "published": "2020",
        "authors": [
            "Seyed-Iman Mirzadeh",
            "Mehrdad Farajtabar",
            "Hassan Ghasemzadeh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1511.01865v3",
        "title": "Convolutional Neural Network for Stereotypical Motor Movement Detection\n  in Autism",
        "abstract": "  Autism Spectrum Disorders (ASDs) are often associated with specific atypical\npostural or motor behaviors, of which Stereotypical Motor Movements (SMMs) have\na specific visibility. While the identification and the quantification of SMM\npatterns remain complex, its automation would provide support to accurate\ntuning of the intervention in the therapy of autism. Therefore, it is essential\nto develop automatic SMM detection systems in a real world setting, taking care\nof strong inter-subject and intra-subject variability. Wireless accelerometer\nsensing technology can provide a valid infrastructure for real-time SMM\ndetection, however such variability remains a problem also for machine learning\nmethods, in particular whenever handcrafted features extracted from\naccelerometer signal are considered. Here, we propose to employ the deep\nlearning paradigm in order to learn discriminating features from multi-sensor\naccelerometer signals. Our results provide preliminary evidence that feature\nlearning and transfer learning embedded in the deep architecture achieve higher\naccurate SMM detectors in longitudinal scenarios.\n",
        "published": "2015",
        "authors": [
            "Nastaran Mohammadian Rad",
            "Andrea Bizzego",
            "Seyed Mostafa Kia",
            "Giuseppe Jurman",
            "Paola Venuti",
            "Cesare Furlanello"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1511.07125v1",
        "title": "What Happened to My Dog in That Network: Unraveling Top-down Generators\n  in Convolutional Neural Networks",
        "abstract": "  Top-down information plays a central role in human perception, but plays\nrelatively little role in many current state-of-the-art deep networks, such as\nConvolutional Neural Networks (CNNs). This work seeks to explore a path by\nwhich top-down information can have a direct impact within current deep\nnetworks. We explore this path by learning and using \"generators\" corresponding\nto the network internal effects of three types of transformation (each a\nrestriction of a general affine transformation): rotation, scaling, and\ntranslation. We demonstrate how these learned generators can be used to\ntransfer top-down information to novel settings, as mediated by the \"feature\nflows\" that the transformations (and the associated generators) correspond to\ninside the network. Specifically, we explore three aspects: 1) using generators\nas part of a method for synthesizing transformed images --- given a previously\nunseen image, produce versions of that image corresponding to one or more\nspecified transformations, 2) \"zero-shot learning\" --- when provided with a\nfeature flow corresponding to the effect of a transformation of unknown amount,\nleverage learned generators as part of a method by which to perform an accurate\ncategorization of the amount of transformation, even for amounts never observed\nduring training, and 3) (inside-CNN) \"data augmentation\" --- improve the\nclassification performance of an existing network by using the learned\ngenerators to directly provide additional training \"inside the CNN\".\n",
        "published": "2015",
        "authors": [
            "Patrick W. Gallagher",
            "Shuai Tang",
            "Zhuowen Tu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1709.08524v1",
        "title": "Generative learning for deep networks",
        "abstract": "  Learning, taking into account full distribution of the data, referred to as\ngenerative, is not feasible with deep neural networks (DNNs) because they model\nonly the conditional distribution of the outputs given the inputs. Current\nsolutions are either based on joint probability models facing difficult\nestimation problems or learn two separate networks, mapping inputs to outputs\n(recognition) and vice-versa (generation). We propose an intermediate approach.\nFirst, we show that forward computation in DNNs with logistic sigmoid\nactivations corresponds to a simplified approximate Bayesian inference in a\ndirected probabilistic multi-layer model. This connection allows to interpret\nDNN as a probabilistic model of the output and all hidden units given the\ninput. Second, we propose that in order for the recognition and generation\nnetworks to be more consistent with the joint model of the data, weights of the\nrecognition and generator network should be related by transposition. We\ndemonstrate in a tentative experiment that such a coupled pair can be learned\ngeneratively, modelling the full distribution of the data, and has enough\ncapacity to perform well in both recognition and generation.\n",
        "published": "2017",
        "authors": [
            "Boris Flach",
            "Alexander Shekhovtsov",
            "Ondrej Fikar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.00262v1",
        "title": "Dissecting Pruned Neural Networks",
        "abstract": "  Pruning is a standard technique for removing unnecessary structure from a\nneural network to reduce its storage footprint, computational demands, or\nenergy consumption. Pruning can reduce the parameter-counts of many\nstate-of-the-art neural networks by an order of magnitude without compromising\naccuracy, meaning these networks contain a vast amount of unnecessary\nstructure. In this paper, we study the relationship between pruning and\ninterpretability. Namely, we consider the effect of removing unnecessary\nstructure on the number of hidden units that learn disentangled representations\nof human-recognizable concepts as identified by network dissection. We aim to\nevaluate how the interpretability of pruned neural networks changes as they are\ncompressed. We find that pruning has no detrimental effect on this measure of\ninterpretability until so few parameters remain that accuracy beings to drop.\nResnet-50 models trained on ImageNet maintain the same number of interpretable\nconcepts and units until more than 90% of parameters have been pruned.\n",
        "published": "2019",
        "authors": [
            "Jonathan Frankle",
            "David Bau"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.03799v3",
        "title": "Rehearsal-Free Continual Learning over Small Non-I.I.D. Batches",
        "abstract": "  Robotic vision is a field where continual learning can play a significant\nrole. An embodied agent operating in a complex environment subject to frequent\nand unpredictable changes is required to learn and adapt continuously. In the\ncontext of object recognition, for example, a robot should be able to learn\n(without forgetting) objects of never before seen classes as well as improving\nits recognition capabilities as new instances of already known classes are\ndiscovered. Ideally, continual learning should be triggered by the availability\nof short videos of single objects and performed on-line on on-board hardware\nwith fine-grained updates. In this paper, we introduce a novel continual\nlearning protocol based on the CORe50 benchmark and propose two rehearsal-free\ncontinual learning techniques, CWR* and AR1*, that can learn effectively even\nin the challenging case of nearly 400 small non-i.i.d. incremental batches. In\nparticular, our experiments show that AR1* can outperform other\nstate-of-the-art rehearsal-free techniques by more than 15% accuracy in some\ncases, with a very light and constant computational and memory overhead across\ntraining batches.\n",
        "published": "2019",
        "authors": [
            "Vincenzo Lomonaco",
            "Davide Maltoni",
            "Lorenzo Pellegrini"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.06916v2",
        "title": "Single-bit-per-weight deep convolutional neural networks without\n  batch-normalization layers for embedded systems",
        "abstract": "  Batch-normalization (BN) layers are thought to be an integrally important\nlayer type in today's state-of-the-art deep convolutional neural networks for\ncomputer vision tasks such as classification and detection. However, BN layers\nintroduce complexity and computational overheads that are highly undesirable\nfor training and/or inference on low-power custom hardware implementations of\nreal-time embedded vision systems such as UAVs, robots and Internet of Things\n(IoT) devices. They are also problematic when batch sizes need to be very small\nduring training, and innovations such as residual connections introduced more\nrecently than BN layers could potentially have lessened their impact. In this\npaper we aim to quantify the benefits BN layers offer in image classification\nnetworks, in comparison with alternative choices. In particular, we study\nnetworks that use shifted-ReLU layers instead of BN layers. We found, following\nexperiments with wide residual networks applied to the ImageNet, CIFAR 10 and\nCIFAR 100 image classification datasets, that BN layers do not consistently\noffer a significant advantage. We found that the accuracy margin offered by BN\nlayers depends on the data set, the network size, and the bit-depth of weights.\nWe conclude that in situations where BN layers are undesirable due to speed,\nmemory or complexity costs, that using shifted-ReLU layers instead should be\nconsidered; we found they can offer advantages in all these areas, and often do\nnot impose a significant accuracy cost.\n",
        "published": "2019",
        "authors": [
            "Mark D. McDonnell",
            "Hesham Mostafa",
            "Runchun Wang",
            "Andre van Schaik"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.07640v5",
        "title": "Robustness properties of Facebook's ResNeXt WSL models",
        "abstract": "  We investigate the robustness properties of ResNeXt class image recognition\nmodels trained with billion scale weakly supervised data (ResNeXt WSL models).\nThese models, recently made public by Facebook AI, were trained with ~1B images\nfrom Instagram and fine-tuned on ImageNet. We show that these models display an\nunprecedented degree of robustness against common image corruptions and\nperturbations, as measured by the ImageNet-C and ImageNet-P benchmarks. They\nalso achieve substantially improved accuracies on the recently introduced\n\"natural adversarial examples\" benchmark (ImageNet-A). The largest of the\nreleased models, in particular, achieves state-of-the-art results on\nImageNet-C, ImageNet-P, and ImageNet-A by a large margin. The gains on\nImageNet-C, ImageNet-P, and ImageNet-A far outpace the gains on ImageNet\nvalidation accuracy, suggesting the former as more useful benchmarks to measure\nfurther progress in image recognition. Remarkably, the ResNeXt WSL models even\nachieve a limited degree of adversarial robustness against state-of-the-art\nwhite-box attacks (10-step PGD attacks). However, in contrast to adversarially\ntrained models, the robustness of the ResNeXt WSL models rapidly declines with\nthe number of PGD steps, suggesting that these models do not achieve genuine\nadversarial robustness. Visualization of the learned features also confirms\nthis conclusion. Finally, we show that although the ResNeXt WSL models are more\nshape-biased than comparable ImageNet-trained models in a shape-texture cue\nconflict experiment, they still remain much more texture-biased than humans,\nsuggesting that they share some of the underlying characteristics of\nImageNet-trained models that make this benchmark challenging.\n",
        "published": "2019",
        "authors": [
            "A. Emin Orhan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.08307v1",
        "title": "XferNAS: Transfer Neural Architecture Search",
        "abstract": "  The term Neural Architecture Search (NAS) refers to the automatic\noptimization of network architectures for a new, previously unknown task. Since\ntesting an architecture is computationally very expensive, many optimizers need\ndays or even weeks to find suitable architectures. However, this search time\ncan be significantly reduced if knowledge from previous searches on different\ntasks is reused. In this work, we propose a generally applicable framework that\nintroduces only minor changes to existing optimizers to leverage this feature.\nAs an example, we select an existing optimizer and demonstrate the complexity\nof the integration of the framework as well as its impact. In experiments on\nCIFAR-10 and CIFAR-100, we observe a reduction in the search time from 200 to\nonly 6 GPU days, a speed up by a factor of 33. In addition, we observe new\nrecords of 1.99 and 14.06 for NAS optimizers on the CIFAR benchmarks,\nrespectively. In a separate study, we analyze the impact of the amount of\nsource and target data. Empirically, we demonstrate that the proposed framework\ngenerally gives better results and, in the worst case, is just as good as the\nunmodified optimizer.\n",
        "published": "2019",
        "authors": [
            "Martin Wistuba"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.12920v2",
        "title": "Tracking Holistic Object Representations",
        "abstract": "  Recent advances in visual tracking are based on siamese feature extractors\nand template matching. For this category of trackers, latest research focuses\non better feature embeddings and similarity measures. In this work, we focus on\nbuilding holistic object representations for tracking. We propose a framework\nthat is designed to be used on top of previous trackers without any need for\nfurther training of the siamese network. The framework leverages the idea of\nobtaining additional object templates during the tracking process. Since the\nnumber of stored templates is limited, our method only keeps the most diverse\nones. We achieve this by providing a new diversity measure in the space of\nsiamese features. The obtained representation contains information beyond the\nground truth object location provided to the system. It is then useful for\ntracking itself but also for further tasks which require a visual understanding\nof objects. Strong empirical results on tracking benchmarks indicate that our\nmethod can improve the performance and robustness of the underlying trackers\nwhile barely reducing their speed. In addition, our method is able to match\ncurrent state-of-the-art results, while using a simpler and older network\narchitecture and running three times faster.\n",
        "published": "2019",
        "authors": [
            "Axel Sauer",
            "Elie Aljalbout",
            "Sami Haddadin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1908.01314v4",
        "title": "MoGA: Searching Beyond MobileNetV3",
        "abstract": "  The evolution of MobileNets has laid a solid foundation for neural network\napplications on mobile end. With the latest MobileNetV3, neural architecture\nsearch again claimed its supremacy in network design. Unfortunately, till today\nall mobile methods mainly focus on CPU latencies instead of GPU, the latter,\nhowever, is much preferred in practice for it has faster speed, lower overhead\nand less interference. Bearing the target hardware in mind, we propose the\nfirst Mobile GPU-Aware (MoGA) neural architecture search in order to be\nprecisely tailored for real-world applications. Further, the ultimate objective\nto devise a mobile network lies in achieving better performance by maximizing\nthe utilization of bounded resources. Urging higher capability while\nrestraining time consumption is not reconcilable. We alleviate the tension by\nweighted evolution techniques. Moreover, we encourage increasing the number of\nparameters for higher representational power. With 200x fewer GPU days than\nMnasNet, we obtain a series of models that outperform MobileNetV3 under the\nsimilar latency constraints, i.e., MoGA-A achieves 75.9% top-1 accuracy on\nImageNet, MoGA-B meets 75.5% which costs only 0.5 ms more on mobile GPU. MoGA-C\nbest attests GPU-awareness by reaching 75.3% and being slower on CPU but faster\non GPU.The models and test code is made available here\nhttps://github.com/xiaomi-automl/MoGA.\n",
        "published": "2019",
        "authors": [
            "Xiangxiang Chu",
            "Bo Zhang",
            "Ruijun Xu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1908.08681v3",
        "title": "Mish: A Self Regularized Non-Monotonic Activation Function",
        "abstract": "  We propose $\\textit{Mish}$, a novel self-regularized non-monotonic activation\nfunction which can be mathematically defined as: $f(x)=x\\tanh(softplus(x))$. As\nactivation functions play a crucial role in the performance and training\ndynamics in neural networks, we validated experimentally on several well-known\nbenchmarks against the best combinations of architectures and activation\nfunctions. We also observe that data augmentation techniques have a favorable\neffect on benchmarks like ImageNet-1k and MS-COCO across multiple\narchitectures. For example, Mish outperformed Leaky ReLU on YOLOv4 with a\nCSP-DarkNet-53 backbone on average precision ($AP_{50}^{val}$) by 2.1$\\%$ in\nMS-COCO object detection and ReLU on ResNet-50 on ImageNet-1k in Top-1 accuracy\nby $\\approx$1$\\%$ while keeping all other network parameters and\nhyperparameters constant. Furthermore, we explore the mathematical formulation\nof Mish in relation with the Swish family of functions and propose an intuitive\nunderstanding on how the first derivative behavior may be acting as a\nregularizer helping the optimization of deep neural networks. Code is publicly\navailable at https://github.com/digantamisra98/Mish.\n",
        "published": "2019",
        "authors": [
            "Diganta Misra"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1301.4083v6",
        "title": "Knowledge Matters: Importance of Prior Information for Optimization",
        "abstract": "  We explore the effect of introducing prior information into the intermediate\nlevel of neural networks for a learning task on which all the state-of-the-art\nmachine learning algorithms tested failed to learn. We motivate our work from\nthe hypothesis that humans learn such intermediate concepts from other\nindividuals via a form of supervision or guidance using a curriculum. The\nexperiments we have conducted provide positive evidence in favor of this\nhypothesis. In our experiments, a two-tiered MLP architecture is trained on a\ndataset with 64x64 binary inputs images, each image with three sprites. The\nfinal task is to decide whether all the sprites are the same or one of them is\ndifferent. Sprites are pentomino tetris shapes and they are placed in an image\nwith different locations using scaling and rotation transformations. The first\npart of the two-tiered MLP is pre-trained with intermediate-level targets being\nthe presence of sprites at each location, while the second part takes the\noutput of the first part as input and predicts the final task's target binary\nevent. The two-tiered MLP architecture, with a few tens of thousand examples,\nwas able to learn the task perfectly, whereas all other algorithms (include\nunsupervised pre-training, but also traditional algorithms like SVMs, decision\ntrees and boosting) all perform no better than chance. We hypothesize that the\noptimization difficulty involved when the intermediate pre-training is not\nperformed is due to the {\\em composition} of two highly non-linear tasks. Our\nfindings are also consistent with hypotheses on cultural learning inspired by\nthe observations of optimization problems with deep learning, presumably\nbecause of effective local minima.\n",
        "published": "2013",
        "authors": [
            "\u00c7a\u011flar G\u00fcl\u00e7ehre",
            "Yoshua Bengio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1504.00641v1",
        "title": "A Probabilistic Theory of Deep Learning",
        "abstract": "  A grand challenge in machine learning is the development of computational\nalgorithms that match or outperform humans in perceptual inference tasks that\nare complicated by nuisance variation. For instance, visual object recognition\ninvolves the unknown object position, orientation, and scale in object\nrecognition while speech recognition involves the unknown voice pronunciation,\npitch, and speed. Recently, a new breed of deep learning algorithms have\nemerged for high-nuisance inference tasks that routinely yield pattern\nrecognition systems with near- or super-human capabilities. But a fundamental\nquestion remains: Why do they work? Intuitions abound, but a coherent framework\nfor understanding, analyzing, and synthesizing deep learning architectures has\nremained elusive. We answer this question by developing a new probabilistic\nframework for deep learning based on the Deep Rendering Model: a generative\nprobabilistic model that explicitly captures latent nuisance variation. By\nrelaxing the generative model to a discriminative one, we can recover two of\nthe current leading deep learning systems, deep convolutional neural networks\nand random decision forests, providing insights into their successes and\nshortcomings, as well as a principled route to their improvement.\n",
        "published": "2015",
        "authors": [
            "Ankit B. Patel",
            "Tan Nguyen",
            "Richard G. Baraniuk"
        ]
    }
]