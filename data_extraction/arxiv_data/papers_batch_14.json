[
    {
        "id": "http://arxiv.org/abs/2311.02314v1",
        "title": "Thermal Face Image Classification using Deep Learning Techniques",
        "abstract": "  Thermal images have various applications in security, medical and industrial\ndomains. This paper proposes a practical deep-learning approach for thermal\nimage classification. Accurate and efficient classification of thermal images\nposes a significant challenge across various fields due to the complex image\ncontent and the scarcity of annotated datasets. This work uses a convolutional\nneural network (CNN) architecture, specifically ResNet-50 and VGGNet-19, to\nextract features from thermal images. This work also applied Kalman filter on\nthermal input images for image denoising. The experimental results demonstrate\nthe effectiveness of the proposed approach in terms of accuracy and efficiency.\n",
        "published": "2023",
        "authors": [
            "Prosenjit Chatterjee",
            "ANK Zaman"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1103.4487v1",
        "title": "Handwritten Digit Recognition with a Committee of Deep Neural Nets on\n  GPUs",
        "abstract": "  The competitive MNIST handwritten digit recognition benchmark has a long\nhistory of broken records since 1998. The most recent substantial improvement\nby others dates back 7 years (error rate 0.4%) . Recently we were able to\nsignificantly improve this result, using graphics cards to greatly speed up\ntraining of simple but deep MLPs, which achieved 0.35%, outperforming all the\nprevious more complex methods. Here we report another substantial improvement:\n0.31% obtained using a committee of MLPs.\n",
        "published": "2011",
        "authors": [
            "Dan C. Cire\u015fan",
            "Ueli Meier",
            "Luca M. Gambardella",
            "J\u00fcrgen Schmidhuber"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1110.0214v1",
        "title": "Eclectic Extraction of Propositional Rules from Neural Networks",
        "abstract": "  Artificial Neural Network is among the most popular algorithm for supervised\nlearning. However, Neural Networks have a well-known drawback of being a \"Black\nBox\" learner that is not comprehensible to the Users. This lack of transparency\nmakes it unsuitable for many high risk tasks such as medical diagnosis that\nrequires a rational justification for making a decision. Rule Extraction\nmethods attempt to curb this limitation by extracting comprehensible rules from\na trained Network. Many such extraction algorithms have been developed over the\nyears with their respective strengths and weaknesses. They have been broadly\ncategorized into three types based on their approach to use internal model of\nthe Network. Eclectic Methods are hybrid algorithms that combine the other\napproaches to attain more performance. In this paper, we present an Eclectic\nmethod called HERETIC. Our algorithm uses Inductive Decision Tree learning\ncombined with information of the neural network structure for extracting\nlogical rules. Experiments and theoretical analysis show HERETIC to be better\nin terms of speed and performance.\n",
        "published": "2011",
        "authors": [
            "Ridwan Al Iqbal"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1510.04609v1",
        "title": "Layer-Specific Adaptive Learning Rates for Deep Networks",
        "abstract": "  The increasing complexity of deep learning architectures is resulting in\ntraining time requiring weeks or even months. This slow training is due in part\nto vanishing gradients, in which the gradients used by back-propagation are\nextremely large for weights connecting deep layers (layers near the output\nlayer), and extremely small for shallow layers (near the input layer); this\nresults in slow learning in the shallow layers. Additionally, it has also been\nshown that in highly non-convex problems, such as deep neural networks, there\nis a proliferation of high-error low curvature saddle points, which slows down\nlearning dramatically. In this paper, we attempt to overcome the two above\nproblems by proposing an optimization method for training deep neural networks\nwhich uses learning rates which are both specific to each layer in the network\nand adaptive to the curvature of the function, increasing the learning rate at\nlow curvature points. This enables us to speed up learning in the shallow\nlayers of the network and quickly escape high-error low curvature saddle\npoints. We test our method on standard image classification datasets such as\nMNIST, CIFAR10 and ImageNet, and demonstrate that our method increases accuracy\nas well as reduces the required training time over standard algorithms.\n",
        "published": "2015",
        "authors": [
            "Bharat Singh",
            "Soham De",
            "Yangmuzi Zhang",
            "Thomas Goldstein",
            "Gavin Taylor"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1605.05359v3",
        "title": "Option Discovery in Hierarchical Reinforcement Learning using\n  Spatio-Temporal Clustering",
        "abstract": "  This paper introduces an automated skill acquisition framework in\nreinforcement learning which involves identifying a hierarchical description of\nthe given task in terms of abstract states and extended actions between\nabstract states. Identifying such structures present in the task provides ways\nto simplify and speed up reinforcement learning algorithms. These structures\nalso help to generalize such algorithms over multiple tasks without relearning\npolicies from scratch. We use ideas from dynamical systems to find metastable\nregions in the state space and associate them with abstract states. The\nspectral clustering algorithm PCCA+ is used to identify suitable abstractions\naligned to the underlying structure. Skills are defined in terms of the\nsequence of actions that lead to transitions between such abstract states. The\nconnectivity information from PCCA+ is used to generate these skills or\noptions. These skills are independent of the learning task and can be\nefficiently reused across a variety of tasks defined over the same model. This\napproach works well even without the exact model of the environment by using\nsample trajectories to construct an approximate estimate. We also present our\napproach to scaling the skill acquisition framework to complex tasks with large\nstate spaces for which we perform state aggregation using the representation\nlearned from an action conditional video prediction network and use the skill\nacquisition framework on the aggregated state space.\n",
        "published": "2016",
        "authors": [
            "Aravind Srinivas",
            "Ramnandan Krishnamurthy",
            "Peeyush Kumar",
            "Balaraman Ravindran"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1605.06431v2",
        "title": "Residual Networks Behave Like Ensembles of Relatively Shallow Networks",
        "abstract": "  In this work we propose a novel interpretation of residual networks showing\nthat they can be seen as a collection of many paths of differing length.\nMoreover, residual networks seem to enable very deep networks by leveraging\nonly the short paths during training. To support this observation, we rewrite\nresidual networks as an explicit collection of paths. Unlike traditional\nmodels, paths through residual networks vary in length. Further, a lesion study\nreveals that these paths show ensemble-like behavior in the sense that they do\nnot strongly depend on each other. Finally, and most surprising, most paths are\nshorter than one might expect, and only the short paths are needed during\ntraining, as longer paths do not contribute any gradient. For example, most of\nthe gradient in a residual network with 110 layers comes from paths that are\nonly 10-34 layers deep. Our results reveal one of the key characteristics that\nseem to enable the training of very deep networks: Residual networks avoid the\nvanishing gradient problem by introducing short paths which can carry gradient\nthroughout the extent of very deep networks.\n",
        "published": "2016",
        "authors": [
            "Andreas Veit",
            "Michael Wilber",
            "Serge Belongie"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1605.09304v5",
        "title": "Synthesizing the preferred inputs for neurons in neural networks via\n  deep generator networks",
        "abstract": "  Deep neural networks (DNNs) have demonstrated state-of-the-art results on\nmany pattern recognition tasks, especially vision classification problems.\nUnderstanding the inner workings of such computational brains is both\nfascinating basic science that is interesting in its own right - similar to why\nwe study the human brain - and will enable researchers to further improve DNNs.\nOne path to understanding how a neural network functions internally is to study\nwhat each of its neurons has learned to detect. One such method is called\nactivation maximization (AM), which synthesizes an input (e.g. an image) that\nhighly activates a neuron. Here we dramatically improve the qualitative state\nof the art of activation maximization by harnessing a powerful, learned prior:\na deep generator network (DGN). The algorithm (1) generates qualitatively\nstate-of-the-art synthetic images that look almost real, (2) reveals the\nfeatures learned by each neuron in an interpretable way, (3) generalizes well\nto new datasets and somewhat well to different network architectures without\nrequiring the prior to be relearned, and (4) can be considered as a\nhigh-quality generative method (in this case, by generating novel, creative,\ninteresting, recognizable images).\n",
        "published": "2016",
        "authors": [
            "Anh Nguyen",
            "Alexey Dosovitskiy",
            "Jason Yosinski",
            "Thomas Brox",
            "Jeff Clune"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1701.05221v5",
        "title": "Parsimonious Inference on Convolutional Neural Networks: Learning and\n  applying on-line kernel activation rules",
        "abstract": "  A new, radical CNN design approach is presented in this paper, considering\nthe reduction of the total computational load during inference. This is\nachieved by a new holistic intervention on both the CNN architecture and the\ntraining procedure, which targets to the parsimonious inference by learning to\nexploit or remove the redundant capacity of a CNN architecture. This is\naccomplished, by the introduction of a new structural element that can be\ninserted as an add-on to any contemporary CNN architecture, whilst preserving\nor even improving its recognition accuracy. Our approach formulates a\nsystematic and data-driven method for developing CNNs that are trained to\neventually change size and form in real-time during inference, targeting to the\nsmaller possible computational footprint. Results are provided for the optimal\nimplementation on a few modern, high-end mobile computing platforms indicating\na significant speed-up of up to x3 times.\n",
        "published": "2017",
        "authors": [
            "I. Theodorakopoulos",
            "V. Pothos",
            "D. Kastaniotis",
            "N. Fragoulis"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1703.03400v3",
        "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
        "abstract": "  We propose an algorithm for meta-learning that is model-agnostic, in the\nsense that it is compatible with any model trained with gradient descent and\napplicable to a variety of different learning problems, including\nclassification, regression, and reinforcement learning. The goal of\nmeta-learning is to train a model on a variety of learning tasks, such that it\ncan solve new learning tasks using only a small number of training samples. In\nour approach, the parameters of the model are explicitly trained such that a\nsmall number of gradient steps with a small amount of training data from a new\ntask will produce good generalization performance on that task. In effect, our\nmethod trains the model to be easy to fine-tune. We demonstrate that this\napproach leads to state-of-the-art performance on two few-shot image\nclassification benchmarks, produces good results on few-shot regression, and\naccelerates fine-tuning for policy gradient reinforcement learning with neural\nnetwork policies.\n",
        "published": "2017",
        "authors": [
            "Chelsea Finn",
            "Pieter Abbeel",
            "Sergey Levine"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1705.10694v3",
        "title": "Deep Learning is Robust to Massive Label Noise",
        "abstract": "  Deep neural networks trained on large supervised datasets have led to\nimpressive results in image classification and other tasks. However,\nwell-annotated datasets can be time-consuming and expensive to collect, lending\nincreased interest to larger but noisy datasets that are more easily obtained.\nIn this paper, we show that deep neural networks are capable of generalizing\nfrom training data for which true labels are massively outnumbered by incorrect\nlabels. We demonstrate remarkably high test performance after training on\ncorrupted data from MNIST, CIFAR, and ImageNet. For example, on MNIST we obtain\ntest accuracy above 90 percent even after each clean training example has been\ndiluted with 100 randomly-labeled examples. Such behavior holds across multiple\npatterns of label noise, even when erroneous labels are biased towards\nconfusing classes. We show that training in this regime requires a significant\nbut manageable increase in dataset size that is related to the factor by which\ncorrect labels have been diluted. Finally, we provide an analysis of our\nresults that shows how increasing noise decreases the effective batch size.\n",
        "published": "2017",
        "authors": [
            "David Rolnick",
            "Andreas Veit",
            "Serge Belongie",
            "Nir Shavit"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1707.03502v2",
        "title": "Deep Learning for Sensor-based Activity Recognition: A Survey",
        "abstract": "  Sensor-based activity recognition seeks the profound high-level knowledge\nabout human activities from multitudes of low-level sensor readings.\nConventional pattern recognition approaches have made tremendous progress in\nthe past years. However, those methods often heavily rely on heuristic\nhand-crafted feature extraction, which could hinder their generalization\nperformance. Additionally, existing methods are undermined for unsupervised and\nincremental learning tasks. Recently, the recent advancement of deep learning\nmakes it possible to perform automatic high-level feature extraction thus\nachieves promising performance in many areas. Since then, deep learning based\nmethods have been widely adopted for the sensor-based activity recognition\ntasks. This paper surveys the recent advance of deep learning based\nsensor-based activity recognition. We summarize existing literature from three\naspects: sensor modality, deep model, and application. We also present detailed\ninsights on existing work and propose grand challenges for future research.\n",
        "published": "2017",
        "authors": [
            "Jindong Wang",
            "Yiqiang Chen",
            "Shuji Hao",
            "Xiaohui Peng",
            "Lisha Hu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.08219v3",
        "title": "Tensor field networks: Rotation- and translation-equivariant neural\n  networks for 3D point clouds",
        "abstract": "  We introduce tensor field neural networks, which are locally equivariant to\n3D rotations, translations, and permutations of points at every layer. 3D\nrotation equivariance removes the need for data augmentation to identify\nfeatures in arbitrary orientations. Our network uses filters built from\nspherical harmonics; due to the mathematical consequences of this filter\nchoice, each layer accepts as input (and guarantees as output) scalars,\nvectors, and higher-order tensors, in the geometric sense of these terms. We\ndemonstrate the capabilities of tensor field networks with tasks in geometry,\nphysics, and chemistry.\n",
        "published": "2018",
        "authors": [
            "Nathaniel Thomas",
            "Tess Smidt",
            "Steven Kearnes",
            "Lusann Yang",
            "Li Li",
            "Kai Kohlhoff",
            "Patrick Riley"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1803.09760v1",
        "title": "Predicting the Future with Transformational States",
        "abstract": "  An intelligent observer looks at the world and sees not only what is, but\nwhat is moving and what can be moved. In other words, the observer sees how the\npresent state of the world can transform in the future. We propose a model that\npredicts future images by learning to represent the present state and its\ntransformation given only a sequence of images. To do so, we introduce an\narchitecture with a latent state composed of two components designed to capture\n(i) the present image state and (ii) the transformation between present and\nfuture states, respectively. We couple this latent state with a recurrent\nneural network (RNN) core that predicts future frames by transforming past\nstates into future states by applying the accumulated state transformation with\na learned operator. We describe how this model can be integrated into an\nencoder-decoder convolutional neural network (CNN) architecture that uses\nweighted residual connections to integrate representations of the past with\nrepresentations of the future. Qualitatively, our approach generates image\nsequences that are stable and capture realistic motion over multiple predicted\nframes, without requiring adversarial training. Quantitatively, our method\nachieves prediction results comparable to state-of-the-art results on standard\nimage prediction benchmarks (Moving MNIST, KTH, and UCF101).\n",
        "published": "2018",
        "authors": [
            "Andrew Jaegle",
            "Oleh Rybkin",
            "Konstantinos G. Derpanis",
            "Kostas Daniilidis"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.08047v2",
        "title": "Flexible Neural Representation for Physics Prediction",
        "abstract": "  Humans have a remarkable capacity to understand the physical dynamics of\nobjects in their environment, flexibly capturing complex structures and\ninteractions at multiple levels of detail. Inspired by this ability, we propose\na hierarchical particle-based object representation that covers a wide variety\nof types of three-dimensional objects, including both arbitrary rigid\ngeometrical shapes and deformable materials. We then describe the Hierarchical\nRelation Network (HRN), an end-to-end differentiable neural network based on\nhierarchical graph convolution, that learns to predict physical dynamics in\nthis representation. Compared to other neural network baselines, the HRN\naccurately handles complex collisions and nonrigid deformations, generating\nplausible dynamics predictions at long time scales in novel settings, and\nscaling to large scene configurations. These results demonstrate an\narchitecture with the potential to form the basis of next-generation physics\npredictors for use in computer vision, robotics, and quantitative cognitive\nscience.\n",
        "published": "2018",
        "authors": [
            "Damian Mrowca",
            "Chengxu Zhuang",
            "Elias Wang",
            "Nick Haber",
            "Li Fei-Fei",
            "Joshua B. Tenenbaum",
            "Daniel L. K. Yamins"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.03361v1",
        "title": "Weakly-Supervised Convolutional Neural Networks for Multimodal Image\n  Registration",
        "abstract": "  One of the fundamental challenges in supervised learning for multimodal image\nregistration is the lack of ground-truth for voxel-level spatial\ncorrespondence. This work describes a method to infer voxel-level\ntransformation from higher-level correspondence information contained in\nanatomical labels. We argue that such labels are more reliable and practical to\nobtain for reference sets of image pairs than voxel-level correspondence.\nTypical anatomical labels of interest may include solid organs, vessels, ducts,\nstructure boundaries and other subject-specific ad hoc landmarks. The proposed\nend-to-end convolutional neural network approach aims to predict displacement\nfields to align multiple labelled corresponding structures for individual image\npairs during the training, while only unlabelled image pairs are used as the\nnetwork input for inference. We highlight the versatility of the proposed\nstrategy, for training, utilising diverse types of anatomical labels, which\nneed not to be identifiable over all training image pairs. At inference, the\nresulting 3D deformable image registration algorithm runs in real-time and is\nfully-automated without requiring any anatomical labels or initialisation.\nSeveral network architecture variants are compared for registering T2-weighted\nmagnetic resonance images and 3D transrectal ultrasound images from prostate\ncancer patients. A median target registration error of 3.6 mm on landmark\ncentroids and a median Dice of 0.87 on prostate glands are achieved from\ncross-validation experiments, in which 108 pairs of multimodal images from 76\npatients were tested with high-quality anatomical labels.\n",
        "published": "2018",
        "authors": [
            "Yipeng Hu",
            "Marc Modat",
            "Eli Gibson",
            "Wenqi Li",
            "Nooshin Ghavami",
            "Ester Bonmati",
            "Guotai Wang",
            "Steven Bandula",
            "Caroline M. Moore",
            "Mark Emberton",
            "S\u00e9bastien Ourselin",
            "J. Alison Noble",
            "Dean C. Barratt",
            "Tom Vercauteren"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.02234v1",
        "title": "Semantic bottleneck for computer vision tasks",
        "abstract": "  This paper introduces a novel method for the representation of images that is\nsemantic by nature, addressing the question of computation intelligibility in\ncomputer vision tasks. More specifically, our proposition is to introduce what\nwe call a semantic bottleneck in the processing pipeline, which is a crossing\npoint in which the representation of the image is entirely expressed with\nnatural language , while retaining the efficiency of numerical representations.\nWe show that our approach is able to generate semantic representations that\ngive state-of-the-art results on semantic content-based image retrieval and\nalso perform very well on image classification tasks. Intelligibility is\nevaluated through user centered experiments for failure detection.\n",
        "published": "2018",
        "authors": [
            "Maxime Bucher",
            "St\u00e9phane Herbin",
            "Fr\u00e9d\u00e9ric Jurie"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.02244v2",
        "title": "Yet another but more efficient black-box adversarial attack: tiling and\n  evolution strategies",
        "abstract": "  We introduce a new black-box attack achieving state of the art performances.\nOur approach is based on a new objective function, borrowing ideas from\n$\\ell_\\infty$-white box attacks, and particularly designed to fit\nderivative-free optimization requirements. It only requires to have access to\nthe logits of the classifier without any other information which is a more\nrealistic scenario. Not only we introduce a new objective function, we extend\nprevious works on black box adversarial attacks to a larger spectrum of\nevolution strategies and other derivative-free optimization methods. We also\nhighlight a new intriguing property that deep neural networks are not robust to\nsingle shot tiled attacks. Our models achieve, with a budget limited to\n$10,000$ queries, results up to $99.2\\%$ of success rate against InceptionV3\nclassifier with $630$ queries to the network on average in the untargeted\nattacks setting, which is an improvement by $90$ queries of the current state\nof the art. In the targeted setting, we are able to reach, with a limited\nbudget of $100,000$, $100\\%$ of success rate with a budget of $6,662$ queries\non average, i.e. we need $800$ queries less than the current state of the art.\n",
        "published": "2019",
        "authors": [
            "Laurent Meunier",
            "Jamal Atif",
            "Olivier Teytaud"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.10579v8",
        "title": "Autoencoding with a Classifier System",
        "abstract": "  Autoencoders are data-specific compression algorithms learned automatically\nfrom examples. The predominant approach has been to construct single large\nglobal models that cover the domain. However, training and evaluating models of\nincreasing size comes at the price of additional time and computational cost.\nConditional computation, sparsity, and model pruning techniques can reduce\nthese costs while maintaining performance. Learning classifier systems (LCS)\nare a framework for adaptively subdividing input spaces into an ensemble of\nsimpler local approximations that together cover the domain. LCS perform\nconditional computation through the use of a population of individual\ngating/guarding components, each associated with a local approximation. This\narticle explores the use of an LCS to adaptively decompose the input domain\ninto a collection of small autoencoders where local solutions of different\ncomplexity may emerge. In addition to benefits in convergence time and\ncomputational cost, it is shown possible to reduce code size as well as the\nresulting decoder computational cost when compared with the global model\nequivalent.\n",
        "published": "2019",
        "authors": [
            "Richard J. Preen",
            "Stewart W. Wilson",
            "Larry Bull"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.13351v1",
        "title": "Admiring the Great Mountain: A Celebration Special Issue in Honor of\n  Stephen Grossbergs 80th Birthday",
        "abstract": "  This editorial summarizes selected key contributions of Prof. Stephen\nGrossberg and describes the papers in this 80th birthday special issue in his\nhonor. His productivity, creativity, and vision would each be enough to mark a\nscientist of the first caliber. In combination, they have resulted in\ncontributions that have changed the entire discipline of neural networks.\nGrossberg has been tremendously influential in engineering, dynamical systems,\nand artificial intelligence as well. Indeed, he has been one of the most\nimportant mentors and role models in my career, and has done so with\nextraordinary generosity and encouragement. All authors in this special issue\nhave taken great pleasure in hereby commemorating his extraordinary career and\ncontributions.\n",
        "published": "2019",
        "authors": [
            "Donald C. Wunsch"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.05565v1",
        "title": "FBNetV2: Differentiable Neural Architecture Search for Spatial and\n  Channel Dimensions",
        "abstract": "  Differentiable Neural Architecture Search (DNAS) has demonstrated great\nsuccess in designing state-of-the-art, efficient neural networks. However,\nDARTS-based DNAS's search space is small when compared to other search\nmethods', since all candidate network layers must be explicitly instantiated in\nmemory. To address this bottleneck, we propose a memory and computationally\nefficient DNAS variant: DMaskingNAS. This algorithm expands the search space by\nup to $10^{14}\\times$ over conventional DNAS, supporting searches over spatial\nand channel dimensions that are otherwise prohibitively expensive: input\nresolution and number of filters. We propose a masking mechanism for feature\nmap reuse, so that memory and computational costs stay nearly constant as the\nsearch space expands. Furthermore, we employ effective shape propagation to\nmaximize per-FLOP or per-parameter accuracy. The searched FBNetV2s yield\nstate-of-the-art performance when compared with all previous architectures.\nWith up to 421$\\times$ less search cost, DMaskingNAS finds models with 0.9%\nhigher accuracy, 15% fewer FLOPs than MobileNetV3-Small; and with similar\naccuracy but 20% fewer FLOPs than Efficient-B0. Furthermore, our FBNetV2\noutperforms MobileNetV3 by 2.6% in accuracy, with equivalent model size.\nFBNetV2 models are open-sourced at\nhttps://github.com/facebookresearch/mobile-vision.\n",
        "published": "2020",
        "authors": [
            "Alvin Wan",
            "Xiaoliang Dai",
            "Peizhao Zhang",
            "Zijian He",
            "Yuandong Tian",
            "Saining Xie",
            "Bichen Wu",
            "Matthew Yu",
            "Tao Xu",
            "Kan Chen",
            "Peter Vajda",
            "Joseph E. Gonzalez"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1511.05547v2",
        "title": "Return of Frustratingly Easy Domain Adaptation",
        "abstract": "  Unlike human learning, machine learning often fails to handle changes between\ntraining (source) and test (target) input distributions. Such domain shifts,\ncommon in practical scenarios, severely damage the performance of conventional\nmachine learning methods. Supervised domain adaptation methods have been\nproposed for the case when the target data have labels, including some that\nperform very well despite being \"frustratingly easy\" to implement. However, in\npractice, the target domain is often unlabeled, requiring unsupervised\nadaptation. We propose a simple, effective, and efficient method for\nunsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL\nminimizes domain shift by aligning the second-order statistics of source and\ntarget distributions, without requiring any target labels. Even though it is\nextraordinarily simple--it can be implemented in four lines of Matlab\ncode--CORAL performs remarkably well in extensive evaluations on standard\nbenchmark datasets.\n",
        "published": "2015",
        "authors": [
            "Baochen Sun",
            "Jiashi Feng",
            "Kate Saenko"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1512.04295v2",
        "title": "Origami: A 803 GOp/s/W Convolutional Network Accelerator",
        "abstract": "  An ever increasing number of computer vision and image/video processing\nchallenges are being approached using deep convolutional neural networks,\nobtaining state-of-the-art results in object recognition and detection,\nsemantic segmentation, action recognition, optical flow and superresolution.\nHardware acceleration of these algorithms is essential to adopt these\nimprovements in embedded and mobile computer vision systems. We present a new\narchitecture, design and implementation as well as the first reported silicon\nmeasurements of such an accelerator, outperforming previous work in terms of\npower-, area- and I/O-efficiency. The manufactured device provides up to 196\nGOp/s on 3.09 mm^2 of silicon in UMC 65nm technology and can achieve a power\nefficiency of 803 GOp/s/W. The massively reduced bandwidth requirements make it\nthe first architecture scalable to TOp/s performance.\n",
        "published": "2015",
        "authors": [
            "Lukas Cavigelli",
            "Luca Benini"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1709.03450v1",
        "title": "UI-Net: Interactive Artificial Neural Networks for Iterative Image\n  Segmentation Based on a User Model",
        "abstract": "  For complex segmentation tasks, fully automatic systems are inherently\nlimited in their achievable accuracy for extracting relevant objects.\nEspecially in cases where only few data sets need to be processed for a highly\naccurate result, semi-automatic segmentation techniques exhibit a clear benefit\nfor the user. One area of application is medical image processing during an\nintervention for a single patient. We propose a learning-based cooperative\nsegmentation approach which includes the computing entity as well as the user\ninto the task. Our system builds upon a state-of-the-art fully convolutional\nartificial neural network (FCN) as well as an active user model for training.\nDuring the segmentation process, a user of the trained system can iteratively\nadd additional hints in form of pictorial scribbles as seed points into the FCN\nsystem to achieve an interactive and precise segmentation result. The\nsegmentation quality of interactive FCNs is evaluated. Iterative FCN approaches\ncan yield superior results compared to networks without the user input channel\ncomponent, due to a consistent improvement in segmentation quality after each\ninteraction.\n",
        "published": "2017",
        "authors": [
            "Mario Amrehn",
            "Sven Gaube",
            "Mathias Unberath",
            "Frank Schebesch",
            "Tim Horz",
            "Maddalena Strumia",
            "Stefan Steidl",
            "Markus Kowarschik",
            "Andreas Maier"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.05695v1",
        "title": "Lightweight Neural Networks",
        "abstract": "  Most of the weights in a Lightweight Neural Network have a value of zero,\nwhile the remaining ones are either +1 or -1. These universal approximators\nrequire approximately 1.1 bits/weight of storage, posses a quick forward pass\nand achieve classification accuracies similar to conventional continuous-weight\nnetworks. Their training regimen focuses on error reduction initially, but\nlater emphasizes discretization of weights. They ignore insignificant inputs,\nremove unnecessary weights, and drop unneeded hidden neurons. We have\nsuccessfully tested them on the MNIST, credit card fraud, and credit card\ndefaults data sets using networks having 2 to 16 hidden layers and up to 4.4\nmillion weights.\n",
        "published": "2017",
        "authors": [
            "Altaf H. Khan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.03893v1",
        "title": "A Hybrid GA-PSO Method for Evolving Architecture and Short Connections\n  of Deep Convolutional Neural Networks",
        "abstract": "  Image classification is a difficult machine learning task, where\nConvolutional Neural Networks (CNNs) have been applied for over 20 years in\norder to solve the problem. In recent years, instead of the traditional way of\nonly connecting the current layer with its next layer, shortcut connections\nhave been proposed to connect the current layer with its forward layers apart\nfrom its next layer, which has been proved to be able to facilitate the\ntraining process of deep CNNs. However, there are various ways to build the\nshortcut connections, it is hard to manually design the best shortcut\nconnections when solving a particular problem, especially given the design of\nthe network architecture is already very challenging.\n  In this paper, a hybrid evolutionary computation (EC) method is proposed to\n\\textit{automatically} evolve both the architecture of deep CNNs and the\nshortcut connections. Three major contributions of this work are: Firstly, a\nnew encoding strategy is proposed to encode a CNN, where the architecture and\nthe shortcut connections are encoded separately; Secondly, a hybrid two-level\nEC method, which combines particle swarm optimisation and genetic algorithms,\nis developed to search for the optimal CNNs; Lastly, an adjustable learning\nrate is introduced for the fitness evaluations, which provides a better\nlearning rate for the training process given a fixed number of epochs. The\nproposed algorithm is evaluated on three widely used benchmark datasets of\nimage classification and compared with 12 peer Non-EC based competitors and one\nEC based competitor. The experimental results demonstrate that the proposed\nmethod outperforms all of the peer competitors in terms of classification\naccuracy.\n",
        "published": "2019",
        "authors": [
            "Bin Wang",
            "Yanan Sun",
            "Bing Xue",
            "Mengjie Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.09876v1",
        "title": "Automated pulmonary nodule detection using 3D deep convolutional neural\n  networks",
        "abstract": "  Early detection of pulmonary nodules in computed tomography (CT) images is\nessential for successful outcomes among lung cancer patients. Much attention\nhas been given to deep convolutional neural network (DCNN)-based approaches to\nthis task, but models have relied at least partly on 2D or 2.5D components for\ninherently 3D data. In this paper, we introduce a novel DCNN approach,\nconsisting of two stages, that is fully three-dimensional end-to-end and\nutilizes the state-of-the-art in object detection. First, nodule candidates are\nidentified with a U-Net-inspired 3D Faster R-CNN trained using online hard\nnegative mining. Second, false positive reduction is performed by 3D DCNN\nclassifiers trained on difficult examples produced during candidate screening.\nFinally, we introduce a method to ensemble models from both stages via\nconsensus to give the final predictions. By using this framework, we ranked\nfirst of 2887 teams in Season One of Alibaba's 2017 TianChi AI Competition for\nHealthcare.\n",
        "published": "2019",
        "authors": [
            "Hao Tang",
            "Daniel R. Kim",
            "Xiaohui Xie"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2007.04756v1",
        "title": "Learning to Prune Deep Neural Networks via Reinforcement Learning",
        "abstract": "  This paper proposes PuRL - a deep reinforcement learning (RL) based algorithm\nfor pruning neural networks. Unlike current RL based model compression\napproaches where feedback is given only at the end of each episode to the\nagent, PuRL provides rewards at every pruning step. This enables PuRL to\nachieve sparsity and accuracy comparable to current state-of-the-art methods,\nwhile having a much shorter training cycle. PuRL achieves more than 80%\nsparsity on the ResNet-50 model while retaining a Top-1 accuracy of 75.37% on\nthe ImageNet dataset. Through our experiments we show that PuRL is also able to\nsparsify already efficient architectures like MobileNet-V2. In addition to\nperformance characterisation experiments, we also provide a discussion and\nanalysis of the various RL design choices that went into the tuning of the\nMarkov Decision Process underlying PuRL. Lastly, we point out that PuRL is\nsimple to use and can be easily adapted for various architectures.\n",
        "published": "2020",
        "authors": [
            "Manas Gupta",
            "Siddharth Aravindan",
            "Aleksandra Kalisz",
            "Vijay Chandrasekhar",
            "Lin Jie"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2007.05606v1",
        "title": "Neuromorphic Processing and Sensing: Evolutionary Progression of AI to\n  Spiking",
        "abstract": "  The increasing rise in machine learning and deep learning applications is\nrequiring ever more computational resources to successfully meet the growing\ndemands of an always-connected, automated world. Neuromorphic technologies\nbased on Spiking Neural Network algorithms hold the promise to implement\nadvanced artificial intelligence using a fraction of the computations and power\nrequirements by modeling the functioning, and spiking, of the human brain. With\nthe proliferation of tools and platforms aiding data scientists and machine\nlearning engineers to develop the latest innovations in artificial and deep\nneural networks, a transition to a new paradigm will require building from the\ncurrent well-established foundations. This paper explains the theoretical\nworkings of neuromorphic technologies based on spikes, and overviews the\nstate-of-art in hardware processors, software platforms and neuromorphic\nsensing devices. A progression path is paved for current machine learning\nspecialists to update their skillset, as well as classification or predictive\nmodels from the current generation of deep neural networks to SNNs. This can be\nachieved by leveraging existing, specialized hardware in the form of SpiNNaker\nand the Nengo migration toolkit. First-hand, experimental results of converting\na VGG-16 neural network to an SNN are shared. A forward gaze into industrial,\nmedical and commercial applications that can readily benefit from SNNs wraps up\nthis investigation into the neuromorphic computing future.\n",
        "published": "2020",
        "authors": [
            "Philippe Reiter",
            "Geet Rose Jose",
            "Spyridon Bizmpikis",
            "Ionela-Ancu\u0163a C\u00eerjil\u0103"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.04916v3",
        "title": "Pruning of Deep Spiking Neural Networks through Gradient Rewiring",
        "abstract": "  Spiking Neural Networks (SNNs) have been attached great importance due to\ntheir biological plausibility and high energy-efficiency on neuromorphic chips.\nAs these chips are usually resource-constrained, the compression of SNNs is\nthus crucial along the road of practical use of SNNs. Most existing methods\ndirectly apply pruning approaches in artificial neural networks (ANNs) to SNNs,\nwhich ignore the difference between ANNs and SNNs, thus limiting the\nperformance of the pruned SNNs. Besides, these methods are only suitable for\nshallow SNNs. In this paper, inspired by synaptogenesis and synapse elimination\nin the neural system, we propose gradient rewiring (Grad R), a joint learning\nalgorithm of connectivity and weight for SNNs, that enables us to seamlessly\noptimize network structure without retraining. Our key innovation is to\nredefine the gradient to a new synaptic parameter, allowing better exploration\nof network structures by taking full advantage of the competition between\npruning and regrowth of connections. The experimental results show that the\nproposed method achieves minimal loss of SNNs' performance on MNIST and\nCIFAR-10 dataset so far. Moreover, it reaches a $\\sim$3.5% accuracy loss under\nunprecedented 0.73% connectivity, which reveals remarkable structure refining\ncapability in SNNs. Our work suggests that there exists extremely high\nredundancy in deep SNNs. Our codes are available at\nhttps://github.com/Yanqi-Chen/Gradient-Rewiring.\n",
        "published": "2021",
        "authors": [
            "Yanqi Chen",
            "Zhaofei Yu",
            "Wei Fang",
            "Tiejun Huang",
            "Yonghong Tian"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.05916v1",
        "title": "Dynamical Isometry: The Missing Ingredient for Neural Network Pruning",
        "abstract": "  Several recent works [40, 24] observed an interesting phenomenon in neural\nnetwork pruning: A larger finetuning learning rate can improve the final\nperformance significantly. Unfortunately, the reason behind it remains elusive\nup to date. This paper is meant to explain it through the lens of dynamical\nisometry [42]. Specifically, we examine neural network pruning from an unusual\nperspective: pruning as initialization for finetuning, and ask whether the\ninherited weights serve as a good initialization for the finetuning? The\ninsights from dynamical isometry suggest a negative answer. Despite its\ncritical role, this issue has not been well-recognized by the community so far.\nIn this paper, we will show the understanding of this problem is very important\n-- on top of explaining the aforementioned mystery about the larger finetuning\nrate, it also unveils the mystery about the value of pruning [5, 30]. Besides a\nclearer theoretical understanding of pruning, resolving the problem can also\nbring us considerable performance benefits in practice.\n",
        "published": "2021",
        "authors": [
            "Huan Wang",
            "Can Qin",
            "Yue Bai",
            "Yun Fu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.11654v1",
        "title": "Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep\n  Spiking Neural Networks",
        "abstract": "  Spiking Neural Networks (SNNs), as bio-inspired energy-efficient neural\nnetworks, have attracted great attentions from researchers and industry. The\nmost efficient way to train deep SNNs is through ANN-SNN conversion. However,\nthe conversion usually suffers from accuracy loss and long inference time,\nwhich impede the practical application of SNN. In this paper, we theoretically\nanalyze ANN-SNN conversion and derive sufficient conditions of the optimal\nconversion. To better correlate ANN-SNN and get greater accuracy, we propose\nRate Norm Layer to replace the ReLU activation function in source ANN training,\nenabling direct conversion from a trained ANN to an SNN. Moreover, we propose\nan optimal fit curve to quantify the fit between the activation value of source\nANN and the actual firing rate of target SNN. We show that the inference time\ncan be reduced by optimizing the upper bound of the fit curve in the revised\nANN to achieve fast inference. Our theory can explain the existing work on fast\nreasoning and get better results. The experimental results show that the\nproposed method achieves near loss less conversion with VGG-16,\nPreActResNet-18, and deeper structures. Moreover, it can reach 8.6x faster\nreasoning performance under 0.265x energy consumption of the typical method.\nThe code is available at\nhttps://github.com/DingJianhao/OptSNNConvertion-RNL-RIL.\n",
        "published": "2021",
        "authors": [
            "Jianhao Ding",
            "Zhaofei Yu",
            "Yonghong Tian",
            "Tiejun Huang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.14399v10",
        "title": "Enhanced Isotropy Maximization Loss: Seamless and High-Performance\n  Out-of-Distribution Detection Simply Replacing the SoftMax Loss",
        "abstract": "  Current out-of-distribution detection approaches usually present special\nrequirements (e.g., collecting outlier data and hyperparameter validation) and\nproduce side effects (e.g., classification accuracy drop and slow/inefficient\ninferences). Recently, entropic out-of-distribution detection has been proposed\nas a seamless approach (i.e., a solution that avoids all previously mentioned\ndrawbacks). The entropic out-of-distribution detection solution uses the IsoMax\nloss for training and the entropic score for out-of-distribution detection. The\nIsoMax loss works as a drop-in replacement of the SoftMax loss (i.e., the\ncombination of the output linear layer, the SoftMax activation, and the\ncross-entropy loss) because swapping the SoftMax loss with the IsoMax loss\nrequires no changes in the model's architecture or training\nprocedures/hyperparameters. In this paper, we perform what we call an\nisometrization of the distances used in the IsoMax loss. Additionally, we\npropose replacing the entropic score with the minimum distance score.\nExperiments showed that these modifications significantly increase\nout-of-distribution detection performance while keeping the solution seamless.\nBesides being competitive with or outperforming all major current approaches,\nthe proposed solution avoids all their current limitations, in addition to\nbeing much easier to use because only a simple loss replacement for training\nthe neural network is required. The code to replace the SoftMax loss with the\nIsoMax+ loss and reproduce the results is available at\nhttps://github.com/dlmacedo/entropic-out-of-distribution-detection.\n",
        "published": "2021",
        "authors": [
            "David Mac\u00eado",
            "Teresa Ludermir"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2107.06862v1",
        "title": "Differentiable Programming of Reaction-Diffusion Patterns",
        "abstract": "  Reaction-Diffusion (RD) systems provide a computational framework that\ngoverns many pattern formation processes in nature. Current RD system design\npractices boil down to trial-and-error parameter search. We propose a\ndifferentiable optimization method for learning the RD system parameters to\nperform example-based texture synthesis on a 2D plane. We do this by\nrepresenting the RD system as a variant of Neural Cellular Automata and using\ntask-specific differentiable loss functions. RD systems generated by our method\nexhibit robust, non-trivial 'life-like' behavior.\n",
        "published": "2021",
        "authors": [
            "Alexander Mordvintsev",
            "Ettore Randazzo",
            "Eyvind Niklasson"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.13072v1",
        "title": "Adversarial Contrastive Self-Supervised Learning",
        "abstract": "  Recently, learning from vast unlabeled data, especially self-supervised\nlearning, has been emerging and attracted widespread attention. Self-supervised\nlearning followed by the supervised fine-tuning on a few labeled examples can\nsignificantly improve label efficiency and outperform standard supervised\ntraining using fully annotated data. In this work, we present a novel\nself-supervised deep learning paradigm based on online hard negative pair\nmining. Specifically, we design a student-teacher network to generate\nmulti-view of the data for self-supervised learning and integrate hard negative\npair mining into the training. Then we derive a new triplet-like loss\nconsidering both positive sample pairs and mined hard negative sample pairs.\nExtensive experiments demonstrate the effectiveness of the proposed method and\nits components on ILSVRC-2012.\n",
        "published": "2022",
        "authors": [
            "Wentao Zhu",
            "Hang Shang",
            "Tingxun Lv",
            "Chao Liao",
            "Sen Yang",
            "Ji Liu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1606.02407v1",
        "title": "Structured Convolution Matrices for Energy-efficient Deep learning",
        "abstract": "  We derive a relationship between network representation in energy-efficient\nneuromorphic architectures and block Toplitz convolutional matrices. Inspired\nby this connection, we develop deep convolutional networks using a family of\nstructured convolutional matrices and achieve state-of-the-art trade-off\nbetween energy efficiency and classification accuracy for well-known image\nrecognition tasks. We also put forward a novel method to train binary\nconvolutional networks by utilising an existing connection between\nnoisy-rectified linear units and binary activations.\n",
        "published": "2016",
        "authors": [
            "Rathinakumar Appuswamy",
            "Tapan Nayak",
            "John Arthur",
            "Steven Esser",
            "Paul Merolla",
            "Jeffrey Mckinstry",
            "Timothy Melano",
            "Myron Flickner",
            "Dharmendra Modha"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1607.01719v1",
        "title": "Deep CORAL: Correlation Alignment for Deep Domain Adaptation",
        "abstract": "  Deep neural networks are able to learn powerful representations from large\nquantities of labeled input data, however they cannot always generalize well\nacross changes in input distributions. Domain adaptation algorithms have been\nproposed to compensate for the degradation in performance due to domain shift.\nIn this paper, we address the case when the target domain is unlabeled,\nrequiring unsupervised adaptation. CORAL is a \"frustratingly easy\" unsupervised\ndomain adaptation method that aligns the second-order statistics of the source\nand target distributions with a linear transformation. Here, we extend CORAL to\nlearn a nonlinear transformation that aligns correlations of layer activations\nin deep neural networks (Deep CORAL). Experiments on standard benchmark\ndatasets show state-of-the-art performance.\n",
        "published": "2016",
        "authors": [
            "Baochen Sun",
            "Kate Saenko"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1607.07043v1",
        "title": "Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition",
        "abstract": "  3D action recognition - analysis of human actions based on 3D skeleton data -\nbecomes popular recently due to its succinctness, robustness, and\nview-invariant representation. Recent attempts on this problem suggested to\ndevelop RNN-based learning methods to model the contextual dependency in the\ntemporal domain. In this paper, we extend this idea to spatio-temporal domains\nto analyze the hidden sources of action-related information within the input\ndata over both domains concurrently. Inspired by the graphical structure of the\nhuman skeleton, we further propose a more powerful tree-structure based\ntraversal method. To handle the noise and occlusion in 3D skeleton data, we\nintroduce new gating mechanism within LSTM to learn the reliability of the\nsequential input data and accordingly adjust its effect on updating the\nlong-term context information stored in the memory cell. Our method achieves\nstate-of-the-art performance on 4 challenging benchmark datasets for 3D human\naction analysis.\n",
        "published": "2016",
        "authors": [
            "Jun Liu",
            "Amir Shahroudy",
            "Dong Xu",
            "Gang Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.06791v1",
        "title": "Generalized Dropout",
        "abstract": "  Deep Neural Networks often require good regularizers to generalize well.\nDropout is one such regularizer that is widely used among Deep Learning\npractitioners. Recent work has shown that Dropout can also be viewed as\nperforming Approximate Bayesian Inference over the network parameters. In this\nwork, we generalize this notion and introduce a rich family of regularizers\nwhich we call Generalized Dropout. One set of methods in this family, called\nDropout++, is a version of Dropout with trainable parameters. Classical Dropout\nemerges as a special case of this method. Another member of this family selects\nthe width of neural network layers. Experiments show that these methods help in\nimproving generalization performance over Dropout.\n",
        "published": "2016",
        "authors": [
            "Suraj Srinivas",
            "R. Venkatesh Babu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.01294v1",
        "title": "Message Passing Multi-Agent GANs",
        "abstract": "  Communicating and sharing intelligence among agents is an important facet of\nachieving Artificial General Intelligence. As a first step towards this\nchallenge, we introduce a novel framework for image generation: Message Passing\nMulti-Agent Generative Adversarial Networks (MPM GANs). While GANs have\nrecently been shown to be very effective for image generation and other tasks,\nthese networks have been limited to mostly single generator-discriminator\nnetworks. We show that we can obtain multi-agent GANs that communicate through\nmessage passing to achieve better image generation. The objectives of the\nindividual agents in this framework are two fold: a co-operation objective and\na competing objective. The co-operation objective ensures that the message\nsharing mechanism guides the other generator to generate better than itself\nwhile the competing objective encourages each generator to generate better than\nits counterpart. We analyze and visualize the messages that these GANs share\namong themselves in various scenarios. We quantitatively show that the message\nsharing formulation serves as a regularizer for the adversarial training.\nQualitatively, we show that the different generators capture different traits\nof the underlying data distribution.\n",
        "published": "2016",
        "authors": [
            "Arnab Ghosh",
            "Viveka Kulharia",
            "Vinay Namboodiri"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.02136v5",
        "title": "Mode Regularized Generative Adversarial Networks",
        "abstract": "  Although Generative Adversarial Networks achieve state-of-the-art results on\na variety of generative tasks, they are regarded as highly unstable and prone\nto miss modes. We argue that these bad behaviors of GANs are due to the very\nparticular functional shape of the trained discriminators in high dimensional\nspaces, which can easily make training stuck or push probability mass in the\nwrong direction, towards that of higher concentration than that of the data\ngenerating distribution. We introduce several ways of regularizing the\nobjective, which can dramatically stabilize the training of GAN models. We also\nshow that our regularizers can help the fair distribution of probability mass\nacross the modes of the data generating distribution, during the early phases\nof training and thus providing a unified solution to the missing modes problem.\n",
        "published": "2016",
        "authors": [
            "Tong Che",
            "Yanran Li",
            "Athul Paul Jacob",
            "Yoshua Bengio",
            "Wenjie Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.03079v1",
        "title": "WRPN: Training and Inference using Wide Reduced-Precision Networks",
        "abstract": "  For computer vision applications, prior works have shown the efficacy of\nreducing the numeric precision of model parameters (network weights) in deep\nneural networks but also that reducing the precision of activations hurts model\naccuracy much more than reducing the precision of model parameters. We study\nschemes to train networks from scratch using reduced-precision activations\nwithout hurting the model accuracy. We reduce the precision of activation maps\n(along with model parameters) using a novel quantization scheme and increase\nthe number of filter maps in a layer, and find that this scheme compensates or\nsurpasses the accuracy of the baseline full-precision network. As a result, one\ncan significantly reduce the dynamic memory footprint, memory bandwidth,\ncomputational energy and speed up the training and inference process with\nappropriate hardware support. We call our scheme WRPN - wide reduced-precision\nnetworks. We report results using our proposed schemes and show that our\nresults are better than previously reported accuracies on ILSVRC-12 dataset\nwhile being computationally less expensive compared to previously reported\nreduced-precision networks.\n",
        "published": "2017",
        "authors": [
            "Asit Mishra",
            "Jeffrey J Cook",
            "Eriko Nurvitadhi",
            "Debbie Marr"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.00631v1",
        "title": "On the Importance of Consistency in Training Deep Neural Networks",
        "abstract": "  We explain that the difficulties of training deep neural networks come from a\nsyndrome of three consistency issues. This paper describes our efforts in their\nanalysis and treatment. The first issue is the training speed inconsistency in\ndifferent layers. We propose to address it with an intuitive,\nsimple-to-implement, low footprint second-order method. The second issue is the\nscale inconsistency between the layer inputs and the layer residuals. We\nexplain how second-order information provides favorable convenience in removing\nthis roadblock. The third and most challenging issue is the inconsistency in\nresidual propagation. Based on the fundamental theorem of linear algebra, we\nprovide a mathematical characterization of the famous vanishing gradient\nproblem. Thus, an important design principle for future optimization and neural\nnetwork design is derived. We conclude this paper with the construction of a\nnovel contractive neural network.\n",
        "published": "2017",
        "authors": [
            "Chengxi Ye",
            "Yezhou Yang",
            "Cornelia Fermuller",
            "Yiannis Aloimonos"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.08191v3",
        "title": "Hierarchically Structured Reinforcement Learning for Topically Coherent\n  Visual Story Generation",
        "abstract": "  We propose a hierarchically structured reinforcement learning approach to\naddress the challenges of planning for generating coherent multi-sentence\nstories for the visual storytelling task. Within our framework, the task of\ngenerating a story given a sequence of images is divided across a two-level\nhierarchical decoder. The high-level decoder constructs a plan by generating a\nsemantic concept (i.e., topic) for each image in sequence. The low-level\ndecoder generates a sentence for each image using a semantic compositional\nnetwork, which effectively grounds the sentence generation conditioned on the\ntopic. The two decoders are jointly trained end-to-end using reinforcement\nlearning. We evaluate our model on the visual storytelling (VIST) dataset.\nEmpirical results from both automatic and human evaluations demonstrate that\nthe proposed hierarchically structured reinforced training achieves\nsignificantly better performance compared to a strong flat deep reinforcement\nlearning baseline.\n",
        "published": "2018",
        "authors": [
            "Qiuyuan Huang",
            "Zhe Gan",
            "Asli Celikyilmaz",
            "Dapeng Wu",
            "Jianfeng Wang",
            "Xiaodong He"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.10255v1",
        "title": "Parallel Architecture and Hyperparameter Search via Successive Halving\n  and Classification",
        "abstract": "  We present a simple and powerful algorithm for parallel black box\noptimization called Successive Halving and Classification (SHAC). The algorithm\noperates in $K$ stages of parallel function evaluations and trains a cascade of\nbinary classifiers to iteratively cull the undesirable regions of the search\nspace. SHAC is easy to implement, requires no tuning of its own configuration\nparameters, is invariant to the scale of the objective function and can be\nbuilt using any choice of binary classifier. We adopt tree-based classifiers\nwithin SHAC and achieve competitive performance against several strong\nbaselines for optimizing synthetic functions, hyperparameters and\narchitectures.\n",
        "published": "2018",
        "authors": [
            "Manoj Kumar",
            "George E. Dahl",
            "Vijay Vasudevan",
            "Mohammad Norouzi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.10795v1",
        "title": "Deep Discriminative Latent Space for Clustering",
        "abstract": "  Clustering is one of the most fundamental tasks in data analysis and machine\nlearning. It is central to many data-driven applications that aim to separate\nthe data into groups with similar patterns. Moreover, clustering is a complex\nprocedure that is affected significantly by the choice of the data\nrepresentation method. Recent research has demonstrated encouraging clustering\nresults by learning effectively these representations. In most of these works a\ndeep auto-encoder is initially pre-trained to minimize a reconstruction loss,\nand then jointly optimized with clustering centroids in order to improve the\nclustering objective. Those works focus mainly on the clustering phase of the\nprocedure, while not utilizing the potential benefit out of the initial phase.\nIn this paper we propose to optimize an auto-encoder with respect to a\ndiscriminative pairwise loss function during the auto-encoder pre-training\nphase. We demonstrate the high accuracy obtained by the proposed method as well\nas its rapid convergence (e.g. reaching above 92% accuracy on MNIST during the\npre-training phase, in less than 50 epochs), even with small networks.\n",
        "published": "2018",
        "authors": [
            "Elad Tzoreff",
            "Olga Kogan",
            "Yoni Choukroun"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1808.06661v2",
        "title": "A Hybrid Differential Evolution Approach to Designing Deep Convolutional\n  Neural Networks for Image Classification",
        "abstract": "  Convolutional Neural Networks (CNNs) have demonstrated their superiority in\nimage classification, and evolutionary computation (EC) methods have recently\nbeen surging to automatically design the architectures of CNNs to save the\ntedious work of manually designing CNNs. In this paper, a new hybrid\ndifferential evolution (DE) algorithm with a newly added crossover operator is\nproposed to evolve the architectures of CNNs of any lengths, which is named\nDECNN. There are three new ideas in the proposed DECNN method. Firstly, an\nexisting effective encoding scheme is refined to cater for variable-length CNN\narchitectures; Secondly, the new mutation and crossover operators are developed\nfor variable-length DE to optimise the hyperparameters of CNNs; Finally, the\nnew second crossover is introduced to evolve the depth of the CNN\narchitectures. The proposed algorithm is tested on six widely-used benchmark\ndatasets and the results are compared to 12 state-of-the-art methods, which\nshows the proposed method is vigorously competitive to the state-of-the-art\nalgorithms. Furthermore, the proposed method is also compared with a method\nusing particle swarm optimisation with a similar encoding strategy named IPPSO,\nand the proposed DECNN outperforms IPPSO in terms of the accuracy.\n",
        "published": "2018",
        "authors": [
            "Bin Wang",
            "Yanan Sun",
            "Bing Xue",
            "Mengjie Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.13166v1",
        "title": "Don't forget, there is more than forgetting: new metrics for Continual\n  Learning",
        "abstract": "  Continual learning consists of algorithms that learn from a stream of\ndata/tasks continuously and adaptively thought time, enabling the incremental\ndevelopment of ever more complex knowledge and skills. The lack of consensus in\nevaluating continual learning algorithms and the almost exclusive focus on\nforgetting motivate us to propose a more comprehensive set of implementation\nindependent metrics accounting for several factors we believe have practical\nimplications worth considering in the deployment of real AI systems that learn\ncontinually: accuracy or performance over time, backward and forward knowledge\ntransfer, memory overhead as well as computational efficiency. Drawing\ninspiration from the standard Multi-Attribute Value Theory (MAVT) we further\npropose to fuse these metrics into a single score for ranking purposes and we\nevaluate our proposal with five continual learning strategies on the iCIFAR-100\ncontinual learning benchmark.\n",
        "published": "2018",
        "authors": [
            "Natalia D\u00edaz-Rodr\u00edguez",
            "Vincenzo Lomonaco",
            "David Filliat",
            "Davide Maltoni"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.01390v1",
        "title": "Spontaneous Facial Micro-Expression Recognition using 3D Spatiotemporal\n  Convolutional Neural Networks",
        "abstract": "  Facial expression recognition in videos is an active area of research in\ncomputer vision. However, fake facial expressions are difficult to be\nrecognized even by humans. On the other hand, facial micro-expressions\ngenerally represent the actual emotion of a person, as it is a spontaneous\nreaction expressed through human face. Despite of a few attempts made for\nrecognizing micro-expressions, still the problem is far from being a solved\nproblem, which is depicted by the poor rate of accuracy shown by the\nstate-of-the-art methods. A few CNN based approaches are found in the\nliterature to recognize micro-facial expressions from still images. Whereas, a\nspontaneous micro-expression video contains multiple frames that have to be\nprocessed together to encode both spatial and temporal information. This paper\nproposes two 3D-CNN methods: MicroExpSTCNN and MicroExpFuseNet, for spontaneous\nfacial micro-expression recognition by exploiting the spatiotemporal\ninformation in CNN framework. The MicroExpSTCNN considers the full spatial\ninformation, whereas the MicroExpFuseNet is based on the 3D-CNN feature fusion\nof the eyes and mouth regions. The experiments are performed over CAS(ME)^2 and\nSMIC micro-expression databases. The proposed MicroExpSTCNN model outperforms\nthe state-of-the-art methods.\n",
        "published": "2019",
        "authors": [
            "Sai Prasanna Teja Reddy",
            "Surya Teja Karri",
            "Shiv Ram Dubey",
            "Snehasis Mukherjee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.03816v1",
        "title": "Towards Real-Time Automatic Portrait Matting on Mobile Devices",
        "abstract": "  We tackle the problem of automatic portrait matting on mobile devices. The\nproposed model is aimed at attaining real-time inference on mobile devices with\nminimal degradation of model performance. Our model MMNet, based on\nmulti-branch dilated convolution with linear bottleneck blocks, outperforms the\nstate-of-the-art model and is orders of magnitude faster. The model can be\naccelerated four times to attain 30 FPS on Xiaomi Mi 5 device with moderate\nincrease in the gradient error. Under the same conditions, our model has an\norder of magnitude less number of parameters and is faster than Mobile\nDeepLabv3 while maintaining comparable performance. The accompanied\nimplementation can be found at \\url{https://github.com/hyperconnect/MMNet}.\n",
        "published": "2019",
        "authors": [
            "Seokjun Seo",
            "Seungwoo Choi",
            "Martin Kersner",
            "Beomjun Shin",
            "Hyungsuk Yoon",
            "Hyeongmin Byun",
            "Sungjoo Ha"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.04175v1",
        "title": "AI in the media and creative industries",
        "abstract": "  Thanks to the Big Data revolution and increasing computing capacities,\nArtificial Intelligence (AI) has made an impressive revival over the past few\nyears and is now omnipresent in both research and industry. The creative\nsectors have always been early adopters of AI technologies and this continues\nto be the case. As a matter of fact, recent technological developments keep\npushing the boundaries of intelligent systems in creative applications: the\ncritically acclaimed movie \"Sunspring\", released in 2016, was entirely written\nby AI technology, and the first-ever Music Album, called \"Hello World\",\nproduced using AI has been released this year. Simultaneously, the exploratory\nnature of the creative process is raising important technical challenges for AI\nsuch as the ability for AI-powered techniques to be accurate under limited data\nresources, as opposed to the conventional \"Big Data\" approach, or the ability\nto process, analyse and match data from multiple modalities (text, sound,\nimages, etc.) at the same time. The purpose of this white paper is to\nunderstand future technological advances in AI and their growing impact on\ncreative industries. This paper addresses the following questions: Where does\nAI operate in creative Industries? What is its operative role? How will AI\ntransform creative industries in the next ten years? This white paper aims to\nprovide a realistic perspective of the scope of AI actions in creative\nindustries, proposes a vision of how this technology could contribute to\nresearch and development works in such context, and identifies research and\ndevelopment challenges.\n",
        "published": "2019",
        "authors": [
            "Giuseppe Amato",
            "Malte Behrmann",
            "Fr\u00e9d\u00e9ric Bimbot",
            "Baptiste Caramiaux",
            "Fabrizio Falchi",
            "Ander Garcia",
            "Joost Geurts",
            "Jaume Gibert",
            "Guillaume Gravier",
            "Hadmut Holken",
            "Hartmut Koenitz",
            "Sylvain Lefebvre",
            "Antoine Liutkus",
            "Fabien Lotte",
            "Andrew Perkis",
            "Rafael Redondo",
            "Enrico Turrin",
            "Thierry Vieville",
            "Emmanuel Vincent"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.01558v2",
        "title": "Disentangling neural mechanisms for perceptual grouping",
        "abstract": "  Forming perceptual groups and individuating objects in visual scenes is an\nessential step towards visual intelligence. This ability is thought to arise in\nthe brain from computations implemented by bottom-up, horizontal, and top-down\nconnections between neurons. However, the relative contributions of these\nconnections to perceptual grouping are poorly understood. We address this\nquestion by systematically evaluating neural network architectures featuring\ncombinations bottom-up, horizontal, and top-down connections on two synthetic\nvisual tasks, which stress low-level \"Gestalt\" vs. high-level object cues for\nperceptual grouping. We show that increasing the difficulty of either task\nstrains learning for networks that rely solely on bottom-up connections.\nHorizontal connections resolve straining on tasks with Gestalt cues by\nsupporting incremental grouping, whereas top-down connections rescue learning\non tasks with high-level object cues by modifying coarse predictions about the\nposition of the target object. Our findings dissociate the computational roles\nof bottom-up, horizontal and top-down connectivity, and demonstrate how a model\nfeaturing all of these interactions can more flexibly learn to form perceptual\ngroups.\n",
        "published": "2019",
        "authors": [
            "Junkyung Kim",
            "Drew Linsley",
            "Kalpit Thakkar",
            "Thomas Serre"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1911.13135v3",
        "title": "Radon Sobolev Variational Auto-Encoders",
        "abstract": "  The quality of generative models (such as Generative adversarial networks and\nVariational Auto-Encoders) depends heavily on the choice of a good probability\ndistance. However some popular metrics like the Wasserstein or the Sliced\nWasserstein distances, the Jensen-Shannon divergence, the Kullback-Leibler\ndivergence, lack convenient properties such as (geodesic) convexity, fast\nevaluation and so on. To address these shortcomings, we introduce a class of\ndistances that have built-in convexity. We investigate the relationship with\nsome known paradigms (sliced distances - a synonym for Radon distances -,\nreproducing kernel Hilbert spaces, energy distances). The distances are shown\nto possess fast implementations and are included in an adapted Variational\nAuto-Encoder termed Radon Sobolev Variational Auto-Encoder (RS-VAE) which\nproduces high quality results on standard generative datasets.\n  Keywords: Variational Auto-Encoder; Generative model; Sobolev spaces; Radon\nSobolev Variational Auto-Encoder;\n",
        "published": "2019",
        "authors": [
            "Gabriel Turinici"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2002.02210v3",
        "title": "From Data to Actions in Intelligent Transportation Systems: a\n  Prescription of Functional Requirements for Model Actionability",
        "abstract": "  Advances in Data Science permeate every field of Transportation Science and\nEngineering, resulting in developments in the transportation sector that {are}\ndata-driven. Nowadays, Intelligent Transportation Systems (ITS) could be\narguably approached as a ``story'' intensively producing and consuming large\namounts of data. A~diversity of sensing devices densely spread over the\ninfrastructure, vehicles or the travelers' personal devices act as sources of\ndata flows that are eventually fed {into} software running on automatic\ndevices, actuators or control systems producing, in~turn, complex information\nflows {among} users, traffic managers, data analysts, traffic modeling\nscientists, etc. These~information flows provide enormous opportunities to\nimprove model development and decision-making. This work aims to describe how\ndata, coming from diverse ITS sources, can be used to learn and adapt\ndata-driven models for efficiently operating ITS assets, systems and processes;\nin~other words, for data-based models to fully become \\emph{actionable}.\nGrounded in this described data modeling pipeline for ITS, we~define the\ncharacteristics, engineering requisites and challenges intrinsic to its three\ncompounding stages, namely, data fusion, adaptive learning and model\nevaluation. We~deliberately generalize model learning to be adaptive, since,\nin~the core of our paper is the firm conviction that most learners will have to\nadapt to the ever-changing phenomenon scenario underlying the majority of ITS\napplications. Finally, we~provide a prospect of current research lines within\nData Science that can bring notable advances to data-based ITS modeling, which\nwill eventually bridge the gap towards the practicality and actionability of\nsuch models.\n",
        "published": "2020",
        "authors": [
            "Ibai Lana",
            "Javier J. Sanchez-Medina",
            "Eleni I. Vlahogianni",
            "Javier Del Ser"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.03863v1",
        "title": "TanhSoft -- a family of activation functions combining Tanh and Softplus",
        "abstract": "  Deep learning at its core, contains functions that are composition of a\nlinear transformation with a non-linear function known as activation function.\nIn past few years, there is an increasing interest in construction of novel\nactivation functions resulting in better learning. In this work, we propose a\nfamily of novel activation functions, namely TanhSoft, with four undetermined\nhyper-parameters of the form\ntanh({\\alpha}x+{\\beta}e^{{\\gamma}x})ln({\\delta}+e^x) and tune these\nhyper-parameters to obtain activation functions which are shown to outperform\nseveral well known activation functions. For instance, replacing ReLU with\nxtanh(0.6e^x)improves top-1 classification accuracy on CIFAR-10 by 0.46% for\nDenseNet-169 and 0.7% for Inception-v3 while with tanh(0.87x)ln(1 +e^x) top-1\nclassification accuracy on CIFAR-100 improves by 1.24% for DenseNet-169 and\n2.57% for SimpleNet model.\n",
        "published": "2020",
        "authors": [
            "Koushik Biswas",
            "Sandeep Kumar",
            "Shilpak Banerjee",
            "Ashish Kumar Pandey"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.08497v1",
        "title": "The Next Big Thing(s) in Unsupervised Machine Learning: Five Lessons\n  from Infant Learning",
        "abstract": "  After a surge in popularity of supervised Deep Learning, the desire to reduce\nthe dependence on curated, labelled data sets and to leverage the vast\nquantities of unlabelled data available recently triggered renewed interest in\nunsupervised learning algorithms. Despite a significantly improved performance\ndue to approaches such as the identification of disentangled latent\nrepresentations, contrastive learning, and clustering optimisations, the\nperformance of unsupervised machine learning still falls short of its\nhypothesised potential. Machine learning has previously taken inspiration from\nneuroscience and cognitive science with great success. However, this has mostly\nbeen based on adult learners with access to labels and a vast amount of prior\nknowledge. In order to push unsupervised machine learning forward, we argue\nthat developmental science of infant cognition might hold the key to unlocking\nthe next generation of unsupervised learning approaches. Conceptually, human\ninfant learning is the closest biological parallel to artificial unsupervised\nlearning, as infants too must learn useful representations from unlabelled\ndata. In contrast to machine learning, these new representations are learned\nrapidly and from relatively few examples. Moreover, infants learn robust\nrepresentations that can be used flexibly and efficiently in a number of\ndifferent tasks and contexts. We identify five crucial factors enabling\ninfants' quality and speed of learning, assess the extent to which these have\nalready been exploited in machine learning, and propose how further adoption of\nthese factors can give rise to previously unseen performance levels in\nunsupervised learning.\n",
        "published": "2020",
        "authors": [
            "Lorijn Zaadnoordijk",
            "Tarek R. Besold",
            "Rhodri Cusack"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2011.12930v2",
        "title": "Unsupervised Object Keypoint Learning using Local Spatial Predictability",
        "abstract": "  We propose PermaKey, a novel approach to representation learning based on\nobject keypoints. It leverages the predictability of local image regions from\nspatial neighborhoods to identify salient regions that correspond to object\nparts, which are then converted to keypoints. Unlike prior approaches, it\nutilizes predictability to discover object keypoints, an intrinsic property of\nobjects. This ensures that it does not overly bias keypoints to focus on\ncharacteristics that are not unique to objects, such as movement, shape, colour\netc. We demonstrate the efficacy of PermaKey on Atari where it learns keypoints\ncorresponding to the most salient object parts and is robust to certain visual\ndistractors. Further, on downstream RL tasks in the Atari domain we demonstrate\nhow agents equipped with our keypoints outperform those using competing\nalternatives, even on challenging environments with moving backgrounds or\ndistractor objects.\n",
        "published": "2020",
        "authors": [
            "Anand Gopalakrishnan",
            "Sjoerd van Steenkiste",
            "J\u00fcrgen Schmidhuber"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.00596v3",
        "title": "NPAS: A Compiler-aware Framework of Unified Network Pruning and\n  Architecture Search for Beyond Real-Time Mobile Acceleration",
        "abstract": "  With the increasing demand to efficiently deploy DNNs on mobile edge devices,\nit becomes much more important to reduce unnecessary computation and increase\nthe execution speed. Prior methods towards this goal, including model\ncompression and network architecture search (NAS), are largely performed\nindependently and do not fully consider compiler-level optimizations which is a\nmust-do for mobile acceleration. In this work, we first propose (i) a general\ncategory of fine-grained structured pruning applicable to various DNN layers,\nand (ii) a comprehensive, compiler automatic code generation framework\nsupporting different DNNs and different pruning schemes, which bridge the gap\nof model compression and NAS. We further propose NPAS, a compiler-aware unified\nnetwork pruning, and architecture search. To deal with large search space, we\npropose a meta-modeling procedure based on reinforcement learning with fast\nevaluation and Bayesian optimization, ensuring the total number of training\nepochs comparable with representative NAS frameworks. Our framework achieves\n6.7ms, 5.9ms, 3.9ms ImageNet inference times with 78.2%, 75% (MobileNet-V3\nlevel), and 71% (MobileNet-V2 level) Top-1 accuracy respectively on an\noff-the-shelf mobile phone, consistently outperforming prior work.\n",
        "published": "2020",
        "authors": [
            "Zhengang Li",
            "Geng Yuan",
            "Wei Niu",
            "Pu Zhao",
            "Yanyu Li",
            "Yuxuan Cai",
            "Xuan Shen",
            "Zheng Zhan",
            "Zhenglun Kong",
            "Qing Jin",
            "Zhiyu Chen",
            "Sijia Liu",
            "Kaiyuan Yang",
            "Bin Ren",
            "Yanzhi Wang",
            "Xue Lin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.02909v3",
        "title": "What Makes a \"Good\" Data Augmentation in Knowledge Distillation -- A\n  Statistical Perspective",
        "abstract": "  Knowledge distillation (KD) is a general neural network training approach\nthat uses a teacher model to guide the student model. Existing works mainly\nstudy KD from the network output side (e.g., trying to design a better KD loss\nfunction), while few have attempted to understand it from the input side.\nEspecially, its interplay with data augmentation (DA) has not been well\nunderstood. In this paper, we ask: Why do some DA schemes (e.g., CutMix)\ninherently perform much better than others in KD? What makes a \"good\" DA in KD?\nOur investigation from a statistical perspective suggests that a good DA scheme\nshould reduce the covariance of the teacher-student cross-entropy. A practical\nmetric, the stddev of teacher's mean probability (T. stddev), is further\npresented and well justified empirically. Besides the theoretical\nunderstanding, we also introduce a new entropy-based data-mixing DA scheme,\nCutMixPick, to further enhance CutMix. Extensive empirical studies support our\nclaims and demonstrate how we can harvest considerable performance gains simply\nby using a better DA scheme in knowledge distillation.\n",
        "published": "2020",
        "authors": [
            "Huan Wang",
            "Suhas Lohit",
            "Mike Jones",
            "Yun Fu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.02911v1",
        "title": "Multi-head Knowledge Distillation for Model Compression",
        "abstract": "  Several methods of knowledge distillation have been developed for neural\nnetwork compression. While they all use the KL divergence loss to align the\nsoft outputs of the student model more closely with that of the teacher, the\nvarious methods differ in how the intermediate features of the student are\nencouraged to match those of the teacher. In this paper, we propose a\nsimple-to-implement method using auxiliary classifiers at intermediate layers\nfor matching features, which we refer to as multi-head knowledge distillation\n(MHKD). We add loss terms for training the student that measure the\ndissimilarity between student and teacher outputs of the auxiliary classifiers.\nAt the same time, the proposed method also provides a natural way to measure\ndifferences at the intermediate layers even though the dimensions of the\ninternal teacher and student features may be different. Through several\nexperiments in image classification on multiple datasets we show that the\nproposed method outperforms prior relevant approaches presented in the\nliterature.\n",
        "published": "2020",
        "authors": [
            "Huan Wang",
            "Suhas Lohit",
            "Michael Jones",
            "Yun Fu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.09243v2",
        "title": "Neural Pruning via Growing Regularization",
        "abstract": "  Regularization has long been utilized to learn sparsity in deep neural\nnetwork pruning. However, its role is mainly explored in the small penalty\nstrength regime. In this work, we extend its application to a new scenario\nwhere the regularization grows large gradually to tackle two central problems\nof pruning: pruning schedule and weight importance scoring. (1) The former\ntopic is newly brought up in this work, which we find critical to the pruning\nperformance while receives little research attention. Specifically, we propose\nan L2 regularization variant with rising penalty factors and show it can bring\nsignificant accuracy gains compared with its one-shot counterpart, even when\nthe same weights are removed. (2) The growing penalty scheme also brings us an\napproach to exploit the Hessian information for more accurate pruning without\nknowing their specific values, thus not bothered by the common Hessian\napproximation problems. Empirically, the proposed algorithms are easy to\nimplement and scalable to large datasets and networks in both structured and\nunstructured pruning. Their effectiveness is demonstrated with modern deep\nneural networks on the CIFAR and ImageNet datasets, achieving competitive\nresults compared to many state-of-the-art algorithms. Our code and trained\nmodels are publicly available at\nhttps://github.com/mingsuntse/regularization-pruning.\n",
        "published": "2020",
        "authors": [
            "Huan Wang",
            "Can Qin",
            "Yulun Zhang",
            "Yun Fu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.13628v1",
        "title": "A Simple Fine-tuning Is All You Need: Towards Robust Deep Learning Via\n  Adversarial Fine-tuning",
        "abstract": "  Adversarial Training (AT) with Projected Gradient Descent (PGD) is an\neffective approach for improving the robustness of the deep neural networks.\nHowever, PGD AT has been shown to suffer from two main limitations: i) high\ncomputational cost, and ii) extreme overfitting during training that leads to\nreduction in model generalization. While the effect of factors such as model\ncapacity and scale of training data on adversarial robustness have been\nextensively studied, little attention has been paid to the effect of a very\nimportant parameter in every network optimization on adversarial robustness:\nthe learning rate. In particular, we hypothesize that effective learning rate\nscheduling during adversarial training can significantly reduce the overfitting\nissue, to a degree where one does not even need to adversarially train a model\nfrom scratch but can instead simply adversarially fine-tune a pre-trained\nmodel. Motivated by this hypothesis, we propose a simple yet very effective\nadversarial fine-tuning approach based on a $\\textit{slow start, fast decay}$\nlearning rate scheduling strategy which not only significantly decreases\ncomputational cost required, but also greatly improves the accuracy and\nrobustness of a deep neural network. Experimental results show that the\nproposed adversarial fine-tuning approach outperforms the state-of-the-art\nmethods on CIFAR-10, CIFAR-100 and ImageNet datasets in both test accuracy and\nthe robustness, while reducing the computational cost by 8-10$\\times$.\nFurthermore, a very important benefit of the proposed adversarial fine-tuning\napproach is that it enables the ability to improve the robustness of any\npre-trained deep neural network without needing to train the model from\nscratch, which to the best of the authors' knowledge has not been previously\ndemonstrated in research literature.\n",
        "published": "2020",
        "authors": [
            "Ahmadreza Jeddi",
            "Mohammad Javad Shafiee",
            "Alexander Wong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.01345v1",
        "title": "Fast Exploration of Weight Sharing Opportunities for CNN Compression",
        "abstract": "  The computational workload involved in Convolutional Neural Networks (CNNs)\nis typically out of reach for low-power embedded devices. There are a large\nnumber of approximation techniques to address this problem. These methods have\nhyper-parameters that need to be optimized for each CNNs using design space\nexploration (DSE). The goal of this work is to demonstrate that the DSE phase\ntime can easily explode for state of the art CNN. We thus propose the use of an\noptimized exploration process to drastically reduce the exploration time\nwithout sacrificing the quality of the output.\n",
        "published": "2021",
        "authors": [
            "Etienne Dupuis",
            "David Novo",
            "Ian O'Connor",
            "Alberto Bosio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.01355v1",
        "title": "Mining Feature Relationships in Data",
        "abstract": "  When faced with a new dataset, most practitioners begin by performing\nexploratory data analysis to discover interesting patterns and characteristics\nwithin data. Techniques such as association rule mining are commonly applied to\nuncover relationships between features (attributes) of the data. However,\nassociation rules are primarily designed for use on binary or categorical data,\ndue to their use of rule-based machine learning. A large proportion of\nreal-world data is continuous in nature, and discretisation of such data leads\nto inaccurate and less informative association rules. In this paper, we propose\nan alternative approach called feature relationship mining (FRM), which uses a\ngenetic programming approach to automatically discover symbolic relationships\nbetween continuous or categorical features in data. To the best of our\nknowledge, our proposed approach is the first such symbolic approach with the\ngoal of explicitly discovering relationships between features. Empirical\ntesting on a variety of real-world datasets shows the proposed method is able\nto find high-quality, simple feature relationships which can be easily\ninterpreted and which provide clear and non-trivial insight into data.\n",
        "published": "2021",
        "authors": [
            "Andrew Lensen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.05451v1",
        "title": "Two Novel Performance Improvements for Evolving CNN Topologies",
        "abstract": "  Convolutional Neural Networks (CNNs) are the state-of-the-art algorithms for\nthe processing of images. However the configuration and training of these\nnetworks is a complex task requiring deep domain knowledge, experience and much\ntrial and error. Using genetic algorithms, competitive CNN topologies for image\nrecognition can be produced for any specific purpose, however in previous work\nthis has come at high computational cost. In this work two novel approaches are\npresented to the utilisation of these algorithms, effective in reducing\ncomplexity and training time by nearly 20%. This is accomplished via\nregularisation directly on training time, and the use of partial training to\nenable early ranking of individual architectures. Both approaches are validated\non the benchmark CIFAR10 data set, and maintain accuracy.\n",
        "published": "2021",
        "authors": [
            "Yaron Strauch",
            "Jo Grundy"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.08634v1",
        "title": "On the Post-hoc Explainability of Deep Echo State Networks for Time\n  Series Forecasting, Image and Video Classification",
        "abstract": "  Since their inception, learning techniques under the Reservoir Computing\nparadigm have shown a great modeling capability for recurrent systems without\nthe computing overheads required for other approaches. Among them, different\nflavors of echo state networks have attracted many stares through time, mainly\ndue to the simplicity and computational efficiency of their learning algorithm.\nHowever, these advantages do not compensate for the fact that echo state\nnetworks remain as black-box models whose decisions cannot be easily explained\nto the general audience. This work addresses this issue by conducting an\nexplainability study of Echo State Networks when applied to learning tasks with\ntime series, image and video data. Specifically, the study proposes three\ndifferent techniques capable of eliciting understandable information about the\nknowledge grasped by these recurrent models, namely, potential memory, temporal\npatterns and pixel absence effect. Potential memory addresses questions related\nto the effect of the reservoir size in the capability of the model to store\ntemporal information, whereas temporal patterns unveils the recurrent\nrelationships captured by the model over time. Finally, pixel absence effect\nattempts at evaluating the effect of the absence of a given pixel when the echo\nstate network model is used for image and video classification. We showcase the\nbenefits of our proposed suite of techniques over three different domains of\napplicability: time series modeling, image and, for the first time in the\nrelated literature, video classification. Our results reveal that the proposed\ntechniques not only allow for a informed understanding of the way these models\nwork, but also serve as diagnostic tools capable of detecting issues inherited\nfrom data (e.g. presence of hidden bias).\n",
        "published": "2021",
        "authors": [
            "Alejandro Barredo Arrieta",
            "Sergio Gil-Lopez",
            "Ibai La\u00f1a",
            "Miren Nekane Bilbao",
            "Javier Del Ser"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2103.01205v3",
        "title": "Statistically Significant Stopping of Neural Network Training",
        "abstract": "  The general approach taken when training deep learning classifiers is to save\nthe parameters after every few iterations, train until either a human observer\nor a simple metric-based heuristic decides the network isn't learning anymore,\nand then backtrack and pick the saved parameters with the best validation\naccuracy. Simple methods are used to determine if a neural network isn't\nlearning anymore because, as long as it's well after the optimal values are\nfound, the condition doesn't impact the final accuracy of the model. However\nfrom a runtime perspective, this is of great significance to the many cases\nwhere numerous neural networks are trained simultaneously (e.g. hyper-parameter\ntuning). Motivated by this, we introduce a statistical significance test to\ndetermine if a neural network has stopped learning. This stopping criterion\nappears to represent a happy medium compared to other popular stopping\ncriterions, achieving comparable accuracy to the criterions that achieve the\nhighest final accuracies in 77% or fewer epochs, while the criterions which\nstop sooner do so with an appreciable loss to final accuracy. Additionally, we\nuse this as the basis of a new learning rate scheduler, removing the need to\nmanually choose learning rate schedules and acting as a quasi-line search,\nachieving superior or comparable empirical performance to existing methods.\n",
        "published": "2021",
        "authors": [
            "J. K. Terry",
            "Mario Jayakumar",
            "Kusal De Alwis"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2103.03060v1",
        "title": "BM3D vs 2-Layer ONN",
        "abstract": "  Despite their recent success on image denoising, the need for deep and\ncomplex architectures still hinders the practical usage of CNNs. Older but\ncomputationally more efficient methods such as BM3D remain a popular choice,\nespecially in resource-constrained scenarios. In this study, we aim to find out\nwhether compact neural networks can learn to produce competitive results as\ncompared to BM3D for AWGN image denoising. To this end, we configure networks\nwith only two hidden layers and employ different neuron models and layer widths\nfor comparing the performance with BM3D across different AWGN noise levels. Our\nresults conclusively show that the recently proposed self-organized variant of\noperational neural networks based on a generative neuron model (Self-ONNs) is\nnot only a better choice as compared to CNNs, but also provide competitive\nresults as compared to BM3D and even significantly surpass it for high noise\nlevels.\n",
        "published": "2021",
        "authors": [
            "Junaid Malik",
            "Serkan Kiranyaz",
            "Mehmet Yamac",
            "Moncef Gabbouj"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2103.06460v3",
        "title": "Recent Advances on Neural Network Pruning at Initialization",
        "abstract": "  Neural network pruning typically removes connections or neurons from a\npretrained converged model; while a new pruning paradigm, pruning at\ninitialization (PaI), attempts to prune a randomly initialized network. This\npaper offers the first survey concentrated on this emerging pruning fashion. We\nfirst introduce a generic formulation of neural network pruning, followed by\nthe major classic pruning topics. Then, as the main body of this paper, a\nthorough and structured literature review of PaI methods is presented,\nconsisting of two major tracks (sparse training and sparse selection). Finally,\nwe summarize the surge of PaI compared to PaT and discuss the open problems.\nApart from the dedicated literature review, this paper also offers a code base\nfor easy sanity-checking and benchmarking of different PaI methods.\n",
        "published": "2021",
        "authors": [
            "Huan Wang",
            "Can Qin",
            "Yue Bai",
            "Yulun Zhang",
            "Yun Fu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.01862v2",
        "title": "Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural\n  Networks",
        "abstract": "  The field of neuromorphic computing promises extremely low-power and\nlow-latency sensing and processing. Challenges in transferring learning\nalgorithms from traditional artificial neural networks (ANNs) to spiking neural\nnetworks (SNNs) have so far prevented their application to large-scale, complex\nregression tasks. Furthermore, realizing a truly asynchronous and fully\nneuromorphic pipeline that maximally attains the abovementioned benefits\ninvolves rethinking the way in which this pipeline takes in and accumulates\ninformation. In the case of perception, spikes would be passed as-is and\none-by-one between an event camera and an SNN, meaning all temporal integration\nof information must happen inside the network. In this article, we tackle these\ntwo problems. We focus on the complex task of learning to estimate optical flow\nfrom event-based camera inputs in a self-supervised manner, and modify the\nstate-of-the-art ANN training pipeline to encode minimal temporal information\nin its inputs. Moreover, we reformulate the self-supervised loss function for\nevent-based optical flow to improve its convexity. We perform experiments with\nvarious types of recurrent ANNs and SNNs using the proposed pipeline.\nConcerning SNNs, we investigate the effects of elements such as parameter\ninitialization and optimization, surrogate gradient shape, and adaptive\nneuronal mechanisms. We find that initialization and surrogate gradient width\nplay a crucial part in enabling learning with sparse inputs, while the\ninclusion of adaptivity and learnable neuronal parameters can improve\nperformance. We show that the performance of the proposed ANNs and SNNs are on\npar with that of the current state-of-the-art ANNs trained in a self-supervised\nmanner.\n",
        "published": "2021",
        "authors": [
            "Jesse Hagenaars",
            "Federico Paredes-Vall\u00e9s",
            "Guido de Croon"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.01920v1",
        "title": "Convolutional Neural Network(CNN/ConvNet) in Stock Price Movement\n  Prediction",
        "abstract": "  With technological advancements and the exponential growth of data, we have\nbeen unfolding different capabilities of neural networks in different sectors.\nIn this paper, I have tried to use a specific type of Neural Network known as\nConvolutional Neural Network(CNN/ConvNet) in the stock market. In other words,\nI have tried to construct and train a convolutional neural network on past\nstock prices data and then tried to predict the movement of stock price i.e.\nwhether the stock price would rise or fall, in the coming time.\n",
        "published": "2021",
        "authors": [
            "Kunal Bhardwaj"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.02328v1",
        "title": "Temporally coherent video anonymization through GAN inpainting",
        "abstract": "  This work tackles the problem of temporally coherent face anonymization in\nnatural video streams.We propose JaGAN, a two-stage system starting with\ndetecting and masking out faces with black image patches in all individual\nframes of the video. The second stage leverages a privacy-preserving Video\nGenerative Adversarial Network designed to inpaint the missing image patches\nwith artificially generated faces. Our initial experiments reveal that image\nbased generative models are not capable of inpainting patches showing temporal\ncoherent appearance across neighboring video frames. To address this issue we\nintroduce a newly curated video collection, which is made publicly available\nfor the research community along with this paper. We also introduce the\nIdentity Invariance Score IdI as a means to quantify temporal coherency between\nneighboring frames.\n",
        "published": "2021",
        "authors": [
            "Thangapavithraa Balaji",
            "Patrick Blies",
            "Georg G\u00f6ri",
            "Raphael Mitsch",
            "Marcel Wasserer",
            "Torsten Sch\u00f6n"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.07091v1",
        "title": "On-Off Center-Surround Receptive Fields for Accurate and Robust Image\n  Classification",
        "abstract": "  Robustness to variations in lighting conditions is a key objective for any\ndeep vision system. To this end, our paper extends the receptive field of\nconvolutional neural networks with two residual components, ubiquitous in the\nvisual processing system of vertebrates: On-center and off-center pathways,\nwith excitatory center and inhibitory surround; OOCS for short. The on-center\npathway is excited by the presence of a light stimulus in its center but not in\nits surround, whereas the off-center one is excited by the absence of a light\nstimulus in its center but not in its surround. We design OOCS pathways via a\ndifference of Gaussians, with their variance computed analytically from the\nsize of the receptive fields. OOCS pathways complement each other in their\nresponse to light stimuli, ensuring this way a strong edge-detection\ncapability, and as a result, an accurate and robust inference under challenging\nlighting conditions. We provide extensive empirical evidence showing that\nnetworks supplied with the OOCS edge representation gain accuracy and\nillumination-robustness compared to standard deep models.\n",
        "published": "2021",
        "authors": [
            "Zahra Babaiee",
            "Ramin Hasani",
            "Mathias Lechner",
            "Daniela Rus",
            "Radu Grosu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.09693v1",
        "title": "Orthogonal-Pad\u00e9 Activation Functions: Trainable Activation functions\n  for smooth and faster convergence in deep networks",
        "abstract": "  We have proposed orthogonal-Pad\\'e activation functions, which are trainable\nactivation functions and show that they have faster learning capability and\nimproves the accuracy in standard deep learning datasets and models. Based on\nour experiments, we have found two best candidates out of six orthogonal-Pad\\'e\nactivations, which we call safe Hermite-Pade (HP) activation functions, namely\nHP-1 and HP-2. When compared to ReLU, HP-1 and HP-2 has an increment in top-1\naccuracy by 5.06% and 4.63% respectively in PreActResNet-34, by 3.02% and 2.75%\nrespectively in MobileNet V2 model on CIFAR100 dataset while on CIFAR10 dataset\ntop-1 accuracy increases by 2.02% and 1.78% respectively in PreActResNet-34, by\n2.24% and 2.06% respectively in LeNet, by 2.15% and 2.03% respectively in\nEfficientnet B0.\n",
        "published": "2021",
        "authors": [
            "Koushik Biswas",
            "Shilpak Banerjee",
            "Ashish Kumar Pandey"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.09857v3",
        "title": "Effective Model Sparsification by Scheduled Grow-and-Prune Methods",
        "abstract": "  Deep neural networks (DNNs) are effective in solving many real-world\nproblems. Larger DNN models usually exhibit better quality (e.g., accuracy) but\ntheir excessive computation results in long inference time. Model\nsparsification can reduce the computation and memory cost while maintaining\nmodel quality. Most existing sparsification algorithms unidirectionally remove\nweights, while others randomly or greedily explore a small subset of weights in\neach layer for pruning. The limitations of these algorithms reduce the level of\nachievable sparsity. In addition, many algorithms still require pre-trained\ndense models and thus suffer from large memory footprint. In this paper, we\npropose a novel scheduled grow-and-prune (GaP) methodology without having to\npre-train a dense model. It addresses the shortcomings of the previous works by\nrepeatedly growing a subset of layers to dense and then pruning them back to\nsparse after some training. Experiments show that the models pruned using the\nproposed methods match or beat the quality of the highly optimized dense models\nat 80% sparsity on a variety of tasks, such as image classification, objective\ndetection, 3D object part segmentation, and translation. They also outperform\nother state-of-the-art (SOTA) methods for model sparsification. As an example,\na 90% non-uniform sparse ResNet-50 model obtained via GaP achieves 77.9% top-1\naccuracy on ImageNet, improving the previous SOTA results by 1.5%. Code\navailable at: https://github.com/boone891214/GaP.\n",
        "published": "2021",
        "authors": [
            "Xiaolong Ma",
            "Minghai Qin",
            "Fei Sun",
            "Zejiang Hou",
            "Kun Yuan",
            "Yi Xu",
            "Yanzhi Wang",
            "Yen-Kuang Chen",
            "Rong Jin",
            "Yuan Xie"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.10944v2",
        "title": "Hard hat wearing detection based on head keypoint localization",
        "abstract": "  In recent years, a lot of attention is paid to deep learning methods in the\ncontext of vision-based construction site safety systems, especially regarding\npersonal protective equipment. However, despite all this attention, there is\nstill no reliable way to establish the relationship between workers and their\nhard hats. To answer this problem a combination of deep learning, object\ndetection and head keypoint localization, with simple rule-based reasoning is\nproposed in this article. In tests, this solution surpassed the previous\nmethods based on the relative bounding box position of different instances, as\nwell as direct detection of hard hat wearers and non-wearers. The results show\nthat the conjunction of novel deep learning methods with humanly-interpretable\nrule-based systems can result in a solution that is both reliable and can\nsuccessfully mimic manual, on-site supervision. This work is the next step in\nthe development of fully autonomous construction site safety systems and shows\nthat there is still room for improvement in this area.\n",
        "published": "2021",
        "authors": [
            "Bartosz W\u00f3jcik",
            "Mateusz \u017barski",
            "Kamil Ksi\u0105\u017cek",
            "Jaros\u0142aw Adam Miszczak",
            "Miros\u0142aw Jan Skibniewski"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.12499v1",
        "title": "Generative Self-training for Cross-domain Unsupervised Tagged-to-Cine\n  MRI Synthesis",
        "abstract": "  Self-training based unsupervised domain adaptation (UDA) has shown great\npotential to address the problem of domain shift, when applying a trained deep\nlearning model in a source domain to unlabeled target domains. However, while\nthe self-training UDA has demonstrated its effectiveness on discriminative\ntasks, such as classification and segmentation, via the reliable pseudo-label\nselection based on the softmax discrete histogram, the self-training UDA for\ngenerative tasks, such as image synthesis, is not fully investigated. In this\nwork, we propose a novel generative self-training (GST) UDA framework with\ncontinuous value prediction and regression objective for cross-domain image\nsynthesis. Specifically, we propose to filter the pseudo-label with an\nuncertainty mask, and quantify the predictive confidence of generated images\nwith practical variational Bayes learning. The fast test-time adaptation is\nachieved by a round-based alternative optimization scheme. We validated our\nframework on the tagged-to-cine magnetic resonance imaging (MRI) synthesis\nproblem, where datasets in the source and target domains were acquired from\ndifferent scanners or centers. Extensive validations were carried out to verify\nour framework against popular adversarial training UDA methods. Results show\nthat our GST, with tagged MRI of test subjects in new target domains, improved\nthe synthesis quality by a large margin, compared with the adversarial training\nUDA methods.\n",
        "published": "2021",
        "authors": [
            "Xiaofeng Liu",
            "Fangxu Xing",
            "Maureen Stone",
            "Jiachen Zhuo",
            "Reese Timothy",
            "Jerry L. Prince",
            "Georges El Fakhri",
            "Jonghye Woo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2108.01899v2",
        "title": "Generic Neural Architecture Search via Regression",
        "abstract": "  Most existing neural architecture search (NAS) algorithms are dedicated to\nand evaluated by the downstream tasks, e.g., image classification in computer\nvision. However, extensive experiments have shown that, prominent neural\narchitectures, such as ResNet in computer vision and LSTM in natural language\nprocessing, are generally good at extracting patterns from the input data and\nperform well on different downstream tasks. In this paper, we attempt to answer\ntwo fundamental questions related to NAS. (1) Is it necessary to use the\nperformance of specific downstream tasks to evaluate and search for good neural\narchitectures? (2) Can we perform NAS effectively and efficiently while being\nagnostic to the downstream tasks? To answer these questions, we propose a novel\nand generic NAS framework, termed Generic NAS (GenNAS). GenNAS does not use\ntask-specific labels but instead adopts regression on a set of manually\ndesigned synthetic signal bases for architecture evaluation. Such a\nself-supervised regression task can effectively evaluate the intrinsic power of\nan architecture to capture and transform the input signal patterns, and allow\nmore sufficient usage of training samples. Extensive experiments across 13 CNN\nsearch spaces and one NLP space demonstrate the remarkable efficiency of GenNAS\nusing regression, in terms of both evaluating the neural architectures\n(quantified by the ranking correlation Spearman's rho between the approximated\nperformances and the downstream task performances) and the convergence speed\nfor training (within a few seconds).\n",
        "published": "2021",
        "authors": [
            "Yuhong Li",
            "Cong Hao",
            "Pan Li",
            "Jinjun Xiong",
            "Deming Chen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2108.09598v3",
        "title": "SERF: Towards better training of deep neural networks using log-Softplus\n  ERror activation Function",
        "abstract": "  Activation functions play a pivotal role in determining the training dynamics\nand neural network performance. The widely adopted activation function ReLU\ndespite being simple and effective has few disadvantages including the Dying\nReLU problem. In order to tackle such problems, we propose a novel activation\nfunction called Serf which is self-regularized and nonmonotonic in nature. Like\nMish, Serf also belongs to the Swish family of functions. Based on several\nexperiments on computer vision (image classification and object detection) and\nnatural language processing (machine translation, sentiment classification and\nmultimodal entailment) tasks with different state-of-the-art architectures, it\nis observed that Serf vastly outperforms ReLU (baseline) and other activation\nfunctions including both Swish and Mish, with a markedly bigger margin on\ndeeper architectures. Ablation studies further demonstrate that Serf based\narchitectures perform better than those of Swish and Mish in varying scenarios,\nvalidating the effectiveness and compatibility of Serf with varying depth,\ncomplexity, optimizers, learning rates, batch sizes, initializers and dropout\nrates. Finally, we investigate the mathematical relation between Swish and\nSerf, thereby showing the impact of preconditioner function ingrained in the\nfirst derivative of Serf which provides a regularization effect making\ngradients smoother and optimization faster.\n",
        "published": "2021",
        "authors": [
            "Sayan Nag",
            "Mayukh Bhattacharyya"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2109.04386v4",
        "title": "ErfAct and Pserf: Non-monotonic Smooth Trainable Activation Functions",
        "abstract": "  An activation function is a crucial component of a neural network that\nintroduces non-linearity in the network. The state-of-the-art performance of a\nneural network depends also on the perfect choice of an activation function. We\npropose two novel non-monotonic smooth trainable activation functions, called\nErfAct and Pserf. Experiments suggest that the proposed functions improve the\nnetwork performance significantly compared to the widely used activations like\nReLU, Swish, and Mish. Replacing ReLU by ErfAct and Pserf, we have 5.68% and\n5.42% improvement for top-1 accuracy on Shufflenet V2 (2.0x) network in\nCIFAR100 dataset, 2.11% and 1.96% improvement for top-1 accuracy on Shufflenet\nV2 (2.0x) network in CIFAR10 dataset, 1.0%, and 1.0% improvement on mean\naverage precision (mAP) on SSD300 model in Pascal VOC dataset.\n",
        "published": "2021",
        "authors": [
            "Koushik Biswas",
            "Sandeep Kumar",
            "Shilpak Banerjee",
            "Ashish Kumar Pandey"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2109.13210v1",
        "title": "SAU: Smooth activation function using convolution with approximate\n  identities",
        "abstract": "  Well-known activation functions like ReLU or Leaky ReLU are\nnon-differentiable at the origin. Over the years, many smooth approximations of\nReLU have been proposed using various smoothing techniques. We propose new\nsmooth approximations of a non-differentiable activation function by convolving\nit with approximate identities. In particular, we present smooth approximations\nof Leaky ReLU and show that they outperform several well-known activation\nfunctions in various datasets and models. We call this function Smooth\nActivation Unit (SAU). Replacing ReLU by SAU, we get 5.12% improvement with\nShuffleNet V2 (2.0x) model on CIFAR100 dataset.\n",
        "published": "2021",
        "authors": [
            "Koushik Biswas",
            "Sandeep Kumar",
            "Shilpak Banerjee",
            "Ashish Kumar Pandey"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2109.13751v3",
        "title": "StereoSpike: Depth Learning with a Spiking Neural Network",
        "abstract": "  Depth estimation is an important computer vision task, useful in particular\nfor navigation in autonomous vehicles, or for object manipulation in robotics.\nHere we solved it using an end-to-end neuromorphic approach, combining two\nevent-based cameras and a Spiking Neural Network (SNN) with a slightly modified\nU-Net-like encoder-decoder architecture, that we named StereoSpike. More\nspecifically, we used the Multi Vehicle Stereo Event Camera Dataset (MVSEC). It\nprovides a depth ground-truth, which was used to train StereoSpike in a\nsupervised manner, using surrogate gradient descent. We propose a novel readout\nparadigm to obtain a dense analog prediction -- the depth of each pixel -- from\nthe spikes of the decoder. We demonstrate that this architecture generalizes\nvery well, even better than its non-spiking counterparts, leading to\nstate-of-the-art test accuracy. To the best of our knowledge, it is the first\ntime that such a large-scale regression problem is solved by a fully spiking\nnetwork. Finally, we show that low firing rates (<10%) can be obtained via\nregularization, with a minimal cost in accuracy. This means that StereoSpike\ncould be efficiently implemented on neuromorphic chips, opening the door for\nlow power and real time embedded systems.\n",
        "published": "2021",
        "authors": [
            "Ulysse Ran\u00e7on",
            "Javier Cuadrado-Anibarro",
            "Benoit R. Cottereau",
            "Timoth\u00e9e Masquelier"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2110.14032v1",
        "title": "MEST: Accurate and Fast Memory-Economic Sparse Training Framework on the\n  Edge",
        "abstract": "  Recently, a new trend of exploring sparsity for accelerating neural network\ntraining has emerged, embracing the paradigm of training on the edge. This\npaper proposes a novel Memory-Economic Sparse Training (MEST) framework\ntargeting for accurate and fast execution on edge devices. The proposed MEST\nframework consists of enhancements by Elastic Mutation (EM) and Soft Memory\nBound (&S) that ensure superior accuracy at high sparsity ratios. Different\nfrom the existing works for sparse training, this current work reveals the\nimportance of sparsity schemes on the performance of sparse training in terms\nof accuracy as well as training speed on real edge devices. On top of that, the\npaper proposes to employ data efficiency for further acceleration of sparse\ntraining. Our results suggest that unforgettable examples can be identified\nin-situ even during the dynamic exploration of sparsity masks in the sparse\ntraining process, and therefore can be removed for further training speedup on\nedge devices. Comparing with state-of-the-art (SOTA) works on accuracy, our\nMEST increases Top-1 accuracy significantly on ImageNet when using the same\nunstructured sparsity scheme. Systematical evaluation on accuracy, training\nspeed, and memory footprint are conducted, where the proposed MEST framework\nconsistently outperforms representative SOTA works. A reviewer strongly against\nour work based on his false assumptions and misunderstandings. On top of the\nprevious submission, we employ data efficiency for further acceleration of\nsparse training. And we explore the impact of model sparsity, sparsity schemes,\nand sparse training algorithms on the number of removable training examples.\nOur codes are publicly available at: https://github.com/boone891214/MEST.\n",
        "published": "2021",
        "authors": [
            "Geng Yuan",
            "Xiaolong Ma",
            "Wei Niu",
            "Zhengang Li",
            "Zhenglun Kong",
            "Ning Liu",
            "Yifan Gong",
            "Zheng Zhan",
            "Chaoyang He",
            "Qing Jin",
            "Siyue Wang",
            "Minghai Qin",
            "Bin Ren",
            "Yanzhi Wang",
            "Sijia Liu",
            "Xue Lin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2111.01584v1",
        "title": "Fitness Landscape Footprint: A Framework to Compare Neural Architecture\n  Search Problems",
        "abstract": "  Neural architecture search is a promising area of research dedicated to\nautomating the design of neural network models. This field is rapidly growing,\nwith a surge of methodologies ranging from Bayesian optimization,neuroevoltion,\nto differentiable search, and applications in various contexts. However,\ndespite all great advances, few studies have presented insights on the\ndifficulty of the problem itself, thus the success (or fail) of these\nmethodologies remains unexplained. In this sense, the field of optimization has\ndeveloped methods that highlight key aspects to describe optimization problems.\nThe fitness landscape analysis stands out when it comes to characterize\nreliably and quantitatively search algorithms. In this paper, we propose to use\nfitness landscape analysis to study a neural architecture search problem.\nParticularly, we introduce the fitness landscape footprint, an aggregation of\neight (8)general-purpose metrics to synthesize the landscape of an architecture\nsearch problem. We studied two problems, the classical image classification\nbenchmark CIFAR-10, and the Remote-Sensing problem So2Sat LCZ42. The results\npresent a quantitative appraisal of the problems, allowing to characterize the\nrelative difficulty and other characteristics, such as the ruggedness or the\npersistence, that helps to tailor a search strategy to the problem. Also, the\nfootprint is a tool that enables the comparison of multiple problems.\n",
        "published": "2021",
        "authors": [
            "Kalifou Ren\u00e9 Traor\u00e9",
            "Andr\u00e9s Camero",
            "Xiao Xiang Zhu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2111.04682v2",
        "title": "SMU: smooth activation function for deep networks using smoothing\n  maximum technique",
        "abstract": "  Deep learning researchers have a keen interest in proposing two new novel\nactivation functions which can boost network performance. A good choice of\nactivation function can have significant consequences in improving network\nperformance. A handcrafted activation is the most common choice in neural\nnetwork models. ReLU is the most common choice in the deep learning community\ndue to its simplicity though ReLU has some serious drawbacks. In this paper, we\nhave proposed a new novel activation function based on approximation of known\nactivation functions like Leaky ReLU, and we call this function Smooth Maximum\nUnit (SMU). Replacing ReLU by SMU, we have got 6.22% improvement in the\nCIFAR100 dataset with the ShuffleNet V2 model.\n",
        "published": "2021",
        "authors": [
            "Koushik Biswas",
            "Sandeep Kumar",
            "Shilpak Banerjee",
            "Ashish Kumar Pandey"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2112.05657v1",
        "title": "Artificial Intellgence -- Application in Life Sciences and Beyond. The\n  Upper Rhine Artificial Intelligence Symposium UR-AI 2021",
        "abstract": "  The TriRhenaTech alliance presents the accepted papers of the 'Upper-Rhine\nArtificial Intelligence Symposium' held on October 27th 2021 in Kaiserslautern,\nGermany. Topics of the conference are applications of Artificial Intellgence in\nlife sciences, intelligent systems, industry 4.0, mobility and others. The\nTriRhenaTech alliance is a network of universities in the Upper-Rhine\nTrinational Metropolitan Region comprising of the German universities of\napplied sciences in Furtwangen, Kaiserslautern, Karlsruhe, Offenburg and Trier,\nthe Baden-Wuerttemberg Cooperative State University Loerrach, the French\nuniversity network Alsace Tech (comprised of 14 'grandes \\'ecoles' in the\nfields of engineering, architecture and management) and the University of\nApplied Sciences and Arts Northwestern Switzerland. The alliance's common goal\nis to reinforce the transfer of knowledge, research, and technology, as well as\nthe cross-border mobility of students.\n",
        "published": "2021",
        "authors": [
            "Karl-Herbert Sch\u00e4fer",
            "Franz Quint"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2112.10017v1",
        "title": "Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks",
        "abstract": "  Existing research on continual learning of a sequence of tasks focused on\ndealing with catastrophic forgetting, where the tasks are assumed to be\ndissimilar and have little shared knowledge. Some work has also been done to\ntransfer previously learned knowledge to the new task when the tasks are\nsimilar and have shared knowledge. To the best of our knowledge, no technique\nhas been proposed to learn a sequence of mixed similar and dissimilar tasks\nthat can deal with forgetting and also transfer knowledge forward and backward.\nThis paper proposes such a technique to learn both types of tasks in the same\nnetwork. For dissimilar tasks, the algorithm focuses on dealing with\nforgetting, and for similar tasks, the algorithm focuses on selectively\ntransferring the knowledge learned from some similar previous tasks to improve\nthe new task learning. Additionally, the algorithm automatically detects\nwhether a new task is similar to any previous tasks. Empirical evaluation using\nsequences of mixed tasks demonstrates the effectiveness of the proposed model.\n",
        "published": "2021",
        "authors": [
            "Zixuan Ke",
            "Bing Liu",
            "Xingchang Huang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2112.12510v3",
        "title": "Neuroevolution deep learning architecture search for estimation of river\n  surface elevation from photogrammetric Digital Surface Models",
        "abstract": "  Development of the new methods of surface water observation is crucial in the\nperspective of increasingly frequent extreme hydrological events related to\nglobal warming and increasing demand for water. Orthophotos and digital surface\nmodels (DSMs) obtained using UAV photogrammetry can be used to determine the\nWater Surface Elevation (WSE) of a river. However, this task is difficult due\nto disturbances of the water surface on DSMs caused by limitations of\nphotogrammetric algorithms. In this study, machine learning was used to extract\na WSE value from disturbed photogrammetric data. A brand new dataset has been\nprepared specifically for this purpose by hydrology and photogrammetry experts.\nThe new method is an important step toward automating water surface level\nmeasurements with high spatial and temporal resolution. Such data can be used\nto validate and calibrate of hydrological, hydraulic and hydrodynamic models\nmaking hydrological forecasts more accurate, in particular predicting extreme\nand dangerous events such as floods or droughts. For our knowledge this is the\nfirst approach in which dataset was created for this purpose and deep learning\nmodels were used for this task. Additionally, neuroevolution algorithm was set\nto explore different architectures to find local optimal models and\nnon-gradient search was performed to fine-tune the model parameters. The\nachieved results have better accuracy compared to manual methods of determining\nWSE from photogrammetric DSMs.\n",
        "published": "2021",
        "authors": [
            "Rados\u0142aw Szostak",
            "Marcin Pietro\u0144",
            "Miros\u0142aw Zimnoch",
            "Przemys\u0142aw Wachniew",
            "Pawe\u0142 \u0106wi\u0105ka\u0142a",
            "Edyta Puniach"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2112.13121v4",
        "title": "The Curse of Zero Task Diversity: On the Failure of Transfer Learning to\n  Outperform MAML and their Empirical Equivalence",
        "abstract": "  Recently, it has been observed that a transfer learning solution might be all\nwe need to solve many few-shot learning benchmarks -- thus raising important\nquestions about when and how meta-learning algorithms should be deployed. In\nthis paper, we seek to clarify these questions by proposing a novel metric --\nthe diversity coefficient -- to measure the diversity of tasks in a few-shot\nlearning benchmark. We hypothesize that the diversity coefficient of the\nfew-shot learning benchmark is predictive of whether meta-learning solutions\nwill succeed or not. Using the diversity coefficient, we show that the\nMiniImagenet benchmark has zero diversity. This novel insight contextualizes\nclaims that transfer learning solutions are better than meta-learned solutions.\nSpecifically, we empirically find that a diversity coefficient of zero\ncorrelates with a high similarity between transfer learning and Model-Agnostic\nMeta-Learning (MAML) learned solutions in terms of meta-accuracy (at meta-test\ntime). Therefore, we conjecture meta-learned solutions have the same meta-test\nperformance as transfer learning when the diversity coefficient is zero. Our\nwork provides the first test of whether diversity correlates with meta-learning\nsuccess.\n",
        "published": "2021",
        "authors": [
            "Brando Miranda",
            "Yu-Xiong Wang",
            "Sanmi Koyejo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2112.13137v1",
        "title": "Does MAML Only Work via Feature Re-use? A Data Centric Perspective",
        "abstract": "  Recent work has suggested that a good embedding is all we need to solve many\nfew-shot learning benchmarks. Furthermore, other work has strongly suggested\nthat Model Agnostic Meta-Learning (MAML) also works via this same method - by\nlearning a good embedding. These observations highlight our lack of\nunderstanding of what meta-learning algorithms are doing and when they work. In\nthis work, we provide empirical results that shed some light on how\nmeta-learned MAML representations function. In particular, we identify three\ninteresting properties: 1) In contrast to previous work, we show that it is\npossible to define a family of synthetic benchmarks that result in a low degree\nof feature re-use - suggesting that current few-shot learning benchmarks might\nnot have the properties needed for the success of meta-learning algorithms; 2)\nmeta-overfitting occurs when the number of classes (or concepts) are finite,\nand this issue disappears once the task has an unbounded number of concepts\n(e.g., online learning); 3) more adaptation at meta-test time with MAML does\nnot necessarily result in a significant representation change or even an\nimprovement in meta-test performance - even when training on our proposed\nsynthetic benchmarks. Finally, we suggest that to understand meta-learning\nalgorithms better, we must go beyond tracking only absolute performance and, in\naddition, formally quantify the degree of meta-learning and track both metrics\ntogether. Reporting results in future work this way will help us identify the\nsources of meta-overfitting more accurately and help us design more flexible\nmeta-learning algorithms that learn beyond fixed feature re-use. Finally, we\nconjecture the core challenge of re-thinking meta-learning is in the design of\nfew-shot learning data sets and benchmarks - rather than in the algorithms, as\nsuggested by previous work.\n",
        "published": "2021",
        "authors": [
            "Brando Miranda",
            "Yu-Xiong Wang",
            "Sanmi Koyejo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2112.14983v1",
        "title": "Exploring the pattern of Emotion in children with ASD as an early\n  biomarker through Recurring-Convolution Neural Network (R-CNN)",
        "abstract": "  Autism Spectrum Disorder (ASD) is found to be a major concern among various\noccupational therapists. The foremost challenge of this neurodevelopmental\ndisorder lies in the fact of analyzing and exploring various symptoms of the\nchildren at their early stage of development. Such early identification could\nprop up the therapists and clinicians to provide proper assistive support to\nmake the children lead an independent life. Facial expressions and emotions\nperceived by the children could contribute to such early intervention of\nautism. In this regard, the paper implements in identifying basic facial\nexpression and exploring their emotions upon a time variant factor. The\nemotions are analyzed by incorporating the facial expression identified through\nCNN using 68 landmark points plotted on the frontal face with a prediction\nnetwork formed by RNN known as RCNN-FER system. The paper adopts R-CNN to take\nthe advantage of increased accuracy and performance with decreased time\ncomplexity in predicting emotion as a textual network analysis. The papers\nproves better accuracy in identifying the emotion in autistic children when\ncompared over simple machine learning models built for such identifications\ncontributing to autistic society.\n",
        "published": "2021",
        "authors": [
            "Abirami S P",
            "Kousalya G",
            "Karthick R"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2201.05809v2",
        "title": "Weighting and Pruning based Ensemble Deep Random Vector Functional Link\n  Network for Tabular Data Classification",
        "abstract": "  In this paper, we first introduce batch normalization to the edRVFL network.\nThis re-normalization method can help the network avoid divergence of the\nhidden features. Then we propose novel variants of Ensemble Deep Random Vector\nFunctional Link (edRVFL). Weighted edRVFL (WedRVFL) uses weighting methods to\ngive training samples different weights in different layers according to how\nthe samples were classified confidently in the previous layer thereby\nincreasing the ensemble's diversity and accuracy. Furthermore, a pruning-based\nedRVFL (PedRVFL) has also been proposed. We prune some inferior neurons based\non their importance for classification before generating the next hidden layer.\nThrough this method, we ensure that the randomly generated inferior features\nwill not propagate to deeper layers. Subsequently, the combination of weighting\nand pruning, called Weighting and Pruning based Ensemble Deep Random Vector\nFunctional Link Network (WPedRVFL), is proposed. We compare their performances\nwith other state-of-the-art deep feedforward neural networks (FNNs) on 24\ntabular UCI classification datasets. The experimental results illustrate the\nsuperior performance of our proposed methods.\n",
        "published": "2022",
        "authors": [
            "Qiushi Shi",
            "Ponnuthurai Nagaratnam Suganthan",
            "Rakesh Katuwal"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2201.06321v2",
        "title": "Landscape of Neural Architecture Search across sensors: how much do they\n  differ ?",
        "abstract": "  With the rapid rise of neural architecture search, the ability to understand\nits complexity from the perspective of a search algorithm is desirable.\nRecently, Traor\\'e et al. have proposed the framework of Fitness Landscape\nFootprint to help describe and compare neural architecture search problems. It\nattempts at describing why a search strategy might be successful, struggle or\nfail on a target task. Our study leverages this methodology in the context of\nsearching across sensors, including sensor data fusion. In particular, we apply\nthe Fitness Landscape Footprint to the real-world image classification problem\nof So2Sat LCZ42, in order to identify the most beneficial sensor to our neural\nnetwork hyper-parameter optimization problem. From the perspective of\ndistributions of fitness, our findings indicate a similar behaviour of the\nsearch space for all sensors: the longer the training time, the larger the\noverall fitness, and more flatness in the landscapes (less ruggedness and\ndeviation). Regarding sensors, the better the fitness they enable (Sentinel-2),\nthe better the search trajectories (smoother, higher persistence). Results also\nindicate very similar search behaviour for sensors that can be decently fitted\nby the search space (Sentinel-2 and fusion).\n",
        "published": "2022",
        "authors": [
            "Kalifou Ren\u00e9 Traor\u00e9",
            "Andr\u00e9s Camero",
            "Xiao Xiang Zhu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2203.01544v1",
        "title": "Rethinking the role of normalization and residual blocks for spiking\n  neural networks",
        "abstract": "  Biologically inspired spiking neural networks (SNNs) are widely used to\nrealize ultralow-power energy consumption. However, deep SNNs are not easy to\ntrain due to the excessive firing of spiking neurons in the hidden layers. To\ntackle this problem, we propose a novel but simple normalization technique\ncalled postsynaptic potential normalization. This normalization removes the\nsubtraction term from the standard normalization and uses the second raw moment\ninstead of the variance as the division term. The spike firing can be\ncontrolled, enabling the training to proceed appropriating, by conducting this\nsimple normalization to the postsynaptic potential. The experimental results\nshow that SNNs with our normalization outperformed other models using other\nnormalizations. Furthermore, through the pre-activation residual blocks, the\nproposed model can train with more than 100 layers without other special\ntechniques dedicated to SNNs.\n",
        "published": "2022",
        "authors": [
            "Shin-ichi Ikegawa",
            "Ryuji Saiin",
            "Yoshihide Sawada",
            "Naotake Natori"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2203.05508v2",
        "title": "Towards Less Constrained Macro-Neural Architecture Search",
        "abstract": "  Networks found with Neural Architecture Search (NAS) achieve state-of-the-art\nperformance in a variety of tasks, out-performing human-designed networks.\nHowever, most NAS methods heavily rely on human-defined assumptions that\nconstrain the search: architecture's outer-skeletons, number of layers,\nparameter heuristics and search spaces. Additionally, common search spaces\nconsist of repeatable modules (cells) instead of fully exploring the\narchitecture's search space by designing entire architectures (macro-search).\nImposing such constraints requires deep human expertise and restricts the\nsearch to pre-defined settings. In this paper, we propose LCMNAS, a method that\npushes NAS to less constrained search spaces by performing macro-search without\nrelying on pre-defined heuristics or bounded search spaces. LCMNAS introduces\nthree components for the NAS pipeline: i) a method that leverages information\nabout well-known architectures to autonomously generate complex search spaces\nbased on Weighted Directed Graphs with hidden properties, ii) an evolutionary\nsearch strategy that generates complete architectures from scratch, and iii) a\nmixed-performance estimation approach that combines information about\narchitectures at initialization stage and lower fidelity estimates to infer\ntheir trainability and capacity to model complex functions. We present\nexperiments in 13 different data sets showing that LCMNAS is capable of\ngenerating both cell and macro-based architectures with minimal GPU computation\nand state-of-the-art results. More, we conduct extensive studies on the\nimportance of different NAS components in both cell and macro-based settings.\nCode for reproducibility is public at https://github.com/VascoLopes/LCMNAS.\n",
        "published": "2022",
        "authors": [
            "Vasco Lopes",
            "Lu\u00eds A. Alexandre"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2203.12853v1",
        "title": "Direct evaluation of progression or regression of disease burden in\n  brain metastatic disease with Deep Neuroevolution",
        "abstract": "  Purpose: A core component of advancing cancer treatment research is assessing\nresponse to therapy. Doing so by hand, for example as per RECIST or RANO\ncriteria, is tedious, time-consuming, and can miss important tumor response\ninformation; most notably, they exclude non-target lesions. We wish to assess\nchange in a holistic fashion that includes all lesions, obtaining simple,\ninformative, and automated assessments of tumor progression or regression. Due\nto often low patient enrolments in clinical trials, we wish to make response\nassessments with small training sets. Deep neuroevolution (DNE) can produce\nradiology artificial intelligence (AI) that performs well on small training\nsets. Here we use DNE for function approximation that predicts progression\nversus regression of metastatic brain disease.\n  Methods: We analyzed 50 pairs of MRI contrast-enhanced images as our training\nset. Half of these pairs, separated in time, qualified as disease progression,\nwhile the other 25 images constituted regression. We trained the parameters of\na relatively small CNN via mutations that consisted of random CNN weight\nadjustments and mutation fitness. We then incorporated the best mutations into\nthe next generations CNN, repeating this process for approximately 50,000\ngenerations. We applied the CNNs to our training set, as well as a separate\ntesting set with the same class balance of 25 progression and 25 regression\nimages.\n  Results: DNE achieved monotonic convergence to 100% training set accuracy.\nDNE also converged monotonically to 100% testing set accuracy.\n  Conclusion: DNE can accurately classify brain-metastatic disease progression\nversus regression. Future work will extend the input from 2D image slices to\nfull 3D volumes, and include the category of no change. We believe that an\napproach such as our could ultimately provide a useful adjunct to RANO/RECIST\nassessment.\n",
        "published": "2022",
        "authors": [
            "Joseph Stember",
            "Robert Young",
            "Hrithwik Shalu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2204.11887v2",
        "title": "Evolutionary latent space search for driving human portrait generation",
        "abstract": "  This article presents an evolutionary approach for synthetic human portraits\ngeneration based on the latent space exploration of a generative adversarial\nnetwork. The idea is to produce different human face images very similar to a\ngiven target portrait. The approach applies StyleGAN2 for portrait generation\nand FaceNet for face similarity evaluation. The evolutionary search is based on\nexploring the real-coded latent space of StyleGAN2. The main results over both\nsynthetic and real images indicate that the proposed approach generates\naccurate and diverse solutions, which represent realistic human portraits. The\nproposed research can contribute to improving the security of face recognition\nsystems.\n",
        "published": "2022",
        "authors": [
            "Benjam\u00edn Mach\u00edn",
            "Sergio Nesmachnow",
            "Jamal Toutouh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2205.05167v2",
        "title": "Robustness of Humans and Machines on Object Recognition with Extreme\n  Image Transformations",
        "abstract": "  Recent neural network architectures have claimed to explain data from the\nhuman visual cortex. Their demonstrated performance is however still limited by\nthe dependence on exploiting low-level features for solving visual tasks. This\nstrategy limits their performance in case of out-of-distribution/adversarial\ndata. Humans, meanwhile learn abstract concepts and are mostly unaffected by\neven extreme image distortions. Humans and networks employ strikingly different\nstrategies to solve visual tasks. To probe this, we introduce a novel set of\nimage transforms and evaluate humans and networks on an object recognition\ntask. We found performance for a few common networks quickly decreases while\nhumans are able to recognize objects with a high accuracy.\n",
        "published": "2022",
        "authors": [
            "Dakarai Crowder",
            "Girik Malik"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2205.05874v5",
        "title": "Distinction Maximization Loss: Efficiently Improving Out-of-Distribution\n  Detection and Uncertainty Estimation by Replacing the Loss and Calibrating",
        "abstract": "  Building robust deterministic neural networks remains a challenge. On the one\nhand, some approaches improve out-of-distribution detection at the cost of\nreducing classification accuracy in some situations. On the other hand, some\nmethods simultaneously increase classification accuracy, uncertainty\nestimation, and out-of-distribution detection at the expense of reducing the\ninference efficiency. In this paper, we propose training deterministic neural\nnetworks using our DisMax loss, which works as a drop-in replacement for the\nusual SoftMax loss (i.e., the combination of the linear output layer, the\nSoftMax activation, and the cross-entropy loss). Starting from the IsoMax+\nloss, we create each logit based on the distances to all prototypes, rather\nthan just the one associated with the correct class. We also introduce a\nmechanism to combine images to construct what we call fractional probability\nregularization. Moreover, we present a fast way to calibrate the network after\ntraining. Finally, we propose a composite score to perform out-of-distribution\ndetection. Our experiments show that DisMax usually outperforms current\napproaches simultaneously in classification accuracy, uncertainty estimation,\nand out-of-distribution detection while maintaining deterministic neural\nnetwork inference efficiency. The code to reproduce the results is available at\nhttps://github.com/dlmacedo/distinction-maximization-loss.\n",
        "published": "2022",
        "authors": [
            "David Mac\u00eado",
            "Cleber Zanchettin",
            "Teresa Ludermir"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2205.08836v2",
        "title": "Large Neural Networks Learning from Scratch with Very Few Data and\n  without Explicit Regularization",
        "abstract": "  Recent findings have shown that highly over-parameterized Neural Networks\ngeneralize without pretraining or explicit regularization. It is achieved with\nzero training error, i.e., complete over-fitting by memorizing the training\ndata. This is surprising, since it is completely against traditional machine\nlearning wisdom. In our empirical study we fortify these findings in the domain\nof fine-grained image classification. We show that very large Convolutional\nNeural Networks with millions of weights do learn with only a handful of\ntraining samples and without image augmentation, explicit regularization or\npretraining. We train the architectures ResNet018, ResNet101 and VGG19 on\nsubsets of the difficult benchmark datasets Caltech101, CUB_200_2011,\nFGVCAircraft, Flowers102 and StanfordCars with 100 classes and more, perform a\ncomprehensive comparative study and draw implications for the practical\napplication of CNNs. Finally, we show that a randomly initialized VGG19 with\n140 million weights learns to distinguish airplanes and motorbikes with up to\n95% accuracy using only 20 training samples per class.\n",
        "published": "2022",
        "authors": [
            "Christoph Linse",
            "Thomas Martinetz"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2205.10937v2",
        "title": "muNet: Evolving Pretrained Deep Neural Networks into Scalable\n  Auto-tuning Multitask Systems",
        "abstract": "  Most uses of machine learning today involve training a model from scratch for\na particular task, or sometimes starting with a model pretrained on a related\ntask and then fine-tuning on a downstream task. Both approaches offer limited\nknowledge transfer between different tasks, time-consuming human-driven\ncustomization to individual tasks and high computational costs especially when\nstarting from randomly initialized models. We propose a method that uses the\nlayers of a pretrained deep neural network as building blocks to construct an\nML system that can jointly solve an arbitrary number of tasks. The resulting\nsystem can leverage cross tasks knowledge transfer, while being immune from\ncommon drawbacks of multitask approaches such as catastrophic forgetting,\ngradients interference and negative transfer. We define an evolutionary\napproach designed to jointly select the prior knowledge relevant for each task,\nchoose the subset of the model parameters to train and dynamically auto-tune\nits hyperparameters. Furthermore, a novel scale control method is employed to\nachieve quality/size trade-offs that outperform common fine-tuning techniques.\nCompared with standard fine-tuning on a benchmark of 10 diverse image\nclassification tasks, the proposed model improves the average accuracy by 2.39%\nwhile using 47% less parameters per task.\n",
        "published": "2022",
        "authors": [
            "Andrea Gesmundo",
            "Jeff Dean"
        ]
    }
]