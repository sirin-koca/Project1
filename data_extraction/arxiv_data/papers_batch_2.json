[
    {
        "id": "http://arxiv.org/abs/2303.16203v3",
        "title": "Your Diffusion Model is Secretly a Zero-Shot Classifier",
        "abstract": "  The recent wave of large-scale text-to-image diffusion models has\ndramatically increased our text-based image generation abilities. These models\ncan generate realistic images for a staggering variety of prompts and exhibit\nimpressive compositional generalization abilities. Almost all use cases thus\nfar have solely focused on sampling; however, diffusion models can also provide\nconditional density estimates, which are useful for tasks beyond image\ngeneration. In this paper, we show that the density estimates from large-scale\ntext-to-image diffusion models like Stable Diffusion can be leveraged to\nperform zero-shot classification without any additional training. Our\ngenerative approach to classification, which we call Diffusion Classifier,\nattains strong results on a variety of benchmarks and outperforms alternative\nmethods of extracting knowledge from diffusion models. Although a gap remains\nbetween generative and discriminative approaches on zero-shot recognition\ntasks, our diffusion-based approach has significantly stronger multimodal\ncompositional reasoning ability than competing discriminative approaches.\nFinally, we use Diffusion Classifier to extract standard classifiers from\nclass-conditional diffusion models trained on ImageNet. Our models achieve\nstrong classification performance using only weak augmentations and exhibit\nqualitatively better \"effective robustness\" to distribution shift. Overall, our\nresults are a step toward using generative over discriminative models for\ndownstream tasks. Results and visualizations at\nhttps://diffusion-classifier.github.io/\n",
        "published": "2023",
        "authors": [
            "Alexander C. Li",
            "Mihir Prabhudesai",
            "Shivam Duggal",
            "Ellis Brown",
            "Deepak Pathak"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1909.10387v3",
        "title": "An Adversarial Approach to Private Flocking in Mobile Robot Teams",
        "abstract": "  Privacy is an important facet of defence against adversaries. In this letter,\nwe introduce the problem of private flocking. We consider a team of mobile\nrobots flocking in the presence of an adversary, who is able to observe all\nrobots' trajectories, and who is interested in identifying the leader. We\npresent a method that generates private flocking controllers that hide the\nidentity of the leader robot. Our approach towards privacy leverages a\ndata-driven adversarial co-optimization scheme. We design a mechanism that\noptimizes flocking control parameters, such that leader inference is hindered.\nAs the flocking performance improves, we successively train an adversarial\ndiscriminator that tries to infer the identity of the leader robot. To evaluate\nthe performance of our co-optimization scheme, we investigate different classes\nof reference trajectories. Although it is reasonable to assume that there is an\ninherent trade-off between flocking performance and privacy, our results\ndemonstrate that we are able to achieve high flocking performance and\nsimultaneously reduce the risk of revealing the leader.\n",
        "published": "2019",
        "authors": [
            "Hehui Zheng",
            "Jacopo Panerati",
            "Giovanni Beltrame",
            "Amanda Prorok"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1603.03827v1",
        "title": "Sequential Short-Text Classification with Recurrent and Convolutional\n  Neural Networks",
        "abstract": "  Recent approaches based on artificial neural networks (ANNs) have shown\npromising results for short-text classification. However, many short texts\noccur in sequences (e.g., sentences in a document or utterances in a dialog),\nand most existing ANN-based systems do not leverage the preceding short texts\nwhen classifying a subsequent one. In this work, we present a model based on\nrecurrent neural networks and convolutional neural networks that incorporates\nthe preceding short texts. Our model achieves state-of-the-art results on three\ndifferent datasets for dialog act prediction.\n",
        "published": "2016",
        "authors": [
            "Ji Young Lee",
            "Franck Dernoncourt"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1705.08142v3",
        "title": "Latent Multi-task Architecture Learning",
        "abstract": "  Multi-task learning (MTL) allows deep neural networks to learn from related\ntasks by sharing parameters with other networks. In practice, however, MTL\ninvolves searching an enormous space of possible parameter sharing\narchitectures to find (a) the layers or subspaces that benefit from sharing,\n(b) the appropriate amount of sharing, and (c) the appropriate relative weights\nof the different task losses. Recent work has addressed each of the above\nproblems in isolation. In this work we present an approach that learns a latent\nmulti-task architecture that jointly addresses (a)--(c). We present experiments\non synthetic data and data from OntoNotes 5.0, including four different tasks\nand seven different domains. Our extension consistently outperforms previous\napproaches to learning latent architectures for multi-task problems and\nachieves up to 15% average error reductions over common approaches to MTL.\n",
        "published": "2017",
        "authors": [
            "Sebastian Ruder",
            "Joachim Bingel",
            "Isabelle Augenstein",
            "Anders S\u00f8gaard"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1801.06700v1",
        "title": "A Deep Reinforcement Learning Chatbot (Short Version)",
        "abstract": "  We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including neural network and\ntemplate-based models. By applying reinforcement learning to crowdsourced data\nand real-world user interactions, the system has been trained to select an\nappropriate response from the models in its ensemble. The system has been\nevaluated through A/B testing with real-world users, where it performed\nsignificantly better than other systems. The results highlight the potential of\ncoupling ensemble systems with deep reinforcement learning as a fruitful path\nfor developing real-world, open-domain conversational agents.\n",
        "published": "2018",
        "authors": [
            "Iulian V. Serban",
            "Chinnadhurai Sankar",
            "Mathieu Germain",
            "Saizheng Zhang",
            "Zhouhan Lin",
            "Sandeep Subramanian",
            "Taesup Kim",
            "Michael Pieper",
            "Sarath Chandar",
            "Nan Rosemary Ke",
            "Sai Rajeswar",
            "Alexandre de Brebisson",
            "Jose M. R. Sotelo",
            "Dendi Suhubdy",
            "Vincent Michalski",
            "Alexandre Nguyen",
            "Joelle Pineau",
            "Yoshua Bengio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.04723v1",
        "title": "The Bottleneck Simulator: A Model-based Deep Reinforcement Learning\n  Approach",
        "abstract": "  Deep reinforcement learning has recently shown many impressive successes.\nHowever, one major obstacle towards applying such methods to real-world\nproblems is their lack of data-efficiency. To this end, we propose the\nBottleneck Simulator: a model-based reinforcement learning method which\ncombines a learned, factorized transition model of the environment with rollout\nsimulations to learn an effective policy from few examples. The learned\ntransition model employs an abstract, discrete (bottleneck) state, which\nincreases sample efficiency by reducing the number of model parameters and by\nexploiting structural properties of the environment. We provide a mathematical\nanalysis of the Bottleneck Simulator in terms of fixed points of the learned\npolicy, which reveals how performance is affected by four distinct sources of\nerror: an error related to the abstract space structure, an error related to\nthe transition model estimation variance, an error related to the transition\nmodel estimation bias, and an error related to the transition model class bias.\nFinally, we evaluate the Bottleneck Simulator on two natural language\nprocessing tasks: a text adventure game and a real-world, complex dialogue\nresponse selection task. On both tasks, the Bottleneck Simulator yields\nexcellent performance beating competing approaches.\n",
        "published": "2018",
        "authors": [
            "Iulian Vlad Serban",
            "Chinnadhurai Sankar",
            "Michael Pieper",
            "Joelle Pineau",
            "Yoshua Bengio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.08133v1",
        "title": "What is not where: the challenge of integrating spatial representations\n  into deep learning architectures",
        "abstract": "  This paper examines to what degree current deep learning architectures for\nimage caption generation capture spatial language. On the basis of the\nevaluation of examples of generated captions from the literature we argue that\nsystems capture what objects are in the image data but not where these objects\nare located: the captions generated by these systems are the output of a\nlanguage model conditioned on the output of an object detector that cannot\ncapture fine-grained location information. Although language models provide\nuseful knowledge for image captions, we argue that deep learning image\ncaptioning architectures should also model geometric relations between objects.\n",
        "published": "2018",
        "authors": [
            "John D. Kelleher",
            "Simon Dobnik"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.09844v2",
        "title": "Modular Mechanistic Networks: On Bridging Mechanistic and\n  Phenomenological Models with Deep Neural Networks in Natural Language\n  Processing",
        "abstract": "  Natural language processing (NLP) can be done using either top-down (theory\ndriven) and bottom-up (data driven) approaches, which we call mechanistic and\nphenomenological respectively. The approaches are frequently considered to\nstand in opposition to each other. Examining some recent approaches in deep\nlearning we argue that deep neural networks incorporate both perspectives and,\nfurthermore, that leveraging this aspect of deep learning may help in solving\ncomplex problems within language technology, such as modelling language and\nperception in the domain of spatial cognition.\n",
        "published": "2018",
        "authors": [
            "Simon Dobnik",
            "John D. Kelleher"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1709.02349v2",
        "title": "A Deep Reinforcement Learning Chatbot",
        "abstract": "  We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including template-based\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\nvariable neural network models. By applying reinforcement learning to\ncrowdsourced data and real-world user interactions, the system has been trained\nto select an appropriate response from the models in its ensemble. The system\nhas been evaluated through A/B testing with real-world users, where it\nperformed significantly better than many competing systems. Due to its machine\nlearning architecture, the system is likely to improve with additional data.\n",
        "published": "2017",
        "authors": [
            "Iulian V. Serban",
            "Chinnadhurai Sankar",
            "Mathieu Germain",
            "Saizheng Zhang",
            "Zhouhan Lin",
            "Sandeep Subramanian",
            "Taesup Kim",
            "Michael Pieper",
            "Sarath Chandar",
            "Nan Rosemary Ke",
            "Sai Rajeshwar",
            "Alexandre de Brebisson",
            "Jose M. R. Sotelo",
            "Dendi Suhubdy",
            "Vincent Michalski",
            "Alexandre Nguyen",
            "Joelle Pineau",
            "Yoshua Bengio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1709.08878v2",
        "title": "Generating Sentences by Editing Prototypes",
        "abstract": "  We propose a new generative model of sentences that first samples a prototype\nsentence from the training corpus and then edits it into a new sentence.\nCompared to traditional models that generate from scratch either left-to-right\nor by first sampling a latent sentence vector, our prototype-then-edit model\nimproves perplexity on language modeling and generates higher quality outputs\naccording to human evaluation. Furthermore, the model gives rise to a latent\nedit vector that captures interpretable semantics such as sentence similarity\nand sentence-level analogies.\n",
        "published": "2017",
        "authors": [
            "Kelvin Guu",
            "Tatsunori B. Hashimoto",
            "Yonatan Oren",
            "Percy Liang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2006.13760v2",
        "title": "The NetHack Learning Environment",
        "abstract": "  Progress in Reinforcement Learning (RL) algorithms goes hand-in-hand with the\ndevelopment of challenging environments that test the limits of current\nmethods. While existing RL environments are either sufficiently complex or\nbased on fast simulation, they are rarely both. Here, we present the NetHack\nLearning Environment (NLE), a scalable, procedurally generated, stochastic,\nrich, and challenging environment for RL research based on the popular\nsingle-player terminal-based roguelike game, NetHack. We argue that NetHack is\nsufficiently complex to drive long-term research on problems such as\nexploration, planning, skill acquisition, and language-conditioned RL, while\ndramatically reducing the computational resources required to gather a large\namount of experience. We compare NLE and its task suite to existing\nalternatives, and discuss why it is an ideal medium for testing the robustness\nand systematic generalization of RL agents. We demonstrate empirical success\nfor early stages of the game using a distributed Deep RL baseline and Random\nNetwork Distillation exploration, alongside qualitative analysis of various\nagents trained in the environment. NLE is open source at\nhttps://github.com/facebookresearch/nle.\n",
        "published": "2020",
        "authors": [
            "Heinrich K\u00fcttler",
            "Nantas Nardelli",
            "Alexander H. Miller",
            "Roberta Raileanu",
            "Marco Selvatici",
            "Edward Grefenstette",
            "Tim Rockt\u00e4schel"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1606.00776v2",
        "title": "Multiresolution Recurrent Neural Networks: An Application to Dialogue\n  Response Generation",
        "abstract": "  We introduce the multiresolution recurrent neural network, which extends the\nsequence-to-sequence framework to model natural language generation as two\nparallel discrete stochastic processes: a sequence of high-level coarse tokens,\nand a sequence of natural language tokens. There are many ways to estimate or\nlearn the high-level coarse tokens, but we argue that a simple extraction\nprocedure is sufficient to capture a wealth of high-level discourse semantics.\nSuch procedure allows training the multiresolution recurrent neural network by\nmaximizing the exact joint log-likelihood over both sequences. In contrast to\nthe standard log- likelihood objective w.r.t. natural language tokens (word\nperplexity), optimizing the joint log-likelihood biases the model towards\nmodeling high-level abstractions. We apply the proposed model to the task of\ndialogue response generation in two challenging domains: the Ubuntu technical\nsupport domain, and Twitter conversations. On Ubuntu, the model outperforms\ncompeting approaches by a substantial margin, achieving state-of-the-art\nresults according to both automatic evaluation metrics and a human evaluation\nstudy. On Twitter, the model appears to generate more relevant and on-topic\nresponses according to automatic evaluation metrics. Finally, our experiments\ndemonstrate that the proposed model is more adept at overcoming the sparsity of\nnatural language and is better able to capture long-term structure.\n",
        "published": "2016",
        "authors": [
            "Iulian Vlad Serban",
            "Tim Klinger",
            "Gerald Tesauro",
            "Kartik Talamadupula",
            "Bowen Zhou",
            "Yoshua Bengio",
            "Aaron Courville"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.09558v2",
        "title": "A Visual Distance for WordNet",
        "abstract": "  Measuring the distance between concepts is an important field of study of\nNatural Language Processing, as it can be used to improve tasks related to the\ninterpretation of those same concepts. WordNet, which includes a wide variety\nof concepts associated with words (i.e., synsets), is often used as a source\nfor computing those distances. In this paper, we explore a distance for WordNet\nsynsets based on visual features, instead of lexical ones. For this purpose, we\nextract the graphic features generated within a deep convolutional neural\nnetworks trained with ImageNet and use those features to generate a\nrepresentative of each synset. Based on those representatives, we define a\ndistance measure of synsets, which complements the traditional lexical\ndistances. Finally, we propose some experiments to evaluate its performance and\ncompare it with the current state-of-the-art.\n",
        "published": "2018",
        "authors": [
            "Raquel P\u00e9rez-Arnal",
            "Armand Vilalta",
            "Dario Garcia-Gasulla",
            "Ulises Cort\u00e9s",
            "Eduard Ayguad\u00e9",
            "Jesus Labarta"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.11752v5",
        "title": "Multi-turn Dialogue Response Generation in an Adversarial Learning\n  Framework",
        "abstract": "  We propose an adversarial learning approach for generating multi-turn\ndialogue responses. Our proposed framework, hredGAN, is based on conditional\ngenerative adversarial networks (GANs). The GAN's generator is a modified\nhierarchical recurrent encoder-decoder network (HRED) and the discriminator is\na word-level bidirectional RNN that shares context and word embeddings with the\ngenerator. During inference, noise samples conditioned on the dialogue history\nare used to perturb the generator's latent space to generate several possible\nresponses. The final response is the one ranked best by the discriminator. The\nhredGAN shows improved performance over existing methods: (1) it generalizes\nbetter than networks trained using only the log-likelihood criterion, and (2)\nit generates longer, more informative and more diverse responses with high\nutterance and topic relevance even with limited training data. This improvement\nis demonstrated on the Movie triples and Ubuntu dialogue datasets using both\nautomatic and human evaluations.\n",
        "published": "2018",
        "authors": [
            "Oluwatobi Olabiyi",
            "Alan Salimov",
            "Anish Khazane",
            "Erik T. Mueller"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1808.03920v1",
        "title": "Multimodal Language Analysis with Recurrent Multistage Fusion",
        "abstract": "  Computational modeling of human multimodal language is an emerging research\narea in natural language processing spanning the language, visual and acoustic\nmodalities. Comprehending multimodal language requires modeling not only the\ninteractions within each modality (intra-modal interactions) but more\nimportantly the interactions between modalities (cross-modal interactions). In\nthis paper, we propose the Recurrent Multistage Fusion Network (RMFN) which\ndecomposes the fusion problem into multiple stages, each of them focused on a\nsubset of multimodal signals for specialized, effective fusion. Cross-modal\ninteractions are modeled using this multistage fusion approach which builds\nupon intermediate representations of previous stages. Temporal and intra-modal\ninteractions are modeled by integrating our proposed fusion approach with a\nsystem of recurrent neural networks. The RMFN displays state-of-the-art\nperformance in modeling human multimodal language across three public datasets\nrelating to multimodal sentiment analysis, emotion recognition, and speaker\ntraits recognition. We provide visualizations to show that each stage of fusion\nfocuses on a different subset of multimodal signals, learning increasingly\ndiscriminative multimodal representations.\n",
        "published": "2018",
        "authors": [
            "Paul Pu Liang",
            "Ziyin Liu",
            "Amir Zadeh",
            "Louis-Philippe Morency"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.01803v1",
        "title": "Sparse Meta Networks for Sequential Adaptation and its Application to\n  Adaptive Language Modelling",
        "abstract": "  Training a deep neural network requires a large amount of single-task data\nand involves a long time-consuming optimization phase. This is not scalable to\ncomplex, realistic environments with new unexpected changes. Humans can perform\nfast incremental learning on the fly and memory systems in the brain play a\ncritical role. We introduce Sparse Meta Networks -- a meta-learning approach to\nlearn online sequential adaptation algorithms for deep neural networks, by\nusing deep neural networks. We augment a deep neural network with a\nlayer-specific fast-weight memory. The fast-weights are generated sparsely at\neach time step and accumulated incrementally through time providing a useful\ninductive bias for online continual adaptation. We demonstrate strong\nperformance on a variety of sequential adaptation scenarios, from a simple\nonline reinforcement learning to a large scale adaptive language modelling.\n",
        "published": "2020",
        "authors": [
            "Tsendsuren Munkhdalai"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2210.14593v1",
        "title": "Scaling Laws Beyond Backpropagation",
        "abstract": "  Alternatives to backpropagation have long been studied to better understand\nhow biological brains may learn. Recently, they have also garnered interest as\na way to train neural networks more efficiently. By relaxing constraints\ninherent to backpropagation (e.g., symmetric feedforward and feedback weights,\nsequential updates), these methods enable promising prospects, such as local\nlearning. However, the tradeoffs between different methods in terms of final\ntask performance, convergence speed, and ultimately compute and data\nrequirements are rarely outlined. In this work, we use scaling laws to study\nthe ability of Direct Feedback Alignment~(DFA) to train causal decoder-only\nTransformers efficiently. Scaling laws provide an overview of the tradeoffs\nimplied by a modeling decision, up to extrapolating how it might transfer to\nincreasingly large models. We find that DFA fails to offer more efficient\nscaling than backpropagation: there is never a regime for which the degradation\nin loss incurred by using DFA is worth the potential reduction in compute\nbudget. Our finding comes at variance with previous beliefs in the alternative\ntraining methods community, and highlights the need for holistic empirical\napproaches to better understand modeling decisions.\n",
        "published": "2022",
        "authors": [
            "Matthew J. Filipovich",
            "Alessandro Cappelli",
            "Daniel Hesslow",
            "Julien Launay"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.02984v1",
        "title": "Scaling Laws for Associative Memories",
        "abstract": "  Learning arguably involves the discovery and memorization of abstract rules.\nThe aim of this paper is to study associative memory mechanisms. Our model is\nbased on high-dimensional matrices consisting of outer products of embeddings,\nwhich relates to the inner layers of transformer language models. We derive\nprecise scaling laws with respect to sample size and parameter size, and\ndiscuss the statistical efficiency of different estimators, including\noptimization-based algorithms. We provide extensive numerical experiments to\nvalidate and interpret theoretical results, including fine-grained\nvisualizations of the stored memory associations.\n",
        "published": "2023",
        "authors": [
            "Vivien Cabannes",
            "Elvis Dohmatob",
            "Alberto Bietti"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0812.0743v2",
        "title": "A Novel Clustering Algorithm Based on Quantum Games",
        "abstract": "  Enormous successes have been made by quantum algorithms during the last\ndecade. In this paper, we combine the quantum game with the problem of data\nclustering, and then develop a quantum-game-based clustering algorithm, in\nwhich data points in a dataset are considered as players who can make decisions\nand implement quantum strategies in quantum games. After each round of a\nquantum game, each player's expected payoff is calculated. Later, he uses a\nlink-removing-and-rewiring (LRR) function to change his neighbors and adjust\nthe strength of links connecting to them in order to maximize his payoff.\nFurther, algorithms are discussed and analyzed in two cases of strategies, two\npayoff matrixes and two LRR functions. Consequently, the simulation results\nhave demonstrated that data points in datasets are clustered reasonably and\nefficiently, and the clustering algorithms have fast rates of convergence.\nMoreover, the comparison with other algorithms also provides an indication of\nthe effectiveness of the proposed approach.\n",
        "published": "2008",
        "authors": [
            "Qiang Li",
            "Yan He",
            "Jing-ping Jiang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.05521v1",
        "title": "Swarm Intelligence for Self-Organized Clustering",
        "abstract": "  Algorithms implementing populations of agents which interact with one another\nand sense their environment may exhibit emergent behavior such as\nself-organization and swarm intelligence. Here a swarm system, called\nDatabionic swarm (DBS), is introduced which is able to adapt itself to\nstructures of high-dimensional data characterized by distance and/or\ndensity-based structures in the data space. By exploiting the interrelations of\nswarm intelligence, self-organization and emergence, DBS serves as an\nalternative approach to the optimization of a global objective function in the\ntask of clustering. The swarm omits the usage of a global objective function\nand is parameter-free because it searches for the Nash equilibrium during its\nannealing process. To our knowledge, DBS is the first swarm combining these\napproaches. Its clustering can outperform common clustering methods such as\nK-means, PAM, single linkage, spectral clustering, model-based clustering, and\nWard, if no prior knowledge about the data is available. A central problem in\nclustering is the correct estimation of the number of clusters. This is\naddressed by a DBS visualization called topographic map which allows assessing\nthe number of clusters. It is known that all clustering algorithms construct\nclusters, irrespective of the data set contains clusters or not. In contrast to\nmost other clustering algorithms, the topographic map identifies, that\nclustering of the data is meaningless if the data contains no (natural)\nclusters. The performance of DBS is demonstrated on a set of benchmark data,\nwhich are constructed to pose difficult clustering problems and in two\nreal-world applications.\n",
        "published": "2021",
        "authors": [
            "Michael C. Thrun",
            "Alfred Ultsch"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.07804v2",
        "title": "OmniNet: A unified architecture for multi-modal multi-task learning",
        "abstract": "  Transformer is a popularly used neural network architecture, especially for\nlanguage understanding. We introduce an extended and unified architecture that\ncan be used for tasks involving a variety of modalities like image, text,\nvideos, etc. We propose a spatio-temporal cache mechanism that enables learning\nspatial dimension of the input in addition to the hidden states corresponding\nto the temporal input sequence. The proposed architecture further enables a\nsingle model to support tasks with multiple input modalities as well as\nasynchronous multi-task learning, thus we refer to it as OmniNet. For example,\na single instance of OmniNet can concurrently learn to perform the tasks of\npart-of-speech tagging, image captioning, visual question answering and video\nactivity recognition. We demonstrate that training these four tasks together\nresults in about three times compressed model while retaining the performance\nin comparison to training them individually. We also show that using this\nneural network pre-trained on some modalities assists in learning unseen tasks\nsuch as video captioning and video question answering. This illustrates the\ngeneralization capacity of the self-attention mechanism on the spatio-temporal\ncache present in OmniNet.\n",
        "published": "2019",
        "authors": [
            "Subhojeet Pramanik",
            "Priyanka Agrawal",
            "Aman Hussain"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.03268v2",
        "title": "Efficient Neural Architecture Search via Parameter Sharing",
        "abstract": "  We propose Efficient Neural Architecture Search (ENAS), a fast and\ninexpensive approach for automatic model design. In ENAS, a controller learns\nto discover neural network architectures by searching for an optimal subgraph\nwithin a large computational graph. The controller is trained with policy\ngradient to select a subgraph that maximizes the expected reward on the\nvalidation set. Meanwhile the model corresponding to the selected subgraph is\ntrained to minimize a canonical cross entropy loss. Thanks to parameter sharing\nbetween child models, ENAS is fast: it delivers strong empirical performances\nusing much fewer GPU-hours than all existing automatic model design approaches,\nand notably, 1000x less expensive than standard Neural Architecture Search. On\nthe Penn Treebank dataset, ENAS discovers a novel architecture that achieves a\ntest perplexity of 55.8, establishing a new state-of-the-art among all methods\nwithout post-training processing. On the CIFAR-10 dataset, ENAS designs novel\narchitectures that achieve a test error of 2.89%, which is on par with NASNet\n(Zoph et al., 2018), whose test error is 2.65%.\n",
        "published": "2018",
        "authors": [
            "Hieu Pham",
            "Melody Y. Guan",
            "Barret Zoph",
            "Quoc V. Le",
            "Jeff Dean"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1504.00923v1",
        "title": "A Unified Deep Neural Network for Speaker and Language Recognition",
        "abstract": "  Learned feature representations and sub-phoneme posteriors from Deep Neural\nNetworks (DNNs) have been used separately to produce significant performance\ngains for speaker and language recognition tasks. In this work we show how\nthese gains are possible using a single DNN for both speaker and language\nrecognition. The unified DNN approach is shown to yield substantial performance\nimprovements on the the 2013 Domain Adaptation Challenge speaker recognition\ntask (55% reduction in EER for the out-of-domain condition) and on the NIST\n2011 Language Recognition Evaluation (48% reduction in EER for the 30s test\ncondition).\n",
        "published": "2015",
        "authors": [
            "Fred Richardson",
            "Douglas Reynolds",
            "Najim Dehak"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.09317v2",
        "title": "Challenges and Prospects in Vision and Language Research",
        "abstract": "  Language grounded image understanding tasks have often been proposed as a\nmethod for evaluating progress in artificial intelligence. Ideally, these tasks\nshould test a plethora of capabilities that integrate computer vision,\nreasoning, and natural language understanding. However, rather than behaving as\nvisual Turing tests, recent studies have demonstrated state-of-the-art systems\nare achieving good performance through flaws in datasets and evaluation\nprocedures. We review the current state of affairs and outline a path forward.\n",
        "published": "2019",
        "authors": [
            "Kushal Kafle",
            "Robik Shrestha",
            "Christopher Kanan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1609.06492v1",
        "title": "Document Image Coding and Clustering for Script Discrimination",
        "abstract": "  The paper introduces a new method for discrimination of documents given in\ndifferent scripts. The document is mapped into a uniformly coded text of\nnumerical values. It is derived from the position of the letters in the text\nline, based on their typographical characteristics. Each code is considered as\na gray level. Accordingly, the coded text determines a 1-D image, on which\ntexture analysis by run-length statistics and local binary pattern is\nperformed. It defines feature vectors representing the script content of the\ndocument. A modified clustering approach employed on document feature vector\ngroups documents written in the same script. Experimentation performed on two\ncustom oriented databases of historical documents in old Cyrillic, angular and\nround Glagolitic as well as Antiqua and Fraktur scripts demonstrates the\nsuperiority of the proposed method with respect to well-known methods in the\nstate-of-the-art.\n",
        "published": "2016",
        "authors": [
            "Darko Brodic",
            "Alessia Amelio",
            "Zoran N. Milivojevic",
            "Milena Jevtic"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1705.07962v2",
        "title": "pix2code: Generating Code from a Graphical User Interface Screenshot",
        "abstract": "  Transforming a graphical user interface screenshot created by a designer into\ncomputer code is a typical task conducted by a developer in order to build\ncustomized software, websites, and mobile applications. In this paper, we show\nthat deep learning methods can be leveraged to train a model end-to-end to\nautomatically generate code from a single input image with over 77% of accuracy\nfor three different platforms (i.e. iOS, Android and web-based technologies).\n",
        "published": "2017",
        "authors": [
            "Tony Beltramelli"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.01076v1",
        "title": "Tutorial on Answering Questions about Images with Deep Learning",
        "abstract": "  Together with the development of more accurate methods in Computer Vision and\nNatural Language Understanding, holistic architectures that answer on questions\nabout the content of real-world images have emerged. In this tutorial, we build\na neural-based approach to answer questions about images. We base our tutorial\non two datasets: (mostly on) DAQUAR, and (a bit on) VQA. With small tweaks the\nmodels that we present here can achieve a competitive performance on both\ndatasets, in fact, they are among the best methods that use a combination of\nLSTM with a global, full frame CNN representation of an image. We hope that\nafter reading this tutorial, the reader will be able to use Deep Learning\nframeworks, such as Keras and introduced Kraino, to build various architectures\nthat will lead to a further performance improvement on this challenging task.\n",
        "published": "2016",
        "authors": [
            "Mateusz Malinowski",
            "Mario Fritz"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1808.00300v1",
        "title": "Learning Visual Question Answering by Bootstrapping Hard Attention",
        "abstract": "  Attention mechanisms in biological perception are thought to select subsets\nof perceptual information for more sophisticated processing which would be\nprohibitive to perform on all sensory inputs. In computer vision, however,\nthere has been relatively little exploration of hard attention, where some\ninformation is selectively ignored, in spite of the success of soft attention,\nwhere information is re-weighted and aggregated, but never filtered out. Here,\nwe introduce a new approach for hard attention and find it achieves very\ncompetitive performance on a recently-released visual question answering\ndatasets, equalling and in some cases surpassing similar soft attention\narchitectures while entirely ignoring some features. Even though the hard\nattention mechanism is thought to be non-differentiable, we found that the\nfeature magnitudes correlate with semantic relevance, and provide a useful\nsignal for our mechanism's attentional selection criterion. Because hard\nattention selects important features of the input information, it can also be\nmore efficient than analogous soft attention mechanisms. This is especially\nimportant for recent approaches that use non-local pairwise operations, whereby\ncomputational and memory costs are quadratic in the size of the set of\nfeatures.\n",
        "published": "2018",
        "authors": [
            "Mateusz Malinowski",
            "Carl Doersch",
            "Adam Santoro",
            "Peter Battaglia"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2011.07661v1",
        "title": "hyper-sinh: An Accurate and Reliable Function from Shallow to Deep\n  Learning in TensorFlow and Keras",
        "abstract": "  This paper presents the 'hyper-sinh', a variation of the m-arcsinh activation\nfunction suitable for Deep Learning (DL)-based algorithms for supervised\nlearning, such as Convolutional Neural Networks (CNN). hyper-sinh, developed in\nthe open source Python libraries TensorFlow and Keras, is thus described and\nvalidated as an accurate and reliable activation function for both shallow and\ndeep neural networks. Improvements in accuracy and reliability in image and\ntext classification tasks on five (N = 5) benchmark data sets available from\nKeras are discussed. Experimental results demonstrate the overall competitive\nclassification performance of both shallow and deep neural networks, obtained\nvia this novel function. This function is evaluated with respect to gold\nstandard activation functions, demonstrating its overall competitive accuracy\nand reliability for both image and text classification.\n",
        "published": "2020",
        "authors": [
            "Luca Parisi",
            "Renfei Ma",
            "Narrendar RaviChandran",
            "Matteo Lanzillotta"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2209.12951v1",
        "title": "Liquid Structural State-Space Models",
        "abstract": "  A proper parametrization of state transition matrices of linear state-space\nmodels (SSMs) followed by standard nonlinearities enables them to efficiently\nlearn representations from sequential data, establishing the state-of-the-art\non a large series of long-range sequence modeling benchmarks. In this paper, we\nshow that we can improve further when the structural SSM such as S4 is given by\na linear liquid time-constant (LTC) state-space model. LTC neural networks are\ncausal continuous-time neural networks with an input-dependent state transition\nmodule, which makes them learn to adapt to incoming inputs at inference. We\nshow that by using a diagonal plus low-rank decomposition of the state\ntransition matrix introduced in S4, and a few simplifications, the LTC-based\nstructural state-space model, dubbed Liquid-S4, achieves the new\nstate-of-the-art generalization across sequence modeling tasks with long-term\ndependencies such as image, text, audio, and medical time-series, with an\naverage performance of 87.32% on the Long-Range Arena benchmark. On the full\nraw Speech Command recognition, dataset Liquid-S4 achieves 96.78% accuracy with\na 30% reduction in parameter counts compared to S4. The additional gain in\nperformance is the direct result of the Liquid-S4's kernel structure that takes\ninto account the similarities of the input sequence samples during training and\ninference.\n",
        "published": "2022",
        "authors": [
            "Ramin Hasani",
            "Mathias Lechner",
            "Tsun-Hsuan Wang",
            "Makram Chahine",
            "Alexander Amini",
            "Daniela Rus"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2302.01676v2",
        "title": "Show me your NFT and I tell you how it will perform: Multimodal\n  representation learning for NFT selling price prediction",
        "abstract": "  Non-Fungible Tokens (NFTs) represent deeds of ownership, based on blockchain\ntechnologies and smart contracts, of unique crypto assets on digital art forms\n(e.g., artworks or collectibles). In the spotlight after skyrocketing in 2021,\nNFTs have attracted the attention of crypto enthusiasts and investors intent on\nplacing promising investments in this profitable market. However, the NFT\nfinancial performance prediction has not been widely explored to date.\n  In this work, we address the above problem based on the hypothesis that NFT\nimages and their textual descriptions are essential proxies to predict the NFT\nselling prices. To this purpose, we propose MERLIN, a novel multimodal deep\nlearning framework designed to train Transformer-based language and visual\nmodels, along with graph neural network models, on collections of NFTs' images\nand texts. A key aspect in MERLIN is its independence on financial features, as\nit exploits only the primary data a user interested in NFT trading would like\nto deal with, i.e., NFT images and textual descriptions. By learning dense\nrepresentations of such data, a price-category classification task is performed\nby MERLIN models, which can also be tuned according to user preferences in the\ninference phase to mimic different risk-return investment profiles.\nExperimental evaluation on a publicly available dataset has shown that MERLIN\nmodels achieve significant performances according to several financial\nassessment criteria, fostering profitable investments, and also beating\nbaseline machine-learning classifiers based on financial features.\n",
        "published": "2023",
        "authors": [
            "Davide Costa",
            "Lucio La Cava",
            "Andrea Tagarelli"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2302.06675v4",
        "title": "Symbolic Discovery of Optimization Algorithms",
        "abstract": "  We present a method to formulate algorithm discovery as program search, and\napply it to discover optimization algorithms for deep neural network training.\nWe leverage efficient search techniques to explore an infinite and sparse\nprogram space. To bridge the large generalization gap between proxy and target\ntasks, we also introduce program selection and simplification strategies. Our\nmethod discovers a simple and effective optimization algorithm, $\\textbf{Lion}$\n($\\textit{Evo$\\textbf{L}$ved S$\\textbf{i}$gn M$\\textbf{o}$me$\\textbf{n}$tum}$).\nIt is more memory-efficient than Adam as it only keeps track of the momentum.\nDifferent from adaptive optimizers, its update has the same magnitude for each\nparameter calculated through the sign operation. We compare Lion with widely\nused optimizers, such as Adam and Adafactor, for training a variety of models\non different tasks. On image classification, Lion boosts the accuracy of ViT by\nup to 2% on ImageNet and saves up to 5x the pre-training compute on JFT. On\nvision-language contrastive learning, we achieve 88.3% $\\textit{zero-shot}$ and\n91.1% $\\textit{fine-tuning}$ accuracy on ImageNet, surpassing the previous best\nresults by 2% and 0.1%, respectively. On diffusion models, Lion outperforms\nAdam by achieving a better FID score and reducing the training compute by up to\n2.3x. For autoregressive, masked language modeling, and fine-tuning, Lion\nexhibits a similar or better performance compared to Adam. Our analysis of Lion\nreveals that its performance gain grows with the training batch size. It also\nrequires a smaller learning rate than Adam due to the larger norm of the update\nproduced by the sign function. Additionally, we examine the limitations of Lion\nand identify scenarios where its improvements are small or not statistically\nsignificant. Lion is also successfully deployed in production systems such as\nGoogle search ads CTR model.\n",
        "published": "2023",
        "authors": [
            "Xiangning Chen",
            "Chen Liang",
            "Da Huang",
            "Esteban Real",
            "Kaiyuan Wang",
            "Yao Liu",
            "Hieu Pham",
            "Xuanyi Dong",
            "Thang Luong",
            "Cho-Jui Hsieh",
            "Yifeng Lu",
            "Quoc V. Le"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.08291v1",
        "title": "Large Language Model Guided Tree-of-Thought",
        "abstract": "  In this paper, we introduce the Tree-of-Thought (ToT) framework, a novel\napproach aimed at improving the problem-solving capabilities of auto-regressive\nlarge language models (LLMs). The ToT technique is inspired by the human mind's\napproach for solving complex reasoning tasks through trial and error. In this\nprocess, the human mind explores the solution space through a tree-like thought\nprocess, allowing for backtracking when necessary. To implement ToT as a\nsoftware system, we augment an LLM with additional modules including a prompter\nagent, a checker module, a memory module, and a ToT controller. In order to\nsolve a given problem, these modules engage in a multi-round conversation with\nthe LLM. The memory module records the conversation and state history of the\nproblem solving process, which allows the system to backtrack to the previous\nsteps of the thought-process and explore other directions from there. To verify\nthe effectiveness of the proposed technique, we implemented a ToT-based solver\nfor the Sudoku Puzzle. Experimental results show that the ToT framework can\nsignificantly increase the success rate of Sudoku puzzle solving. Our\nimplementation of the ToT-based Sudoku solver is available on GitHub:\n\\url{https://github.com/jieyilong/tree-of-thought-puzzle-solver}.\n",
        "published": "2023",
        "authors": [
            "Jieyi Long"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.11884v1",
        "title": "From Neural Activations to Concepts: A Survey on Explaining Concepts in\n  Neural Networks",
        "abstract": "  In this paper, we review recent approaches for explaining concepts in neural\nnetworks. Concepts can act as a natural link between learning and reasoning:\nonce the concepts are identified that a neural learning system uses, one can\nintegrate those concepts with a reasoning system for inference or use a\nreasoning system to act upon them to improve or enhance the learning system. On\nthe other hand, knowledge can not only be extracted from neural networks but\nconcept knowledge can also be inserted into neural network architectures. Since\nintegrating learning and reasoning is at the core of neuro-symbolic AI, the\ninsights gained from this survey can serve as an important step towards\nrealizing neuro-symbolic AI based on explainable concepts.\n",
        "published": "2023",
        "authors": [
            "Jae Hee Lee",
            "Sergio Lanza",
            "Stefan Wermter"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.01463v1",
        "title": "Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI",
        "abstract": "  Large language models have proliferated across multiple domains in as short\nperiod of time. There is however hesitation in the medical and healthcare\ndomain towards their adoption because of issues like factuality, coherence, and\nhallucinations. Give the high stakes nature of healthcare, many researchers\nhave even cautioned against its usage until these issues are resolved. The key\nto the implementation and deployment of LLMs in healthcare is to make these\nmodels trustworthy, transparent (as much possible) and explainable. In this\npaper we describe the key elements in creating reliable, trustworthy, and\nunbiased models as a necessary condition for their adoption in healthcare.\nSpecifically we focus on the quantification, validation, and mitigation of\nhallucinations in the context in healthcare. Lastly, we discuss how the future\nof LLMs in healthcare may look like.\n",
        "published": "2023",
        "authors": [
            "Muhammad Aurangzeb Ahmad",
            "Ilker Yaramis",
            "Taposh Dutta Roy"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2006.11671v1",
        "title": "Collective Learning by Ensembles of Altruistic Diversifying Neural\n  Networks",
        "abstract": "  Combining the predictions of collections of neural networks often outperforms\nthe best single network. Such ensembles are typically trained independently,\nand their superior `wisdom of the crowd' originates from the differences\nbetween networks. Collective foraging and decision making in socially\ninteracting animal groups is often improved or even optimal thanks to local\ninformation sharing between conspecifics. We therefore present a model for\nco-learning by ensembles of interacting neural networks that aim to maximize\ntheir own performance but also their functional relations to other networks. We\nshow that ensembles of interacting networks outperform independent ones, and\nthat optimal ensemble performance is reached when the coupling between networks\nincreases diversity and degrades the performance of individual networks. Thus,\neven without a global goal for the ensemble, optimal collective behavior\nemerges from local interactions between networks. We show the scaling of\noptimal coupling strength with ensemble size, and that networks in these\nensembles specialize functionally and become more `confident' in their\nassessments. Moreover, optimal co-learning networks differ structurally,\nrelying on sparser activity, a wider range of synaptic weights, and higher\nfiring rates - compared to independently trained networks. Finally, we explore\ninteractions-based co-learning as a framework for expanding and boosting\nensembles.\n",
        "published": "2020",
        "authors": [
            "Benjamin Brazowski",
            "Elad Schneidman"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1409.6041v1",
        "title": "Domain Adaptive Neural Networks for Object Recognition",
        "abstract": "  We propose a simple neural network model to deal with the domain adaptation\nproblem in object recognition. Our model incorporates the Maximum Mean\nDiscrepancy (MMD) measure as a regularization in the supervised learning to\nreduce the distribution mismatch between the source and target domains in the\nlatent space. From experiments, we demonstrate that the MMD regularization is\nan effective tool to provide good domain adaptation models on both SURF\nfeatures and raw image pixels of a particular image data set. We also show that\nour proposed model, preceded by the denoising auto-encoder pretraining,\nachieves better performance than recent benchmark models on the same data sets.\nThis work represents the first study of MMD measure in the context of neural\nnetworks.\n",
        "published": "2014",
        "authors": [
            "Muhammad Ghifary",
            "W. Bastiaan Kleijn",
            "Mengjie Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1410.0736v4",
        "title": "HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale\n  Visual Recognition",
        "abstract": "  In image classification, visual separability between different object\ncategories is highly uneven, and some categories are more difficult to\ndistinguish than others. Such difficult categories demand more dedicated\nclassifiers. However, existing deep convolutional neural networks (CNN) are\ntrained as flat N-way classifiers, and few efforts have been made to leverage\nthe hierarchical structure of categories. In this paper, we introduce\nhierarchical deep CNNs (HD-CNNs) by embedding deep CNNs into a category\nhierarchy. An HD-CNN separates easy classes using a coarse category classifier\nwhile distinguishing difficult classes using fine category classifiers. During\nHD-CNN training, component-wise pretraining is followed by global finetuning\nwith a multinomial logistic loss regularized by a coarse category consistency\nterm. In addition, conditional executions of fine category classifiers and\nlayer parameter compression make HD-CNNs scalable for large-scale visual\nrecognition. We achieve state-of-the-art results on both CIFAR100 and\nlarge-scale ImageNet 1000-class benchmark datasets. In our experiments, we\nbuild up three different HD-CNNs and they lower the top-1 error of the standard\nCNNs by 2.65%, 3.1% and 1.1%, respectively.\n",
        "published": "2014",
        "authors": [
            "Zhicheng Yan",
            "Hao Zhang",
            "Robinson Piramuthu",
            "Vignesh Jagadeesh",
            "Dennis DeCoste",
            "Wei Di",
            "Yizhou Yu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1506.01911v3",
        "title": "Beyond Temporal Pooling: Recurrence and Temporal Convolutions for\n  Gesture Recognition in Video",
        "abstract": "  Recent studies have demonstrated the power of recurrent neural networks for\nmachine translation, image captioning and speech recognition. For the task of\ncapturing temporal structure in video, however, there still remain numerous\nopen research questions. Current research suggests using a simple temporal\nfeature pooling strategy to take into account the temporal aspect of video. We\ndemonstrate that this method is not sufficient for gesture recognition, where\ntemporal information is more discriminative compared to general video\nclassification tasks. We explore deep architectures for gesture recognition in\nvideo and propose a new end-to-end trainable neural network architecture\nincorporating temporal convolutions and bidirectional recurrence. Our main\ncontributions are twofold; first, we show that recurrence is crucial for this\ntask; second, we show that adding temporal convolutions leads to significant\nimprovements. We evaluate the different approaches on the Montalbano gesture\nrecognition dataset, where we achieve state-of-the-art results.\n",
        "published": "2015",
        "authors": [
            "Lionel Pigou",
            "A\u00e4ron van den Oord",
            "Sander Dieleman",
            "Mieke Van Herreweghe",
            "Joni Dambre"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1509.05962v2",
        "title": "Telugu OCR Framework using Deep Learning",
        "abstract": "  In this paper, we address the task of Optical Character Recognition(OCR) for\nthe Telugu script. We present an end-to-end framework that segments the text\nimage, classifies the characters and extracts lines using a language model. The\nsegmentation is based on mathematical morphology. The classification module,\nwhich is the most challenging task of the three, is a deep convolutional neural\nnetwork. The language is modelled as a third degree markov chain at the glyph\nlevel. Telugu script is a complex alphasyllabary and the language is\nagglutinative, making the problem hard. In this paper we apply the latest\nadvances in neural networks to achieve state-of-the-art error rates. We also\nreview convolutional neural networks in great detail and expound the\nstatistical justification behind the many tricks needed to make Deep Learning\nwork.\n",
        "published": "2015",
        "authors": [
            "Rakesh Achanta",
            "Trevor Hastie"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1605.09782v7",
        "title": "Adversarial Feature Learning",
        "abstract": "  The ability of the Generative Adversarial Networks (GANs) framework to learn\ngenerative models mapping from simple latent distributions to arbitrarily\ncomplex data distributions has been demonstrated empirically, with compelling\nresults showing that the latent space of such generators captures semantic\nvariation in the data distribution. Intuitively, models trained to predict\nthese semantic latent representations given data may serve as useful feature\nrepresentations for auxiliary problems where semantics are relevant. However,\nin their existing form, GANs have no means of learning the inverse mapping --\nprojecting data back into the latent space. We propose Bidirectional Generative\nAdversarial Networks (BiGANs) as a means of learning this inverse mapping, and\ndemonstrate that the resulting learned feature representation is useful for\nauxiliary supervised discrimination tasks, competitive with contemporary\napproaches to unsupervised and self-supervised feature learning.\n",
        "published": "2016",
        "authors": [
            "Jeff Donahue",
            "Philipp Kr\u00e4henb\u00fchl",
            "Trevor Darrell"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1701.06106v2",
        "title": "Neurogenesis-Inspired Dictionary Learning: Online Model Adaption in a\n  Changing World",
        "abstract": "  In this paper, we focus on online representation learning in non-stationary\nenvironments which may require continuous adaptation of model architecture. We\npropose a novel online dictionary-learning (sparse-coding) framework which\nincorporates the addition and deletion of hidden units (dictionary elements),\nand is inspired by the adult neurogenesis phenomenon in the dentate gyrus of\nthe hippocampus, known to be associated with improved cognitive function and\nadaptation to new environments. In the online learning setting, where new input\ninstances arrive sequentially in batches, the neuronal-birth is implemented by\nadding new units with random initial weights (random dictionary elements); the\nnumber of new units is determined by the current performance (representation\nerror) of the dictionary, higher error causing an increase in the birth rate.\nNeuronal-death is implemented by imposing l1/l2-regularization (group sparsity)\non the dictionary within the block-coordinate descent optimization at each\niteration of our online alternating minimization scheme, which iterates between\nthe code and dictionary updates. Finally, hidden unit connectivity adaptation\nis facilitated by introducing sparsity in dictionary elements. Our empirical\nevaluation on several real-life datasets (images and language) as well as on\nsynthetic data demonstrates that the proposed approach can considerably\noutperform the state-of-art fixed-size (nonadaptive) online sparse coding of\nMairal et al. (2009) in the presence of nonstationary data. Moreover, we\nidentify certain properties of the data (e.g., sparse inputs with nearly\nnon-overlapping supports) and of the model (e.g., dictionary sparsity)\nassociated with such improvements.\n",
        "published": "2017",
        "authors": [
            "Sahil Garg",
            "Irina Rish",
            "Guillermo Cecchi",
            "Aurelie Lozano"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1702.08690v2",
        "title": "Borrowing Treasures from the Wealthy: Deep Transfer Learning through\n  Selective Joint Fine-tuning",
        "abstract": "  Deep neural networks require a large amount of labeled training data during\nsupervised learning. However, collecting and labeling so much data might be\ninfeasible in many cases. In this paper, we introduce a source-target selective\njoint fine-tuning scheme for improving the performance of deep learning tasks\nwith insufficient training data. In this scheme, a target learning task with\ninsufficient training data is carried out simultaneously with another source\nlearning task with abundant training data. However, the source learning task\ndoes not use all existing training data. Our core idea is to identify and use a\nsubset of training images from the original source learning task whose\nlow-level characteristics are similar to those from the target learning task,\nand jointly fine-tune shared convolutional layers for both tasks. Specifically,\nwe compute descriptors from linear or nonlinear filter bank responses on\ntraining images from both tasks, and use such descriptors to search for a\ndesired subset of training samples for the source learning task.\n  Experiments demonstrate that our selective joint fine-tuning scheme achieves\nstate-of-the-art performance on multiple visual classification tasks with\ninsufficient training data for deep learning. Such tasks include Caltech 256,\nMIT Indoor 67, Oxford Flowers 102 and Stanford Dogs 120. In comparison to\nfine-tuning without a source domain, the proposed method can improve the\nclassification accuracy by 2% - 10% using a single model.\n",
        "published": "2017",
        "authors": [
            "Weifeng Ge",
            "Yizhou Yu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1705.07904v3",
        "title": "Semantically Decomposing the Latent Spaces of Generative Adversarial\n  Networks",
        "abstract": "  We propose a new algorithm for training generative adversarial networks that\njointly learns latent codes for both identities (e.g. individual humans) and\nobservations (e.g. specific photographs). By fixing the identity portion of the\nlatent codes, we can generate diverse images of the same subject, and by fixing\nthe observation portion, we can traverse the manifold of subjects while\nmaintaining contingent aspects such as lighting and pose. Our algorithm\nfeatures a pairwise training scheme in which each sample from the generator\nconsists of two images with a common identity code. Corresponding samples from\nthe real dataset consist of two distinct photographs of the same subject. In\norder to fool the discriminator, the generator must produce pairs that are\nphotorealistic, distinct, and appear to depict the same individual. We augment\nboth the DCGAN and BEGAN approaches with Siamese discriminators to facilitate\npairwise training. Experiments with human judges and an off-the-shelf face\nverification system demonstrate our algorithm's ability to generate convincing,\nidentity-matched photographs.\n",
        "published": "2017",
        "authors": [
            "Chris Donahue",
            "Zachary C. Lipton",
            "Akshay Balsubramani",
            "Julian McAuley"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1706.02257v1",
        "title": "Driver Action Prediction Using Deep (Bidirectional) Recurrent Neural\n  Network",
        "abstract": "  Advanced driver assistance systems (ADAS) can be significantly improved with\neffective driver action prediction (DAP). Predicting driver actions early and\naccurately can help mitigate the effects of potentially unsafe driving\nbehaviors and avoid possible accidents. In this paper, we formulate driver\naction prediction as a timeseries anomaly prediction problem. While the anomaly\n(driver actions of interest) detection might be trivial in this context,\nfinding patterns that consistently precede an anomaly requires searching for or\nextracting features across multi-modal sensory inputs. We present such a driver\naction prediction system, including a real-time data acquisition, processing\nand learning framework for predicting future or impending driver action. The\nproposed system incorporates camera-based knowledge of the driving environment\nand the driver themselves, in addition to traditional vehicle dynamics. It then\nuses a deep bidirectional recurrent neural network (DBRNN) to learn the\ncorrelation between sensory inputs and impending driver behavior achieving\naccurate and high horizon action prediction. The proposed system performs\nbetter than other existing systems on driver action prediction tasks and can\naccurately predict key driver actions including acceleration, braking, lane\nchange and turning at durations of 5sec before the action is executed by the\ndriver.\n",
        "published": "2017",
        "authors": [
            "Oluwatobi Olabiyi",
            "Eric Martinson",
            "Vijay Chintalapudi",
            "Rui Guo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1706.05507v2",
        "title": "Variants of RMSProp and Adagrad with Logarithmic Regret Bounds",
        "abstract": "  Adaptive gradient methods have become recently very popular, in particular as\nthey have been shown to be useful in the training of deep neural networks. In\nthis paper we have analyzed RMSProp, originally proposed for the training of\ndeep neural networks, in the context of online convex optimization and show\n$\\sqrt{T}$-type regret bounds. Moreover, we propose two variants SC-Adagrad and\nSC-RMSProp for which we show logarithmic regret bounds for strongly convex\nfunctions. Finally, we demonstrate in the experiments that these new variants\noutperform other adaptive gradient techniques or stochastic gradient descent in\nthe optimization of strongly convex functions as well as in training of deep\nneural networks.\n",
        "published": "2017",
        "authors": [
            "Mahesh Chandra Mukkamala",
            "Matthias Hein"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1801.07648v2",
        "title": "Clustering with Deep Learning: Taxonomy and New Methods",
        "abstract": "  Clustering methods based on deep neural networks have proven promising for\nclustering real-world data because of their high representational power. In\nthis paper, we propose a systematic taxonomy of clustering methods that utilize\ndeep neural networks. We base our taxonomy on a comprehensive review of recent\nwork and validate the taxonomy in a case study. In this case study, we show\nthat the taxonomy enables researchers and practitioners to systematically\ncreate new clustering methods by selectively recombining and replacing distinct\naspects of previous methods with the goal of overcoming their individual\nlimitations. The experimental evaluation confirms this and shows that the\nmethod created for the case study achieves state-of-the-art clustering quality\nand surpasses it in some cases.\n",
        "published": "2018",
        "authors": [
            "Elie Aljalbout",
            "Vladimir Golkov",
            "Yawar Siddiqui",
            "Maximilian Strobel",
            "Daniel Cremers"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.09816v1",
        "title": "Coarse to fine non-rigid registration: a chain of scale-specific neural\n  networks for multimodal image alignment with application to remote sensing",
        "abstract": "  We tackle here the problem of multimodal image non-rigid registration, which\nis of prime importance in remote sensing and medical imaging. The difficulties\nencountered by classical registration approaches include feature design and\nslow optimization by gradient descent. By analyzing these methods, we note the\nsignificance of the notion of scale. We design easy-to-train,\nfully-convolutional neural networks able to learn scale-specific features. Once\nchained appropriately, they perform global registration in linear time, getting\nrid of gradient descent schemes by predicting directly the deformation.We show\ntheir performance in terms of quality and speed through various tasks of remote\nsensing multimodal image alignment. In particular, we are able to register\ncorrectly cadastral maps of buildings as well as road polylines onto RGB\nimages, and outperform current keypoint matching methods.\n",
        "published": "2018",
        "authors": [
            "Armand Zampieri",
            "Guillaume Charpiat",
            "Yuliya Tarabalka"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.02997v2",
        "title": "q-Space Novelty Detection with Variational Autoencoders",
        "abstract": "  In machine learning, novelty detection is the task of identifying novel\nunseen data. During training, only samples from the normal class are available.\nTest samples are classified as normal or abnormal by assignment of a novelty\nscore. Here we propose novelty detection methods based on training variational\nautoencoders (VAEs) on normal data. Since abnormal samples are not used during\ntraining, we define novelty metrics based on the (partially complementary)\nassumptions that the VAE is less capable of reconstructing abnormal samples\nwell; that abnormal samples more strongly violate the VAE regularizer; and that\nabnormal samples differ from normal samples not only in input-feature space,\nbut also in the VAE latent space and VAE output. These approaches, combined\nwith various possibilities of using (e.g. sampling) the probabilistic VAE to\nobtain scalar novelty scores, yield a large family of methods. We apply these\nmethods to magnetic resonance imaging, namely to the detection of\ndiffusion-space (q-space) abnormalities in diffusion MRI scans of multiple\nsclerosis patients, i.e. to detect multiple sclerosis lesions without using any\nlesion labels for training. Many of our methods outperform previously proposed\nq-space novelty detection methods. We also evaluate the proposed methods on the\nMNIST handwritten digits dataset and show that many of them are able to\noutperform the state of the art.\n",
        "published": "2018",
        "authors": [
            "Aleksei Vasilev",
            "Vladimir Golkov",
            "Marc Meissner",
            "Ilona Lipp",
            "Eleonora Sgarlata",
            "Valentina Tomassini",
            "Derek K. Jones",
            "Daniel Cremers"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.04552v1",
        "title": "Combining Model-Free Q-Ensembles and Model-Based Approaches for Informed\n  Exploration",
        "abstract": "  Q-Ensembles are a model-free approach where input images are fed into\ndifferent Q-networks and exploration is driven by the assumption that\nuncertainty is proportional to the variance of the output Q-values obtained.\nThey have been shown to perform relatively well compared to other exploration\nstrategies. Further, model-based approaches, such as encoder-decoder models\nhave been used successfully for next frame prediction given previous frames.\nThis paper proposes to integrate the model-free Q-ensembles and model-based\napproaches with the hope of compounding the benefits of both and achieving\nsuperior exploration as a result. Results show that a model-based trajectory\nmemory approach when combined with Q-ensembles produces superior performance\nwhen compared to only using Q-ensembles.\n",
        "published": "2018",
        "authors": [
            "Sreecharan Sankaranarayanan",
            "Raghuram Mandyam Annasamy",
            "Katia Sycara",
            "Carolyn Penstein Ros\u00e9"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.05759v3",
        "title": "Insights on representational similarity in neural networks with\n  canonical correlation",
        "abstract": "  Comparing different neural network representations and determining how\nrepresentations evolve over time remain challenging open questions in our\nunderstanding of the function of neural networks. Comparing representations in\nneural networks is fundamentally difficult as the structure of representations\nvaries greatly, even across groups of networks trained on identical tasks, and\nover the course of training. Here, we develop projection weighted CCA\n(Canonical Correlation Analysis) as a tool for understanding neural networks,\nbuilding off of SVCCA, a recently proposed method (Raghu et al., 2017). We\nfirst improve the core method, showing how to differentiate between signal and\nnoise, and then apply this technique to compare across a group of CNNs,\ndemonstrating that networks which generalize converge to more similar\nrepresentations than networks which memorize, that wider networks converge to\nmore similar solutions than narrow networks, and that trained networks with\nidentical topology but different learning rates converge to distinct clusters\nwith diverse representations. We also investigate the representational dynamics\nof RNNs, across both training and sequential timesteps, finding that RNNs\nconverge in a bottom-up pattern over the course of training and that the hidden\nstate is highly variable over the course of a sequence, even when accounting\nfor linear transforms. Together, these results provide new insights into the\nfunction of CNNs and RNNs, and demonstrate the utility of using CCA to\nunderstand representations.\n",
        "published": "2018",
        "authors": [
            "Ari S. Morcos",
            "Maithra Raghu",
            "Samy Bengio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.07550v2",
        "title": "Binary Ensemble Neural Network: More Bits per Network or More Networks\n  per Bit?",
        "abstract": "  Binary neural networks (BNN) have been studied extensively since they run\ndramatically faster at lower memory and power consumption than floating-point\nnetworks, thanks to the efficiency of bit operations. However, contemporary\nBNNs whose weights and activations are both single bits suffer from severe\naccuracy degradation. To understand why, we investigate the representation\nability, speed and bias/variance of BNNs through extensive experiments. We\nconclude that the error of BNNs is predominantly caused by the intrinsic\ninstability (training time) and non-robustness (train & test time). Inspired by\nthis investigation, we propose the Binary Ensemble Neural Network (BENN) which\nleverages ensemble methods to improve the performance of BNNs with limited\nefficiency cost. While ensemble techniques have been broadly believed to be\nonly marginally helpful for strong classifiers such as deep neural networks,\nour analyses and experiments show that they are naturally a perfect fit to\nboost BNNs. We find that our BENN, which is faster and much more robust than\nstate-of-the-art binary networks, can even surpass the accuracy of the\nfull-precision floating number network with the same architecture.\n",
        "published": "2018",
        "authors": [
            "Shilin Zhu",
            "Xin Dong",
            "Hao Su"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.08568v3",
        "title": "Continuous Learning in Single-Incremental-Task Scenarios",
        "abstract": "  It was recently shown that architectural, regularization and rehearsal\nstrategies can be used to train deep models sequentially on a number of\ndisjoint tasks without forgetting previously acquired knowledge. However, these\nstrategies are still unsatisfactory if the tasks are not disjoint but\nconstitute a single incremental task (e.g., class-incremental learning). In\nthis paper we point out the differences between multi-task and\nsingle-incremental-task scenarios and show that well-known approaches such as\nLWF, EWC and SI are not ideal for incremental task scenarios. A new approach,\ndenoted as AR1, combining architectural and regularization strategies is then\nspecifically proposed. AR1 overhead (in term of memory and computation) is very\nsmall thus making it suitable for online learning. When tested on CORe50 and\niCIFAR-100, AR1 outperformed existing regularization strategies by a good\nmargin.\n",
        "published": "2018",
        "authors": [
            "Davide Maltoni",
            "Vincenzo Lomonaco"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.01697v5",
        "title": "Benchmarking Neural Network Robustness to Common Corruptions and Surface\n  Variations",
        "abstract": "  In this paper we establish rigorous benchmarks for image classifier\nrobustness. Our first benchmark, ImageNet-C, standardizes and expands the\ncorruption robustness topic, while showing which classifiers are preferable in\nsafety-critical applications. Unlike recent robustness research, this benchmark\nevaluates performance on commonplace corruptions not worst-case adversarial\ncorruptions. We find that there are negligible changes in relative corruption\nrobustness from AlexNet to ResNet classifiers, and we discover ways to enhance\ncorruption robustness. Then we propose a new dataset called Icons-50 which\nopens research on a new kind of robustness, surface variation robustness. With\nthis dataset we evaluate the frailty of classifiers on new styles of known\nobjects and unexpected instances of known classes. We also demonstrate two\nmethods that improve surface variation robustness. Together our benchmarks may\naid future work toward networks that learn fundamental class structure and also\nrobustly generalize.\n",
        "published": "2018",
        "authors": [
            "Dan Hendrycks",
            "Thomas G. Dietterich"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.06540v1",
        "title": "Icing on the Cake: An Easy and Quick Post-Learnig Method You Can Try\n  After Deep Learning",
        "abstract": "  We found an easy and quick post-learning method named \"Icing on the Cake\" to\nenhance a classification performance in deep learning. The method is that we\ntrain only the final classifier again after an ordinary training is done.\n",
        "published": "2018",
        "authors": [
            "Tomohiko Konno",
            "Michiaki Iwazume"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.02657v2",
        "title": "A Bayesian Perspective of Convolutional Neural Networks through a\n  Deconvolutional Generative Model",
        "abstract": "  Inspired by the success of Convolutional Neural Networks (CNNs) for\nsupervised prediction in images, we design the Deconvolutional Generative Model\n(DGM), a new probabilistic generative model whose inference calculations\ncorrespond to those in a given CNN architecture. The DGM uses a CNN to design\nthe prior distribution in the probabilistic model. Furthermore, the DGM\ngenerates images from coarse to finer scales. It introduces a small set of\nlatent variables at each scale, and enforces dependencies among all the latent\nvariables via a conjugate prior distribution. This conjugate prior yields a new\nregularizer based on paths rendered in the generative model for training\nCNNs-the Rendering Path Normalization (RPN). We demonstrate that this\nregularizer improves generalization, both in theory and in practice. In\naddition, likelihood estimation in the DGM yields training losses for CNNs, and\ninspired by this, we design a new loss termed as the Max-Min cross entropy\nwhich outperforms the traditional cross-entropy loss for object classification.\nThe Max-Min cross entropy suggests a new deep network architecture, namely the\nMax-Min network, which can learn from less labeled data while maintaining good\nprediction performance. Our experiments demonstrate that the DGM with the RPN\nand the Max-Min architecture exceeds or matches the-state-of-art on benchmarks\nincluding SVHN, CIFAR10, and CIFAR100 for semi-supervised and supervised\nlearning tasks.\n",
        "published": "2018",
        "authors": [
            "Tan Nguyen",
            "Nhat Ho",
            "Ankit Patel",
            "Anima Anandkumar",
            "Michael I. Jordan",
            "Richard G. Baraniuk"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.03567v3",
        "title": "Biologically-plausible learning algorithms can scale to large datasets",
        "abstract": "  The backpropagation (BP) algorithm is often thought to be biologically\nimplausible in the brain. One of the main reasons is that BP requires symmetric\nweight matrices in the feedforward and feedback pathways. To address this\n\"weight transport problem\" (Grossberg, 1987), two more biologically plausible\nalgorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax\nBP's weight symmetry requirements and demonstrate comparable learning\ncapabilities to that of BP on small datasets. However, a recent study by\nBartunov et al. (2018) evaluate variants of target-propagation (TP) and\nfeedback alignment (FA) on MINIST, CIFAR, and ImageNet datasets, and find that\nalthough many of the proposed algorithms perform well on MNIST and CIFAR, they\nperform significantly worse than BP on ImageNet. Here, we additionally evaluate\nthe sign-symmetry algorithm (Liao et al., 2016), which differs from both BP and\nFA in that the feedback and feedforward weights share signs but not magnitudes.\nWe examine the performance of sign-symmetry and feedback alignment on ImageNet\nand MS COCO datasets using different network architectures (ResNet-18 and\nAlexNet for ImageNet, RetinaNet for MS COCO). Surprisingly, networks trained\nwith sign-symmetry can attain classification performance approaching that of\nBP-trained networks. These results complement the study by Bartunov et al.\n(2018), and establish a new benchmark for future biologically plausible\nlearning algorithms on more difficult datasets and more complex architectures.\n",
        "published": "2018",
        "authors": [
            "Will Xiao",
            "Honglin Chen",
            "Qianli Liao",
            "Tomaso Poggio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1901.09972v1",
        "title": "Heartbeat Anomaly Detection using Adversarial Oversampling",
        "abstract": "  Cardiovascular diseases are one of the most common causes of death in the\nworld. Prevention, knowledge of previous cases in the family, and early\ndetection is the best strategy to reduce this fact. Different machine learning\napproaches to automatic diagnostic are being proposed to this task. As in most\nhealth problems, the imbalance between examples and classes is predominant in\nthis problem and affects the performance of the automated solution. In this\npaper, we address the classification of heartbeats images in different\ncardiovascular diseases. We propose a two-dimensional Convolutional Neural\nNetwork for classification after using a InfoGAN architecture for generating\nsynthetic images to unbalanced classes. We call this proposal Adversarial\nOversampling and compare it with the classical oversampling methods as SMOTE,\nADASYN, and RandomOversampling. The results show that the proposed approach\nimproves the classifier performance for the minority classes without harming\nthe performance in the balanced classes.\n",
        "published": "2019",
        "authors": [
            "Jefferson L. P. Lima",
            "David Mac\u00eado",
            "Cleber Zanchettin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.10178v1",
        "title": "Unmasking Clever Hans Predictors and Assessing What Machines Really\n  Learn",
        "abstract": "  Current learning machines have successfully solved hard application problems,\nreaching high accuracy and displaying seemingly \"intelligent\" behavior. Here we\napply recent techniques for explaining decisions of state-of-the-art learning\nmachines and analyze various tasks from computer vision and arcade games. This\nshowcases a spectrum of problem-solving behaviors ranging from naive and\nshort-sighted, to well-informed and strategic. We observe that standard\nperformance evaluation metrics can be oblivious to distinguishing these diverse\nproblem solving behaviors. Furthermore, we propose our semi-automated Spectral\nRelevance Analysis that provides a practically effective way of characterizing\nand validating the behavior of nonlinear learning machines. This helps to\nassess whether a learned model indeed delivers reliably for the problem that it\nwas conceived for. Furthermore, our work intends to add a voice of caution to\nthe ongoing excitement about machine intelligence and pledges to evaluate and\njudge some of these recent successes in a more nuanced manner.\n",
        "published": "2019",
        "authors": [
            "Sebastian Lapuschkin",
            "Stephan W\u00e4ldchen",
            "Alexander Binder",
            "Gr\u00e9goire Montavon",
            "Wojciech Samek",
            "Klaus-Robert M\u00fcller"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1709.01215v2",
        "title": "ALICE: Towards Understanding Adversarial Learning for Joint Distribution\n  Matching",
        "abstract": "  We investigate the non-identifiability issues associated with bidirectional\nadversarial training for joint distribution matching. Within a framework of\nconditional entropy, we propose both adversarial and non-adversarial approaches\nto learn desirable matched joint distributions for unsupervised and supervised\ntasks. We unify a broad family of adversarial models as joint distribution\nmatching problems. Our approach stabilizes learning of unsupervised\nbidirectional adversarial learning methods. Further, we introduce an extension\nfor semi-supervised learning tasks. Theoretical results are validated in\nsynthetic data and real-world applications.\n",
        "published": "2017",
        "authors": [
            "Chunyuan Li",
            "Hao Liu",
            "Changyou Chen",
            "Yunchen Pu",
            "Liqun Chen",
            "Ricardo Henao",
            "Lawrence Carin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.02124v2",
        "title": "Non-Structured DNN Weight Pruning -- Is It Beneficial in Any Platform?",
        "abstract": "  Large deep neural network (DNN) models pose the key challenge to energy\nefficiency due to the significantly higher energy consumption of off-chip DRAM\naccesses than arithmetic or SRAM operations. It motivates the intensive\nresearch on model compression with two main approaches. Weight pruning\nleverages the redundancy in the number of weights and can be performed in a\nnon-structured, which has higher flexibility and pruning rate but incurs index\naccesses due to irregular weights, or structured manner, which preserves the\nfull matrix structure with lower pruning rate. Weight quantization leverages\nthe redundancy in the number of bits in weights. Compared to pruning,\nquantization is much more hardware-friendly, and has become a \"must-do\" step\nfor FPGA and ASIC implementations. This paper provides a definitive answer to\nthe question for the first time. First, we build ADMM-NN-S by extending and\nenhancing ADMM-NN, a recently proposed joint weight pruning and quantization\nframework. Second, we develop a methodology for fair and fundamental comparison\nof non-structured and structured pruning in terms of both storage and\ncomputation efficiency. Our results show that ADMM-NN-S consistently\noutperforms the prior art: (i) it achieves 348x, 36x, and 8x overall weight\npruning on LeNet-5, AlexNet, and ResNet-50, respectively, with (almost) zero\naccuracy loss; (ii) we demonstrate the first fully binarized (for all layers)\nDNNs can be lossless in accuracy in many cases. These results provide a strong\nbaseline and credibility of our study. Based on the proposed comparison\nframework, with the same accuracy and quantization, the results show that\nnon-structrued pruning is not competitive in terms of both storage and\ncomputation efficiency. Thus, we conclude that non-structured pruning is\nconsidered harmful. We urge the community not to continue the DNN inference\nacceleration for non-structured sparsity.\n",
        "published": "2019",
        "authors": [
            "Xiaolong Ma",
            "Sheng Lin",
            "Shaokai Ye",
            "Zhezhi He",
            "Linfeng Zhang",
            "Geng Yuan",
            "Sia Huat Tan",
            "Zhengang Li",
            "Deliang Fan",
            "Xuehai Qian",
            "Xue Lin",
            "Kaisheng Ma",
            "Yanzhi Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.03141v2",
        "title": "AutoCompress: An Automatic DNN Structured Pruning Framework for\n  Ultra-High Compression Rates",
        "abstract": "  Structured weight pruning is a representative model compression technique of\nDNNs to reduce the storage and computation requirements and accelerate\ninference. An automatic hyperparameter determination process is necessary due\nto the large number of flexible hyperparameters. This work proposes\nAutoCompress, an automatic structured pruning framework with the following key\nperformance improvements: (i) effectively incorporate the combination of\nstructured pruning schemes in the automatic process; (ii) adopt the\nstate-of-art ADMM-based structured weight pruning as the core algorithm, and\npropose an innovative additional purification step for further weight reduction\nwithout accuracy loss; and (iii) develop effective heuristic search method\nenhanced by experience-based guided search, replacing the prior deep\nreinforcement learning technique which has underlying incompatibility with the\ntarget pruning problem. Extensive experiments on CIFAR-10 and ImageNet datasets\ndemonstrate that AutoCompress is the key to achieve ultra-high pruning rates on\nthe number of weights and FLOPs that cannot be achieved before. As an example,\nAutoCompress outperforms the prior work on automatic model compression by up to\n33x in pruning rate (120x reduction in the actual parameter count) under the\nsame accuracy. Significant inference speedup has been observed from the\nAutoCompress framework on actual measurements on smartphone. We release all\nmodels of this work at anonymous link: http://bit.ly/2VZ63dS.\n",
        "published": "2019",
        "authors": [
            "Ning Liu",
            "Xiaolong Ma",
            "Zhiyuan Xu",
            "Yanzhi Wang",
            "Jian Tang",
            "Jieping Ye"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.00289v3",
        "title": "Building Machines That Learn and Think Like People",
        "abstract": "  Recent progress in artificial intelligence (AI) has renewed interest in\nbuilding systems that learn and think like people. Many advances have come from\nusing deep neural networks trained end-to-end in tasks such as object\nrecognition, video games, and board games, achieving performance that equals or\neven beats humans in some respects. Despite their biological inspiration and\nperformance achievements, these systems differ from human intelligence in\ncrucial ways. We review progress in cognitive science suggesting that truly\nhuman-like learning and thinking machines will have to reach beyond current\nengineering trends in both what they learn, and how they learn it.\nSpecifically, we argue that these machines should (a) build causal models of\nthe world that support explanation and understanding, rather than merely\nsolving pattern recognition problems; (b) ground learning in intuitive theories\nof physics and psychology, to support and enrich the knowledge that is learned;\nand (c) harness compositionality and learning-to-learn to rapidly acquire and\ngeneralize knowledge to new tasks and situations. We suggest concrete\nchallenges and promising routes towards these goals that can combine the\nstrengths of recent neural network advances with more structured cognitive\nmodels.\n",
        "published": "2016",
        "authors": [
            "Brenden M. Lake",
            "Tomer D. Ullman",
            "Joshua B. Tenenbaum",
            "Samuel J. Gershman"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.01662v4",
        "title": "A Survey on Bayesian Deep Learning",
        "abstract": "  A comprehensive artificial intelligence system needs to not only perceive the\nenvironment with different `senses' (e.g., seeing and hearing) but also infer\nthe world's conditional (or even causal) relations and corresponding\nuncertainty. The past decade has seen major advances in many perception tasks\nsuch as visual object recognition and speech recognition using deep learning\nmodels. For higher-level inference, however, probabilistic graphical models\nwith their Bayesian nature are still more powerful and flexible. In recent\nyears, Bayesian deep learning has emerged as a unified probabilistic framework\nto tightly integrate deep learning and Bayesian models. In this general\nframework, the perception of text or images using deep learning can boost the\nperformance of higher-level inference and in turn, the feedback from the\ninference process is able to enhance the perception of text or images. This\nsurvey provides a comprehensive introduction to Bayesian deep learning and\nreviews its recent applications on recommender systems, topic models, control,\netc. Besides, we also discuss the relationship and differences between Bayesian\ndeep learning and other related topics such as Bayesian treatment of neural\nnetworks. For a constantly updating project page, please refer to\nhttps://github.com/js05212/BayesianDeepLearning-Survey.\n",
        "published": "2016",
        "authors": [
            "Hao Wang",
            "Dit-Yan Yeung"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.06057v2",
        "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal\n  Abstraction and Intrinsic Motivation",
        "abstract": "  Learning goal-directed behavior in environments with sparse feedback is a\nmajor challenge for reinforcement learning algorithms. The primary difficulty\narises due to insufficient exploration, resulting in an agent being unable to\nlearn robust value functions. Intrinsically motivated agents can explore new\nbehavior for its own sake rather than to directly solve problems. Such\nintrinsic behaviors could eventually help the agent solve tasks posed by the\nenvironment. We present hierarchical-DQN (h-DQN), a framework to integrate\nhierarchical value functions, operating at different temporal scales, with\nintrinsically motivated deep reinforcement learning. A top-level value function\nlearns a policy over intrinsic goals, and a lower-level function learns a\npolicy over atomic actions to satisfy the given goals. h-DQN allows for\nflexible goal specifications, such as functions over entities and relations.\nThis provides an efficient space for exploration in complicated environments.\nWe demonstrate the strength of our approach on two problems with very sparse,\ndelayed feedback: (1) a complex discrete stochastic decision process, and (2)\nthe classic ATARI game `Montezuma's Revenge'.\n",
        "published": "2016",
        "authors": [
            "Tejas D. Kulkarni",
            "Karthik R. Narasimhan",
            "Ardavan Saeedi",
            "Joshua B. Tenenbaum"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.01717v2",
        "title": "Towards Accurate Generative Models of Video: A New Metric & Challenges",
        "abstract": "  Recent advances in deep generative models have lead to remarkable progress in\nsynthesizing high quality images. Following their successful application in\nimage processing and representation learning, an important next step is to\nconsider videos. Learning generative models of video is a much harder task,\nrequiring a model to capture the temporal dynamics of a scene, in addition to\nthe visual presentation of objects. While recent attempts at formulating\ngenerative models of video have had some success, current progress is hampered\nby (1) the lack of qualitative metrics that consider visual quality, temporal\ncoherence, and diversity of samples, and (2) the wide gap between purely\nsynthetic video data sets and challenging real-world data sets in terms of\ncomplexity. To this extent we propose Fr\\'{e}chet Video Distance (FVD), a new\nmetric for generative models of video, and StarCraft 2 Videos (SCV), a\nbenchmark of game play from custom starcraft 2 scenarios that challenge the\ncurrent capabilities of generative models of video. We contribute a large-scale\nhuman study, which confirms that FVD correlates well with qualitative human\njudgment of generated videos, and provide initial benchmark results on SCV.\n",
        "published": "2018",
        "authors": [
            "Thomas Unterthiner",
            "Sjoerd van Steenkiste",
            "Karol Kurach",
            "Raphael Marinier",
            "Marcin Michalski",
            "Sylvain Gelly"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2001.08357v2",
        "title": "BLK-REW: A Unified Block-based DNN Pruning Framework using Reweighted\n  Regularization Method",
        "abstract": "  Accelerating DNN execution on various resource-limited computing platforms\nhas been a long-standing problem. Prior works utilize l1-based group lasso or\ndynamic regularization such as ADMM to perform structured pruning on DNN models\nto leverage the parallel computing architectures. However, both of the pruning\ndimensions and pruning methods lack universality, which leads to degraded\nperformance and limited applicability. To solve the problem, we propose a new\nblock-based pruning framework that comprises a general and flexible structured\npruning dimension as well as a powerful and efficient reweighted regularization\nmethod. Our framework is universal, which can be applied to both CNNs and RNNs,\nimplying complete support for the two major kinds of computation-intensive\nlayers (i.e., CONV and FC layers). To complete all aspects of the\npruning-for-acceleration task, we also integrate compiler-based code\noptimization into our framework that can perform DNN inference in a real-time\nmanner. To the best of our knowledge, it is the first time that the weight\npruning framework achieves universal coverage for both CNNs and RNNs with\nreal-time mobile acceleration and no accuracy compromise.\n",
        "published": "2020",
        "authors": [
            "Xiaolong Ma",
            "Zhengang Li",
            "Yifan Gong",
            "Tianyun Zhang",
            "Wei Niu",
            "Zheng Zhan",
            "Pu Zhao",
            "Jian Tang",
            "Xue Lin",
            "Bin Ren",
            "Yanzhi Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.06513v2",
        "title": "A Privacy-Preserving-Oriented DNN Pruning and Mobile Acceleration\n  Framework",
        "abstract": "  Weight pruning of deep neural networks (DNNs) has been proposed to satisfy\nthe limited storage and computing capability of mobile edge devices. However,\nprevious pruning methods mainly focus on reducing the model size and/or\nimproving performance without considering the privacy of user data. To mitigate\nthis concern, we propose a privacy-preserving-oriented pruning and mobile\nacceleration framework that does not require the private training dataset. At\nthe algorithm level of the proposed framework, a systematic weight pruning\ntechnique based on the alternating direction method of multipliers (ADMM) is\ndesigned to iteratively solve the pattern-based pruning problem for each layer\nwith randomly generated synthetic data. In addition, corresponding\noptimizations at the compiler level are leveraged for inference accelerations\non devices. With the proposed framework, users could avoid the time-consuming\npruning process for non-experts and directly benefit from compressed models.\nExperimental results show that the proposed framework outperforms three\nstate-of-art end-to-end DNN frameworks, i.e., TensorFlow-Lite, TVM, and MNN,\nwith speedup up to 4.2X, 2.5X, and 2.0X, respectively, with almost no accuracy\nloss, while preserving data privacy.\n",
        "published": "2020",
        "authors": [
            "Yifan Gong",
            "Zheng Zhan",
            "Zhengang Li",
            "Wei Niu",
            "Xiaolong Ma",
            "Wenhao Wang",
            "Bin Ren",
            "Caiwen Ding",
            "Xue Lin",
            "Xiaolin Xu",
            "Yanzhi Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.07631v2",
        "title": "Explaining Deep Neural Networks and Beyond: A Review of Methods and\n  Applications",
        "abstract": "  With the broader and highly successful usage of machine learning in industry\nand the sciences, there has been a growing demand for Explainable AI.\nInterpretability and explanation methods for gaining a better understanding\nabout the problem solving abilities and strategies of nonlinear Machine\nLearning, in particular, deep neural networks, are therefore receiving\nincreased attention. In this work we aim to (1) provide a timely overview of\nthis active emerging field, with a focus on 'post-hoc' explanations, and\nexplain its theoretical foundations, (2) put interpretability algorithms to a\ntest both from a theory and comparative evaluation perspective using extensive\nsimulations, (3) outline best practice aspects i.e. how to best include\ninterpretation methods into the standard usage of machine learning and (4)\ndemonstrate successful usage of explainable AI in a representative selection of\napplication scenarios. Finally, we discuss challenges and possible future\ndirections of this exciting foundational field of machine learning.\n",
        "published": "2020",
        "authors": [
            "Wojciech Samek",
            "Gr\u00e9goire Montavon",
            "Sebastian Lapuschkin",
            "Christopher J. Anders",
            "Klaus-Robert M\u00fcller"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.12857v3",
        "title": "NPENAS: Neural Predictor Guided Evolution for Neural Architecture Search",
        "abstract": "  Neural architecture search (NAS) is a promising method for automatically\ndesign neural architectures. NAS adopts a search strategy to explore the\npredefined search space to find outstanding performance architecture with the\nminimum searching costs. Bayesian optimization and evolutionary algorithms are\ntwo commonly used search strategies, but they suffer from computationally\nexpensive, challenge to implement or inefficient exploration ability. In this\npaper, we propose a neural predictor guided evolutionary algorithm to enhance\nthe exploration ability of EA for NAS (NPENAS) and design two kinds of neural\npredictors. The first predictor is defined from Bayesian optimization and we\npropose a graph-based uncertainty estimation network as a surrogate model that\nis easy to implement and computationally efficient. The second predictor is a\ngraph-based neural network that directly outputs the performance prediction of\nthe input neural architecture. The NPENAS using the two neural predictors are\ndenoted as NPENAS-BO and NPENAS-NP respectively. In addition, we introduce a\nnew random architecture sampling method to overcome the drawbacks of the\nexisting sampling method. Extensive experiments demonstrate the superiority of\nNPENAS. Quantitative results on three NAS search spaces indicate that both\nNPENAS-BO and NPENAS-NP outperform most existing NAS algorithms, with NPENAS-BO\nachieving state-of-the-art performance on NASBench-201 and NPENAS-NP on\nNASBench-101 and DARTS, respectively.\n",
        "published": "2020",
        "authors": [
            "Chen Wei",
            "Chuang Niu",
            "Yiping Tang",
            "Yue Wang",
            "Haihong Hu",
            "Jimin Liang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.07693v2",
        "title": "Linking average- and worst-case perturbation robustness via class\n  selectivity and dimensionality",
        "abstract": "  Representational sparsity is known to affect robustness to input\nperturbations in deep neural networks (DNNs), but less is known about how the\nsemantic content of representations affects robustness. Class selectivity-the\nvariability of a unit's responses across data classes or dimensions-is one way\nof quantifying the sparsity of semantic representations. Given recent evidence\nthat class selectivity may not be necessary for, and in some cases can impair\ngeneralization, we investigate whether it also confers robustness (or\nvulnerability) to perturbations of input data. We found that networks\nregularized to have lower levels of class selectivity were more robust to\naverage-case (naturalistic) perturbations, while networks with higher class\nselectivity are more vulnerable. In contrast, class selectivity increases\nrobustness to multiple types of worst-case (i.e. white box adversarial)\nperturbations, suggesting that while decreasing class selectivity is helpful\nfor average-case perturbations, it is harmful for worst-case perturbations. To\nexplain this difference, we studied the dimensionality of the networks'\nrepresentations: we found that the dimensionality of early-layer\nrepresentations is inversely proportional to a network's class selectivity, and\nthat adversarial samples cause a larger increase in early-layer dimensionality\nthan corrupted samples. Furthermore, the input-unit gradient is more variable\nacross samples and units in high-selectivity networks compared to\nlow-selectivity networks. These results lead to the conclusion that units\nparticipate more consistently in low-selectivity regimes compared to\nhigh-selectivity regimes, effectively creating a larger attack surface and\nhence vulnerability to worst-case perturbations.\n",
        "published": "2020",
        "authors": [
            "Matthew L. Leavitt",
            "Ari Morcos"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2107.06475v1",
        "title": "Generative and reproducible benchmarks for comprehensive evaluation of\n  machine learning classifiers",
        "abstract": "  Understanding the strengths and weaknesses of machine learning (ML)\nalgorithms is crucial for determine their scope of application. Here, we\nintroduce the DIverse and GENerative ML Benchmark (DIGEN) - a collection of\nsynthetic datasets for comprehensive, reproducible, and interpretable\nbenchmarking of machine learning algorithms for classification of binary\noutcomes. The DIGEN resource consists of 40 mathematical functions which map\ncontinuous features to discrete endpoints for creating synthetic datasets.\nThese 40 functions were discovered using a heuristic algorithm designed to\nmaximize the diversity of performance among multiple popular machine learning\nalgorithms thus providing a useful test suite for evaluating and comparing new\nmethods. Access to the generative functions facilitates understanding of why a\nmethod performs poorly compared to other algorithms thus providing ideas for\nimprovement. The resource with extensive documentation and analyses is\nopen-source and available on GitHub.\n",
        "published": "2021",
        "authors": [
            "Patryk Orzechowski",
            "Jason H. Moore"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1606.03490v3",
        "title": "The Mythos of Model Interpretability",
        "abstract": "  Supervised machine learning models boast remarkable predictive capabilities.\nBut can you trust your model? Will it work in deployment? What else can it tell\nyou about the world? We want models to be not only good, but interpretable. And\nyet the task of interpretation appears underspecified. Papers provide diverse\nand sometimes non-overlapping motivations for interpretability, and offer\nmyriad notions of what attributes render models interpretable. Despite this\nambiguity, many papers proclaim interpretability axiomatically, absent further\nexplanation. In this paper, we seek to refine the discourse on\ninterpretability. First, we examine the motivations underlying interest in\ninterpretability, finding them to be diverse and occasionally discordant. Then,\nwe address model properties and techniques thought to confer interpretability,\nidentifying transparency to humans and post-hoc explanations as competing\nnotions. Throughout, we discuss the feasibility and desirability of different\nnotions, and question the oft-made assertions that linear models are\ninterpretable and that deep neural networks are not.\n",
        "published": "2016",
        "authors": [
            "Zachary C. Lipton"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.06370v2",
        "title": "Learning Features by Watching Objects Move",
        "abstract": "  This paper presents a novel yet intuitive approach to unsupervised feature\nlearning. Inspired by the human visual system, we explore whether low-level\nmotion-based grouping cues can be used to learn an effective visual\nrepresentation. Specifically, we use unsupervised motion-based segmentation on\nvideos to obtain segments, which we use as 'pseudo ground truth' to train a\nconvolutional network to segment objects from a single frame. Given the\nextensive evidence that motion plays a key role in the development of the human\nvisual system, we hope that this straightforward approach to unsupervised\nlearning will be more effective than cleverly designed 'pretext' tasks studied\nin the literature. Indeed, our extensive experiments show that this is the\ncase. When used for transfer learning on object detection, our representation\nsignificantly outperforms previous unsupervised approaches across multiple\nsettings, especially when training data for the target task is scarce.\n",
        "published": "2016",
        "authors": [
            "Deepak Pathak",
            "Ross Girshick",
            "Piotr Doll\u00e1r",
            "Trevor Darrell",
            "Bharath Hariharan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.00260v2",
        "title": "Aligned Image-Word Representations Improve Inductive Transfer Across\n  Vision-Language Tasks",
        "abstract": "  An important goal of computer vision is to build systems that learn visual\nrepresentations over time that can be applied to many tasks. In this paper, we\ninvestigate a vision-language embedding as a core representation and show that\nit leads to better cross-task transfer than standard multi-task learning. In\nparticular, the task of visual recognition is aligned to the task of visual\nquestion answering by forcing each to use the same word-region embeddings. We\nshow this leads to greater inductive transfer from recognition to VQA than\nstandard multitask learning. Visual recognition also improves, especially for\ncategories that have relatively few recognition training labels but appear\noften in the VQA setting. Thus, our paper takes a small step towards creating\nmore general vision systems by showing the benefit of interpretable, flexible,\nand trainable core representations.\n",
        "published": "2017",
        "authors": [
            "Tanmay Gupta",
            "Kevin Shih",
            "Saurabh Singh",
            "Derek Hoiem"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.05712v3",
        "title": "Universal Adversarial Perturbations Against Semantic Image Segmentation",
        "abstract": "  While deep learning is remarkably successful on perceptual tasks, it was also\nshown to be vulnerable to adversarial perturbations of the input. These\nperturbations denote noise added to the input that was generated specifically\nto fool the system while being quasi-imperceptible for humans. More severely,\nthere even exist universal perturbations that are input-agnostic but fool the\nnetwork on the majority of inputs. While recent work has focused on image\nclassification, this work proposes attacks against semantic image segmentation:\nwe present an approach for generating (universal) adversarial perturbations\nthat make the network yield a desired target segmentation as output. We show\nempirically that there exist barely perceptible universal noise patterns which\nresult in nearly the same predicted segmentation for arbitrary inputs.\nFurthermore, we also show the existence of universal noise which removes a\ntarget class (e.g., all pedestrians) from the segmentation while leaving the\nsegmentation mostly unchanged otherwise.\n",
        "published": "2017",
        "authors": [
            "Jan Hendrik Metzen",
            "Mummadi Chaithanya Kumar",
            "Thomas Brox",
            "Volker Fischer"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.08045v2",
        "title": "The loss surface of deep and wide neural networks",
        "abstract": "  While the optimization problem behind deep neural networks is highly\nnon-convex, it is frequently observed in practice that training deep networks\nseems possible without getting stuck in suboptimal points. It has been argued\nthat this is the case as all local minima are close to being globally optimal.\nWe show that this is (almost) true, in fact almost all local minima are\nglobally optimal, for a fully connected network with squared loss and analytic\nactivation function given that the number of hidden units of one layer of the\nnetwork is larger than the number of training points and the network structure\nfrom this layer on is pyramidal.\n",
        "published": "2017",
        "authors": [
            "Quynh Nguyen",
            "Matthias Hein"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.05381v2",
        "title": "A systematic study of the class imbalance problem in convolutional\n  neural networks",
        "abstract": "  In this study, we systematically investigate the impact of class imbalance on\nclassification performance of convolutional neural networks (CNNs) and compare\nfrequently used methods to address the issue. Class imbalance is a common\nproblem that has been comprehensively studied in classical machine learning,\nyet very limited systematic research is available in the context of deep\nlearning. In our study, we use three benchmark datasets of increasing\ncomplexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of\nimbalance on classification and perform an extensive comparison of several\nmethods to address the issue: oversampling, undersampling, two-phase training,\nand thresholding that compensates for prior class probabilities. Our main\nevaluation metric is area under the receiver operating characteristic curve\n(ROC AUC) adjusted to multi-class tasks since overall accuracy metric is\nassociated with notable difficulties in the context of imbalanced data. Based\non results from our experiments we conclude that (i) the effect of class\nimbalance on classification performance is detrimental; (ii) the method of\naddressing class imbalance that emerged as dominant in almost all analyzed\nscenarios was oversampling; (iii) oversampling should be applied to the level\nthat completely eliminates the imbalance, whereas the optimal undersampling\nratio depends on the extent of imbalance; (iv) as opposed to some classical\nmachine learning models, oversampling does not cause overfitting of CNNs; (v)\nthresholding should be applied to compensate for prior class probabilities when\noverall number of properly classified cases is of interest.\n",
        "published": "2017",
        "authors": [
            "Mateusz Buda",
            "Atsuto Maki",
            "Maciej A. Mazurowski"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.10686v1",
        "title": "Regularization for Deep Learning: A Taxonomy",
        "abstract": "  Regularization is one of the crucial ingredients of deep learning, yet the\nterm regularization has various definitions, and regularization methods are\noften studied separately from each other. In our work we present a systematic,\nunifying taxonomy to categorize existing methods. We distinguish methods that\naffect data, network architectures, error terms, regularization terms, and\noptimization procedures. We do not provide all details about the listed\nmethods; instead, we present an overview of how the methods can be sorted into\nmeaningful categories and sub-categories. This helps revealing links and\nfundamental similarities between them. Finally, we include practical\nrecommendations both for users and for developers of new regularization\nmethods.\n",
        "published": "2017",
        "authors": [
            "Jan Kuka\u010dka",
            "Vladimir Golkov",
            "Daniel Cremers"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.01837v1",
        "title": "Towards a Spectrum of Graph Convolutional Networks",
        "abstract": "  We present our ongoing work on understanding the limitations of graph\nconvolutional networks (GCNs) as well as our work on generalizations of graph\nconvolutions for representing more complex node attribute dependencies. Based\non an analysis of GCNs with the help of the corresponding computation graphs,\nwe propose a generalization of existing GCNs where the aggregation operations\nare (a) determined by structural properties of the local neighborhood graphs\nand (b) not restricted to weighted averages. We show that the proposed approach\nis strictly more expressive while requiring only a modest increase in the\nnumber of parameters and computations. We also show that the proposed\ngeneralization is identical to standard convolutional layers when applied to\nregular grid graphs.\n",
        "published": "2018",
        "authors": [
            "Mathias Niepert",
            "Alberto Garcia-Duran"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.01890v2",
        "title": "RMDL: Random Multimodel Deep Learning for Classification",
        "abstract": "  The continually increasing number of complex datasets each year necessitates\never improving machine learning methods for robust and accurate categorization\nof these data. This paper introduces Random Multimodel Deep Learning (RMDL): a\nnew ensemble, deep learning approach for classification. Deep learning models\nhave achieved state-of-the-art results across many domains. RMDL solves the\nproblem of finding the best deep learning structure and architecture while\nsimultaneously improving robustness and accuracy through ensembles of deep\nlearning architectures. RDML can accept as input a variety data to include\ntext, video, images, and symbolic. This paper describes RMDL and shows test\nresults for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB,\nand 20newsgroup. These test results show that RDML produces consistently better\nperformance than standard methods over a broad range of data types and\nclassification problems.\n",
        "published": "2018",
        "authors": [
            "Kamran Kowsari",
            "Mojtaba Heidarysafa",
            "Donald E. Brown",
            "Kiana Jafari Meimandi",
            "Laura E. Barnes"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.08249v3",
        "title": "Classifier-agnostic saliency map extraction",
        "abstract": "  Currently available methods for extracting saliency maps identify parts of\nthe input which are the most important to a specific fixed classifier. We show\nthat this strong dependence on a given classifier hinders their performance. To\naddress this problem, we propose classifier-agnostic saliency map extraction,\nwhich finds all parts of the image that any classifier could use, not just one\ngiven in advance. We observe that the proposed approach extracts higher quality\nsaliency maps than prior work while being conceptually simple and easy to\nimplement. The method sets the new state of the art result for localization\ntask on the ImageNet data, outperforming all existing weakly-supervised\nlocalization techniques, despite not using the ground truth labels at the\ninference time. The code reproducing the results is available at\nhttps://github.com/kondiz/casme .\n  The final version of this manuscript is published in Computer Vision and\nImage Understanding and is available online at\nhttps://doi.org/10.1016/j.cviu.2020.102969 .\n",
        "published": "2018",
        "authors": [
            "Konrad Zolna",
            "Krzysztof J. Geras",
            "Kyunghyun Cho"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.08311v1",
        "title": "AgileNet: Lightweight Dictionary-based Few-shot Learning",
        "abstract": "  The success of deep learning models is heavily tied to the use of massive\namount of labeled data and excessively long training time. With the emergence\nof intelligent edge applications that use these models, the critical challenge\nis to obtain the same inference capability on a resource-constrained device\nwhile providing adaptability to cope with the dynamic changes in the data. We\npropose AgileNet, a novel lightweight dictionary-based few-shot learning\nmethodology which provides reduced complexity deep neural network for efficient\nexecution at the edge while enabling low-cost updates to capture the dynamics\nof the new data. Evaluations of state-of-the-art few-shot learning benchmarks\ndemonstrate the superior accuracy of AgileNet compared to prior arts.\nAdditionally, AgileNet is the first few-shot learning approach that prevents\nmodel updates by eliminating the knowledge obtained from the primary training.\nThis property is ensured through the dictionaries learned by our novel\nend-to-end structured decomposition, which also reduces the memory footprint\nand computation complexity to match the edge device constraints.\n",
        "published": "2018",
        "authors": [
            "Mohammad Ghasemzadeh",
            "Fang Lin",
            "Bita Darvish Rouhani",
            "Farinaz Koushanfar",
            "Ke Huang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.02244v5",
        "title": "Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks",
        "abstract": "  In recent years, graph neural networks (GNNs) have emerged as a powerful\nneural architecture to learn vector representations of nodes and graphs in a\nsupervised, end-to-end fashion. Up to now, GNNs have only been evaluated\nempirically -- showing promising results. The following work investigates GNNs\nfrom a theoretical point of view and relates them to the $1$-dimensional\nWeisfeiler-Leman graph isomorphism heuristic ($1$-WL). We show that GNNs have\nthe same expressiveness as the $1$-WL in terms of distinguishing non-isomorphic\n(sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on\nthis, we propose a generalization of GNNs, so-called $k$-dimensional GNNs\n($k$-GNNs), which can take higher-order graph structures at multiple scales\ninto account. These higher-order structures play an essential role in the\ncharacterization of social networks and molecule graphs. Our experimental\nevaluation confirms our theoretical findings as well as confirms that\nhigher-order information is useful in the task of graph classification and\nregression.\n",
        "published": "2018",
        "authors": [
            "Christopher Morris",
            "Martin Ritzert",
            "Matthias Fey",
            "William L. Hamilton",
            "Jan Eric Lenssen",
            "Gaurav Rattan",
            "Martin Grohe"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.03389v1",
        "title": "Learning to Evolve",
        "abstract": "  Evolution and learning are two of the fundamental mechanisms by which life\nadapts in order to survive and to transcend limitations. These biological\nphenomena inspired successful computational methods such as evolutionary\nalgorithms and deep learning. Evolution relies on random mutations and on\nrandom genetic recombination. Here we show that learning to evolve, i.e.\nlearning to mutate and recombine better than at random, improves the result of\nevolution in terms of fitness increase per generation and even in terms of\nattainable fitness. We use deep reinforcement learning to learn to dynamically\nadjust the strategy of evolutionary algorithms to varying circumstances. Our\nmethods outperform classical evolutionary algorithms on combinatorial and\ncontinuous optimization problems.\n",
        "published": "2019",
        "authors": [
            "Jan Schuchardt",
            "Vladimir Golkov",
            "Daniel Cremers"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.05849v2",
        "title": "Consensus-based Interpretable Deep Neural Networks with Application to\n  Mortality Prediction",
        "abstract": "  Deep neural networks have achieved remarkable success in various challenging\ntasks. However, the black-box nature of such networks is not acceptable to\ncritical applications, such as healthcare. In particular, the existence of\nadversarial examples and their overgeneralization to irrelevant,\nout-of-distribution inputs with high confidence makes it difficult, if not\nimpossible, to explain decisions by such networks. In this paper, we analyze\nthe underlying mechanism of generalization of deep neural networks and propose\nan ($n$, $k$) consensus algorithm which is insensitive to adversarial examples\nand can reliably reject out-of-distribution samples. Furthermore, the consensus\nalgorithm is able to improve classification accuracy by using multiple trained\ndeep neural networks. To handle the complexity of deep neural networks, we\ncluster linear approximations of individual models and identify highly\ncorrelated clusters among different models to capture feature importance\nrobustly, resulting in improved interpretability. Motivated by the importance\nof building accurate and interpretable prediction models for healthcare, our\nexperimental results on an ICU dataset show the effectiveness of our algorithm\nin enhancing both the prediction accuracy and the interpretability of deep\nneural network models on one-year patient mortality prediction. In particular,\nwhile the proposed method maintains similar interpretability as conventional\nshallow models such as logistic regression, it improves the prediction accuracy\nsignificantly.\n",
        "published": "2019",
        "authors": [
            "Shaeke Salman",
            "Seyedeh Neelufar Payrovnaziri",
            "Xiuwen Liu",
            "Pablo Rengifo-Moreno",
            "Zhe He"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.13211v4",
        "title": "What Can Neural Networks Reason About?",
        "abstract": "  Neural networks have succeeded in many reasoning tasks. Empirically, these\ntasks require specialized network structures, e.g., Graph Neural Networks\n(GNNs) perform well on many such tasks, but less structured networks fail.\nTheoretically, there is limited understanding of why and when a network\nstructure generalizes better than others, although they have equal expressive\npower. In this paper, we develop a framework to characterize which reasoning\ntasks a network can learn well, by studying how well its computation structure\naligns with the algorithmic structure of the relevant reasoning process. We\nformally define this algorithmic alignment and derive a sample complexity bound\nthat decreases with better alignment. This framework offers an explanation for\nthe empirical success of popular reasoning models, and suggests their\nlimitations. As an example, we unify seemingly different reasoning tasks, such\nas intuitive physics, visual question answering, and shortest paths, via the\nlens of a powerful algorithmic paradigm, dynamic programming (DP). We show that\nGNNs align with DP and thus are expected to solve these tasks. On several\nreasoning tasks, our theory is supported by empirical results.\n",
        "published": "2019",
        "authors": [
            "Keyulu Xu",
            "Jingling Li",
            "Mozhi Zhang",
            "Simon S. Du",
            "Ken-ichi Kawarabayashi",
            "Stefanie Jegelka"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1909.07490v1",
        "title": "They Might NOT Be Giants: Crafting Black-Box Adversarial Examples with\n  Fewer Queries Using Particle Swarm Optimization",
        "abstract": "  Machine learning models have been found to be susceptible to adversarial\nexamples that are often indistinguishable from the original inputs. These\nadversarial examples are created by applying adversarial perturbations to input\nsamples, which would cause them to be misclassified by the target models.\nAttacks that search and apply the perturbations to create adversarial examples\nare performed in both white-box and black-box settings, depending on the\ninformation available to the attacker about the target. For black-box attacks,\nthe only capability available to the attacker is the ability to query the\ntarget with specially crafted inputs and observing the labels returned by the\nmodel. Current black-box attacks either have low success rates, requires a high\nnumber of queries, or produce adversarial examples that are easily\ndistinguishable from their sources. In this paper, we present AdversarialPSO, a\nblack-box attack that uses fewer queries to create adversarial examples with\nhigh success rates. AdversarialPSO is based on the evolutionary search\nalgorithm Particle Swarm Optimization, a populationbased gradient-free\noptimization algorithm. It is flexible in balancing the number of queries\nsubmitted to the target vs the quality of imperceptible adversarial examples.\nThe attack has been evaluated using the image classification benchmark datasets\nCIFAR-10, MNIST, and Imagenet, achieving success rates of 99.6%, 96.3%, and\n82.0%, respectively, while submitting substantially fewer queries than the\nstate-of-the-art. We also present a black-box method for isolating salient\nfeatures used by models when making classifications. This method, called Swarms\nwith Individual Search Spaces or SWISS, creates adversarial examples by finding\nand modifying the most important features in the input.\n",
        "published": "2019",
        "authors": [
            "Rayan Mosli",
            "Matthew Wright",
            "Bo Yuan",
            "Yin Pan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.08859v3",
        "title": "Distilling Optimal Neural Networks: Rapid Search in Diverse Spaces",
        "abstract": "  Current state-of-the-art Neural Architecture Search (NAS) methods neither\nefficiently scale to multiple hardware platforms, nor handle diverse\narchitectural search-spaces. To remedy this, we present DONNA (Distilling\nOptimal Neural Network Architectures), a novel pipeline for rapid, scalable and\ndiverse NAS, that scales to many user scenarios. DONNA consists of three\nphases. First, an accuracy predictor is built using blockwise knowledge\ndistillation from a reference model. This predictor enables searching across\ndiverse networks with varying macro-architectural parameters such as layer\ntypes and attention mechanisms, as well as across micro-architectural\nparameters such as block repeats and expansion rates. Second, a rapid\nevolutionary search finds a set of pareto-optimal architectures for any\nscenario using the accuracy predictor and on-device measurements. Third,\noptimal models are quickly finetuned to training-from-scratch accuracy. DONNA\nis up to 100x faster than MNasNet in finding state-of-the-art architectures\non-device. Classifying ImageNet, DONNA architectures are 20% faster than\nEfficientNet-B0 and MobileNetV2 on a Nvidia V100 GPU and 10% faster with 0.5%\nhigher accuracy than MobileNetV2-1.4x on a Samsung S20 smartphone. In addition\nto NAS, DONNA is used for search-space extension and exploration, as well as\nhardware-aware model compression.\n",
        "published": "2020",
        "authors": [
            "Bert Moons",
            "Parham Noorzad",
            "Andrii Skliar",
            "Giovanni Mariani",
            "Dushyant Mehta",
            "Chris Lott",
            "Tijmen Blankevoort"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2103.03905v3",
        "title": "Kanerva++: extending The Kanerva Machine with differentiable, locally\n  block allocated latent memory",
        "abstract": "  Episodic and semantic memory are critical components of the human memory\nmodel. The theory of complementary learning systems (McClelland et al., 1995)\nsuggests that the compressed representation produced by a serial event\n(episodic memory) is later restructured to build a more generalized form of\nreusable knowledge (semantic memory). In this work we develop a new principled\nBayesian memory allocation scheme that bridges the gap between episodic and\nsemantic memory via a hierarchical latent variable model. We take inspiration\nfrom traditional heap allocation and extend the idea of locally contiguous\nmemory to the Kanerva Machine, enabling a novel differentiable block allocated\nlatent memory. In contrast to the Kanerva Machine, we simplify the process of\nmemory writing by treating it as a fully feed forward deterministic process,\nrelying on the stochasticity of the read key distribution to disperse\ninformation within the memory. We demonstrate that this allocation scheme\nimproves performance in memory conditional image generation, resulting in new\nstate-of-the-art conditional likelihood values on binarized MNIST (<=41.58\nnats/image) , binarized Omniglot (<=66.24 nats/image), as well as presenting\ncompetitive performance on CIFAR10, DMLab Mazes, Celeb-A and ImageNet32x32.\n",
        "published": "2021",
        "authors": [
            "Jason Ramapuram",
            "Yan Wu",
            "Alexandros Kalousis"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.12423v4",
        "title": "Alias-Free Generative Adversarial Networks",
        "abstract": "  We observe that despite their hierarchical convolutional nature, the\nsynthesis process of typical generative adversarial networks depends on\nabsolute pixel coordinates in an unhealthy manner. This manifests itself as,\ne.g., detail appearing to be glued to image coordinates instead of the surfaces\nof depicted objects. We trace the root cause to careless signal processing that\ncauses aliasing in the generator network. Interpreting all signals in the\nnetwork as continuous, we derive generally applicable, small architectural\nchanges that guarantee that unwanted information cannot leak into the\nhierarchical synthesis process. The resulting networks match the FID of\nStyleGAN2 but differ dramatically in their internal representations, and they\nare fully equivariant to translation and rotation even at subpixel scales. Our\nresults pave the way for generative models better suited for video and\nanimation.\n",
        "published": "2021",
        "authors": [
            "Tero Karras",
            "Miika Aittala",
            "Samuli Laine",
            "Erik H\u00e4rk\u00f6nen",
            "Janne Hellsten",
            "Jaakko Lehtinen",
            "Timo Aila"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2110.01445v3",
        "title": "Robust and Decomposable Average Precision for Image Retrieval",
        "abstract": "  In image retrieval, standard evaluation metrics rely on score ranking, e.g.\naverage precision (AP). In this paper, we introduce a method for robust and\ndecomposable average precision (ROADMAP) addressing two major challenges for\nend-to-end training of deep neural networks with AP: non-differentiability and\nnon-decomposability. Firstly, we propose a new differentiable approximation of\nthe rank function, which provides an upper bound of the AP loss and ensures\nrobust training. Secondly, we design a simple yet effective loss function to\nreduce the decomposability gap between the AP in the whole training set and its\naveraged batch approximation, for which we provide theoretical guarantees.\nExtensive experiments conducted on three image retrieval datasets show that\nROADMAP outperforms several recent AP approximation methods and highlight the\nimportance of our two contributions. Finally, using ROADMAP for training deep\nmodels yields very good performances, outperforming state-of-the-art results on\nthe three datasets.\n",
        "published": "2021",
        "authors": [
            "Elias Ramzi",
            "Nicolas Thome",
            "Cl\u00e9ment Rambour",
            "Nicolas Audebert",
            "Xavier Bitot"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2203.06026v3",
        "title": "The Role of ImageNet Classes in Fr\u00e9chet Inception Distance",
        "abstract": "  Fr\\'echet Inception Distance (FID) is the primary metric for ranking models\nin data-driven generative modeling. While remarkably successful, the metric is\nknown to sometimes disagree with human judgement. We investigate a root cause\nof these discrepancies, and visualize what FID \"looks at\" in generated images.\nWe show that the feature space that FID is (typically) computed in is so close\nto the ImageNet classifications that aligning the histograms of Top-$N$\nclassifications between sets of generated and real images can reduce FID\nsubstantially -- without actually improving the quality of results. Thus, we\nconclude that FID is prone to intentional or accidental distortions. As a\npractical example of an accidental distortion, we discuss a case where an\nImageNet pre-trained FastGAN achieves a FID comparable to StyleGAN2, while\nbeing worse in terms of human evaluation.\n",
        "published": "2022",
        "authors": [
            "Tuomas Kynk\u00e4\u00e4nniemi",
            "Tero Karras",
            "Miika Aittala",
            "Timo Aila",
            "Jaakko Lehtinen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2206.00364v2",
        "title": "Elucidating the Design Space of Diffusion-Based Generative Models",
        "abstract": "  We argue that the theory and practice of diffusion-based generative models\nare currently unnecessarily convoluted and seek to remedy the situation by\npresenting a design space that clearly separates the concrete design choices.\nThis lets us identify several changes to both the sampling and training\nprocesses, as well as preconditioning of the score networks. Together, our\nimprovements yield new state-of-the-art FID of 1.79 for CIFAR-10 in a\nclass-conditional setting and 1.97 in an unconditional setting, with much\nfaster sampling (35 network evaluations per image) than prior designs. To\nfurther demonstrate their modular nature, we show that our design changes\ndramatically improve both the efficiency and quality obtainable with\npre-trained score networks from previous work, including improving the FID of a\npreviously trained ImageNet-64 model from 2.07 to near-SOTA 1.55, and after\nre-training with our proposed improvements to a new SOTA of 1.36.\n",
        "published": "2022",
        "authors": [
            "Tero Karras",
            "Miika Aittala",
            "Timo Aila",
            "Samuli Laine"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2210.08031v2",
        "title": "Neural Attentive Circuits",
        "abstract": "  Recent work has seen the development of general purpose neural architectures\nthat can be trained to perform tasks across diverse data modalities. General\npurpose models typically make few assumptions about the underlying\ndata-structure and are known to perform well in the large-data regime. At the\nsame time, there has been growing interest in modular neural architectures that\nrepresent the data using sparsely interacting modules. These models can be more\nrobust out-of-distribution, computationally efficient, and capable of\nsample-efficient adaptation to new data. However, they tend to make\ndomain-specific assumptions about the data, and present challenges in how\nmodule behavior (i.e., parameterization) and connectivity (i.e., their layout)\ncan be jointly learned. In this work, we introduce a general purpose, yet\nmodular neural architecture called Neural Attentive Circuits (NACs) that\njointly learns the parameterization and a sparse connectivity of neural modules\nwithout using domain knowledge. NACs are best understood as the combination of\ntwo systems that are jointly trained end-to-end: one that determines the module\nconfiguration and the other that executes it on an input. We demonstrate\nqualitatively that NACs learn diverse and meaningful module configurations on\nthe NLVR2 dataset without additional supervision. Quantitatively, we show that\nby incorporating modularity in this way, NACs improve upon a strong non-modular\nbaseline in terms of low-shot adaptation on CIFAR and CUBs dataset by about\n10%, and OOD robustness on Tiny ImageNet-R by about 2.5%. Further, we find that\nNACs can achieve an 8x speedup at inference time while losing less than 3%\nperformance. Finally, we find NACs to yield competitive results on diverse data\nmodalities spanning point-cloud classification, symbolic processing and\ntext-classification from ASCII bytes, thereby confirming its general purpose\nnature.\n",
        "published": "2022",
        "authors": [
            "Nasim Rahaman",
            "Martin Weiss",
            "Francesco Locatello",
            "Chris Pal",
            "Yoshua Bengio",
            "Bernhard Sch\u00f6lkopf",
            "Li Erran Li",
            "Nicolas Ballas"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.02696v1",
        "title": "Analyzing and Improving the Training Dynamics of Diffusion Models",
        "abstract": "  Diffusion models currently dominate the field of data-driven image synthesis\nwith their unparalleled scaling to large datasets. In this paper, we identify\nand rectify several causes for uneven and ineffective training in the popular\nADM diffusion model architecture, without altering its high-level structure.\nObserving uncontrolled magnitude changes and imbalances in both the network\nactivations and weights over the course of training, we redesign the network\nlayers to preserve activation, weight, and update magnitudes on expectation. We\nfind that systematic application of this philosophy eliminates the observed\ndrifts and imbalances, resulting in considerably better networks at equal\ncomputational complexity. Our modifications improve the previous record FID of\n2.41 in ImageNet-512 synthesis to 1.81, achieved using fast deterministic\nsampling.\n  As an independent contribution, we present a method for setting the\nexponential moving average (EMA) parameters post-hoc, i.e., after completing\nthe training run. This allows precise tuning of EMA length without the cost of\nperforming several training runs, and reveals its surprising interactions with\nnetwork architecture, training time, and guidance.\n",
        "published": "2023",
        "authors": [
            "Tero Karras",
            "Miika Aittala",
            "Jaakko Lehtinen",
            "Janne Hellsten",
            "Timo Aila",
            "Samuli Laine"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.16043v1",
        "title": "An extended asymmetric sigmoid with Perceptron (SIGTRON) for imbalanced\n  linear classification",
        "abstract": "  This article presents a new polynomial parameterized sigmoid called SIGTRON,\nwhich is an extended asymmetric sigmoid with Perceptron, and its companion\nconvex model called SIGTRON-imbalanced classification (SIC) model that employs\na virtual SIGTRON-induced convex loss function. In contrast to the conventional\n$\\pi$-weighted cost-sensitive learning model, the SIC model does not have an\nexternal $\\pi$-weight on the loss function but has internal parameters in the\nvirtual SIGTRON-induced loss function. As a consequence, when the given\ntraining dataset is close to the well-balanced condition, we show that the\nproposed SIC model is more adaptive to variations of the dataset, such as the\ninconsistency of the scale-class-imbalance ratio between the training and test\ndatasets. This adaptation is achieved by creating a skewed hyperplane equation.\nAdditionally, we present a quasi-Newton optimization(L-BFGS) framework for the\nvirtual convex loss by developing an interval-based bisection line search.\nEmpirically, we have observed that the proposed approach outperforms\n$\\pi$-weighted convex focal loss and balanced classifier LIBLINEAR(logistic\nregression, SVM, and L2SVM) in terms of test classification accuracy with $51$\ntwo-class and $67$ multi-class datasets. In binary classification problems,\nwhere the scale-class-imbalance ratio of the training dataset is not\nsignificant but the inconsistency exists, a group of SIC models with the best\ntest accuracy for each dataset (TOP$1$) outperforms LIBSVM(C-SVC with RBF\nkernel), a well-known kernel-based classifier.\n",
        "published": "2023",
        "authors": [
            "Hyenkyun Woo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.17346v1",
        "title": "STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series\n  Prediction",
        "abstract": "  We present STanHop-Net (Sparse Tandem Hopfield Network) for multivariate time\nseries prediction with memory-enhanced capabilities. At the heart of our\napproach is STanHop, a novel Hopfield-based neural network block, which\nsparsely learns and stores both temporal and cross-series representations in a\ndata-dependent fashion. In essence, STanHop sequentially learn temporal\nrepresentation and cross-series representation using two tandem sparse Hopfield\nlayers. In addition, StanHop incorporates two additional external memory\nmodules: a Plug-and-Play module and a Tune-and-Play module for train-less and\ntask-aware memory-enhancements, respectively. They allow StanHop-Net to swiftly\nrespond to certain sudden events. Methodologically, we construct the\nStanHop-Net by stacking STanHop blocks in a hierarchical fashion, enabling\nmulti-resolution feature extraction with resolution-specific sparsity.\nTheoretically, we introduce a sparse extension of the modern Hopfield model\n(Generalized Sparse Modern Hopfield Model) and show that it endows a tighter\nmemory retrieval error compared to the dense counterpart without sacrificing\nmemory capacity. Empirically, we validate the efficacy of our framework on both\nsynthetic and real-world settings.\n",
        "published": "2023",
        "authors": [
            "Dennis Wu",
            "Jerry Yao-Chieh Hu",
            "Weijian Li",
            "Bo-Yu Chen",
            "Han Liu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.04835v2",
        "title": "Multi-Agent Image Classification via Reinforcement Learning",
        "abstract": "  We investigate a classification problem using multiple mobile agents capable\nof collecting (partial) pose-dependent observations of an unknown environment.\nThe objective is to classify an image over a finite time horizon. We propose a\nnetwork architecture on how agents should form a local belief, take local\nactions, and extract relevant features from their raw partial observations.\nAgents are allowed to exchange information with their neighboring agents to\nupdate their own beliefs. It is shown how reinforcement learning techniques can\nbe utilized to achieve decentralized implementation of the classification\nproblem by running a decentralized consensus protocol. Our experimental results\non the MNIST handwritten digit dataset demonstrates the effectiveness of our\nproposed framework.\n",
        "published": "2019",
        "authors": [
            "Hossein K. Mousavi",
            "Mohammadreza Nazari",
            "Martin Tak\u00e1\u010d",
            "Nader Motee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2107.08408v2",
        "title": "Pre-trained Language Models as Prior Knowledge for Playing Text-based\n  Games",
        "abstract": "  Recently, text world games have been proposed to enable artificial agents to\nunderstand and reason about real-world scenarios. These text-based games are\nchallenging for artificial agents, as it requires an understanding of and\ninteraction using natural language in a partially observable environment.\nAgents observe the environment via textual descriptions designed to be\nchallenging enough for even human players. Past approaches have not paid enough\nattention to the language understanding capability of the proposed agents.\nTypically, these approaches train from scratch, an agent that learns both\ntextual representations and the gameplay online during training using a\ntemporal loss function. Given the sample-inefficiency of RL approaches, it is\ninefficient to learn rich enough textual representations to be able to\nunderstand and reason using the textual observation in such a complicated game\nenvironment setting. In this paper, we improve the semantic understanding of\nthe agent by proposing a simple RL with LM framework where we use\ntransformer-based language models with Deep RL models. We perform a detailed\nstudy of our framework to demonstrate how our model outperforms all existing\nagents on the popular game, Zork1, to achieve a score of 44.7, which is 1.6\nhigher than the state-of-the-art model. Overall, our proposed approach\noutperforms 4 games out of the 14 text-based games, while performing comparable\nto the state-of-the-art models on the remaining games.\n",
        "published": "2021",
        "authors": [
            "Ishika Singh",
            "Gargi Singh",
            "Ashutosh Modi"
        ]
    }
]