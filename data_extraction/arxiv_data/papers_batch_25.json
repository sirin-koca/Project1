[
    {
        "id": "http://arxiv.org/abs/1905.12797v1",
        "title": "Bandlimiting Neural Networks Against Adversarial Attacks",
        "abstract": "  In this paper, we study the adversarial attack and defence problem in deep\nlearning from the perspective of Fourier analysis. We first explicitly compute\nthe Fourier transform of deep ReLU neural networks and show that there exist\ndecaying but non-zero high frequency components in the Fourier spectrum of\nneural networks. We demonstrate that the vulnerability of neural networks\ntowards adversarial samples can be attributed to these insignificant but\nnon-zero high frequency components. Based on this analysis, we propose to use a\nsimple post-averaging technique to smooth out these high frequency components\nto improve the robustness of neural networks against adversarial attacks.\nExperimental results on the ImageNet dataset have shown that our proposed\nmethod is universally effective to defend many existing adversarial attacking\nmethods proposed in the literature, including FGSM, PGD, DeepFool and C&W\nattacks. Our post-averaging method is simple since it does not require any\nre-training, and meanwhile it can successfully defend over 95% of the\nadversarial samples generated by these methods without introducing any\nsignificant performance degradation (less than 1%) on the original clean\nimages.\n",
        "published": "2019",
        "authors": [
            "Yuping Lin",
            "Kasra Ahmadi K. A.",
            "Hui Jiang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.06026v3",
        "title": "Adversarial Robustness Assessment: Why both $L_0$ and $L_\\infty$ Attacks\n  Are Necessary",
        "abstract": "  There exists a vast number of adversarial attacks and defences for machine\nlearning algorithms of various types which makes assessing the robustness of\nalgorithms a daunting task. To make matters worse, there is an intrinsic bias\nin these adversarial algorithms. Here, we organise the problems faced: a) Model\nDependence, b) Insufficient Evaluation, c) False Adversarial Samples, and d)\nPerturbation Dependent Results). Based on this, we propose a model agnostic\ndual quality assessment method, together with the concept of robustness levels\nto tackle them. We validate the dual quality assessment on state-of-the-art\nneural networks (WideResNet, ResNet, AllConv, DenseNet, NIN, LeNet and CapsNet)\nas well as adversarial defences for image classification problem. We further\nshow that current networks and defences are vulnerable at all levels of\nrobustness. The proposed robustness assessment reveals that depending on the\nmetric used (i.e., $L_0$ or $L_\\infty$), the robustness may vary significantly.\nHence, the duality should be taken into account for a correct evaluation.\nMoreover, a mathematical derivation, as well as a counter-example, suggest that\n$L_1$ and $L_2$ metrics alone are not sufficient to avoid spurious adversarial\nsamples. Interestingly, the threshold attack of the proposed assessment is a\nnovel $L_\\infty$ black-box adversarial method which requires even less\nperturbation than the One-Pixel Attack (only $12\\%$ of One-Pixel Attack's\namount of perturbation) to achieve similar results.\n  Code is available at http://bit.ly/DualQualityAssessment.\n",
        "published": "2019",
        "authors": [
            "Shashank Kotyan",
            "Danilo Vasconcellos Vargas"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.08861v1",
        "title": "Synthesizing Images from Spatio-Temporal Representations using\n  Spike-based Backpropagation",
        "abstract": "  Spiking neural networks (SNNs) offer a promising alternative to current\nartificial neural networks to enable low-power event-driven neuromorphic\nhardware. Spike-based neuromorphic applications require processing and\nextracting meaningful information from spatio-temporal data, represented as\nseries of spike trains over time. In this paper, we propose a method to\nsynthesize images from multiple modalities in a spike-based environment. We use\nspiking auto-encoders to convert image and audio inputs into compact\nspatio-temporal representations that is then decoded for image synthesis. For\nthis, we use a direct training algorithm that computes loss on the membrane\npotential of the output layer and back-propagates it by using a sigmoid\napproximation of the neuron's activation function to enable differentiability.\nThe spiking autoencoders are benchmarked on MNIST and Fashion-MNIST and achieve\nvery low reconstruction loss, comparable to ANNs. Then, spiking autoencoders\nare trained to learn meaningful spatio-temporal representations of the data,\nacross the two modalities - audio and visual. We synthesize images from audio\nin a spike-based environment by first generating, and then utilizing such\nshared multi-modal spatio-temporal representations. Our audio to image\nsynthesis model is tested on the task of converting TI-46 digits audio samples\nto MNIST images. We are able to synthesize images with high fidelity and the\nmodel achieves competitive performance against ANNs.\n",
        "published": "2019",
        "authors": [
            "Deboleena Roy",
            "Priyadarshini Panda",
            "Kaushik Roy"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1909.05073v4",
        "title": "PCONV: The Missing but Desirable Sparsity in DNN Weight Pruning for\n  Real-time Execution on Mobile Devices",
        "abstract": "  Model compression techniques on Deep Neural Network (DNN) have been widely\nacknowledged as an effective way to achieve acceleration on a variety of\nplatforms, and DNN weight pruning is a straightforward and effective method.\nThere are currently two mainstreams of pruning methods representing two\nextremes of pruning regularity: non-structured, fine-grained pruning can\nachieve high sparsity and accuracy, but is not hardware friendly; structured,\ncoarse-grained pruning exploits hardware-efficient structures in pruning, but\nsuffers from accuracy drop when the pruning rate is high. In this paper, we\nintroduce PCONV, comprising a new sparsity dimension, -- fine-grained pruning\npatterns inside the coarse-grained structures. PCONV comprises two types of\nsparsities, Sparse Convolution Patterns (SCP) which is generated from\nintra-convolution kernel pruning and connectivity sparsity generated from\ninter-convolution kernel pruning. Essentially, SCP enhances accuracy due to its\nspecial vision properties, and connectivity sparsity increases pruning rate\nwhile maintaining balanced workload on filter computation. To deploy PCONV, we\ndevelop a novel compiler-assisted DNN inference framework and execute PCONV\nmodels in real-time without accuracy compromise, which cannot be achieved in\nprior work. Our experimental results show that, PCONV outperforms three\nstate-of-art end-to-end DNN frameworks, TensorFlow-Lite, TVM, and Alibaba\nMobile Neural Network with speedup up to 39.2x, 11.4x, and 6.3x, respectively,\nwith no accuracy loss. Mobile devices can achieve real-time inference on\nlarge-scale DNNs.\n",
        "published": "2019",
        "authors": [
            "Xiaolong Ma",
            "Fu-Ming Guo",
            "Wei Niu",
            "Xue Lin",
            "Jian Tang",
            "Kaisheng Ma",
            "Bin Ren",
            "Yanzhi Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1911.10442v1",
        "title": "Ground Truth Simulation for Deep Learning Classification of\n  Mid-Resolution Venus Images Via Unmixing of High-Resolution Hyperspectral\n  Fenix Data",
        "abstract": "  Training a deep neural network for classification constitutes a major problem\nin remote sensing due to the lack of adequate field data. Acquiring\nhigh-resolution ground truth (GT) by human interpretation is both\ncost-ineffective and inconsistent. We propose, instead, to utilize\nhigh-resolution, hyperspectral images for solving this problem, by unmixing\nthese images to obtain reliable GT for training a deep network. Specifically,\nwe simulate GT from high-resolution, hyperspectral FENIX images, and use it for\ntraining a convolutional neural network (CNN) for pixel-based classification.\nWe show how the model can be transferred successfully to classify new\nmid-resolution VENuS imagery.\n",
        "published": "2019",
        "authors": [
            "Ido Faran",
            "Nathan S. Netanyahu",
            "Eli David",
            "Maxim Shoshany",
            "Fadi Kizel",
            "Jisung Geba Chang",
            "Ronit Rud"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.03391v1",
        "title": "Multivariate Density Estimation with Deep Neural Mixture Models",
        "abstract": "  Albeit worryingly underrated in the recent literature on machine learning in\ngeneral (and, on deep learning in particular), multivariate density estimation\nis a fundamental task in many applications, at least implicitly, and still an\nopen issue. With a few exceptions, deep neural networks (DNNs) have seldom been\napplied to density estimation, mostly due to the unsupervised nature of the\nestimation task, and (especially) due to the need for constrained training\nalgorithms that ended up realizing proper probabilistic models that satisfy\nKolmogorov's axioms. Moreover, in spite of the well-known improvement in terms\nof modeling capabilities yielded by mixture models over plain single-density\nstatistical estimators, no proper mixtures of multivariate DNN-based component\ndensities have been investigated so far. The paper fills this gap by extending\nour previous work on Neural Mixture Densities (NMMs) to multivariate DNN\nmixtures. A maximum-likelihood (ML) algorithm for estimating Deep NMMs (DNMMs)\nis handed out, which satisfies numerically a combination of hard and soft\nconstraints aimed at ensuring satisfaction of Kolmogorov's axioms. The class of\nprobability density functions that can be modeled to any degree of precision\nvia DNMMs is formally defined. A procedure for the automatic selection of the\nDNMM architecture, as well as of the hyperparameters for its ML training\nalgorithm, is presented (exploiting the probabilistic nature of the DNMM).\nExperimental results on univariate and multivariate data are reported on,\ncorroborating the effectiveness of the approach and its superiority to the most\npopular statistical estimation techniques.\n",
        "published": "2020",
        "authors": [
            "Edmondo Trentin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.04567v5",
        "title": "Bayesian Image Reconstruction using Deep Generative Models",
        "abstract": "  Machine learning models are commonly trained end-to-end and in a supervised\nsetting, using paired (input, output) data. Examples include recent\nsuper-resolution methods that train on pairs of (low-resolution,\nhigh-resolution) images. However, these end-to-end approaches require\nre-training every time there is a distribution shift in the inputs (e.g., night\nimages vs daylight) or relevant latent variables (e.g., camera blur or hand\nmotion). In this work, we leverage state-of-the-art (SOTA) generative models\n(here StyleGAN2) for building powerful image priors, which enable application\nof Bayes' theorem for many downstream reconstruction tasks. Our method,\nBayesian Reconstruction through Generative Models (BRGM), uses a single\npre-trained generator model to solve different image restoration tasks, i.e.,\nsuper-resolution and in-painting, by combining it with different forward\ncorruption models. We keep the weights of the generator model fixed, and\nreconstruct the image by estimating the Bayesian maximum a-posteriori (MAP)\nestimate over the input latent vector that generated the reconstructed image.\nWe further use variational inference to approximate the posterior distribution\nover the latent vectors, from which we sample multiple solutions. We\ndemonstrate BRGM on three large and diverse datasets: (i) 60,000 images from\nthe Flick Faces High Quality dataset (ii) 240,000 chest X-rays from MIMIC III\nand (iii) a combined collection of 5 brain MRI datasets with 7,329 scans.\nAcross all three datasets and without any dataset-specific hyperparameter\ntuning, our simple approach yields performance competitive with current\ntask-specific state-of-the-art methods on super-resolution and in-painting,\nwhile being more generalisable and without requiring any training. Our source\ncode and pre-trained models are available online:\nhttps://razvanmarinescu.github.io/brgm/.\n",
        "published": "2020",
        "authors": [
            "Razvan V Marinescu",
            "Daniel Moyer",
            "Polina Golland"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2104.13369v2",
        "title": "Explaining in Style: Training a GAN to explain a classifier in\n  StyleSpace",
        "abstract": "  Image classification models can depend on multiple different semantic\nattributes of the image. An explanation of the decision of the classifier needs\nto both discover and visualize these properties. Here we present StylEx, a\nmethod for doing this, by training a generative model to specifically explain\nmultiple attributes that underlie classifier decisions. A natural source for\nsuch attributes is the StyleSpace of StyleGAN, which is known to generate\nsemantically meaningful dimensions in the image. However, because standard GAN\ntraining is not dependent on the classifier, it may not represent these\nattributes which are important for the classifier decision, and the dimensions\nof StyleSpace may represent irrelevant attributes. To overcome this, we propose\na training procedure for a StyleGAN, which incorporates the classifier model,\nin order to learn a classifier-specific StyleSpace. Explanatory attributes are\nthen selected from this space. These can be used to visualize the effect of\nchanging multiple attributes per image, thus providing image-specific\nexplanations. We apply StylEx to multiple domains, including animals, leaves,\nfaces and retinal images. For these, we show how an image can be modified in\ndifferent ways to change its classifier output. Our results show that the\nmethod finds attributes that align well with semantic ones, generate meaningful\nimage-specific explanations, and are human-interpretable as measured in\nuser-studies.\n",
        "published": "2021",
        "authors": [
            "Oran Lang",
            "Yossi Gandelsman",
            "Michal Yarom",
            "Yoav Wald",
            "Gal Elidan",
            "Avinatan Hassidim",
            "William T. Freeman",
            "Phillip Isola",
            "Amir Globerson",
            "Michal Irani",
            "Inbar Mosseri"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2206.07758v3",
        "title": "Reconstructing Training Data from Trained Neural Networks",
        "abstract": "  Understanding to what extent neural networks memorize training data is an\nintriguing question with practical and theoretical implications. In this paper\nwe show that in some cases a significant fraction of the training data can in\nfact be reconstructed from the parameters of a trained neural network\nclassifier. We propose a novel reconstruction scheme that stems from recent\ntheoretical results about the implicit bias in training neural networks with\ngradient-based methods. To the best of our knowledge, our results are the first\nto show that reconstructing a large portion of the actual training samples from\na trained neural network classifier is generally possible. This has negative\nimplications on privacy, as it can be used as an attack for revealing sensitive\ntraining data. We demonstrate our method for binary MLP classifiers on a few\nstandard computer vision datasets.\n",
        "published": "2022",
        "authors": [
            "Niv Haim",
            "Gal Vardi",
            "Gilad Yehudai",
            "Ohad Shamir",
            "Michal Irani"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2211.13964v2",
        "title": "Generating 2D and 3D Master Faces for Dictionary Attacks with a\n  Network-Assisted Latent Space Evolution",
        "abstract": "  A master face is a face image that passes face-based identity authentication\nfor a high percentage of the population. These faces can be used to\nimpersonate, with a high probability of success, any user, without having\naccess to any user information. We optimize these faces for 2D and 3D face\nverification models, by using an evolutionary algorithm in the latent embedding\nspace of the StyleGAN face generator. For 2D face verification, multiple\nevolutionary strategies are compared, and we propose a novel approach that\nemploys a neural network to direct the search toward promising samples, without\nadding fitness evaluations. The results we present demonstrate that it is\npossible to obtain a considerable coverage of the identities in the LFW or RFW\ndatasets with less than 10 master faces, for six leading deep face recognition\nsystems. In 3D, we generate faces using the 2D StyleGAN2 generator and predict\na 3D structure using a deep 3D face reconstruction network. When employing two\ndifferent 3D face recognition systems, we are able to obtain a coverage of\n40%-50%. Additionally, we present the generation of paired 2D RGB and 3D master\nfaces, which simultaneously match 2D and 3D models with high impersonation\nrates.\n",
        "published": "2022",
        "authors": [
            "Tomer Friedlander",
            "Ron Shmelkin",
            "Lior Wolf"
        ]
    },
    {
        "id": "http://arxiv.org/abs/cs/0210030v1",
        "title": "Intelligence and Cooperative Search by Coupled Local Minimizers",
        "abstract": "  We show how coupling of local optimization processes can lead to better\nsolutions than multi-start local optimization consisting of independent runs.\nThis is achieved by minimizing the average energy cost of the ensemble, subject\nto synchronization constraints between the state vectors of the individual\nlocal minimizers. From an augmented Lagrangian which incorporates the\nsynchronization constraints both as soft and hard constraints, a network is\nderived wherein the local minimizers interact and exchange information through\nthe synchronization constraints. From the viewpoint of neural networks, the\narray can be considered as a Lagrange programming network for continuous\noptimization and as a cellular neural network (CNN). The penalty weights\nassociated with the soft state synchronization constraints follow from the\nsolution to a linear program. This expresses that the energy cost of the\nensemble should maximally decrease. In this way successful local minimizers can\nimplicitly impose their state to the others through a mechanism of master-slave\ndynamics resulting into a cooperative search mechanism. Improved information\nspreading within the ensemble is obtained by applying the concept of\nsmall-world networks. This work suggests, in an interdisciplinary context, the\nimportance of information exchange and state synchronization within ensembles,\ntowards issues as evolution, collective behaviour, optimality and intelligence.\n",
        "published": "2002",
        "authors": [
            "J. A. K. Suykens",
            "J. Vandewalle",
            "B. De Moor"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0803.3912v1",
        "title": "Artificial Immune Systems Tutorial",
        "abstract": "  The biological immune system is a robust, complex, adaptive system that\ndefends the body from foreign pathogens. It is able to categorize all cells (or\nmolecules) within the body as self-cells or non-self cells. It does this with\nthe help of a distributed task force that has the intelligence to take action\nfrom a local and also a global perspective using its network of chemical\nmessengers for communication. There are two major branches of the immune\nsystem. The innate immune system is an unchanging mechanism that detects and\ndestroys certain invading organisms, whilst the adaptive immune system responds\nto previously unknown foreign cells and builds a response to them that can\nremain in the body over a long period of time. This remarkable information\nprocessing biological system has caught the attention of computer science in\nrecent years. A novel computational intelligence technique, inspired by\nimmunology, has emerged, called Artificial Immune Systems. Several concepts\nfrom the immune have been extracted and applied for solution to real world\nscience and engineering problems. In this tutorial, we briefly describe the\nimmune system metaphors that are relevant to existing Artificial Immune Systems\nmethods. We will then show illustrative real-world problems suitable for\nArtificial Immune Systems and give a step-by-step algorithm walkthrough for one\nsuch problem. A comparison of the Artificial Immune Systems to other well-known\nalgorithms, areas for future work, tips & tricks and a list of resources will\nround this tutorial off. It should be noted that as Artificial Immune Systems\nis still a young and evolving field, there is not yet a fixed algorithm\ntemplate and hence actual implementations might differ somewhat from time to\ntime and from those examples given here.\n",
        "published": "2008",
        "authors": [
            "Uwe Aickelin",
            "Dipankar Dasgupta"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0907.0328v1",
        "title": "Degenerate neutrality creates evolvable fitness landscapes",
        "abstract": "  Understanding how systems can be designed to be evolvable is fundamental to\nresearch in optimization, evolution, and complex systems science. Many\nresearchers have thus recognized the importance of evolvability, i.e. the\nability to find new variants of higher fitness, in the fields of biological\nevolution and evolutionary computation. Recent studies by Ciliberti et al\n(Proc. Nat. Acad. Sci., 2007) and Wagner (Proc. R. Soc. B., 2008) propose a\npotentially important link between the robustness and the evolvability of a\nsystem. In particular, it has been suggested that robustness may actually lead\nto the emergence of evolvability. Here we study two design principles,\nredundancy and degeneracy, for achieving robustness and we show that they have\na dramatically different impact on the evolvability of the system. In\nparticular, purely redundant systems are found to have very little evolvability\nwhile systems with degeneracy, i.e. distributed robustness, can be orders of\nmagnitude more evolvable. These results offer insights into the general\nprinciples for achieving evolvability and may prove to be an important step\nforward in the pursuit of evolvable representations in evolutionary\ncomputation.\n",
        "published": "2009",
        "authors": [
            "James M Whitacre",
            "Axel Bender"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1006.4949v1",
        "title": "Artificial Immune Systems (2010)",
        "abstract": "  The human immune system has numerous properties that make it ripe for\nexploitation in the computational domain, such as robustness and fault\ntolerance, and many different algorithms, collectively termed Artificial Immune\nSystems (AIS), have been inspired by it. Two generations of AIS are currently\nin use, with the first generation relying on simplified immune models and the\nsecond generation utilising interdisciplinary collaboration to develop a deeper\nunderstanding of the immune system and hence produce more complex models. Both\ngenerations of algorithms have been successfully applied to a variety of\nproblems, including anomaly detection, pattern recognition, optimisation and\nrobotics. In this chapter an overview of AIS is presented, its evolution is\ndiscussed, and it is shown that the diversification of the field is linked to\nthe diversity of the immune system itself, leading to a number of algorithms as\nopposed to one archetypal system. Two case studies are also presented to help\nprovide insight into the mechanisms of AIS; these are the idiotypic network\napproach and the Dendritic Cell Algorithm.\n",
        "published": "2010",
        "authors": [
            "Julie Greensmith",
            "Amanda Whitbrook",
            "Uwe Aickelin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1308.5032v4",
        "title": "How Did Humans Become So Creative? A Computational Approach",
        "abstract": "  This paper summarizes efforts to computationally model two transitions in the\nevolution of human creativity: its origins about two million years ago, and the\n'big bang' of creativity about 50,000 years ago. Using a computational model of\ncultural evolution in which neural network based agents evolve ideas for\nactions through invention and imitation, we tested the hypothesis that human\ncreativity began with onset of the capacity for recursive recall. We compared\nruns in which agents were limited to single-step actions to runs in which they\nused recursive recall to chain simple actions into complex ones. Chaining\nresulted in higher diversity, open-ended novelty, no ceiling on the mean\nfitness of actions, and greater ability to make use of learning. Using a\ncomputational model of portrait painting, we tested the hypothesis that the\nexplosion of creativity in the Middle/Upper Paleolithic was due to onset of\ncon-textual focus: the capacity to shift between associative and analytic\nthought. This resulted in faster convergence on portraits that resembled the\nsitter, employed painterly techniques, and were rated as preferable. We\nconclude that recursive recall and contextual focus provide a computationally\nplausible explanation of how humans evolved the means to transform this planet.\n",
        "published": "2013",
        "authors": [
            "Liane Gabora",
            "Steve DiPaola"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.08252v3",
        "title": "Towards an Evolvable Cancer Treatment Simulator",
        "abstract": "  The use of high-fidelity computational simulations promises to enable\nhigh-throughput hypothesis testing and optimisation of cancer therapies.\nHowever, increasing realism comes at the cost of increasing computational\nrequirements. This article explores the use of surrogate-assisted evolutionary\nalgorithms to optimise the targeted delivery of a therapeutic compound to\ncancerous tumour cells with the multicellular simulator, PhysiCell. The use of\nboth Gaussian process models and multi-layer perceptron neural network\nsurrogate models are investigated. We find that evolutionary algorithms are\nable to effectively explore the parameter space of biophysical properties\nwithin the agent-based simulations, minimising the resulting number of\ncancerous cells after a period of simulated treatment. Both model-assisted\nalgorithms are found to outperform a standard evolutionary algorithm,\ndemonstrating their ability to perform a more effective search within the very\nsmall evaluation budget. This represents the first use of efficient\nevolutionary algorithms within a high-throughput multicellular computing\napproach to find therapeutic design optima that maximise tumour regression.\n",
        "published": "2018",
        "authors": [
            "Richard J. Preen",
            "Larry Bull",
            "Andrew Adamatzky"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.11637v1",
        "title": "Bio-inspired Optimization: metaheuristic algorithms for optimization",
        "abstract": "  In today's day and time solving real-world complex problems has become\nfundamentally vital and critical task. Many of these are combinatorial\nproblems, where optimal solutions are sought rather than exact solutions.\nTraditional optimization methods are found to be effective for small scale\nproblems. However, for real-world large scale problems, traditional methods\neither do not scale up or fail to obtain optimal solutions or they end-up\ngiving solutions after a long running time. Even earlier artificial\nintelligence based techniques used to solve these problems could not give\nacceptable results. However, last two decades have seen many new methods in AI\nbased on the characteristics and behaviors of the living organisms in the\nnature which are categorized as bio-inspired or nature inspired optimization\nalgorithms. These methods, are also termed meta-heuristic optimization methods,\nhave been proved theoretically and implemented using simulation as well used to\ncreate many useful applications. They have been used extensively to solve many\nindustrial and engineering complex problems due to being easy to understand,\nflexible, simple to adapt to the problem at hand and most importantly their\nability to come out of local optima traps. This local optima avoidance property\nhelps in finding global optimal solutions. This paper is aimed at understanding\nhow nature has inspired many optimization algorithms, basic categorization of\nthem, major bio-inspired optimization algorithms invented in recent time with\ntheir applications.\n",
        "published": "2020",
        "authors": [
            "Pravin S Game",
            "Dr. Vinod Vaze",
            "Dr. Emmanuel M"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2007.08656v1",
        "title": "A Framework for Automatic Behavior Generation in Multi-Function Swarms",
        "abstract": "  Multi-function swarms are swarms that solve multiple tasks at once. For\nexample, a quadcopter swarm could be tasked with exploring an area of interest\nwhile simultaneously functioning as ad-hoc relays. With this type of\nmulti-function comes the challenge of handling potentially conflicting\nrequirements simultaneously. Using the Quality-Diversity algorithm MAP-elites\nin combination with a suitable controller structure, a framework for automatic\nbehavior generation in multi-function swarms is proposed. The framework is\ntested on a scenario with three simultaneous tasks: exploration, communication\nnetwork creation and geolocation of RF emitters. A repertoire is evolved,\nconsisting of a wide range of controllers, or behavior primitives, with\ndifferent characteristics and trade-offs in the different tasks. This\nrepertoire would enable the swarm to transition between behavior trade-offs\nonline, according to the situational requirements. Furthermore, the effect of\nnoise on the behavior characteristics in MAP-elites is investigated. A moderate\nnumber of re-evaluations is found to increase the robustness while keeping the\ncomputational requirements relatively low. A few selected controllers are\nexamined, and the dynamics of transitioning between these controllers are\nexplored. Finally, the study develops a methodology for analyzing the makeup of\nthe resulting controllers. This is done through a parameter variation study\nwhere the importance of individual inputs to the swarm controllers is assessed\nand analyzed.\n",
        "published": "2020",
        "authors": [
            "Sondre A. Engebraaten",
            "Jonas Moen",
            "Oleg A. Yakimenko",
            "Kyrre Glette"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.03620v1",
        "title": "Lights and Shadows in Evolutionary Deep Learning: Taxonomy, Critical\n  Methodological Analysis, Cases of Study, Learned Lessons, Recommendations and\n  Challenges",
        "abstract": "  Much has been said about the fusion of bio-inspired optimization algorithms\nand Deep Learning models for several purposes: from the discovery of network\ntopologies and hyper-parametric configurations with improved performance for a\ngiven task, to the optimization of the model's parameters as a replacement for\ngradient-based solvers. Indeed, the literature is rich in proposals showcasing\nthe application of assorted nature-inspired approaches for these tasks. In this\nwork we comprehensively review and critically examine contributions made so far\nbased on three axes, each addressing a fundamental question in this research\navenue: a) optimization and taxonomy (Why?), including a historical\nperspective, definitions of optimization problems in Deep Learning, and a\ntaxonomy associated with an in-depth analysis of the literature, b) critical\nmethodological analysis (How?), which together with two case studies, allows us\nto address learned lessons and recommendations for good practices following the\nanalysis of the literature, and c) challenges and new directions of research\n(What can be done, and what for?). In summary, three axes - optimization and\ntaxonomy, critical analysis, and challenges - which outline a complete vision\nof a merger of two technologies drawing up an exciting future for this area of\nfusion research.\n",
        "published": "2020",
        "authors": [
            "Aritz D. Martinez",
            "Javier Del Ser",
            "Esther Villar-Rodriguez",
            "Eneko Osaba",
            "Javier Poyatos",
            "Siham Tabik",
            "Daniel Molina",
            "Francisco Herrera"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.10907v1",
        "title": "An Efficient Application of Neuroevolution for Competitive Multiagent\n  Learning",
        "abstract": "  Multiagent systems provide an ideal environment for the evaluation and\nanalysis of real-world problems using reinforcement learning algorithms. Most\ntraditional approaches to multiagent learning are affected by long training\nperiods as well as high computational complexity. NEAT (NeuroEvolution of\nAugmenting Topologies) is a popular evolutionary strategy used to obtain the\nbest performing neural network architecture often used to tackle optimization\nproblems in the field of artificial intelligence. This paper utilizes the NEAT\nalgorithm to achieve competitive multiagent learning on a modified pong game\nenvironment in an efficient manner. The competing agents abide by different\nrules while having similar observation space parameters. The proposed algorithm\nutilizes this property of the environment to define a singular\nneuroevolutionary procedure that obtains the optimal policy for all the agents.\nThe compiled results indicate that the proposed implementation achieves ideal\nbehaviour in a very short training period when compared to existing multiagent\nreinforcement learning models.\n",
        "published": "2021",
        "authors": [
            "Unnikrishnan Rajendran Menon",
            "Anirudh Rajiv Menon"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.09681v2",
        "title": "Structural Self-adaptation for Decentralized Pervasive Intelligence",
        "abstract": "  Communication structure plays a key role in the learning capability of\ndecentralized systems. Structural self-adaptation, by means of\nself-organization, changes the order as well as the input information of the\nagents' collective decision-making. This paper studies the role of agents'\nrepositioning on the same communication structure, i.e. a tree, as the means to\nexpand the learning capacity in complex combinatorial optimization problems,\nfor instance, load-balancing power demand to prevent blackouts or efficient\nutilization of bike sharing stations. The optimality of structural\nself-adaptations is rigorously studied by constructing a novel large-scale\nbenchmark that consists of 4000 agents with synthetic and real-world data\nperforming 4 million structural self-adaptations during which almost 320\nbillion learning messages are exchanged. Based on this benchmark dataset, 124\ndeterministic structural criteria, applied as learning meta-features, are\nsystematically evaluated as well as two online structural self-adaptation\nstrategies designed to expand learning capacity. Experimental evaluation\nidentifies metrics that capture agents with influential information and their\noptimal positioning. Significant gain in learning performance is observed for\nthe two strategies especially under low-performing initialization. Strikingly,\nthe strategy that triggers structural self-adaptation in a more exploratory\nfashion is the most cost-effective.\n",
        "published": "2019",
        "authors": [
            "Jovan Nikolic",
            "Evangelos Pournaras"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.12553v1",
        "title": "Efficient Use of heuristics for accelerating XCS-based Policy Learning\n  in Markov Games",
        "abstract": "  In Markov games, playing against non-stationary opponents with learning\nability is still challenging for reinforcement learning (RL) agents, because\nthe opponents can evolve their policies concurrently. This increases the\ncomplexity of the learning task and slows down the learning speed of the RL\nagents. This paper proposes efficient use of rough heuristics to speed up\npolicy learning when playing against concurrent learners. Specifically, we\npropose an algorithm that can efficiently learn explainable and generalized\naction selection rules by taking advantages of the representation of\nquantitative heuristics and an opponent model with an eXtended classifier\nsystem (XCS) in zero-sum Markov games. A neural network is used to model the\nopponent from their behaviors and the corresponding policy is inferred for\naction selection and rule evolution. In cases of multiple heuristic policies,\nwe introduce the concept of Pareto optimality for action selection. Besides,\ntaking advantages of the condition representation and matching mechanism of\nXCS, the heuristic policies and the opponent model can provide guidance for\nsituations with similar feature representation. Furthermore, we introduce an\naccuracy-based eligibility trace mechanism to speed up rule evolution, i.e.,\nclassifiers that can match the historical traces are reinforced according to\ntheir accuracy. We demonstrate the advantages of the proposed algorithm over\nseveral benchmark algorithms in a soccer and a thief-and-hunter scenarios.\n",
        "published": "2020",
        "authors": [
            "Hao Chen",
            "Chang Wang",
            "Jian Huang",
            "Jianxing Gong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2103.15090v1",
        "title": "Playing Against the Board: Rolling Horizon Evolutionary Algorithms\n  Against Pandemic",
        "abstract": "  Competitive board games have provided a rich and diverse testbed for\nartificial intelligence. This paper contends that collaborative board games\npose a different challenge to artificial intelligence as it must balance\nshort-term risk mitigation with long-term winning strategies. Collaborative\nboard games task all players to coordinate their different powers or pool their\nresources to overcome an escalating challenge posed by the board and a\nstochastic ruleset. This paper focuses on the exemplary collaborative board\ngame Pandemic and presents a rolling horizon evolutionary algorithm designed\nspecifically for this game. The complex way in which the Pandemic game state\nchanges in a stochastic but predictable way required a number of specially\ndesigned forward models, macro-action representations for decision-making, and\nrepair functions for the genetic operations of the evolutionary algorithm.\nVariants of the algorithm which explore optimistic versus pessimistic game\nstate evaluations, different mutation rates and event horizons are compared\nagainst a baseline hierarchical policy agent. Results show that an evolutionary\napproach via short-horizon rollouts can better account for the future dangers\nthat the board may introduce, and guard against them. Results highlight the\ntypes of challenges that collaborative board games pose to artificial\nintelligence, especially for handling multi-player collaboration interactions.\n",
        "published": "2021",
        "authors": [
            "Konstantinos Sfikas",
            "Antonios Liapis"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2104.03404v1",
        "title": "Bootstrapping of memetic from genetic evolution via inter-agent\n  selection pressures",
        "abstract": "  We create an artificial system of agents (attention-based neural networks)\nwhich selectively exchange messages with each-other in order to study the\nemergence of memetic evolution and how memetic evolutionary pressures interact\nwith genetic evolution of the network weights. We observe that the ability of\nagents to exert selection pressures on each-other is essential for memetic\nevolution to bootstrap itself into a state which has both high-fidelity\nreplication of memes, as well as continuing production of new memes over time.\nHowever, in this system there is very little interaction between this memetic\n'ecology' and underlying tasks driving individual fitness - the emergent meme\nlayer appears to be neither helpful nor harmful to agents' ability to learn to\nsolve tasks. Sourcecode for these experiments is available at\nhttps://github.com/GoodAI/memes\n",
        "published": "2021",
        "authors": [
            "Nicholas Guttenberg",
            "Marek Rosa"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.10015v2",
        "title": "Meta-control of social learning strategies",
        "abstract": "  Social learning, copying other's behavior without actual experience, offers a\ncost-effective means of knowledge acquisition. However, it raises the\nfundamental question of which individuals have reliable information: successful\nindividuals versus the majority. The former and the latter are known\nrespectively as success-based and conformist social learning strategies. We\nshow here that while the success-based strategy fully exploits the benign\nenvironment of low uncertainly, it fails in uncertain environments. On the\nother hand, the conformist strategy can effectively mitigate this adverse\neffect. Based on these findings, we hypothesized that meta-control of\nindividual and social learning strategies provides effective and\nsample-efficient learning in volatile and uncertain environments. Simulations\non a set of environments with various levels of volatility and uncertainty\nconfirmed our hypothesis. The results imply that meta-control of social\nlearning affords agents the leverage to resolve environmental uncertainty with\nminimal exploration cost, by exploiting others' learning as an external\nknowledge base.\n",
        "published": "2021",
        "authors": [
            "Anil Yaman",
            "Nicolas Bredeche",
            "Onur \u00c7aylak",
            "Joel Z. Leibo",
            "Sang Wan Lee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2206.13844v1",
        "title": "Cooperative Multi-Agent Search on Endogenously-Changing Fitness\n  Landscapes",
        "abstract": "  We use a multi-agent system to model how agents (representing firms) may\ncollaborate and adapt in a business 'landscape' where some, more influential,\nfirms are given the power to shape the landscape of other firms. The landscapes\nwe study are based on the well-known NK model of Kauffman, with the addition of\n'shapers', firms that can change the landscape's features for themselves and\nall other players. Our work investigates how firms that are additionally\nendowed with cognitive and experiential search, and the ability to form\ncollaborations with other firms, can use these capabilities to adapt more\nquickly and adeptly. We find that, in a collaborative group, firms must still\nhave a mind of their own and resist direct mimicry of stronger partners to\nattain better heights collectively. Larger groups and groups with more\ninfluential members generally do better, so targeted intelligent cooperation is\nbeneficial. These conclusions are tentative, and our results show a sensitivity\nto landscape ruggedness and \"malleability\" (i.e. the capacity of the landscape\nto be changed by the shaper firms). Overall, our work demonstrates the\npotential of computer science, evolution, and machine learning to contribute to\nbusiness strategy in these complex environments.\n",
        "published": "2022",
        "authors": [
            "Chin Woei Lim",
            "Richard Allmendinger",
            "Joshua Knowles",
            "Ayesha Alhosani",
            "Mercedes Bleda"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2208.05568v6",
        "title": "The emergence of division of labor through decentralized social\n  sanctioning",
        "abstract": "  Human ecological success relies on our characteristic ability to flexibly\nself-organize into cooperative social groups, the most successful of which\nemploy substantial specialization and division of labor. Unlike most other\nanimals, humans learn by trial and error during their lives what role to take\non. However, when some critical roles are more attractive than others, and\nindividuals are self-interested, then there is a social dilemma: each\nindividual would prefer others take on the critical but unremunerative roles so\nthey may remain free to take one that pays better. But disaster occurs if all\nact thusly and a critical role goes unfilled. In such situations learning an\noptimum role distribution may not be possible. Consequently, a fundamental\nquestion is: how can division of labor emerge in groups of self-interested\nlifetime-learning individuals? Here we show that by introducing a model of\nsocial norms, which we regard as emergent patterns of decentralized social\nsanctioning, it becomes possible for groups of self-interested individuals to\nlearn a productive division of labor involving all critical roles. Such social\nnorms work by redistributing rewards within the population to disincentivize\nantisocial roles while incentivizing prosocial roles that do not intrinsically\npay as well as others.\n",
        "published": "2022",
        "authors": [
            "Anil Yaman",
            "Joel Z. Leibo",
            "Giovanni Iacca",
            "Sang Wan Lee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2211.08407v4",
        "title": "Trust-Awareness to Secure Swarm Intelligence from Data Injection Attack",
        "abstract": "  Enabled by the emerging industrial agent (IA) technology, swarm intelligence\n(SI) is envisaged to play an important role in future industrial Internet of\nThings (IIoT) that is shaped by Sixth Generation (6G) mobile communications and\ndigital twin (DT). However, its fragility against data injection attack may\nhalt it from practical deployment. In this paper we propose an efficient trust\napproach to address this security concern for SI.\n",
        "published": "2022",
        "authors": [
            "Bin Han",
            "Dennis Krummacker",
            "Qiuheng Zhou",
            "Hans D. Schotten"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2211.13746v6",
        "title": "Melting Pot 2.0",
        "abstract": "  Multi-agent artificial intelligence research promises a path to develop\nintelligent technologies that are more human-like and more human-compatible\nthan those produced by \"solipsistic\" approaches, which do not consider\ninteractions between agents. Melting Pot is a research tool developed to\nfacilitate work on multi-agent artificial intelligence, and provides an\nevaluation protocol that measures generalization to novel social partners in a\nset of canonical test scenarios. Each scenario pairs a physical environment (a\n\"substrate\") with a reference set of co-players (a \"background population\"), to\ncreate a social situation with substantial interdependence between the\nindividuals involved. For instance, some scenarios were inspired by\ninstitutional-economics-based accounts of natural resource management and\npublic-good-provision dilemmas. Others were inspired by considerations from\nevolutionary biology, game theory, and artificial life. Melting Pot aims to\ncover a maximally diverse set of interdependencies and incentives. It includes\nthe commonly-studied extreme cases of perfectly-competitive (zero-sum)\nmotivations and perfectly-cooperative (shared-reward) motivations, but does not\nstop with them. As in real-life, a clear majority of scenarios in Melting Pot\nhave mixed incentives. They are neither purely competitive nor purely\ncooperative and thus demand successful agents be able to navigate the resulting\nambiguity. Here we describe Melting Pot 2.0, which revises and expands on\nMelting Pot. We also introduce support for scenarios with asymmetric roles, and\nexplain how to integrate them into the evaluation protocol. This report also\ncontains: (1) details of all substrates and scenarios; (2) a complete\ndescription of all baseline algorithms and results. Our intention is for it to\nserve as a reference for researchers using Melting Pot 2.0.\n",
        "published": "2022",
        "authors": [
            "John P. Agapiou",
            "Alexander Sasha Vezhnevets",
            "Edgar A. Du\u00e9\u00f1ez-Guzm\u00e1n",
            "Jayd Matyas",
            "Yiran Mao",
            "Peter Sunehag",
            "Raphael K\u00f6ster",
            "Udari Madhushani",
            "Kavya Kopparapu",
            "Ramona Comanescu",
            "DJ Strouse",
            "Michael B. Johanson",
            "Sukhdeep Singh",
            "Julia Haas",
            "Igor Mordatch",
            "Dean Mobbs",
            "Joel Z. Leibo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.05898v1",
        "title": "Mixture of personality improved Spiking actor network for efficient\n  multi-agent cooperation",
        "abstract": "  Adaptive human-agent and agent-agent cooperation are becoming more and more\ncritical in the research area of multi-agent reinforcement learning (MARL),\nwhere remarked progress has been made with the help of deep neural networks.\nHowever, many established algorithms can only perform well during the learning\nparadigm but exhibit poor generalization during cooperation with other unseen\npartners. The personality theory in cognitive psychology describes that humans\ncan well handle the above cooperation challenge by predicting others'\npersonalities first and then their complex actions. Inspired by this two-step\npsychology theory, we propose a biologically plausible mixture of personality\n(MoP) improved spiking actor network (SAN), whereby a determinantal point\nprocess is used to simulate the complex formation and integration of different\ntypes of personality in MoP, and dynamic and spiking neurons are incorporated\ninto the SAN for the efficient reinforcement learning. The benchmark Overcooked\ntask, containing a strong requirement for cooperative cooking, is selected to\ntest the proposed MoP-SAN. The experimental results show that the MoP-SAN can\nachieve both high performances during not only the learning paradigm but also\nthe generalization test (i.e., cooperation with other unseen agents) paradigm\nwhere most counterpart deep actor networks failed. Necessary ablation\nexperiments and visualization analyses were conducted to explain why MoP and\nSAN are effective in multi-agent reinforcement learning scenarios while DNN\nperforms poorly in the generalization test.\n",
        "published": "2023",
        "authors": [
            "Xiyun Li",
            "Ziyi Ni",
            "Jingqing Ruan",
            "Linghui Meng",
            "Jing Shi",
            "Tielin Zhang",
            "Bo Xu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.07366v1",
        "title": "Multi-Value Alignment in Normative Multi-Agent System: Evolutionary\n  Optimisation Approach",
        "abstract": "  Value-alignment in normative multi-agent systems is used to promote a certain\nvalue and to ensure the consistent behavior of agents in autonomous intelligent\nsystems with human values. However, the current literature is limited to\nincorporation of effective norms for single value alignment with no\nconsideration of agents' heterogeneity and the requirement of simultaneous\npromotion and alignment of multiple values. This research proposes a\nmulti-value promotion model that uses multi-objective evolutionary algorithms\nto produce the optimum parametric set of norms that is aligned with multiple\nsimultaneous values of heterogeneous agents and the system. To understand\nvarious aspects of this complex problem, several evolutionary algorithms were\nused to find a set of optimised norm parameters considering two toy tax\nscenarios with two and five values are considered. The results are analysed\nfrom different perspectives to show the impact of a selected evolutionary\nalgorithm on the solution, and the importance of understanding the relation\nbetween values when prioritising them.\n",
        "published": "2023",
        "authors": [
            "Maha Riad",
            "Vinicius Renan de Carvalho",
            "Fatemeh Golpayegani"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.13425v1",
        "title": "EINCASM: Emergent Intelligence in Neural Cellular Automaton Slime Molds",
        "abstract": "  This paper presents EINCASM, a prototype system employing a novel framework\nfor studying emergent intelligence in organisms resembling slime molds. EINCASM\nevolves neural cellular automata with NEAT to maximize cell growth constrained\nby nutrient and energy costs. These organisms capitalize physically simulated\nfluid to transport nutrients and chemical-like signals to orchestrate growth\nand adaptation to complex, changing environments. Our framework builds the\nfoundation for studying how the presence of puzzles, physics, communication,\ncompetition and dynamic open-ended environments contribute to the emergence of\nintelligent behavior. We propose preliminary tests for intelligence in such\norganisms and suggest future work for more powerful systems employing EINCASM\nto better understand intelligence in distributed dynamical systems.\n",
        "published": "2023",
        "authors": [
            "Aidan Barbieux",
            "Rodrigo Canaan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.15559v3",
        "title": "Inverse square Levy walk emerging universally in goal-oriented tasks",
        "abstract": "  The Levy walk in which the frequency of occurrence of step lengths follows a\npower-law distribution, can be observed in the migratory behavior of organisms\nat various levels. Levy walks with power exponents close to 2 are observed, and\nthe reasons are unclear. This study aims to propose a model that universally\ngenerates inverse square Levy walks (called Cauchy walks) and to identify the\nconditions under which Cauchy walks appear. We demonstrate that Cauchy walks\nemerge universally in goal-oriented tasks. We use the term \"goal-oriented\" when\nthe goal is clear, but this can be achieved in different ways, which cannot be\nuniquely determined. We performed a simulation in which an agent observed the\ndata generated from a probability distribution in a two-dimensional space and\nsuccessively estimated the central coordinates of that probability\ndistribution. The agent has a model of probability distribution as a hypothesis\nfor data-generating distribution and can modify the model such that each time a\ndata point is observed, thereby increasing the estimated probability of\noccurrence of the observed data. To achieve this, the center coordinates of the\nmodel must be moved closer to those of the observed data. However, in the case\nof a two-dimensional space, arbitrariness arises in the direction of correction\nof the center; this task is goal oriented. We analyze two cases: a strategy\nthat allocates the amount of modification randomly in the x- and y-directions,\nand a strategy that determines allocation such that movement is minimized. The\nresults reveal that when a random strategy is used, the Cauchy walk appears.\nWhen the minimum strategy is used, the Brownian walk appears. The presence or\nabsence of the constraint of minimizing the amount of movement may be a factor\nthat causes the difference between Brownian and Levy walks.\n",
        "published": "2023",
        "authors": [
            "Shuji Shinohara",
            "Daiki Morita",
            "Nobuhito Manome",
            "Ryota Hayashi",
            "Toru Moriyama",
            "Hiroshi Okamoto",
            "Pegio-Yukio Gunji",
            "Ung-il Chung"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2306.13169v1",
        "title": "Amorphous Fortress: Observing Emergent Behavior in Multi-Agent FSMs",
        "abstract": "  We introduce a system called Amorphous Fortress -- an abstract, yet spatial,\nopen-ended artificial life simulation. In this environment, the agents are\nrepresented as finite-state machines (FSMs) which allow for multi-agent\ninteraction within a constrained space. These agents are created by randomly\ngenerating and evolving the FSMs; sampling from pre-defined states and\ntransitions. This environment was designed to explore the emergent AI behaviors\nfound implicitly in simulation games such as Dwarf Fortress or The Sims. We\napply the hill-climber evolutionary search algorithm to this environment to\nexplore the various levels of depth and interaction from the generated FSMs.\n",
        "published": "2023",
        "authors": [
            "M Charity",
            "Dipika Rajesh",
            "Sam Earle",
            "Julian Togelius"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2308.10435v1",
        "title": "GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems",
        "abstract": "  This paper introduces the \"GPT-in-the-loop\" approach, a novel method\ncombining the advanced reasoning capabilities of Large Language Models (LLMs)\nlike Generative Pre-trained Transformers (GPT) with multiagent (MAS) systems.\nVenturing beyond traditional adaptive approaches that generally require long\ntraining processes, our framework employs GPT-4 for enhanced problem-solving\nand explanation skills. Our experimental backdrop is the smart streetlight\nInternet of Things (IoT) application. Here, agents use sensors, actuators, and\nneural networks to create an energy-efficient lighting system. By integrating\nGPT-4, these agents achieve superior decision-making and adaptability without\nthe need for extensive training. We compare this approach with both traditional\nneuroevolutionary methods and solutions provided by software engineers,\nunderlining the potential of GPT-driven multiagent systems in IoT.\nStructurally, the paper outlines the incorporation of GPT into the agent-driven\nFramework for the Internet of Things (FIoT), introduces our proposed\nGPT-in-the-loop approach, presents comparative results in the IoT context, and\nconcludes with insights and future directions.\n",
        "published": "2023",
        "authors": [
            "Nathalia Nascimento",
            "Paulo Alencar",
            "Donald Cowan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.05375v1",
        "title": "Classical Sorting Algorithms as a Model of Morphogenesis: self-sorting\n  arrays reveal unexpected competencies in a minimal model of basal\n  intelligence",
        "abstract": "  The emerging field of Diverse Intelligence seeks to identify, formalize, and\nunderstand commonalities in behavioral competencies across a wide range of\nimplementations. Especially interesting are simple systems that provide\nunexpected examples of memory, decision-making, or problem-solving in\nsubstrates that at first glance do not appear to be complex enough to implement\nsuch capabilities. We seek to develop tools to help understand the minimal\nrequirements for such capabilities, and to learn to recognize and predict basal\nforms of intelligence in unconventional substrates. Here, we apply novel\nanalyses to the behavior of classical sorting algorithms, short pieces of code\nwhich have been studied for many decades. To study these sorting algorithms as\na model of biological morphogenesis and its competencies, we break two\nformerly-ubiquitous assumptions: top-down control (instead, showing how each\nelement within a array of numbers can exert minimal agency and implement\nsorting policies from the bottom up), and fully reliable hardware (instead,\nallowing some of the elements to be \"damaged\" and fail to execute the\nalgorithm). We quantitatively characterize sorting activity as the traversal of\na problem space, showing that arrays of autonomous elements sort themselves\nmore reliably and robustly than traditional implementations in the presence of\nerrors. Moreover, we find the ability to temporarily reduce progress in order\nto navigate around a defect, and unexpected clustering behavior among the\nelements in chimeric arrays whose elements follow one of two different\nalgorithms. The discovery of emergent problem-solving capacities in simple,\nfamiliar algorithms contributes a new perspective to the field of Diverse\nIntelligence, showing how basal forms of intelligence can emerge in simple\nsystems without being explicitly encoded in their underlying mechanics.\n",
        "published": "2023",
        "authors": [
            "Taining Zhang",
            "Adam Goldstein",
            "Michael Levin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1312.5198v4",
        "title": "Learning Semantic Script Knowledge with Event Embeddings",
        "abstract": "  Induction of common sense knowledge about prototypical sequences of events\nhas recently received much attention. Instead of inducing this knowledge in the\nform of graphs, as in much of the previous work, in our method, distributed\nrepresentations of event realizations are computed based on distributed\nrepresentations of predicates and their arguments, and then these\nrepresentations are used to predict prototypical event orderings. The\nparameters of the compositional process for computing the event representations\nand the ranking component of the model are jointly estimated from texts. We\nshow that this approach results in a substantial boost in ordering performance\nwith respect to previous methods.\n",
        "published": "2013",
        "authors": [
            "Ashutosh Modi",
            "Ivan Titov"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1703.00955v4",
        "title": "Toward Controlled Generation of Text",
        "abstract": "  Generic generation and manipulation of text is challenging and has limited\nsuccess compared to recent deep generative modeling in visual domain. This\npaper aims at generating plausible natural language sentences, whose attributes\nare dynamically controlled by learning disentangled latent representations with\ndesignated semantics. We propose a new neural generative model which combines\nvariational auto-encoders and holistic attribute discriminators for effective\nimposition of semantic structures. With differentiable approximation to\ndiscrete text samples, explicit constraints on independent attribute controls,\nand efficient collaborative learning of generator and discriminators, our model\nlearns highly interpretable representations from even only word annotations,\nand produces realistic sentences with desired attributes. Quantitative\nevaluation validates the accuracy of sentence and attribute generation.\n",
        "published": "2017",
        "authors": [
            "Zhiting Hu",
            "Zichao Yang",
            "Xiaodan Liang",
            "Ruslan Salakhutdinov",
            "Eric P. Xing"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.00924v1",
        "title": "Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement\n  Learning",
        "abstract": "  With the increasing popularity of video sharing websites such as YouTube and\nFacebook, multimodal sentiment analysis has received increasing attention from\nthe scientific community. Contrary to previous works in multimodal sentiment\nanalysis which focus on holistic information in speech segments such as bag of\nwords representations and average facial expression intensity, we develop a\nnovel deep architecture for multimodal sentiment analysis that performs\nmodality fusion at the word level. In this paper, we propose the Gated\nMultimodal Embedding LSTM with Temporal Attention (GME-LSTM(A)) model that is\ncomposed of 2 modules. The Gated Multimodal Embedding alleviates the\ndifficulties of fusion when there are noisy modalities. The LSTM with Temporal\nAttention performs word level fusion at a finer fusion resolution between input\nmodalities and attends to the most important time steps. As a result, the\nGME-LSTM(A) is able to better model the multimodal structure of speech through\ntime and perform better sentiment comprehension. We demonstrate the\neffectiveness of this approach on the publicly-available Multimodal Corpus of\nSentiment Intensity and Subjectivity Analysis (CMU-MOSI) dataset by achieving\nstate-of-the-art sentiment classification and regression results. Qualitative\nanalysis on our model emphasizes the importance of the Temporal Attention Layer\nin sentiment prediction because the additional acoustic and visual modalities\nare noisy. We also demonstrate the effectiveness of the Gated Multimodal\nEmbedding in selectively filtering these noisy modalities out. Our results and\nanalysis open new areas in the study of sentiment analysis in human\ncommunication and provide new models for multimodal fusion.\n",
        "published": "2018",
        "authors": [
            "Minghai Chen",
            "Sen Wang",
            "Paul Pu Liang",
            "Tadas Baltru\u0161aitis",
            "Amir Zadeh",
            "Louis-Philippe Morency"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.09914v1",
        "title": "High-Dimensional Vector Semantics",
        "abstract": "  In this paper we explore the \"vector semantics\" problem from the perspective\nof \"almost orthogonal\" property of high-dimensional random vectors. We show\nthat this intriguing property can be used to \"memorize\" random vectors by\nsimply adding them, and we provide an efficient probabilistic solution to the\nset membership problem. Also, we discuss several applications to word context\nvector embeddings, document sentences similarity, and spam filtering.\n",
        "published": "2018",
        "authors": [
            "M. Andrecut"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.02181v4",
        "title": "Attention in Natural Language Processing",
        "abstract": "  Attention is an increasingly popular mechanism used in a wide range of neural\narchitectures. The mechanism itself has been realized in a variety of formats.\nHowever, because of the fast-paced advances in this domain, a systematic\noverview of attention is still missing. In this article, we define a unified\nmodel for attention architectures in natural language processing, with a focus\non those designed to work with vector representations of the textual data. We\npropose a taxonomy of attention models according to four dimensions: the\nrepresentation of the input, the compatibility function, the distribution\nfunction, and the multiplicity of the input and/or output. We present the\nexamples of how prior information can be exploited in attention models and\ndiscuss ongoing research efforts and open challenges in the area, providing the\nfirst extensive categorization of the vast body of literature in this exciting\ndomain.\n",
        "published": "2019",
        "authors": [
            "Andrea Galassi",
            "Marco Lippi",
            "Paolo Torroni"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.03077v1",
        "title": "Knowledge Graph Fact Prediction via Knowledge-Enriched Tensor\n  Factorization",
        "abstract": "  We present a family of novel methods for embedding knowledge graphs into\nreal-valued tensors. These tensor-based embeddings capture the ordered\nrelations that are typical in the knowledge graphs represented by semantic web\nlanguages like RDF. Unlike many previous models, our methods can easily use\nprior background knowledge provided by users or extracted automatically from\nexisting knowledge graphs. In addition to providing more robust methods for\nknowledge graph embedding, we provide a provably-convergent, linear tensor\nfactorization algorithm. We demonstrate the efficacy of our models for the task\nof predicting new facts across eight different knowledge graphs, achieving\nbetween 5% and 50% relative improvement over existing state-of-the-art\nknowledge graph embedding techniques. Our empirical evaluation shows that all\nof the tensor decomposition models perform well when the average degree of an\nentity in a graph is high, with constraint-based models doing better on graphs\nwith a small number of highly similar relations and regularization-based models\ndominating for graphs with relations of varying degrees of similarity.\n",
        "published": "2019",
        "authors": [
            "Ankur Padia",
            "Kostantinos Kalpakis",
            "Francis Ferraro",
            "Tim Finin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.00084v1",
        "title": "Contextual Graph Attention for Answering Logical Queries over Incomplete\n  Knowledge Graphs",
        "abstract": "  Recently, several studies have explored methods for using KG embedding to\nanswer logical queries. These approaches either treat embedding learning and\nquery answering as two separated learning tasks, or fail to deal with the\nvariability of contributions from different query paths. We proposed to\nleverage a graph attention mechanism to handle the unequal contribution of\ndifferent query paths. However, commonly used graph attention assumes that the\ncenter node embedding is provided, which is unavailable in this task since the\ncenter node is to be predicted. To solve this problem we propose a multi-head\nattention-based end-to-end logical query answering model, called Contextual\nGraph Attention model(CGA), which uses an initial neighborhood aggregation\nlayer to generate the center embedding, and the whole model is trained jointly\non the original KG structure as well as the sampled query-answer pairs. We also\nintroduce two new datasets, DB18 and WikiGeo19, which are rather large in size\ncompared to the existing datasets and contain many more relation types, and use\nthem to evaluate the performance of the proposed model. Our result shows that\nthe proposed CGA with fewer learnable parameters consistently outperforms the\nbaseline models on both datasets as well as Bio dataset.\n",
        "published": "2019",
        "authors": [
            "Gengchen Mai",
            "Krzysztof Janowicz",
            "Bo Yan",
            "Rui Zhu",
            "Ling Cai",
            "Ni Lao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.13818v1",
        "title": "A Survey of Document Grounded Dialogue Systems (DGDS)",
        "abstract": "  Dialogue system (DS) attracts great attention from industry and academia\nbecause of its wide application prospects. Researchers usually divide the DS\naccording to the function. However, many conversations require the DS to switch\nbetween different functions. For example, movie discussion can change from\nchit-chat to QA, the conversational recommendation can transform from chit-chat\nto recommendation, etc. Therefore, classification according to functions may\nnot be enough to help us appreciate the current development trend. We classify\nthe DS based on background knowledge. Specifically, study the latest DS based\non the unstructured document(s). We define Document Grounded Dialogue System\n(DGDS) as the DS that the dialogues are centering on the given document(s). The\nDGDS can be used in scenarios such as talking over merchandise against product\nManual, commenting on news reports, etc. We believe that extracting\nunstructured document(s) information is the future trend of the DS because a\ngreat amount of human knowledge lies in these document(s). The research of the\nDGDS not only possesses a broad application prospect but also facilitates AI to\nbetter understand human knowledge and natural language. We analyze the\nclassification, architecture, datasets, models, and future development trends\nof the DGDS, hoping to help researchers in this field.\n",
        "published": "2020",
        "authors": [
            "Longxuan Ma",
            "Wei-Nan Zhang",
            "Mingda Li",
            "Ting Liu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2007.07151v1",
        "title": "Extracting Structured Data from Physician-Patient Conversations By\n  Predicting Noteworthy Utterances",
        "abstract": "  Despite diverse efforts to mine various modalities of medical data, the\nconversations between physicians and patients at the time of care remain an\nuntapped source of insights. In this paper, we leverage this data to extract\nstructured information that might assist physicians with post-visit\ndocumentation in electronic health records, potentially lightening the clerical\nburden. In this exploratory study, we describe a new dataset consisting of\nconversation transcripts, post-visit summaries, corresponding supporting\nevidence (in the transcript), and structured labels. We focus on the tasks of\nrecognizing relevant diagnoses and abnormalities in the review of organ systems\n(RoS). One methodological challenge is that the conversations are long (around\n1500 words), making it difficult for modern deep-learning models to use them as\ninput. To address this challenge, we extract noteworthy utterances---parts of\nthe conversation likely to be cited as evidence supporting some summary\nsentence. We find that by first filtering for (predicted) noteworthy\nutterances, we can significantly boost predictive performance for recognizing\nboth diagnoses and RoS abnormalities.\n",
        "published": "2020",
        "authors": [
            "Kundan Krishna",
            "Amy Pavel",
            "Benjamin Schloss",
            "Jeffrey P. Bigham",
            "Zachary C. Lipton"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.00217v1",
        "title": "Adversarial Connective-exploiting Networks for Implicit Discourse\n  Relation Classification",
        "abstract": "  Implicit discourse relation classification is of great challenge due to the\nlack of connectives as strong linguistic cues, which motivates the use of\nannotated implicit connectives to improve the recognition. We propose a feature\nimitation framework in which an implicit relation network is driven to learn\nfrom another neural network with access to connectives, and thus encouraged to\nextract similarly salient features for accurate classification. We develop an\nadversarial model to enable an adaptive imitation scheme through competition\nbetween the implicit network and a rival feature discriminator. Our method\neffectively transfers discriminability of connectives to the implicit features,\nand achieves state-of-the-art performance on the PDTB benchmark.\n",
        "published": "2017",
        "authors": [
            "Lianhui Qin",
            "Zhisong Zhang",
            "Hai Zhao",
            "Zhiting Hu",
            "Eric P. Xing"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.08424v2",
        "title": "Multimodal Word Distributions",
        "abstract": "  Word embeddings provide point representations of words containing useful\nsemantic information. We introduce multimodal word distributions formed from\nGaussian mixtures, for multiple word meanings, entailment, and rich uncertainty\ninformation. To learn these distributions, we propose an energy-based\nmax-margin objective. We show that the resulting approach captures uniquely\nexpressive semantic information, and outperforms alternatives, such as word2vec\nskip-grams, and Gaussian embeddings, on benchmark datasets such as word\nsimilarity and entailment.\n",
        "published": "2017",
        "authors": [
            "Ben Athiwaratkun",
            "Andrew Gordon Wilson"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.07918v2",
        "title": "Robust Task Clustering for Deep Many-Task Learning",
        "abstract": "  We investigate task clustering for deep-learning based multi-task and\nfew-shot learning in a many-task setting. We propose a new method to measure\ntask similarities with cross-task transfer performance matrix for the deep\nlearning scenario. Although this matrix provides us critical information\nregarding similarity between tasks, its asymmetric property and unreliable\nperformance scores can affect conventional clustering methods adversely.\nAdditionally, the uncertain task-pairs, i.e., the ones with extremely\nasymmetric transfer scores, may collectively mislead clustering algorithms to\noutput an inaccurate task-partition. To overcome these limitations, we propose\na novel task-clustering algorithm by using the matrix completion technique. The\nproposed algorithm constructs a partially-observed similarity matrix based on\nthe certainty of cluster membership of the task-pairs. We then use a matrix\ncompletion algorithm to complete the similarity matrix. Our theoretical\nanalysis shows that under mild constraints, the proposed algorithm will\nperfectly recover the underlying \"true\" similarity matrix with a high\nprobability. Our results show that the new task clustering method can discover\ntask clusters for training flexible and superior neural network models in a\nmulti-task learning setup for sentiment classification and dialog intent\nclassification tasks. Our task clustering approach also extends metric-based\nfew-shot learning methods to adapt multiple metrics, which demonstrates\nempirical advantages when the tasks are diverse.\n",
        "published": "2017",
        "authors": [
            "Mo Yu",
            "Xiaoxiao Guo",
            "Jinfeng Yi",
            "Shiyu Chang",
            "Saloni Potdar",
            "Gerald Tesauro",
            "Haoyu Wang",
            "Bowen Zhou"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.00823v4",
        "title": "Graph2Seq: Graph to Sequence Learning with Attention-based Neural\n  Networks",
        "abstract": "  The celebrated Sequence to Sequence learning (Seq2Seq) technique and its\nnumerous variants achieve excellent performance on many tasks. However, many\nmachine learning tasks have inputs naturally represented as graphs; existing\nSeq2Seq models face a significant challenge in achieving accurate conversion\nfrom graph form to the appropriate sequence. To address this challenge, we\nintroduce a novel general end-to-end graph-to-sequence neural encoder-decoder\nmodel that maps an input graph to a sequence of vectors and uses an\nattention-based LSTM method to decode the target sequence from these vectors.\nOur method first generates the node and graph embeddings using an improved\ngraph-based neural network with a novel aggregation strategy to incorporate\nedge direction information in the node embeddings. We further introduce an\nattention mechanism that aligns node embeddings and the decoding sequence to\nbetter cope with large graphs. Experimental results on bAbI, Shortest Path, and\nNatural Language Generation tasks demonstrate that our model achieves\nstate-of-the-art performance and significantly outperforms existing graph\nneural networks, Seq2Seq, and Tree2Seq models; using the proposed\nbi-directional node embedding aggregation strategy, the model can converge\nrapidly to the optimal performance.\n",
        "published": "2018",
        "authors": [
            "Kun Xu",
            "Lingfei Wu",
            "Zhiguo Wang",
            "Yansong Feng",
            "Michael Witbrock",
            "Vadim Sheinin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1808.08609v1",
        "title": "Adversarially Regularising Neural NLI Models to Integrate Logical\n  Background Knowledge",
        "abstract": "  Adversarial examples are inputs to machine learning models designed to cause\nthe model to make a mistake. They are useful for understanding the shortcomings\nof machine learning models, interpreting their results, and for regularisation.\nIn NLP, however, most example generation strategies produce input text by using\nknown, pre-specified semantic transformations, requiring significant manual\neffort and in-depth understanding of the problem and domain. In this paper, we\ninvestigate the problem of automatically generating adversarial examples that\nviolate a set of given First-Order Logic constraints in Natural Language\nInference (NLI). We reduce the problem of identifying such adversarial examples\nto a combinatorial optimisation problem, by maximising a quantity measuring the\ndegree of violation of such constraints and by using a language model for\ngenerating linguistically-plausible examples. Furthermore, we propose a method\nfor adversarially regularising neural NLI models for incorporating background\nknowledge. Our results show that, while the proposed method does not always\nimprove results on the SNLI and MultiNLI datasets, it significantly and\nconsistently increases the predictive accuracy on adversarially-crafted\ndatasets -- up to a 79.6% relative improvement -- while drastically reducing\nthe number of background knowledge violations. Furthermore, we show that\nadversarial examples transfer among model architectures, and that the proposed\nadversarial training procedure improves the robustness of NLI models to\nadversarial examples.\n",
        "published": "2018",
        "authors": [
            "Pasquale Minervini",
            "Sebastian Riedel"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.01398v2",
        "title": "Optimal Completion Distillation for Sequence Learning",
        "abstract": "  We present Optimal Completion Distillation (OCD), a training procedure for\noptimizing sequence to sequence models based on edit distance. OCD is\nefficient, has no hyper-parameters of its own, and does not require pretraining\nor joint optimization with conditional log-likelihood. Given a partial sequence\ngenerated by the model, we first identify the set of optimal suffixes that\nminimize the total edit distance, using an efficient dynamic programming\nalgorithm. Then, for each position of the generated sequence, we use a target\ndistribution that puts equal probability on the first token of all the optimal\nsuffixes. OCD achieves the state-of-the-art performance on end-to-end speech\nrecognition, on both Wall Street Journal and Librispeech datasets, achieving\n$9.3\\%$ WER and $4.5\\%$ WER respectively.\n",
        "published": "2018",
        "authors": [
            "Sara Sabour",
            "William Chan",
            "Mohammad Norouzi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.00962v5",
        "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes",
        "abstract": "  Training large deep neural networks on massive datasets is computationally\nvery challenging. There has been recent surge in interest in using large batch\nstochastic optimization methods to tackle this issue. The most prominent\nalgorithm in this line of research is LARS, which by employing layerwise\nadaptive learning rates trains ResNet on ImageNet in a few minutes. However,\nLARS performs poorly for attention models like BERT, indicating that its\nperformance gains are not consistent across tasks. In this paper, we first\nstudy a principled layerwise adaptation strategy to accelerate training of deep\nneural networks using large mini-batches. Using this strategy, we develop a new\nlayerwise adaptive large batch optimization technique called LAMB; we then\nprovide convergence analysis of LAMB as well as LARS, showing convergence to a\nstationary point in general nonconvex settings. Our empirical results\ndemonstrate the superior performance of LAMB across various tasks such as BERT\nand ResNet-50 training with very little hyperparameter tuning. In particular,\nfor BERT training, our optimizer enables use of very large batch sizes of 32868\nwithout any degradation of performance. By increasing the batch size to the\nmemory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to\njust 76 minutes (Table 1). The LAMB implementation is available at\nhttps://github.com/tensorflow/addons/blob/master/tensorflow_addons/optimizers/lamb.py\n",
        "published": "2019",
        "authors": [
            "Yang You",
            "Jing Li",
            "Sashank Reddi",
            "Jonathan Hseu",
            "Sanjiv Kumar",
            "Srinadh Bhojanapalli",
            "Xiaodan Song",
            "James Demmel",
            "Kurt Keutzer",
            "Cho-Jui Hsieh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.02019v1",
        "title": "Conditioning LSTM Decoder and Bi-directional Attention Based Question\n  Answering System",
        "abstract": "  Applying neural-networks on Question Answering has gained increasing\npopularity in recent years. In this paper, I implemented a model with\nBi-directional attention flow layer, connected with a Multi-layer LSTM encoder,\nconnected with one start-index decoder and one conditioning end-index decoder.\nI introduce a new end-index decoder layer, conditioning on start-index output.\nThe Experiment shows this has increased model performance by 15.16%. For\nprediction, I proposed a new smart-span equation, rewarding both short answer\nlength and high probability in start-index and end-index, which further\nimproved the prediction accuracy. The best single model achieves an F1 score of\n73.97% and EM score of 64.95% on test set.\n",
        "published": "2019",
        "authors": [
            "Heguang Liu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.05651v1",
        "title": "Representation Learning for Words and Entities",
        "abstract": "  This thesis presents new methods for unsupervised learning of distributed\nrepresentations of words and entities from text and knowledge bases. The first\nalgorithm presented in the thesis is a multi-view algorithm for learning\nrepresentations of words called Multiview Latent Semantic Analysis (MVLSA). By\nincorporating up to 46 different types of co-occurrence statistics for the same\nvocabulary of english words, I show that MVLSA outperforms other\nstate-of-the-art word embedding models. Next, I focus on learning entity\nrepresentations for search and recommendation and present the second method of\nthis thesis, Neural Variational Set Expansion (NVSE). NVSE is also an\nunsupervised learning method, but it is based on the Variational Autoencoder\nframework. Evaluations with human annotators show that NVSE can facilitate\nbetter search and recommendation of information gathered from noisy, automatic\nannotation of unstructured natural language corpora. Finally, I move from\nunstructured data and focus on structured knowledge graphs. I present novel\napproaches for learning embeddings of vertices and edges in a knowledge graph\nthat obey logical constraints.\n",
        "published": "2019",
        "authors": [
            "Pushpendre Rastogi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2002.04108v3",
        "title": "Adversarial Filters of Dataset Biases",
        "abstract": "  Large neural models have demonstrated human-level performance on language and\nvision benchmarks, while their performance degrades considerably on adversarial\nor out-of-distribution samples. This raises the question of whether these\nmodels have learned to solve a dataset rather than the underlying task by\noverfitting to spurious dataset biases. We investigate one recently proposed\napproach, AFLite, which adversarially filters such dataset biases, as a means\nto mitigate the prevalent overestimation of machine performance. We provide a\ntheoretical understanding for AFLite, by situating it in the generalized\nframework for optimum bias reduction. We present extensive supporting evidence\nthat AFLite is broadly applicable for reduction of measurable dataset biases,\nand that models trained on the filtered datasets yield better generalization to\nout-of-distribution tasks. Finally, filtering results in a large drop in model\nperformance (e.g., from 92% to 62% for SNLI), while human performance still\nremains high. Our work thus shows that such filtered datasets can pose new\nresearch challenges for robust generalization by serving as upgraded\nbenchmarks.\n",
        "published": "2020",
        "authors": [
            "Ronan Le Bras",
            "Swabha Swayamdipta",
            "Chandra Bhagavatula",
            "Rowan Zellers",
            "Matthew E. Peters",
            "Ashish Sabharwal",
            "Yejin Choi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.12339v1",
        "title": "Incidental Supervision: Moving beyond Supervised Learning",
        "abstract": "  Machine Learning and Inference methods have become ubiquitous in our attempt\nto induce more abstract representations of natural language text, visual\nscenes, and other messy, naturally occurring data, and support decisions that\ndepend on it. However, learning models for these tasks is difficult partly\nbecause generating the necessary supervision signals for it is costly and does\nnot scale. This paper describes several learning paradigms that are designed to\nalleviate the supervision bottleneck. It will illustrate their benefit in the\ncontext of multiple problems, all pertaining to inducing various levels of\nsemantic representations from text.\n",
        "published": "2020",
        "authors": [
            "Dan Roth"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.07938v3",
        "title": "Type-augmented Relation Prediction in Knowledge Graphs",
        "abstract": "  Knowledge graphs (KGs) are of great importance to many real world\napplications, but they generally suffer from incomplete information in the form\nof missing relations between entities. Knowledge graph completion (also known\nas relation prediction) is the task of inferring missing facts given existing\nones. Most of the existing work is proposed by maximizing the likelihood of\nobserved instance-level triples. Not much attention, however, is paid to the\nontological information, such as type information of entities and relations. In\nthis work, we propose a type-augmented relation prediction (TaRP) method, where\nwe apply both the type information and instance-level information for relation\nprediction. In particular, type information and instance-level information are\nencoded as prior probabilities and likelihoods of relations respectively, and\nare combined by following Bayes' rule. Our proposed TaRP method achieves\nsignificantly better performance than state-of-the-art methods on four\nbenchmark datasets: FB15K, FB15K-237, YAGO26K-906, and DB111K-174. In addition,\nwe show that TaRP achieves significantly improved data efficiency. More\nimportantly, the type information extracted from a specific dataset can\ngeneralize well to other datasets through the proposed TaRP model.\n",
        "published": "2020",
        "authors": [
            "Zijun Cui",
            "Pavan Kapanipathi",
            "Kartik Talamadupula",
            "Tian Gao",
            "Qiang Ji"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2111.00035v1",
        "title": "Skyformer: Remodel Self-Attention with Gaussian Kernel and Nystr\u00f6m\n  Method",
        "abstract": "  Transformers are expensive to train due to the quadratic time and space\ncomplexity in the self-attention mechanism. On the other hand, although kernel\nmachines suffer from the same computation bottleneck in pairwise dot products,\nseveral approximation schemes have been successfully incorporated to\nconsiderably reduce their computational cost without sacrificing too much\naccuracy. In this work, we leverage the computation methods for kernel machines\nto alleviate the high computational cost and introduce Skyformer, which\nreplaces the softmax structure with a Gaussian kernel to stabilize the model\ntraining and adapts the Nystr\\\"om method to a non-positive semidefinite matrix\nto accelerate the computation. We further conduct theoretical analysis by\nshowing that the matrix approximation error of our proposed method is small in\nthe spectral norm. Experiments on Long Range Arena benchmark show that the\nproposed method is sufficient in getting comparable or even better performance\nthan the full self-attention while requiring fewer computation resources.\n",
        "published": "2021",
        "authors": [
            "Yifan Chen",
            "Qi Zeng",
            "Heng Ji",
            "Yun Yang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2207.01420v1",
        "title": "Comparing Feature Importance and Rule Extraction for Interpretability on\n  Text Data",
        "abstract": "  Complex machine learning algorithms are used more and more often in critical\ntasks involving text data, leading to the development of interpretability\nmethods. Among local methods, two families have emerged: those computing\nimportance scores for each feature and those extracting simple logical rules.\nIn this paper we show that using different methods can lead to unexpectedly\ndifferent explanations, even when applied to simple models for which we would\nexpect qualitative coincidence. To quantify this effect, we propose a new\napproach to compare explanations produced by different methods.\n",
        "published": "2022",
        "authors": [
            "Gianluigi Lopardo",
            "Damien Garreau"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2303.08806v1",
        "title": "Understanding Post-hoc Explainers: The Case of Anchors",
        "abstract": "  In many scenarios, the interpretability of machine learning models is a\nhighly required but difficult task. To explain the individual predictions of\nsuch models, local model-agnostic approaches have been proposed. However, the\nprocess generating the explanations can be, for a user, as mysterious as the\nprediction to be explained. Furthermore, interpretability methods frequently\nlack theoretical guarantees, and their behavior on simple models is frequently\nunknown. While it is difficult, if not impossible, to ensure that an explainer\nbehaves as expected on a cutting-edge model, we can at least ensure that\neverything works on simple, already interpretable models. In this paper, we\npresent a theoretical analysis of Anchors (Ribeiro et al., 2018): a popular\nrule-based interpretability method that highlights a small set of words to\nexplain a text classifier's decision. After formalizing its algorithm and\nproviding useful insights, we demonstrate mathematically that Anchors produces\nmeaningful results when used with linear text classifiers on top of a TF-IDF\nvectorization. We believe that our analysis framework can aid in the\ndevelopment of new explainability methods based on solid theoretical\nfoundations.\n",
        "published": "2023",
        "authors": [
            "Gianluigi Lopardo",
            "Frederic Precioso",
            "Damien Garreau"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.14196v3",
        "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding",
        "abstract": "  We introduce ZeroSCROLLS, a zero-shot benchmark for natural language\nunderstanding over long texts, which contains only test and small validation\nsets, without training data. We adapt six tasks from the SCROLLS benchmark, and\nadd four new datasets, including two novel information fusing tasks, such as\naggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a\ncomprehensive evaluation of both open-source and closed large language models,\nfinding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest\naverage score. However, there is still room for improvement on multiple open\nchallenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to\npass the naive baseline. As the state of the art is a moving target, we invite\nresearchers to evaluate their ideas on the live ZeroSCROLLS leaderboard.\n",
        "published": "2023",
        "authors": [
            "Uri Shaham",
            "Maor Ivgi",
            "Avia Efrat",
            "Jonathan Berant",
            "Omer Levy"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2306.09312v2",
        "title": "Semantic HELM: A Human-Readable Memory for Reinforcement Learning",
        "abstract": "  Reinforcement learning agents deployed in the real world often have to cope\nwith partially observable environments. Therefore, most agents employ memory\nmechanisms to approximate the state of the environment. Recently, there have\nbeen impressive success stories in mastering partially observable environments,\nmostly in the realm of computer games like Dota 2, StarCraft II, or MineCraft.\nHowever, existing methods lack interpretability in the sense that it is not\ncomprehensible for humans what the agent stores in its memory. In this regard,\nwe propose a novel memory mechanism that represents past events in human\nlanguage. Our method uses CLIP to associate visual inputs with language tokens.\nThen we feed these tokens to a pretrained language model that serves the agent\nas memory and provides it with a coherent and human-readable representation of\nthe past. We train our memory mechanism on a set of partially observable\nenvironments and find that it excels on tasks that require a memory component,\nwhile mostly attaining performance on-par with strong baselines on tasks that\ndo not. On a challenging continuous recognition task, where memorizing the past\nis crucial, our memory mechanism converges two orders of magnitude faster than\nprior methods. Since our memory mechanism is human-readable, we can peek at an\nagent's memory and check whether crucial pieces of information have been\nstored. This significantly enhances troubleshooting and paves the way toward\nmore interpretable agents.\n",
        "published": "2023",
        "authors": [
            "Fabian Paischer",
            "Thomas Adler",
            "Markus Hofmarcher",
            "Sepp Hochreiter"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2307.15343v2",
        "title": "Med-HALT: Medical Domain Hallucination Test for Large Language Models",
        "abstract": "  This research paper focuses on the challenges posed by hallucinations in\nlarge language models (LLMs), particularly in the context of the medical\ndomain. Hallucination, wherein these models generate plausible yet unverified\nor incorrect information, can have serious consequences in healthcare\napplications. We propose a new benchmark and dataset, Med-HALT (Medical Domain\nHallucination Test), designed specifically to evaluate and reduce\nhallucinations. Med-HALT provides a diverse multinational dataset derived from\nmedical examinations across various countries and includes multiple innovative\ntesting modalities. Med-HALT includes two categories of tests reasoning and\nmemory-based hallucination tests, designed to assess LLMs's problem-solving and\ninformation retrieval abilities.\n  Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2,\nMPT, and Falcon, revealing significant differences in their performance. The\npaper provides detailed insights into the dataset, promoting transparency and\nreproducibility. Through this work, we aim to contribute to the development of\nsafer and more reliable language models in healthcare. Our benchmark can be\nfound at medhalt.github.io\n",
        "published": "2023",
        "authors": [
            "Ankit Pal",
            "Logesh Kumar Umapathi",
            "Malaikannan Sankarasubbu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.03658v1",
        "title": "The Linear Representation Hypothesis and the Geometry of Large Language\n  Models",
        "abstract": "  Informally, the 'linear representation hypothesis' is the idea that\nhigh-level concepts are represented linearly as directions in some\nrepresentation space. In this paper, we address two closely related questions:\nWhat does \"linear representation\" actually mean? And, how do we make sense of\ngeometric notions (e.g., cosine similarity or projection) in the representation\nspace? To answer these, we use the language of counterfactuals to give two\nformalizations of \"linear representation\", one in the output (word)\nrepresentation space, and one in the input (sentence) space. We then prove\nthese connect to linear probing and model steering, respectively. To make sense\nof geometric notions, we use the formalization to identify a particular\n(non-Euclidean) inner product that respects language structure in a sense we\nmake precise. Using this causal inner product, we show how to unify all notions\nof linear representation. In particular, this allows the construction of probes\nand steering vectors using counterfactual pairs. Experiments with LLaMA-2\ndemonstrate the existence of linear representations of concepts, the connection\nto interpretation and control, and the fundamental role of the choice of inner\nproduct.\n",
        "published": "2023",
        "authors": [
            "Kiho Park",
            "Yo Joong Choe",
            "Victor Veitch"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.01335v1",
        "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language\n  Models",
        "abstract": "  Harnessing the power of human-annotated data through Supervised Fine-Tuning\n(SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we\ndelve into the prospect of growing a strong LLM out of a weak one without the\nneed for acquiring additional human-annotated data. We propose a new\nfine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a\nsupervised fine-tuned model. At the heart of SPIN lies a self-play mechanism,\nwhere the LLM refines its capability by playing against instances of itself.\nMore specifically, the LLM generates its own training data from its previous\niterations, refining its policy by discerning these self-generated responses\nfrom those obtained from human-annotated data. Our method progressively\nelevates the LLM from a nascent model to a formidable one, unlocking the full\npotential of human-annotated demonstration data for SFT. Theoretically, we\nprove that the global optimum to the training objective function of our method\nis achieved only when the LLM policy aligns with the target data distribution.\nEmpirically, we evaluate our method on several benchmark datasets including the\nHuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our\nresults show that SPIN can significantly improve the LLM's performance across a\nvariety of benchmarks and even outperform models trained through direct\npreference optimization (DPO) supplemented with extra GPT-4 preference data.\nThis sheds light on the promise of self-play, enabling the achievement of\nhuman-level performance in LLMs without the need for expert opponents.\n",
        "published": "2024",
        "authors": [
            "Zixiang Chen",
            "Yihe Deng",
            "Huizhuo Yuan",
            "Kaixuan Ji",
            "Quanquan Gu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1412.2812v1",
        "title": "Unsupervised Induction of Semantic Roles within a Reconstruction-Error\n  Minimization Framework",
        "abstract": "  We introduce a new approach to unsupervised estimation of feature-rich\nsemantic role labeling models. Our model consists of two components: (1) an\nencoding component: a semantic role labeling model which predicts roles given a\nrich set of syntactic and lexical features; (2) a reconstruction component: a\ntensor factorization model which relies on roles to predict argument fillers.\nWhen the components are estimated jointly to minimize errors in argument\nreconstruction, the induced roles largely correspond to roles defined in\nannotated resources. Our method performs on par with most accurate role\ninduction methods on English and German, even though, unlike these previous\napproaches, we do not incorporate any prior linguistic knowledge about the\nlanguages.\n",
        "published": "2014",
        "authors": [
            "Ivan Titov",
            "Ehsan Khoddam"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1501.04346v1",
        "title": "Mathematical Language Processing: Automatic Grading and Feedback for\n  Open Response Mathematical Questions",
        "abstract": "  While computer and communication technologies have provided effective means\nto scale up many aspects of education, the submission and grading of\nassessments such as homework assignments and tests remains a weak link. In this\npaper, we study the problem of automatically grading the kinds of open response\nmathematical questions that figure prominently in STEM (science, technology,\nengineering, and mathematics) courses. Our data-driven framework for\nmathematical language processing (MLP) leverages solution data from a large\nnumber of learners to evaluate the correctness of their solutions, assign\npartial-credit scores, and provide feedback to each learner on the likely\nlocations of any errors. MLP takes inspiration from the success of natural\nlanguage processing for text data and comprises three main steps. First, we\nconvert each solution to an open response mathematical question into a series\nof numerical features. Second, we cluster the features from several solutions\nto uncover the structures of correct, partially correct, and incorrect\nsolutions. We develop two different clustering approaches, one that leverages\ngeneric clustering algorithms and one based on Bayesian nonparametrics. Third,\nwe automatically grade the remaining (potentially large number of) solutions\nbased on their assigned cluster and one instructor-provided grade per cluster.\nAs a bonus, we can track the cluster assignment of each step of a multistep\nsolution and determine when it departs from a cluster of correct solutions,\nwhich enables us to indicate the likely locations of errors to learners. We\ntest and validate MLP on real-world MOOC data to demonstrate how it can\nsubstantially reduce the human effort required in large-scale educational\nplatforms.\n",
        "published": "2015",
        "authors": [
            "Andrew S. Lan",
            "Divyanshu Vats",
            "Andrew E. Waters",
            "Richard G. Baraniuk"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1506.06646v2",
        "title": "Nonparametric Bayesian Double Articulation Analyzer for Direct Language\n  Acquisition from Continuous Speech Signals",
        "abstract": "  Human infants can discover words directly from unsegmented speech signals\nwithout any explicitly labeled data. In this paper, we develop a novel machine\nlearning method called nonparametric Bayesian double articulation analyzer\n(NPB-DAA) that can directly acquire language and acoustic models from observed\ncontinuous speech signals. For this purpose, we propose an integrative\ngenerative model that combines a language model and an acoustic model into a\nsingle generative model called the \"hierarchical Dirichlet process hidden\nlanguage model\" (HDP-HLM). The HDP-HLM is obtained by extending the\nhierarchical Dirichlet process hidden semi-Markov model (HDP-HSMM) proposed by\nJohnson et al. An inference procedure for the HDP-HLM is derived using the\nblocked Gibbs sampler originally proposed for the HDP-HSMM. This procedure\nenables the simultaneous and direct inference of language and acoustic models\nfrom continuous speech signals. Based on the HDP-HLM and its inference\nprocedure, we developed a novel double articulation analyzer. By assuming\nHDP-HLM as a generative model of observed time series data, and by inferring\nlatent variables of the model, the method can analyze latent double\narticulation structure, i.e., hierarchically organized latent words and\nphonemes, of the data in an unsupervised manner. The novel unsupervised double\narticulation analyzer is called NPB-DAA.\n  The NPB-DAA can automatically estimate double articulation structure embedded\nin speech signals. We also carried out two evaluation experiments using\nsynthetic data and actual human continuous speech signals representing Japanese\nvowel sequences. In the word acquisition and phoneme categorization tasks, the\nNPB-DAA outperformed a conventional double articulation analyzer (DAA) and\nbaseline automatic speech recognition system whose acoustic model was trained\nin a supervised manner.\n",
        "published": "2015",
        "authors": [
            "Tadahiro Taniguchi",
            "Ryo Nakashima",
            "Shogo Nagasaka"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1603.06318v6",
        "title": "Harnessing Deep Neural Networks with Logic Rules",
        "abstract": "  Combining deep neural networks with structured logic rules is desirable to\nharness flexibility and reduce uninterpretability of the neural models. We\npropose a general framework capable of enhancing various types of neural\nnetworks (e.g., CNNs and RNNs) with declarative first-order logic rules.\nSpecifically, we develop an iterative distillation method that transfers the\nstructured information of logic rules into the weights of neural networks. We\ndeploy the framework on a CNN for sentiment analysis, and an RNN for named\nentity recognition. With a few highly intuitive rules, we obtain substantial\nimprovements and achieve state-of-the-art or comparable results to previous\nbest-performing systems.\n",
        "published": "2016",
        "authors": [
            "Zhiting Hu",
            "Xuezhe Ma",
            "Zhengzhong Liu",
            "Eduard Hovy",
            "Eric Xing"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1701.03577v1",
        "title": "Kernel Approximation Methods for Speech Recognition",
        "abstract": "  We study large-scale kernel methods for acoustic modeling in speech\nrecognition and compare their performance to deep neural networks (DNNs). We\nperform experiments on four speech recognition datasets, including the TIMIT\nand Broadcast News benchmark tasks, and compare these two types of models on\nframe-level performance metrics (accuracy, cross-entropy), as well as on\nrecognition metrics (word/character error rate). In order to scale kernel\nmethods to these large datasets, we use the random Fourier feature method of\nRahimi and Recht (2007). We propose two novel techniques for improving the\nperformance of kernel acoustic models. First, in order to reduce the number of\nrandom features required by kernel models, we propose a simple but effective\nmethod for feature selection. The method is able to explore a large number of\nnon-linear features while maintaining a compact model more efficiently than\nexisting approaches. Second, we present a number of frame-level metrics which\ncorrelate very strongly with recognition performance when computed on the\nheldout set; we take advantage of these correlations by monitoring these\nmetrics during training in order to decide when to stop learning. This\ntechnique can noticeably improve the recognition performance of both DNN and\nkernel models, while narrowing the gap between them. Additionally, we show that\nthe linear bottleneck method of Sainath et al. (2013) improves the performance\nof our kernel models significantly, in addition to speeding up training and\nmaking the models more compact. Together, these three methods dramatically\nimprove the performance of kernel acoustic models, making their performance\ncomparable to DNNs on the tasks we explored.\n",
        "published": "2017",
        "authors": [
            "Avner May",
            "Alireza Bagheri Garakani",
            "Zhiyun Lu",
            "Dong Guo",
            "Kuan Liu",
            "Aur\u00e9lien Bellet",
            "Linxi Fan",
            "Michael Collins",
            "Daniel Hsu",
            "Brian Kingsbury",
            "Michael Picheny",
            "Fei Sha"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1707.08616v2",
        "title": "Guiding Reinforcement Learning Exploration Using Natural Language",
        "abstract": "  In this work we present a technique to use natural language to help\nreinforcement learning generalize to unseen environments. This technique uses\nneural machine translation, specifically the use of encoder-decoder networks,\nto learn associations between natural language behavior descriptions and\nstate-action information. We then use this learned model to guide agent\nexploration using a modified version of policy shaping to make it more\neffective at learning in unseen environments. We evaluate this technique using\nthe popular arcade game, Frogger, under ideal and non-ideal conditions. This\nevaluation shows that our modified policy shaping algorithm improves over a\nQ-learning agent as well as a baseline version of policy shaping.\n",
        "published": "2017",
        "authors": [
            "Brent Harrison",
            "Upol Ehsan",
            "Mark O. Riedl"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.11383v1",
        "title": "Learning to Learn from Weak Supervision by Full Supervision",
        "abstract": "  In this paper, we propose a method for training neural networks when we have\na large set of data with weak labels and a small amount of data with true\nlabels. In our proposed model, we train two neural networks: a target network,\nthe learner and a confidence network, the meta-learner. The target network is\noptimized to perform a given task and is trained using a large set of unlabeled\ndata that are weakly annotated. We propose to control the magnitude of the\ngradient updates to the target network using the scores provided by the second\nconfidence network, which is trained on a small amount of supervised data. Thus\nwe avoid that the weight updates computed from noisy labels harm the quality of\nthe target network model.\n",
        "published": "2017",
        "authors": [
            "Mostafa Dehghani",
            "Aliaksei Severyn",
            "Sascha Rothe",
            "Jaap Kamps"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1801.06024v1",
        "title": "Natural Language Multitasking: Analyzing and Improving Syntactic\n  Saliency of Hidden Representations",
        "abstract": "  We train multi-task autoencoders on linguistic tasks and analyze the learned\nhidden sentence representations. The representations change significantly when\ntranslation and part-of-speech decoders are added. The more decoders a model\nemploys, the better it clusters sentences according to their syntactic\nsimilarity, as the representation space becomes less entangled. We explore the\nstructure of the representation space by interpolating between sentences, which\nyields interesting pseudo-English sentences, many of which have recognizable\nsyntactic structure. Lastly, we point out an interesting property of our\nmodels: The difference-vector between two sentences can be added to change a\nthird sentence with similar features in a meaningful way.\n",
        "published": "2018",
        "authors": [
            "Gino Brunner",
            "Yuyi Wang",
            "Roger Wattenhofer",
            "Michael Weigelt"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.03753v1",
        "title": "Sample Efficient Deep Reinforcement Learning for Dialogue Systems with\n  Large Action Spaces",
        "abstract": "  In spoken dialogue systems, we aim to deploy artificial intelligence to build\nautomated dialogue agents that can converse with humans. A part of this effort\nis the policy optimisation task, which attempts to find a policy describing how\nto respond to humans, in the form of a function taking the current state of the\ndialogue and returning the response of the system. In this paper, we\ninvestigate deep reinforcement learning approaches to solve this problem.\nParticular attention is given to actor-critic methods, off-policy reinforcement\nlearning with experience replay, and various methods aimed at reducing the bias\nand variance of estimators. When combined, these methods result in the\npreviously proposed ACER algorithm that gave competitive results in gaming\nenvironments. These environments however are fully observable and have a\nrelatively small action set so in this paper we examine the application of ACER\nto dialogue policy optimisation. We show that this method beats the current\nstate-of-the-art in deep learning approaches for spoken dialogue systems. This\nnot only leads to a more sample efficient algorithm that can train faster, but\nalso allows us to apply the algorithm in more difficult environments than\nbefore. We thus experiment with learning in a very large action space, which\nhas two orders of magnitude more actions than previously considered. We find\nthat ACER trains significantly faster than the current state-of-the-art.\n",
        "published": "2018",
        "authors": [
            "Gell\u00e9rt Weisz",
            "Pawe\u0142 Budzianowski",
            "Pei-Hao Su",
            "Milica Ga\u0161i\u0107"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1803.09578v1",
        "title": "Why Comparing Single Performance Scores Does Not Allow to Draw\n  Conclusions About Machine Learning Approaches",
        "abstract": "  Developing state-of-the-art approaches for specific tasks is a major driving\nforce in our research community. Depending on the prestige of the task,\npublishing it can come along with a lot of visibility. The question arises how\nreliable are our evaluation methodologies to compare approaches?\n  One common methodology to identify the state-of-the-art is to partition data\ninto a train, a development and a test set. Researchers can train and tune\ntheir approach on some part of the dataset and then select the model that\nworked best on the development set for a final evaluation on unseen test data.\nTest scores from different approaches are compared, and performance differences\nare tested for statistical significance.\n  In this publication, we show that there is a high risk that a statistical\nsignificance in this type of evaluation is not due to a superior learning\napproach. Instead, there is a high risk that the difference is due to chance.\nFor example for the CoNLL 2003 NER dataset we observed in up to 26% of the\ncases type I errors (false positives) with a threshold of p < 0.05, i.e.,\nfalsely concluding a statistically significant difference between two identical\napproaches.\n  We prove that this evaluation setup is unsuitable to compare learning\napproaches. We formalize alternative evaluation setups based on score\ndistributions.\n",
        "published": "2018",
        "authors": [
            "Nils Reimers",
            "Iryna Gurevych"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.02901v1",
        "title": "Probabilistic FastText for Multi-Sense Word Embeddings",
        "abstract": "  We introduce Probabilistic FastText, a new model for word embeddings that can\ncapture multiple word senses, sub-word structure, and uncertainty information.\nIn particular, we represent each word with a Gaussian mixture density, where\nthe mean of a mixture component is given by the sum of n-grams. This\nrepresentation allows the model to share statistical strength across sub-word\nstructures (e.g. Latin roots), producing accurate representations of rare,\nmisspelt, or even unseen words. Moreover, each component of the mixture can\ncapture a different word sense. Probabilistic FastText outperforms both\nFastText, which has no probabilistic model, and dictionary-level probabilistic\nembeddings, which do not incorporate subword structures, on several\nword-similarity benchmarks, including English RareWord and foreign language\ndatasets. We also achieve state-of-art performance on benchmarks that measure\nability to discern different meanings. Thus, the proposed model is the first to\nachieve multi-sense representations while having enriched semantics on rare\nwords.\n",
        "published": "2018",
        "authors": [
            "Ben Athiwaratkun",
            "Andrew Gordon Wilson",
            "Anima Anandkumar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.06950v1",
        "title": "GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model\n  Shrinking",
        "abstract": "  Model compression is essential for serving large deep neural nets on devices\nwith limited resources or applications that require real-time responses. As a\ncase study, a state-of-the-art neural language model usually consists of one or\nmore recurrent layers sandwiched between an embedding layer used for\nrepresenting input tokens and a softmax layer for generating output tokens. For\nproblems with a very large vocabulary size, the embedding and the softmax\nmatrices can account for more than half of the model size. For instance, the\nbigLSTM model achieves state-of- the-art performance on the One-Billion-Word\n(OBW) dataset with around 800k vocabulary, and its word embedding and softmax\nmatrices use more than 6GBytes space, and are responsible for over 90% of the\nmodel parameters. In this paper, we propose GroupReduce, a novel compression\nmethod for neural language models, based on vocabulary-partition (block) based\nlow-rank matrix approximation and the inherent frequency distribution of tokens\n(the power-law distribution of words). The experimental results show our method\ncan significantly outperform traditional compression methods such as low-rank\napproximation and pruning. On the OBW dataset, our method achieved 6.6 times\ncompression rate for the embedding and softmax matrices, and when combined with\nquantization, our method can achieve 26 times compression rate, which\ntranslates to a factor of 12.8 times compression for the entire model with very\nlittle degradation in perplexity.\n",
        "published": "2018",
        "authors": [
            "Patrick H. Chen",
            "Si Si",
            "Yang Li",
            "Ciprian Chelba",
            "Cho-jui Hsieh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.08730v1",
        "title": "The Natural Language Decathlon: Multitask Learning as Question Answering",
        "abstract": "  Deep learning has improved performance on many natural language processing\n(NLP) tasks individually. However, general NLP models cannot emerge within a\nparadigm that focuses on the particularities of a single metric, dataset, and\ntask. We introduce the Natural Language Decathlon (decaNLP), a challenge that\nspans ten tasks: question answering, machine translation, summarization,\nnatural language inference, sentiment analysis, semantic role labeling,\nzero-shot relation extraction, goal-oriented dialogue, semantic parsing, and\ncommonsense pronoun resolution. We cast all tasks as question answering over a\ncontext. Furthermore, we present a new Multitask Question Answering Network\n(MQAN) jointly learns all tasks in decaNLP without any task-specific modules or\nparameters in the multitask setting. MQAN shows improvements in transfer\nlearning for machine translation and named entity recognition, domain\nadaptation for sentiment analysis and natural language inference, and zero-shot\ncapabilities for text classification. We demonstrate that the MQAN's\nmulti-pointer-generator decoder is key to this success and performance further\nimproves with an anti-curriculum training strategy. Though designed for\ndecaNLP, MQAN also achieves state of the art results on the WikiSQL semantic\nparsing task in the single-task setting. We also release code for procuring and\nprocessing data, training and evaluating models, and reproducing all\nexperiments for decaNLP.\n",
        "published": "2018",
        "authors": [
            "Bryan McCann",
            "Nitish Shirish Keskar",
            "Caiming Xiong",
            "Richard Socher"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.00818v1",
        "title": "Improving part-of-speech tagging via multi-task learning and\n  character-level word representations",
        "abstract": "  In this paper, we explore the ways to improve POS-tagging using various types\nof auxiliary losses and different word representations. As a baseline, we\nutilized a BiLSTM tagger, which is able to achieve state-of-the-art results on\nthe sequence labelling tasks. We developed a new method for character-level\nword representation using feedforward neural network. Such representation gave\nus better results in terms of speed and performance of the model. We also\napplied a novel technique of pretraining such word representations with\nexisting word vectors. Finally, we designed a new variant of auxiliary loss for\nsequence labelling tasks: an additional prediction of the neighbour labels.\nSuch loss forces a model to learn the dependencies in-side a sequence of labels\nand accelerates the process of training. We test these methods on English and\nRussian languages.\n",
        "published": "2018",
        "authors": [
            "Daniil Anastasyev",
            "Ilya Gusev",
            "Eugene Indenbom"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.02322v5",
        "title": "Memory Augmented Policy Optimization for Program Synthesis and Semantic\n  Parsing",
        "abstract": "  We present Memory Augmented Policy Optimization (MAPO), a simple and novel\nway to leverage a memory buffer of promising trajectories to reduce the\nvariance of policy gradient estimate. MAPO is applicable to deterministic\nenvironments with discrete actions, such as structured prediction and\ncombinatorial optimization tasks. We express the expected return objective as a\nweighted sum of two terms: an expectation over the high-reward trajectories\ninside the memory buffer, and a separate expectation over trajectories outside\nthe buffer. To make an efficient algorithm of MAPO, we propose: (1) memory\nweight clipping to accelerate and stabilize training; (2) systematic\nexploration to discover high-reward trajectories; (3) distributed sampling from\ninside and outside of the memory buffer to scale up training. MAPO improves the\nsample efficiency and robustness of policy gradient, especially on tasks with\nsparse rewards. We evaluate MAPO on weakly supervised program synthesis from\nnatural language (semantic parsing). On the WikiTableQuestions benchmark, we\nimprove the state-of-the-art by 2.6%, achieving an accuracy of 46.3%. On the\nWikiSQL benchmark, MAPO achieves an accuracy of 74.9% with only weak\nsupervision, outperforming several strong baselines with full supervision. Our\nsource code is available at\nhttps://github.com/crazydonkey200/neural-symbolic-machines\n",
        "published": "2018",
        "authors": [
            "Chen Liang",
            "Mohammad Norouzi",
            "Jonathan Berant",
            "Quoc Le",
            "Ni Lao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.08447v1",
        "title": "LinkNBed: Multi-Graph Representation Learning with Entity Linkage",
        "abstract": "  Knowledge graphs have emerged as an important model for studying complex\nmulti-relational data. This has given rise to the construction of numerous\nlarge scale but incomplete knowledge graphs encoding information extracted from\nvarious resources. An effective and scalable approach to jointly learn over\nmultiple graphs and eventually construct a unified graph is a crucial next step\nfor the success of knowledge-based inference for many downstream applications.\nTo this end, we propose LinkNBed, a deep relational learning framework that\nlearns entity and relationship representations across multiple graphs. We\nidentify entity linkage across graphs as a vital component to achieve our goal.\nWe design a novel objective that leverage entity linkage and build an efficient\nmulti-task training procedure. Experiments on link prediction and entity\nlinkage demonstrate substantial improvements over the state-of-the-art\nrelational learning approaches.\n",
        "published": "2018",
        "authors": [
            "Rakshit Trivedi",
            "Bunyamin Sisman",
            "Jun Ma",
            "Christos Faloutsos",
            "Hongyuan Zha",
            "Xin Luna Dong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.01713v1",
        "title": "Word Mover's Embedding: From Word2Vec to Document Embedding",
        "abstract": "  While the celebrated Word2Vec technique yields semantically rich\nrepresentations for individual words, there has been relatively less success in\nextending to generate unsupervised sentences or documents embeddings. Recent\nwork has demonstrated that a distance measure between documents called\n\\emph{Word Mover's Distance} (WMD) that aligns semantically similar words,\nyields unprecedented KNN classification accuracy. However, WMD is expensive to\ncompute, and it is hard to extend its use beyond a KNN classifier. In this\npaper, we propose the \\emph{Word Mover's Embedding } (WME), a novel approach to\nbuilding an unsupervised document (sentence) embedding from pre-trained word\nembeddings. In our experiments on 9 benchmark text classification datasets and\n22 textual similarity tasks, the proposed technique consistently matches or\noutperforms state-of-the-art techniques, with significantly higher accuracy on\nproblems of short length.\n",
        "published": "2018",
        "authors": [
            "Lingfei Wu",
            "Ian E. H. Yen",
            "Kun Xu",
            "Fangli Xu",
            "Avinash Balakrishnan",
            "Pin-Yu Chen",
            "Pradeep Ravikumar",
            "Michael J. Witbrock"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.01778v2",
        "title": "How Reasonable are Common-Sense Reasoning Tasks: A Case-Study on the\n  Winograd Schema Challenge and SWAG",
        "abstract": "  Recent studies have significantly improved the state-of-the-art on\ncommon-sense reasoning (CSR) benchmarks like the Winograd Schema Challenge\n(WSC) and SWAG. The question we ask in this paper is whether improved\nperformance on these benchmarks represents genuine progress towards\ncommon-sense-enabled systems. We make case studies of both benchmarks and\ndesign protocols that clarify and qualify the results of previous work by\nanalyzing threats to the validity of previous experimental designs. Our\nprotocols account for several properties prevalent in common-sense benchmarks\nincluding size limitations, structural regularities, and variable instance\ndifficulty.\n",
        "published": "2018",
        "authors": [
            "Paul Trichelair",
            "Ali Emami",
            "Adam Trischler",
            "Kaheer Suleman",
            "Jackie Chi Kit Cheung"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.05370v1",
        "title": "Unsupervised Transfer Learning for Spoken Language Understanding in\n  Intelligent Agents",
        "abstract": "  User interaction with voice-powered agents generates large amounts of\nunlabeled utterances. In this paper, we explore techniques to efficiently\ntransfer the knowledge from these unlabeled utterances to improve model\nperformance on Spoken Language Understanding (SLU) tasks. We use Embeddings\nfrom Language Model (ELMo) to take advantage of unlabeled data by learning\ncontextualized word representations. Additionally, we propose ELMo-Light\n(ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our\nfindings suggest unsupervised pre-training on a large corpora of unlabeled\nutterances leads to significantly better SLU performance compared to training\nfrom scratch and it can even outperform conventional supervised transfer.\nAdditionally, we show that the gains from unsupervised transfer techniques can\nbe further improved by supervised transfer. The improvements are more\npronounced in low resource settings and when using only 1000 labeled in-domain\nsamples, our techniques match the performance of training from scratch on\n10-15x more labeled in-domain data.\n",
        "published": "2018",
        "authors": [
            "Aditya Siddhant",
            "Anuj Goyal",
            "Angeliki Metallinou"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.09740v2",
        "title": "Connecting the Dots Between MLE and RL for Sequence Prediction",
        "abstract": "  Sequence prediction models can be learned from example sequences with a\nvariety of training algorithms. Maximum likelihood learning is simple and\nefficient, yet can suffer from compounding error at test time. Reinforcement\nlearning such as policy gradient addresses the issue but can have prohibitively\npoor exploration efficiency. A rich set of other algorithms such as RAML, SPG,\nand data noising, have also been developed from different perspectives. This\npaper establishes a formal connection between these algorithms. We present a\ngeneralized entropy regularized policy optimization formulation, and show that\nthe apparently distinct algorithms can all be reformulated as special instances\nof the framework, with the only difference being the configurations of a reward\nfunction and a couple of hyperparameters. The unified interpretation offers a\nsystematic view of the varying properties of exploration and learning\nefficiency. Besides, inspired from the framework, we present a new algorithm\nthat dynamically interpolates among the family of algorithms for scheduled\nsequence model learning. Experiments on machine translation, text\nsummarization, and game imitation learning demonstrate the superiority of the\nproposed algorithm.\n",
        "published": "2018",
        "authors": [
            "Bowen Tan",
            "Zhiting Hu",
            "Zichao Yang",
            "Ruslan Salakhutdinov",
            "Eric Xing"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.10990v1",
        "title": "Generating Responses Expressing Emotion in an Open-domain Dialogue\n  System",
        "abstract": "  Neural network-based Open-ended conversational agents automatically generate\nresponses based on predictive models learned from a large number of pairs of\nutterances. The generated responses are typically acceptable as a sentence but\nare often dull, generic, and certainly devoid of any emotion. In this paper, we\npresent neural models that learn to express a given emotion in the generated\nresponse. We propose four models and evaluate them against 3 baselines. An\nencoder-decoder framework-based model with multiple attention layers provides\nthe best overall performance in terms of expressing the required emotion. While\nit does not outperform other models on all emotions, it presents promising\nresults in most cases.\n",
        "published": "2018",
        "authors": [
            "Chenyang Huang",
            "Osmar R. Za\u00efane"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.12640v2",
        "title": "Inferring Concept Prerequisite Relations from Online Educational\n  Resources",
        "abstract": "  The Internet has rich and rapidly increasing sources of high quality\neducational content. Inferring prerequisite relations between educational\nconcepts is required for modern large-scale online educational technology\napplications such as personalized recommendations and automatic curriculum\ncreation. We present PREREQ, a new supervised learning method for inferring\nconcept prerequisite relations. PREREQ is designed using latent representations\nof concepts obtained from the Pairwise Latent Dirichlet Allocation model, and a\nneural network based on the Siamese network architecture. PREREQ can learn\nunknown concept prerequisites from course prerequisites and labeled concept\nprerequisite data. It outperforms state-of-the-art approaches on benchmark\ndatasets and can effectively learn from very less training data. PREREQ can\nalso use unlabeled video playlists, a steadily growing source of training data,\nto learn concept prerequisites, thus obviating the need for manual annotation\nof course prerequisites.\n",
        "published": "2018",
        "authors": [
            "Sudeshna Roy",
            "Meghana Madhyastha",
            "Sheril Lawrence",
            "Vaibhav Rajan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1901.00158v2",
        "title": "Text Infilling",
        "abstract": "  Recent years have seen remarkable progress of text generation in different\ncontexts, such as the most common setting of generating text from scratch, and\nthe emerging paradigm of retrieval-and-rewriting. Text infilling, which fills\nmissing text portions of a sentence or paragraph, is also of numerous use in\nreal life, yet is under-explored. Previous work has focused on restricted\nsettings by either assuming single word per missing portion or limiting to a\nsingle missing portion to the end of the text. This paper studies the general\ntask of text infilling, where the input text can have an arbitrary number of\nportions to be filled, each of which may require an arbitrary unknown number of\ntokens. We study various approaches for the task, including a self-attention\nmodel with segment-aware position encoding and bidirectional context modeling.\nWe create extensive supervised data by masking out text with varying\nstrategies. Experiments show the self-attention model greatly outperforms\nothers, creating a strong baseline for future research.\n",
        "published": "2019",
        "authors": [
            "Wanrong Zhu",
            "Zhiting Hu",
            "Eric Xing"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.02113v1",
        "title": "Latent Space Cartography: Generalised Metric-Inspired Measures and\n  Measure-Based Transformations for Generative Models",
        "abstract": "  Deep generative models are universal tools for learning data distributions on\nhigh dimensional data spaces via a mapping to lower dimensional latent spaces.\nWe provide a study of latent space geometries and extend and build upon\nprevious results on Riemannian metrics. We show how a class of heuristic\nmeasures gives more flexibility in finding meaningful, problem-specific\ndistances, and how it can be applied to diverse generator types such as\nautoregressive generators commonly used in e.g. language and other sequence\nmodeling. We further demonstrate how a diffusion-inspired transformation\npreviously studied in cartography can be used to smooth out latent spaces,\nstretching them according to a chosen measure. In addition to providing more\nmeaningful distances directly in latent space, this also provides a unique tool\nfor novel kinds of data visualizations. We believe that the proposed methods\ncan be a valuable tool for studying the structure of latent spaces and learned\ndata distributions of generative models.\n",
        "published": "2019",
        "authors": [
            "Max F. Frenzel",
            "Bogdan Teleaga",
            "Asahi Ushio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.02169v1",
        "title": "Learning Taxonomies of Concepts and not Words using Contextualized Word\n  Representations: A Position Paper",
        "abstract": "  Taxonomies are semantic hierarchies of concepts. One limitation of current\ntaxonomy learning systems is that they define concepts as single words. This\nposition paper argues that contextualized word representations, which recently\nachieved state-of-the-art results on many competitive NLP tasks, are a\npromising method to address this limitation. We outline a novel approach for\ntaxonomy learning that (1) defines concepts as synsets, (2) learns\ndensity-based approximations of contextualized word representations, and (3)\ncan measure similarity and hypernymy among them.\n",
        "published": "2019",
        "authors": [
            "Lukas Schmelzeisen",
            "Steffen Staab"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.04187v1",
        "title": "LS-Tree: Model Interpretation When the Data Are Linguistic",
        "abstract": "  We study the problem of interpreting trained classification models in the\nsetting of linguistic data sets. Leveraging a parse tree, we propose to assign\nleast-squares based importance scores to each word of an instance by exploiting\nsyntactic constituency structure. We establish an axiomatic characterization of\nthese importance scores by relating them to the Banzhaf value in coalitional\ngame theory. Based on these importance scores, we develop a principled method\nfor detecting and quantifying interactions between words in a sentence. We\ndemonstrate that the proposed method can aid in interpretability and\ndiagnostics for several widely-used language models.\n",
        "published": "2019",
        "authors": [
            "Jianbo Chen",
            "Michael I. Jordan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.07198v4",
        "title": "Learning to Generalize from Sparse and Underspecified Rewards",
        "abstract": "  We consider the problem of learning from sparse and underspecified rewards,\nwhere an agent receives a complex input, such as a natural language\ninstruction, and needs to generate a complex response, such as an action\nsequence, while only receiving binary success-failure feedback. Such\nsuccess-failure rewards are often underspecified: they do not distinguish\nbetween purposeful and accidental success. Generalization from underspecified\nrewards hinges on discounting spurious trajectories that attain accidental\nsuccess, while learning from sparse feedback requires effective exploration. We\naddress exploration by using a mode covering direction of KL divergence to\ncollect a diverse set of successful trajectories, followed by a mode seeking KL\ndivergence to train a robust policy. We propose Meta Reward Learning (MeRL) to\nconstruct an auxiliary reward function that provides more refined feedback for\nlearning. The parameters of the auxiliary reward function are optimized with\nrespect to the validation performance of a trained policy. The MeRL approach\noutperforms our alternative reward learning technique based on Bayesian\nOptimization, and achieves the state-of-the-art on weakly-supervised semantic\nparsing. It improves previous work by 1.2% and 2.4% on WikiTableQuestions and\nWikiSQL datasets respectively.\n",
        "published": "2019",
        "authors": [
            "Rishabh Agarwal",
            "Chen Liang",
            "Dale Schuurmans",
            "Mohammad Norouzi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.10126v2",
        "title": "BUT-FIT at SemEval-2019 Task 7: Determining the Rumour Stance with\n  Pre-Trained Deep Bidirectional Transformers",
        "abstract": "  This paper describes our system submitted to SemEval 2019 Task 7: RumourEval\n2019: Determining Rumour Veracity and Support for Rumours, Subtask A (Gorrell\net al., 2019). The challenge focused on classifying whether posts from Twitter\nand Reddit support, deny, query, or comment a hidden rumour, truthfulness of\nwhich is the topic of an underlying discussion thread. We formulate the problem\nas a stance classification, determining the rumour stance of a post with\nrespect to the previous thread post and the source thread post. The recent BERT\narchitecture was employed to build an end-to-end system which has reached the\nF1 score of 61.67% on the provided test data. It finished at the 2nd place in\nthe competition, without any hand-crafted features, only 0.2% behind the\nwinner.\n",
        "published": "2019",
        "authors": [
            "Martin Fajcik",
            "Luk\u00e1\u0161 Burget",
            "Pavel Smrz"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.03329v2",
        "title": "MedDialog: Two Large-scale Medical Dialogue Datasets",
        "abstract": "  Medical dialogue systems are promising in assisting in telemedicine to\nincrease access to healthcare services, improve the quality of patient care,\nand reduce medical costs. To facilitate the research and development of medical\ndialogue systems, we build two large-scale medical dialogue datasets:\nMedDialog-EN and MedDialog-CN. MedDialog-EN is an English dataset containing\n0.3 million conversations between patients and doctors and 0.5 million\nutterances. MedDialog-CN is an Chinese dataset containing 1.1 million\nconversations and 4 million utterances. To our best knowledge,\nMedDialog-(EN,CN) are the largest medical dialogue datasets to date. The\ndataset is available at https://github.com/UCSD-AI4H/Medical-Dialogue-System\n",
        "published": "2020",
        "authors": [
            "Xuehai He",
            "Shu Chen",
            "Zeqian Ju",
            "Xiangyu Dong",
            "Hongchao Fang",
            "Sicheng Wang",
            "Yue Yang",
            "Jiaqi Zeng",
            "Ruisi Zhang",
            "Ruoyu Zhang",
            "Meng Zhou",
            "Penghui Zhu",
            "Pengtao Xie"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.07790v5",
        "title": "Avoiding the Hypothesis-Only Bias in Natural Language Inference via\n  Ensemble Adversarial Training",
        "abstract": "  Natural Language Inference (NLI) datasets contain annotation artefacts\nresulting in spurious correlations between the natural language utterances and\ntheir respective entailment classes. These artefacts are exploited by neural\nnetworks even when only considering the hypothesis and ignoring the premise,\nleading to unwanted biases. Belinkov et al. (2019b) proposed tackling this\nproblem via adversarial training, but this can lead to learned sentence\nrepresentations that still suffer from the same biases. We show that the bias\ncan be reduced in the sentence representations by using an ensemble of\nadversaries, encouraging the model to jointly decrease the accuracy of these\ndifferent adversaries while fitting the data. This approach produces more\nrobust NLI models, outperforming previous de-biasing efforts when generalised\nto 12 other datasets (Belinkov et al., 2019a; Mahabadi et al., 2020). In\naddition, we find that the optimal number of adversarial classifiers depends on\nthe dimensionality of the sentence representations, with larger sentence\nrepresentations being more difficult to de-bias while benefiting from using a\ngreater number of adversaries.\n",
        "published": "2020",
        "authors": [
            "Joe Stacey",
            "Pasquale Minervini",
            "Haim Dubossarsky",
            "Sebastian Riedel",
            "Tim Rockt\u00e4schel"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.05336v1",
        "title": "Adaptive Margin Ranking Loss for Knowledge Graph Embeddings via a\n  Correntropy Objective Function",
        "abstract": "  Translation-based embedding models have gained significant attention in link\nprediction tasks for knowledge graphs. TransE is the primary model among\ntranslation-based embeddings and is well-known for its low complexity and high\nefficiency. Therefore, most of the earlier works have modified the score\nfunction of the TransE approach in order to improve the performance of link\nprediction tasks. Nevertheless, proven theoretically and experimentally, the\nperformance of TransE strongly depends on the loss function. Margin Ranking\nLoss (MRL) has been one of the earlier loss functions which is widely used for\ntraining TransE. However, the scores of positive triples are not necessarily\nenforced to be sufficiently small to fulfill the translation from head to tail\nby using relation vector (original assumption of TransE). To tackle this\nproblem, several loss functions have been proposed recently by adding upper\nbounds and lower bounds to the scores of positive and negative samples.\nAlthough highly effective, previously developed models suffer from an expansion\nin search space for a selection of the hyperparameters (in particular the upper\nand lower bounds of scores) on which the performance of the translation-based\nmodels is highly dependent. In this paper, we propose a new loss function\ndubbed Adaptive Margin Loss (AML) for training translation-based embedding\nmodels. The formulation of the proposed loss function enables an adaptive and\nautomated adjustment of the margin during the learning process. Therefore,\ninstead of obtaining two values (upper bound and lower bound), only the center\nof a margin needs to be determined. During learning, the margin is expanded\nautomatically until it converges. In our experiments on a set of standard\nbenchmark datasets including Freebase and WordNet, the effectiveness of AML is\nconfirmed for training TransE on link prediction tasks.\n",
        "published": "2019",
        "authors": [
            "Mojtaba Nayyeri",
            "Xiaotian Zhou",
            "Sahar Vahdati",
            "Hamed Shariat Yazdi",
            "Jens Lehmann"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1907.08937v1",
        "title": "Quantifying Similarity between Relations with Fact Distribution",
        "abstract": "  We introduce a conceptually simple and effective method to quantify the\nsimilarity between relations in knowledge bases. Specifically, our approach is\nbased on the divergence between the conditional probability distributions over\nentity pairs. In this paper, these distributions are parameterized by a very\nsimple neural network. Although computing the exact similarity is in-tractable,\nwe provide a sampling-based method to get a good approximation. We empirically\nshow the outputs of our approach significantly correlate with human judgments.\nBy applying our method to various tasks, we also find that (1) our approach\ncould effectively detect redundant relations extracted by open information\nextraction (Open IE) models, that (2) even the most competitive models for\nrelational classification still make mistakes among very similar relations, and\nthat (3) our approach could be incorporated into negative sampling and softmax\nclassification to alleviate these mistakes. The source code and experiment\ndetails of this paper can be obtained from\nhttps://github.com/thunlp/relation-similarity.\n",
        "published": "2019",
        "authors": [
            "Weize Chen",
            "Hao Zhu",
            "Xu Han",
            "Zhiyuan Liu",
            "Maosong Sun"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1908.01843v1",
        "title": "GEAR: Graph-based Evidence Aggregating and Reasoning for Fact\n  Verification",
        "abstract": "  Fact verification (FV) is a challenging task which requires to retrieve\nrelevant evidence from plain text and use the evidence to verify given claims.\nMany claims require to simultaneously integrate and reason over several pieces\nof evidence for verification. However, previous work employs simple models to\nextract information from evidence without letting evidence communicate with\neach other, e.g., merely concatenate the evidence for processing. Therefore,\nthese methods are unable to grasp sufficient relational and logical information\namong the evidence. To alleviate this issue, we propose a graph-based evidence\naggregating and reasoning (GEAR) framework which enables information to\ntransfer on a fully-connected evidence graph and then utilizes different\naggregators to collect multi-evidence information. We further employ BERT, an\neffective pre-trained language representation model, to improve the\nperformance. Experimental results on a large-scale benchmark dataset FEVER have\ndemonstrated that GEAR could leverage multi-evidence information for FV and\nthus achieves the promising result with a test FEVER score of 67.10%. Our code\nis available at https://github.com/thunlp/GEAR.\n",
        "published": "2019",
        "authors": [
            "Jie Zhou",
            "Xu Han",
            "Cheng Yang",
            "Zhiyuan Liu",
            "Lifeng Wang",
            "Changcheng Li",
            "Maosong Sun"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1908.06008v1",
        "title": "Variational Fusion for Multimodal Sentiment Analysis",
        "abstract": "  Multimodal fusion is considered a key step in multimodal tasks such as\nsentiment analysis, emotion detection, question answering, and others. Most of\nthe recent work on multimodal fusion does not guarantee the fidelity of the\nmultimodal representation with respect to the unimodal representations. In this\npaper, we propose a variational autoencoder-based approach for modality fusion\nthat minimizes information loss between unimodal and multimodal\nrepresentations. We empirically show that this method outperforms the\nstate-of-the-art methods by a significant margin on several popular datasets.\n",
        "published": "2019",
        "authors": [
            "Navonil Majumder",
            "Soujanya Poria",
            "Gangeshwar Krishnamurthy",
            "Niyati Chhaya",
            "Rada Mihalcea",
            "Alexander Gelbukh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1908.07064v1",
        "title": "Domain-Independent turn-level Dialogue Quality Evaluation via User\n  Satisfaction Estimation",
        "abstract": "  An automated metric to evaluate dialogue quality is vital for optimizing data\ndriven dialogue management. The common approach of relying on explicit user\nfeedback during a conversation is intrusive and sparse. Current models to\nestimate user satisfaction use limited feature sets and rely on annotation\nschemes with low inter-rater reliability, limiting generalizability to\nconversations spanning multiple domains. To address these gaps, we created a\nnew Response Quality annotation scheme, based on which we developed turn-level\nUser Satisfaction metric. We introduced five new domain-independent feature\nsets and experimented with six machine learning models to estimate the new\nsatisfaction metric.\n  Using Response Quality annotation scheme, across randomly sampled single and\nmulti-turn conversations from 26 domains, we achieved high inter-annotator\nagreement (Spearman's rho 0.94). The Response Quality labels were highly\ncorrelated (0.76) with explicit turn-level user ratings. Gradient boosting\nregression achieved best correlation of ~0.79 between predicted and annotated\nuser satisfaction labels. Multi Layer Perceptron and Gradient Boosting\nregression models generalized to an unseen domain better (linear correlation\n0.67) than other models. Finally, our ablation study verified that our novel\nfeatures significantly improved model performance.\n",
        "published": "2019",
        "authors": [
            "Praveen Kumar Bodigutla",
            "Longshaokan Wang",
            "Kate Ridgeway",
            "Joshua Levy",
            "Swanand Joshi",
            "Alborz Geramifard",
            "Spyros Matsoukas"
        ]
    }
]