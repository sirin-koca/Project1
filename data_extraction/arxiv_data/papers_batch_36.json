[
    {
        "id": "http://arxiv.org/abs/2107.01988v1",
        "title": "UCSL : A Machine Learning Expectation-Maximization framework for\n  Unsupervised Clustering driven by Supervised Learning",
        "abstract": "  Subtype Discovery consists in finding interpretable and consistent sub-parts\nof a dataset, which are also relevant to a certain supervised task. From a\nmathematical point of view, this can be defined as a clustering task driven by\nsupervised learning in order to uncover subgroups in line with the supervised\nprediction. In this paper, we propose a general Expectation-Maximization\nensemble framework entitled UCSL (Unsupervised Clustering driven by Supervised\nLearning). Our method is generic, it can integrate any clustering method and\ncan be driven by both binary classification and regression. We propose to\nconstruct a non-linear model by merging multiple linear estimators, one per\ncluster. Each hyperplane is estimated so that it correctly discriminates - or\npredict - only one cluster. We use SVC or Logistic Regression for\nclassification and SVR for regression. Furthermore, to perform cluster analysis\nwithin a more suitable space, we also propose a dimension-reduction algorithm\nthat projects the data onto an orthonormal space relevant to the supervised\ntask. We analyze the robustness and generalization capability of our algorithm\nusing synthetic and experimental datasets. In particular, we validate its\nability to identify suitable consistent sub-types by conducting a\npsychiatric-diseases cluster analysis with known ground-truth labels. The gain\nof the proposed method over previous state-of-the-art techniques is about +1.9\npoints in terms of balanced accuracy. Finally, we make codes and examples\navailable in a scikit-learn-compatible Python package at\nhttps://github.com/neurospin-projects/2021_rlouiset_ucsl\n",
        "published": "2021",
        "authors": [
            "Robin Louiset",
            "Pietro Gori",
            "Benoit Dufumier",
            "Josselin Houenou",
            "Antoine Grigis",
            "Edouard Duchesnay"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2107.05446v3",
        "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature\n  Restoration",
        "abstract": "  Source-free domain adaptation (SFDA) aims to adapt a model trained on\nlabelled data in a source domain to unlabelled data in a target domain without\naccess to the source-domain data during adaptation. Existing methods for SFDA\nleverage entropy-minimization techniques which: (i) apply only to\nclassification; (ii) destroy model calibration; and (iii) rely on the source\nmodel achieving a good level of feature-space class-separation in the target\ndomain. We address these issues for a particularly pervasive type of domain\nshift called measurement shift which can be resolved by restoring the source\nfeatures rather than extracting new ones. In particular, we propose Feature\nRestoration (FR) wherein we: (i) store a lightweight and flexible approximation\nof the feature distribution under the source data; and (ii) adapt the\nfeature-extractor such that the approximate feature distribution under the\ntarget data realigns with that saved on the source. We additionally propose a\nbottom-up training scheme which boosts performance, which we call Bottom-Up\nFeature Restoration (BUFR). On real and synthetic data, we demonstrate that\nBUFR outperforms existing SFDA methods in terms of accuracy, calibration, and\ndata efficiency, while being less reliant on the performance of the source\nmodel in the target domain.\n",
        "published": "2021",
        "authors": [
            "Cian Eastwood",
            "Ian Mason",
            "Christopher K. I. Williams",
            "Bernhard Sch\u00f6lkopf"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.08835v2",
        "title": "General Cyclical Training of Neural Networks",
        "abstract": "  This paper describes the principle of \"General Cyclical Training\" in machine\nlearning, where training starts and ends with \"easy training\" and the \"hard\ntraining\" happens during the middle epochs. We propose several manifestations\nfor training neural networks, including algorithmic examples (via\nhyper-parameters and loss functions), data-based examples, and model-based\nexamples. Specifically, we introduce several novel techniques: cyclical weight\ndecay, cyclical batch size, cyclical focal loss, cyclical softmax temperature,\ncyclical data augmentation, cyclical gradient clipping, and cyclical\nsemi-supervised learning. In addition, we demonstrate that cyclical weight\ndecay, cyclical softmax temperature, and cyclical gradient clipping (as three\nexamples of this principle) are beneficial in the test accuracy performance of\na trained model. Furthermore, we discuss model-based examples (such as\npretraining and knowledge distillation) from the perspective of general\ncyclical training and recommend some changes to the typical training\nmethodology. In summary, this paper defines the general cyclical training\nconcept and discusses several specific ways in which this concept can be\napplied to training neural networks. In the spirit of reproducibility, the code\nused in our experiments is available at \\url{https://github.com/lnsmith54/CFL}.\n",
        "published": "2022",
        "authors": [
            "Leslie N. Smith"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.09931v2",
        "title": "Deconstructing Distributions: A Pointwise Framework of Learning",
        "abstract": "  In machine learning, we traditionally evaluate the performance of a single\nmodel, averaged over a collection of test inputs. In this work, we propose a\nnew approach: we measure the performance of a collection of models when\nevaluated on a $\\textit{single input point}$. Specifically, we study a point's\n$\\textit{profile}$: the relationship between models' average performance on the\ntest distribution and their pointwise performance on this individual point. We\nfind that profiles can yield new insights into the structure of both models and\ndata -- in and out-of-distribution. For example, we empirically show that real\ndata distributions consist of points with qualitatively different profiles. On\none hand, there are \"compatible\" points with strong correlation between the\npointwise and average performance. On the other hand, there are points with\nweak and even $\\textit{negative}$ correlation: cases where improving overall\nmodel accuracy actually $\\textit{hurts}$ performance on these inputs. We prove\nthat these experimental observations are inconsistent with the predictions of\nseveral simplified models of learning proposed in prior work. As an\napplication, we use profiles to construct a dataset we call CIFAR-10-NEG: a\nsubset of CINIC-10 such that for standard models, accuracy on CIFAR-10-NEG is\n$\\textit{negatively correlated}$ with accuracy on CIFAR-10 test. This\nillustrates, for the first time, an OOD dataset that completely inverts\n\"accuracy-on-the-line\" (Miller, Taori, Raghunathan, Sagawa, Koh, Shankar,\nLiang, Carmon, and Schmidt 2021)\n",
        "published": "2022",
        "authors": [
            "Gal Kaplun",
            "Nikhil Ghosh",
            "Saurabh Garg",
            "Boaz Barak",
            "Preetum Nakkiran"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.14026v2",
        "title": "Robust Training under Label Noise by Over-parameterization",
        "abstract": "  Recently, over-parameterized deep networks, with increasingly more network\nparameters than training samples, have dominated the performances of modern\nmachine learning. However, when the training data is corrupted, it has been\nwell-known that over-parameterized networks tend to overfit and do not\ngeneralize. In this work, we propose a principled approach for robust training\nof over-parameterized deep networks in classification tasks where a proportion\nof training labels are corrupted. The main idea is yet very simple: label noise\nis sparse and incoherent with the network learned from clean data, so we model\nthe noise and learn to separate it from the data. Specifically, we model the\nlabel noise via another sparse over-parameterization term, and exploit implicit\nalgorithmic regularizations to recover and separate the underlying corruptions.\nRemarkably, when trained using such a simple method in practice, we demonstrate\nstate-of-the-art test accuracy against label noise on a variety of real\ndatasets. Furthermore, our experimental results are corroborated by theory on\nsimplified linear models, showing that exact separation between sparse noise\nand low-rank data can be achieved under incoherent conditions. The work opens\nmany interesting directions for improving over-parameterized models by using\nsparse over-parameterization and implicit regularization.\n",
        "published": "2022",
        "authors": [
            "Sheng Liu",
            "Zhihui Zhu",
            "Qing Qu",
            "Chong You"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1607.03516v2",
        "title": "Deep Reconstruction-Classification Networks for Unsupervised Domain\n  Adaptation",
        "abstract": "  In this paper, we propose a novel unsupervised domain adaptation algorithm\nbased on deep learning for visual object recognition. Specifically, we design a\nnew model called Deep Reconstruction-Classification Network (DRCN), which\njointly learns a shared encoding representation for two tasks: i) supervised\nclassification of labeled source data, and ii) unsupervised reconstruction of\nunlabeled target data.In this way, the learnt representation not only preserves\ndiscriminability, but also encodes useful information from the target domain.\nOur new DRCN model can be optimized by using backpropagation similarly as the\nstandard neural networks.\n  We evaluate the performance of DRCN on a series of cross-domain object\nrecognition tasks, where DRCN provides a considerable improvement (up to ~8% in\naccuracy) over the prior state-of-the-art algorithms. Interestingly, we also\nobserve that the reconstruction pipeline of DRCN transforms images from the\nsource domain into images whose appearance resembles the target dataset. This\nsuggests that DRCN's performance is due to constructing a single composite\nrepresentation that encodes information about both the structure of target\nimages and the classification of source images. Finally, we provide a formal\nanalysis to justify the algorithm's objective in domain adaptation context.\n",
        "published": "2016",
        "authors": [
            "Muhammad Ghifary",
            "W. Bastiaan Kleijn",
            "Mengjie Zhang",
            "David Balduzzi",
            "Wen Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.03761v3",
        "title": "Detecting Unseen Falls from Wearable Devices using Channel-wise Ensemble\n  of Autoencoders",
        "abstract": "  A fall is an abnormal activity that occurs rarely, so it is hard to collect\nreal data for falls. It is, therefore, difficult to use supervised learning\nmethods to automatically detect falls. Another challenge in using machine\nlearning methods to automatically detect falls is the choice of engineered\nfeatures. In this paper, we propose to use an ensemble of autoencoders to\nextract features from different channels of wearable sensor data trained only\non normal activities. We show that the traditional approach of choosing a\nthreshold as the maximum of the reconstruction error on the training normal\ndata is not the right way to identify unseen falls. We propose two methods for\nautomatic tightening of reconstruction error from only the normal activities\nfor better identification of unseen falls. We present our results on two\nactivity recognition datasets and show the efficacy of our proposed method\nagainst traditional autoencoder models and two standard one-class\nclassification methods.\n",
        "published": "2016",
        "authors": [
            "Shehroz S. Khan",
            "Babak Taati"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.04574v3",
        "title": "Generalization Error of Invariant Classifiers",
        "abstract": "  This paper studies the generalization error of invariant classifiers. In\nparticular, we consider the common scenario where the classification task is\ninvariant to certain transformations of the input, and that the classifier is\nconstructed (or learned) to be invariant to these transformations. Our approach\nrelies on factoring the input space into a product of a base space and a set of\ntransformations. We show that whereas the generalization error of a\nnon-invariant classifier is proportional to the complexity of the input space,\nthe generalization error of an invariant classifier is proportional to the\ncomplexity of the base space. We also derive a set of sufficient conditions on\nthe geometry of the base space and the set of transformations that ensure that\nthe complexity of the base space is much smaller than the complexity of the\ninput space. Our analysis applies to general classifiers such as convolutional\nneural networks. We demonstrate the implications of the developed theory for\nsuch classifiers with experiments on the MNIST and CIFAR-10 datasets.\n",
        "published": "2016",
        "authors": [
            "Jure Sokolic",
            "Raja Giryes",
            "Guillermo Sapiro",
            "Miguel R. D. Rodrigues"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.03296v4",
        "title": "Interpretable Explanations of Black Boxes by Meaningful Perturbation",
        "abstract": "  As machine learning algorithms are increasingly applied to high impact yet\nhigh risk tasks, such as medical diagnosis or autonomous driving, it is\ncritical that researchers can explain how such algorithms arrived at their\npredictions. In recent years, a number of image saliency methods have been\ndeveloped to summarize where highly complex neural networks \"look\" in an image\nfor evidence for their predictions. However, these techniques are limited by\ntheir heuristic nature and architectural constraints. In this paper, we make\ntwo main contributions: First, we propose a general framework for learning\ndifferent kinds of explanations for any black box algorithm. Second, we\nspecialise the framework to find the part of an image most responsible for a\nclassifier decision. Unlike previous works, our method is model-agnostic and\ntestable because it is grounded in explicit and interpretable image\nperturbations.\n",
        "published": "2017",
        "authors": [
            "Ruth Fong",
            "Andrea Vedaldi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.06885v1",
        "title": "A General Theory for Training Learning Machine",
        "abstract": "  Though the deep learning is pushing the machine learning to a new stage,\nbasic theories of machine learning are still limited. The principle of\nlearning, the role of the a prior knowledge, the role of neuron bias, and the\nbasis for choosing neural transfer function and cost function, etc., are still\nfar from clear. In this paper, we present a general theoretical framework for\nmachine learning. We classify the prior knowledge into common and\nproblem-dependent parts, and consider that the aim of learning is to maximally\nincorporate them. The principle we suggested for maximizing the former is the\ndesign risk minimization principle, while the neural transfer function, the\ncost function, as well as pretreatment of samples, are endowed with the role\nfor maximizing the latter. The role of the neuron bias is explained from a\ndifferent angle. We develop a Monte Carlo algorithm to establish the\ninput-output responses, and we control the input-output sensitivity of a\nlearning machine by controlling that of individual neurons. Applications of\nfunction approaching and smoothing, pattern recognition and classification, are\nprovided to illustrate how to train general learning machines based on our\ntheory and algorithm. Our method may in addition induce new applications, such\nas the transductive inference.\n",
        "published": "2017",
        "authors": [
            "Hong Zhao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.08165v1",
        "title": "A Generalization of Convolutional Neural Networks to Graph-Structured\n  Data",
        "abstract": "  This paper introduces a generalization of Convolutional Neural Networks\n(CNNs) from low-dimensional grid data, such as images, to graph-structured\ndata. We propose a novel spatial convolution utilizing a random walk to uncover\nthe relations within the input, analogous to the way the standard convolution\nuses the spatial neighborhood of a pixel on the grid. The convolution has an\nintuitive interpretation, is efficient and scalable and can also be used on\ndata with varying graph structure. Furthermore, this generalization can be\napplied to many standard regression or classification problems, by learning the\nthe underlying graph. We empirically demonstrate the performance of the\nproposed CNN on MNIST, and challenge the state-of-the-art on Merck molecular\nactivity data set.\n",
        "published": "2017",
        "authors": [
            "Yotam Hechtlinger",
            "Purvasha Chakravarti",
            "Jining Qin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.01648v1",
        "title": "3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks",
        "abstract": "  The success of various applications including robotics, digital content\ncreation, and visualization demand a structured and abstract representation of\nthe 3D world from limited sensor data. Inspired by the nature of human\nperception of 3D shapes as a collection of simple parts, we explore such an\nabstract shape representation based on primitives. Given a single depth image\nof an object, we present 3D-PRNN, a generative recurrent neural network that\nsynthesizes multiple plausible shapes composed of a set of primitives. Our\ngenerative model encodes symmetry characteristics of common man-made objects,\npreserves long-range structural coherence, and describes objects of varying\ncomplexity with a compact representation. We also propose a method based on\nGaussian Fields to generate a large scale dataset of primitive-based shape\nrepresentations to train our network. We evaluate our approach on a wide range\nof examples and show that it outperforms nearest-neighbor based shape retrieval\nmethods and is on-par with voxel-based generative models while using a\nsignificantly reduced parameter space.\n",
        "published": "2017",
        "authors": [
            "Chuhang Zou",
            "Ersin Yumer",
            "Jimei Yang",
            "Duygu Ceylan",
            "Derek Hoiem"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.05866v2",
        "title": "A Brief Survey of Deep Reinforcement Learning",
        "abstract": "  Deep reinforcement learning is poised to revolutionise the field of AI and\nrepresents a step towards building autonomous systems with a higher level\nunderstanding of the visual world. Currently, deep learning is enabling\nreinforcement learning to scale to problems that were previously intractable,\nsuch as learning to play video games directly from pixels. Deep reinforcement\nlearning algorithms are also applied to robotics, allowing control policies for\nrobots to be learned directly from camera inputs in the real world. In this\nsurvey, we begin with an introduction to the general field of reinforcement\nlearning, then progress to the main streams of value-based and policy-based\nmethods. Our survey will cover central algorithms in deep reinforcement\nlearning, including the deep $Q$-network, trust region policy optimisation, and\nasynchronous advantage actor-critic. In parallel, we highlight the unique\nadvantages of deep neural networks, focusing on visual understanding via\nreinforcement learning. To conclude, we describe several current areas of\nresearch within the field.\n",
        "published": "2017",
        "authors": [
            "Kai Arulkumaran",
            "Marc Peter Deisenroth",
            "Miles Brundage",
            "Anil Anthony Bharath"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.08917v1",
        "title": "CirCNN: Accelerating and Compressing Deep Neural Networks Using\n  Block-CirculantWeight Matrices",
        "abstract": "  Large-scale deep neural networks (DNNs) are both compute and memory\nintensive. As the size of DNNs continues to grow, it is critical to improve the\nenergy efficiency and performance while maintaining accuracy. For DNNs, the\nmodel size is an important factor affecting performance, scalability and energy\nefficiency. Weight pruning achieves good compression ratios but suffers from\nthree drawbacks: 1) the irregular network structure after pruning; 2) the\nincreased training complexity; and 3) the lack of rigorous guarantee of\ncompression ratio and inference accuracy. To overcome these limitations, this\npaper proposes CirCNN, a principled approach to represent weights and process\nneural networks using block-circulant matrices. CirCNN utilizes the Fast\nFourier Transform (FFT)-based fast multiplication, simultaneously reducing the\ncomputational complexity (both in inference and training) from O(n2) to\nO(nlogn) and the storage complexity from O(n2) to O(n), with negligible\naccuracy loss. Compared to other approaches, CirCNN is distinct due to its\nmathematical rigor: it can converge to the same effectiveness as DNNs without\ncompression. The CirCNN architecture, a universal DNN inference engine that can\nbe implemented on various hardware/software platforms with configurable network\narchitecture. To demonstrate the performance and energy efficiency, we test\nCirCNN in FPGA, ASIC and embedded processors. Our results show that CirCNN\narchitecture achieves very high energy efficiency and performance with a small\nhardware footprint. Based on the FPGA implementation and ASIC synthesis\nresults, CirCNN achieves 6-102X energy efficiency improvements compared with\nthe best state-of-the-art results.\n",
        "published": "2017",
        "authors": [
            "Caiwen Ding",
            "Siyu Liao",
            "Yanzhi Wang",
            "Zhe Li",
            "Ning Liu",
            "Youwei Zhuo",
            "Chao Wang",
            "Xuehai Qian",
            "Yu Bai",
            "Geng Yuan",
            "Xiaolong Ma",
            "Yipeng Zhang",
            "Jian Tang",
            "Qinru Qiu",
            "Xue Lin",
            "Bo Yuan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.01691v3",
        "title": "Context Embedding Networks",
        "abstract": "  Low dimensional embeddings that capture the main variations of interest in\ncollections of data are important for many applications. One way to construct\nthese embeddings is to acquire estimates of similarity from the crowd. However,\nsimilarity is a multi-dimensional concept that varies from individual to\nindividual. Existing models for learning embeddings from the crowd typically\nmake simplifying assumptions such as all individuals estimate similarity using\nthe same criteria, the list of criteria is known in advance, or that the crowd\nworkers are not influenced by the data that they see. To overcome these\nlimitations we introduce Context Embedding Networks (CENs). In addition to\nlearning interpretable embeddings from images, CENs also model worker biases\nfor different attributes along with the visual context i.e. the visual\nattributes highlighted by a set of images. Experiments on two noisy crowd\nannotated datasets show that modeling both worker bias and visual context\nresults in more interpretable embeddings compared to existing approaches.\n",
        "published": "2017",
        "authors": [
            "Kun Ho Kim",
            "Oisin Mac Aodha",
            "Pietro Perona"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.02238v2",
        "title": "How Much Chemistry Does a Deep Neural Network Need to Know to Make\n  Accurate Predictions?",
        "abstract": "  The meteoric rise of deep learning models in computer vision research, having\nachieved human-level accuracy in image recognition tasks is firm evidence of\nthe impact of representation learning of deep neural networks. In the chemistry\ndomain, recent advances have also led to the development of similar CNN models,\nsuch as Chemception, that is trained to predict chemical properties using\nimages of molecular drawings. In this work, we investigate the effects of\nsystematically removing and adding localized domain-specific information to the\nimage channels of the training data. By augmenting images with only 3\nadditional basic information, and without introducing any architectural\nchanges, we demonstrate that an augmented Chemception (AugChemception)\noutperforms the original model in the prediction of toxicity, activity, and\nsolvation free energy. Then, by altering the information content in the images,\nand examining the resulting model's performance, we also identify two distinct\nlearning patterns in predicting toxicity/activity as compared to solvation free\nenergy. These patterns suggest that Chemception is learning about its tasks in\nthe manner that is consistent with established knowledge. Thus, our work\ndemonstrates that advanced chemical knowledge is not a pre-requisite for deep\nlearning models to accurately predict complex chemical properties.\n",
        "published": "2017",
        "authors": [
            "Garrett B. Goh",
            "Charles Siegel",
            "Abhinav Vishnu",
            "Nathan O. Hodas",
            "Nathan Baker"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.00432v1",
        "title": "Deep Residual Learning for Accelerated MRI using Magnitude and Phase\n  Networks",
        "abstract": "  Accelerated magnetic resonance (MR) scan acquisition with compressed sensing\n(CS) and parallel imaging is a powerful method to reduce MR imaging scan time.\nHowever, many reconstruction algorithms have high computational costs. To\naddress this, we investigate deep residual learning networks to remove aliasing\nartifacts from artifact corrupted images. The proposed deep residual learning\nnetworks are composed of magnitude and phase networks that are separately\ntrained. If both phase and magnitude information are available, the proposed\nalgorithm can work as an iterative k-space interpolation algorithm using\nframelet representation. When only magnitude data is available, the proposed\napproach works as an image domain post-processing algorithm. Even with strong\ncoherent aliasing artifacts, the proposed network successfully learned and\nremoved the aliasing artifacts, whereas current parallel and CS reconstruction\nmethods were unable to remove these artifacts. Comparisons using single and\nmultiple coil show that the proposed residual network provides good\nreconstruction results with orders of magnitude faster computational time than\nexisting compressed sensing methods. The proposed deep learning framework may\nhave a great potential for accelerated MR reconstruction by generating accurate\nresults immediately.\n",
        "published": "2018",
        "authors": [
            "Dongwook Lee",
            "Jaejun Yoo",
            "Sungho Tak",
            "Jong Chul Ye"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.04241v1",
        "title": "Capsules for Object Segmentation",
        "abstract": "  Convolutional neural networks (CNNs) have shown remarkable results over the\nlast several years for a wide range of computer vision tasks. A new\narchitecture recently introduced by Sabour et al., referred to as a capsule\nnetworks with dynamic routing, has shown great initial results for digit\nrecognition and small image classification. The success of capsule networks\nlies in their ability to preserve more information about the input by replacing\nmax-pooling layers with convolutional strides and dynamic routing, allowing for\npreservation of part-whole relationships in the data. This preservation of the\ninput is demonstrated by reconstructing the input from the output capsule\nvectors. Our work expands the use of capsule networks to the task of object\nsegmentation for the first time in the literature. We extend the idea of\nconvolutional capsules with locally-connected routing and propose the concept\nof deconvolutional capsules. Further, we extend the masked reconstruction to\nreconstruct the positive input class. The proposed\nconvolutional-deconvolutional capsule network, called SegCaps, shows strong\nresults for the task of object segmentation with substantial decrease in\nparameter space. As an example application, we applied the proposed SegCaps to\nsegment pathological lungs from low dose CT scans and compared its accuracy and\nefficiency with other U-Net-based architectures. SegCaps is able to handle\nlarge image sizes (512 x 512) as opposed to baseline capsules (typically less\nthan 32 x 32). The proposed SegCaps reduced the number of parameters of U-Net\narchitecture by 95.4% while still providing a better segmentation accuracy.\n",
        "published": "2018",
        "authors": [
            "Rodney LaLonde",
            "Ulas Bagci"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.04458v1",
        "title": "CubeNet: Equivariance to 3D Rotation and Translation",
        "abstract": "  3D Convolutional Neural Networks are sensitive to transformations applied to\ntheir input. This is a problem because a voxelized version of a 3D object, and\nits rotated clone, will look unrelated to each other after passing through to\nthe last layer of a network. Instead, an idealized model would preserve a\nmeaningful representation of the voxelized object, while explaining the\npose-difference between the two inputs. An equivariant representation vector\nhas two components: the invariant identity part, and a discernable encoding of\nthe transformation. Models that can't explain pose-differences risk \"diluting\"\nthe representation, in pursuit of optimizing a classification or regression\nloss function.\n  We introduce a Group Convolutional Neural Network with linear equivariance to\ntranslations and right angle rotations in three dimensions. We call this\nnetwork CubeNet, reflecting its cube-like symmetry. By construction, this\nnetwork helps preserve a 3D shape's global and local signature, as it is\ntransformed through successive layers. We apply this network to a variety of 3D\ninference problems, achieving state-of-the-art on the ModelNet10 classification\nchallenge, and comparable performance on the ISBI 2012 Connectome Segmentation\nBenchmark. To the best of our knowledge, this is the first 3D rotation\nequivariant CNN for voxel representations.\n",
        "published": "2018",
        "authors": [
            "Daniel Worrall",
            "Gabriel Brostow"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.09400v1",
        "title": "3D Consistent & Robust Segmentation of Cardiac Images by Deep Learning\n  with Spatial Propagation",
        "abstract": "  We propose a method based on deep learning to perform cardiac segmentation on\nshort axis MRI image stacks iteratively from the top slice (around the base) to\nthe bottom slice (around the apex). At each iteration, a novel variant of U-net\nis applied to propagate the segmentation of a slice to the adjacent slice below\nit. In other words, the prediction of a segmentation of a slice is dependent\nupon the already existing segmentation of an adjacent slice. 3D-consistency is\nhence explicitly enforced. The method is trained on a large database of 3078\ncases from UK Biobank. It is then tested on 756 different cases from UK Biobank\nand three other state-of-the-art cohorts (ACDC with 100 cases, Sunnybrook with\n30 cases, RVSC with 16 cases). Results comparable or even better than the\nstate-of-the-art in terms of distance measures are achieved. They also\nemphasize the assets of our method, namely enhanced spatial consistency\n(currently neither considered nor achieved by the state-of-the-art), and the\ngeneralization ability to unseen cases even from other databases.\n",
        "published": "2018",
        "authors": [
            "Qiao Zheng",
            "Herv\u00e9 Delingette",
            "Nicolas Duchateau",
            "Nicholas Ayache"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.10969v3",
        "title": "UNIQ: Uniform Noise Injection for Non-Uniform Quantization of Neural\n  Networks",
        "abstract": "  We present a novel method for neural network quantization that emulates a\nnon-uniform $k$-quantile quantizer, which adapts to the distribution of the\nquantized parameters. Our approach provides a novel alternative to the existing\nuniform quantization techniques for neural networks. We suggest to compare the\nresults as a function of the bit-operations (BOPS) performed, assuming a\nlook-up table availability for the non-uniform case. In this setup, we show the\nadvantages of our strategy in the low computational budget regime. While the\nproposed solution is harder to implement in hardware, we believe it sets a\nbasis for new alternatives to neural networks quantization.\n",
        "published": "2018",
        "authors": [
            "Chaim Baskin",
            "Eli Schwartz",
            "Evgenii Zheltonozhskii",
            "Natan Liss",
            "Raja Giryes",
            "Alex M. Bronstein",
            "Avi Mendelson"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.02279v2",
        "title": "S4ND: Single-Shot Single-Scale Lung Nodule Detection",
        "abstract": "  The state of the art lung nodule detection studies rely on computationally\nexpensive multi-stage frameworks to detect nodules from CT scans. To address\nthis computational challenge and provide better performance, in this paper we\npropose S4ND, a new deep learning based method for lung nodule detection. Our\napproach uses a single feed forward pass of a single network for detection and\nprovides better performance when compared to the current literature. The whole\ndetection pipeline is designed as a single $3D$ Convolutional Neural Network\n(CNN) with dense connections, trained in an end-to-end manner. S4ND does not\nrequire any further post-processing or user guidance to refine detection\nresults. Experimentally, we compared our network with the current\nstate-of-the-art object detection network (SSD) in computer vision as well as\nthe state-of-the-art published method for lung nodule detection (3D DCNN). We\nused publically available $888$ CT scans from LUNA challenge dataset and showed\nthat the proposed method outperforms the current literature both in terms of\nefficiency and accuracy by achieving an average FROC-score of $0.897$. We also\nprovide an in-depth analysis of our proposed network to shed light on the\nunclear paradigms of tiny object detection.\n",
        "published": "2018",
        "authors": [
            "Naji Khosravan",
            "Ulas Bagci"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.07473v2",
        "title": "Progressive Ensemble Networks for Zero-Shot Recognition",
        "abstract": "  Despite the advancement of supervised image recognition algorithms, their\ndependence on the availability of labeled data and the rapid expansion of image\ncategories raise the significant challenge of zero-shot learning. Zero-shot\nlearning (ZSL) aims to transfer knowledge from labeled classes into unlabeled\nclasses to reduce human labeling effort. In this paper, we propose a novel\nprogressive ensemble network model with multiple projected label embeddings to\naddress zero-shot image recognition. The ensemble network is built by learning\nmultiple image classification functions with a shared feature extraction\nnetwork but different label embedding representations, which enhance the\ndiversity of the classifiers and facilitate information transfer to unlabeled\nclasses. A progressive training framework is then deployed to gradually label\nthe most confident images in each unlabeled class with predicted pseudo-labels\nand update the ensemble network with the training data augmented by the\npseudo-labels. The proposed model performs training on both labeled and\nunlabeled data. It can naturally bridge the domain shift problem in visual\nappearances and be extended to the generalized zero-shot learning scenario. We\nconduct experiments on multiple ZSL datasets and the empirical results\ndemonstrate the efficacy of the proposed model.\n",
        "published": "2018",
        "authors": [
            "Meng Ye",
            "Yuhong Guo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.07883v3",
        "title": "How Many Samples are Needed to Estimate a Convolutional or Recurrent\n  Neural Network?",
        "abstract": "  It is widely believed that the practical success of Convolutional Neural\nNetworks (CNNs) and Recurrent Neural Networks (RNNs) owes to the fact that CNNs\nand RNNs use a more compact parametric representation than their\nFully-Connected Neural Network (FNN) counterparts, and consequently require\nfewer training examples to accurately estimate their parameters. We initiate\nthe study of rigorously characterizing the sample-complexity of estimating CNNs\nand RNNs. We show that the sample-complexity to learn CNNs and RNNs scales\nlinearly with their intrinsic dimension and this sample-complexity is much\nsmaller than for their FNN counterparts. For both CNNs and RNNs, we also\npresent lower bounds showing our sample complexities are tight up to\nlogarithmic factors. Our main technical tools for deriving these results are a\nlocalized empirical process analysis and a new technical lemma characterizing\nthe convolutional and recurrent structure. We believe that these tools may\ninspire further developments in understanding CNNs and RNNs.\n",
        "published": "2018",
        "authors": [
            "Simon S. Du",
            "Yining Wang",
            "Xiyu Zhai",
            "Sivaraman Balakrishnan",
            "Ruslan Salakhutdinov",
            "Aarti Singh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.07941v1",
        "title": "Quantizing Convolutional Neural Networks for Low-Power High-Throughput\n  Inference Engines",
        "abstract": "  Deep learning as a means to inferencing has proliferated thanks to its\nversatility and ability to approach or exceed human-level accuracy. These\ncomputational models have seemingly insatiable appetites for computational\nresources not only while training, but also when deployed at scales ranging\nfrom data centers all the way down to embedded devices. As such, increasing\nconsideration is being made to maximize the computational efficiency given\nlimited hardware and energy resources and, as a result, inferencing with\nreduced precision has emerged as a viable alternative to the IEEE 754 Standard\nfor Floating-Point Arithmetic. We propose a quantization scheme that allows\ninferencing to be carried out using arithmetic that is fundamentally more\nefficient when compared to even half-precision floating-point. Our quantization\nprocedure is significant in that we determine our quantization scheme\nparameters by calibrating against its reference floating-point model using a\nsingle inference batch rather than (re)training and achieve end-to-end post\nquantization accuracies comparable to the reference model.\n",
        "published": "2018",
        "authors": [
            "Sean O. Settle",
            "Manasa Bollavaram",
            "Paolo D'Alberto",
            "Elliott Delaye",
            "Oscar Fernandez",
            "Nicholas Fraser",
            "Aaron Ng",
            "Ashish Sirasao",
            "Michael Wu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.08440v2",
        "title": "Classification Uncertainty of Deep Neural Networks Based on Gradient\n  Information",
        "abstract": "  We study the quantification of uncertainty of Convolutional Neural Networks\n(CNNs) based on gradient metrics. Unlike the classical softmax entropy, such\nmetrics gather information from all layers of the CNN. We show for the EMNIST\ndigits data set that for several such metrics we achieve the same meta\nclassification accuracy -- i.e. the task of classifying predictions as correct\nor incorrect without knowing the actual label -- as for entropy thresholding.\nWe apply meta classification to unknown concepts (out-of-distribution samples)\n-- EMNIST/Omniglot letters, CIFAR10 and noise -- and demonstrate that meta\nclassification rates for unknown concepts can be increased when using entropy\ntogether with several gradient based metrics as input quantities for a meta\nclassifier. Meta classifiers only trained on the uncertainty metrics of known\nconcepts, i.e. EMNIST digits, usually do not perform equally well for all\nunknown concepts. If we however allow the meta classifier to be trained on\nuncertainty metrics for some out-of-distribution samples, meta classification\nfor concepts remote from EMNIST digits (then termed known unknowns) can be\nimproved considerably.\n",
        "published": "2018",
        "authors": [
            "Philipp Oberdiek",
            "Matthias Rottmann",
            "Hanno Gottschalk"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.08657v2",
        "title": "Robust Conditional Generative Adversarial Networks",
        "abstract": "  Conditional generative adversarial networks (cGAN) have led to large\nimprovements in the task of conditional image generation, which lies at the\nheart of computer vision. The major focus so far has been on performance\nimprovement, while there has been little effort in making cGAN more robust to\nnoise. The regression (of the generator) might lead to arbitrarily large errors\nin the output, which makes cGAN unreliable for real-world applications. In this\nwork, we introduce a novel conditional GAN model, called RoCGAN, which\nleverages structure in the target space of the model to address the issue. Our\nmodel augments the generator with an unsupervised pathway, which promotes the\noutputs of the generator to span the target manifold even in the presence of\nintense noise. We prove that RoCGAN share similar theoretical properties as GAN\nand experimentally verify that our model outperforms existing state-of-the-art\ncGAN architectures by a large margin in a variety of domains including images\nfrom natural scenes and faces.\n",
        "published": "2018",
        "authors": [
            "Grigorios G. Chrysos",
            "Jean Kossaifi",
            "Stefanos Zafeiriou"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.10123v4",
        "title": "TADAM: Task dependent adaptive metric for improved few-shot learning",
        "abstract": "  Few-shot learning has become essential for producing models that generalize\nfrom few examples. In this work, we identify that metric scaling and metric\ntask conditioning are important to improve the performance of few-shot\nalgorithms. Our analysis reveals that simple metric scaling completely changes\nthe nature of few-shot algorithm parameter updates. Metric scaling provides\nimprovements up to 14% in accuracy for certain metrics on the mini-Imagenet\n5-way 5-shot classification task. We further propose a simple and effective way\nof conditioning a learner on the task sample set, resulting in learning a\ntask-dependent metric space. Moreover, we propose and empirically test a\npractical end-to-end optimization procedure based on auxiliary task co-training\nto learn a task-dependent metric space. The resulting few-shot learning model\nbased on the task-dependent scaled metric achieves state of the art on\nmini-Imagenet. We confirm these results on another few-shot dataset that we\nintroduce in this paper based on CIFAR100. Our code is publicly available at\nhttps://github.com/ElementAI/TADAM.\n",
        "published": "2018",
        "authors": [
            "Boris N. Oreshkin",
            "Pau Rodriguez",
            "Alexandre Lacoste"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.10129v1",
        "title": "Dyna Planning using a Feature Based Generative Model",
        "abstract": "  Dyna-style reinforcement learning is a powerful approach for problems where\nnot much real data is available. The main idea is to supplement real\ntrajectories, or sequences of sampled states over time, with simulated ones\nsampled from a learned model of the environment. However, in large state\nspaces, the problem of learning a good generative model of the environment has\nbeen open so far. We propose to use deep belief networks to learn an\nenvironment model for use in Dyna. We present our approach and validate it\nempirically on problems where the state observations consist of images. Our\nresults demonstrate that using deep belief networks, which are full generative\nmodels, significantly outperforms the use of linear expectation models,\nproposed in Sutton et al. (2008)\n",
        "published": "2018",
        "authors": [
            "Ryan Faulkner",
            "Doina Precup"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.11592v2",
        "title": "Playing hard exploration games by watching YouTube",
        "abstract": "  Deep reinforcement learning methods traditionally struggle with tasks where\nenvironment rewards are particularly sparse. One successful method of guiding\nexploration in these domains is to imitate trajectories provided by a human\ndemonstrator. However, these demonstrations are typically collected under\nartificial conditions, i.e. with access to the agent's exact environment setup\nand the demonstrator's action and reward trajectories. Here we propose a\ntwo-stage method that overcomes these limitations by relying on noisy,\nunaligned footage without access to such data. First, we learn to map unaligned\nvideos from multiple sources to a common representation using self-supervised\nobjectives constructed over both time and modality (i.e. vision and sound).\nSecond, we embed a single YouTube video in this representation to construct a\nreward function that encourages an agent to imitate human gameplay. This method\nof one-shot imitation allows our agent to convincingly exceed human-level\nperformance on the infamously hard exploration games Montezuma's Revenge,\nPitfall! and Private Eye for the first time, even if the agent is not presented\nwith any environment rewards.\n",
        "published": "2018",
        "authors": [
            "Yusuf Aytar",
            "Tobias Pfaff",
            "David Budden",
            "Tom Le Paine",
            "Ziyu Wang",
            "Nando de Freitas"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1808.04456v2",
        "title": "Multimodal Deep Neural Networks using Both Engineered and Learned\n  Representations for Biodegradability Prediction",
        "abstract": "  Deep learning algorithms excel at extracting patterns from raw data, and with\nlarge datasets, they have been very successful in computer vision and natural\nlanguage applications. However, in other domains, large datasets on which to\nlearn representations from may not exist. In this work, we develop a novel\nmultimodal CNN-MLP neural network architecture that utilizes both\ndomain-specific feature engineering as well as learned representations from raw\ndata. We illustrate the effectiveness of such network designs in the chemical\nsciences, for predicting biodegradability. DeepBioD, a multimodal CNN-MLP\nnetwork is more accurate than either standalone network designs, and achieves\nan error classification rate of 0.125 that is 27% lower than the current\nstate-of-the-art. Thus, our work indicates that combining traditional feature\nengineering with representation learning can be effective, particularly in\nsituations where labeled data is limited.\n",
        "published": "2018",
        "authors": [
            "Garrett B. Goh",
            "Khushmeen Sakloth",
            "Charles Siegel",
            "Abhinav Vishnu",
            "Jim Pfaendtner"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.01868v3",
        "title": "Set Aggregation Network as a Trainable Pooling Layer",
        "abstract": "  Global pooling, such as max- or sum-pooling, is one of the key ingredients in\ndeep neural networks used for processing images, texts, graphs and other types\nof structured data. Based on the recent DeepSets architecture proposed by\nZaheer et al. (NIPS 2017), we introduce a Set Aggregation Network (SAN) as an\nalternative global pooling layer. In contrast to typical pooling operators, SAN\nallows to embed a given set of features to a vector representation of arbitrary\nsize. We show that by adjusting the size of embedding, SAN is capable of\npreserving the whole information from the input. In experiments, we demonstrate\nthat replacing global pooling layer by SAN leads to the improvement of\nclassification accuracy. Moreover, it is less prone to overfitting and can be\nused as a regularizer.\n",
        "published": "2018",
        "authors": [
            "\u0141ukasz Maziarka",
            "Marek \u015amieja",
            "Aleksandra Nowak",
            "Jacek Tabor",
            "\u0141ukasz Struski",
            "Przemys\u0142aw Spurek"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.02334v6",
        "title": "Unsupervised Learning via Meta-Learning",
        "abstract": "  A central goal of unsupervised learning is to acquire representations from\nunlabeled data or experience that can be used for more effective learning of\ndownstream tasks from modest amounts of labeled data. Many prior unsupervised\nlearning works aim to do so by developing proxy objectives based on\nreconstruction, disentanglement, prediction, and other metrics. Instead, we\ndevelop an unsupervised meta-learning method that explicitly optimizes for the\nability to learn a variety of tasks from small amounts of data. To do so, we\nconstruct tasks from unlabeled data in an automatic way and run meta-learning\nover the constructed tasks. Surprisingly, we find that, when integrated with\nmeta-learning, relatively simple task construction mechanisms, such as\nclustering embeddings, lead to good performance on a variety of downstream,\nhuman-specified tasks. Our experiments across four image datasets indicate that\nour unsupervised meta-learning approach acquires a learning algorithm without\nany labeled data that is applicable to a wide range of downstream\nclassification tasks, improving upon the embedding learned by four prior\nunsupervised learning methods.\n",
        "published": "2018",
        "authors": [
            "Kyle Hsu",
            "Sergey Levine",
            "Chelsea Finn"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.02797v3",
        "title": "RCCNet: An Efficient Convolutional Neural Network for Histological\n  Routine Colon Cancer Nuclei Classification",
        "abstract": "  Efficient and precise classification of histological cell nuclei is of utmost\nimportance due to its potential applications in the field of medical image\nanalysis. It would facilitate the medical practitioners to better understand\nand explore various factors for cancer treatment. The classification of\nhistological cell nuclei is a challenging task due to the cellular\nheterogeneity. This paper proposes an efficient Convolutional Neural Network\n(CNN) based architecture for classification of histological routine colon\ncancer nuclei named as RCCNet. The main objective of this network is to keep\nthe CNN model as simple as possible. The proposed RCCNet model consists of only\n1,512,868 learnable parameters which are significantly less compared to the\npopular CNN models such as AlexNet, CIFARVGG, GoogLeNet, and WRN. The\nexperiments are conducted over publicly available routine colon cancer\nhistological dataset \"CRCHistoPhenotypes\". The results of the proposed RCCNet\nmodel are compared with five state-of-the-art CNN models in terms of the\naccuracy, weighted average F1 score and training time. The proposed method has\nachieved a classification accuracy of 80.61% and 0.7887 weighted average F1\nscore. The proposed RCCNet is more efficient and generalized terms of the\ntraining time and data over-fitting, respectively.\n",
        "published": "2018",
        "authors": [
            "S H Shabbeer Basha",
            "Soumen Ghosh",
            "Kancharagunta Kishan Babu",
            "Shiv Ram Dubey",
            "Viswanath Pulabaigari",
            "Snehasis Mukherjee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.02897v3",
        "title": "CDF Transform-and-Shift: An effective way to deal with datasets of\n  inhomogeneous cluster densities",
        "abstract": "  The problem of inhomogeneous cluster densities has been a long-standing issue\nfor distance-based and density-based algorithms in clustering and anomaly\ndetection. These algorithms implicitly assume that all clusters have\napproximately the same density. As a result, they often exhibit a bias towards\ndense clusters in the presence of sparse clusters. Many remedies have been\nsuggested; yet, we show that they are partial solutions which do not address\nthe issue satisfactorily. To match the implicit assumption, we propose to\ntransform a given dataset such that the transformed clusters have approximately\nthe same density while all regions of locally low density become globally low\ndensity -- homogenising cluster density while preserving the cluster structure\nof the dataset. We show that this can be achieved by using a new\nmulti-dimensional Cumulative Distribution Function in a transform-and-shift\nmethod. The method can be applied to every dataset, before the dataset is used\nin many existing algorithms to match their implicit assumption without\nalgorithmic modification. We show that the proposed method performs better than\nexisting remedies.\n",
        "published": "2018",
        "authors": [
            "Ye Zhu",
            "Kai Ming Ting",
            "Mark Carman",
            "Maia Angelova"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.03105v2",
        "title": "ASVRG: Accelerated Proximal SVRG",
        "abstract": "  This paper proposes an accelerated proximal stochastic variance reduced\ngradient (ASVRG) method, in which we design a simple and effective momentum\nacceleration trick. Unlike most existing accelerated stochastic variance\nreduction methods such as Katyusha, ASVRG has only one additional variable and\none momentum parameter. Thus, ASVRG is much simpler than those methods, and has\nmuch lower per-iteration complexity. We prove that ASVRG achieves the best\nknown oracle complexities for both strongly convex and non-strongly convex\nobjectives. In addition, we extend ASVRG to mini-batch and non-smooth settings.\nWe also empirically verify our theoretical results and show that the\nperformance of ASVRG is comparable with, and sometimes even better than that of\nthe state-of-the-art stochastic methods.\n",
        "published": "2018",
        "authors": [
            "Fanhua Shang",
            "Licheng Jiao",
            "Kaiwen Zhou",
            "James Cheng",
            "Yan Ren",
            "Yufei Jin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.08515v1",
        "title": "Transfer Learning versus Multi-agent Learning regarding Distributed\n  Decision-Making in Highway Traffic",
        "abstract": "  Transportation and traffic are currently undergoing a rapid increase in terms\nof both scale and complexity. At the same time, an increasing share of traffic\nparticipants are being transformed into agents driven or supported by\nartificial intelligence resulting in mixed-intelligence traffic. This work\nexplores the implications of distributed decision-making in mixed-intelligence\ntraffic. The investigations are carried out on the basis of an online-simulated\nhighway scenario, namely the MIT \\emph{DeepTraffic} simulation. In the first\nstep traffic agents are trained by means of a deep reinforcement learning\napproach, being deployed inside an elitist evolutionary algorithm for\nhyperparameter search. The resulting architectures and training parameters are\nthen utilized in order to either train a single autonomous traffic agent and\ntransfer the learned weights onto a multi-agent scenario or else to conduct\nmulti-agent learning directly. Both learning strategies are evaluated on\ndifferent ratios of mixed-intelligence traffic. The strategies are assessed\naccording to the average speed of all agents driven by artificial intelligence.\nTraffic patterns that provoke a reduction in traffic flow are analyzed with\nrespect to the different strategies.\n",
        "published": "2018",
        "authors": [
            "Mark Schutera",
            "Niklas Goby",
            "Dirk Neumann",
            "Markus Reischl"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.03259v1",
        "title": "Is 'Unsupervised Learning' a Misconceived Term?",
        "abstract": "  Is all of machine learning supervised to some degree? The field of machine\nlearning has traditionally been categorized pedagogically into\n$supervised~vs~unsupervised~learning$; where supervised learning has typically\nreferred to learning from labeled data, while unsupervised learning has\ntypically referred to learning from unlabeled data. In this paper, we assert\nthat all machine learning is in fact supervised to some degree, and that the\nscope of supervision is necessarily commensurate to the scope of learning\npotential. In particular, we argue that clustering algorithms such as k-means,\nand dimensionality reduction algorithms such as principal component analysis,\nvariational autoencoders, and deep belief networks are each internally\nsupervised by the data itself to learn their respective representations of its\nfeatures. Furthermore, these algorithms are not capable of external inference\nuntil their respective outputs (clusters, principal components, or\nrepresentation codes) have been identified and externally labeled in effect. As\nsuch, they do not suffice as examples of unsupervised learning. We propose that\nthe categorization `supervised vs unsupervised learning' be dispensed with, and\ninstead, learning algorithms be categorized as either\n$internally~or~externally~supervised$ (or both). We believe this change in\nperspective will yield new fundamental insights into the structure and\ncharacter of data and of learning algorithms.\n",
        "published": "2019",
        "authors": [
            "Stephen G. Odaibo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.04862v1",
        "title": "SWNet: Small-World Neural Networks and Rapid Convergence",
        "abstract": "  Training large and highly accurate deep learning (DL) models is\ncomputationally costly. This cost is in great part due to the excessive number\nof trained parameters, which are well-known to be redundant and compressible\nfor the execution phase. This paper proposes a novel transformation which\nchanges the topology of the DL architecture such that it reaches an optimal\ncross-layer connectivity. This transformation leverages our important\nobservation that for a set level of accuracy, convergence is fastest when\nnetwork topology reaches the boundary of a Small-World Network. Small-world\ngraphs are known to possess a specific connectivity structure that enables\nenhanced signal propagation among nodes. Our small-world models, called SWNets,\nprovide several intriguing benefits: they facilitate data (gradient) flow\nwithin the network, enable feature-map reuse by adding long-range connections\nand accommodate various network architectures/datasets. Compared to densely\nconnected networks (e.g., DenseNets), SWNets require a substantially fewer\nnumber of training parameters while maintaining a similar level of\nclassification accuracy. We evaluate our networks on various DL model\narchitectures and image classification datasets, namely, CIFAR10, CIFAR100, and\nILSVRC (ImageNet). Our experiments demonstrate an average of ~2.1x improvement\nin convergence speed to the desired accuracy\n",
        "published": "2019",
        "authors": [
            "Mojan Javaheripi",
            "Bita Darvish Rouhani",
            "Farinaz Koushanfar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.07302v2",
        "title": "Automatic alignment of surgical videos using kinematic data",
        "abstract": "  Over the past one hundred years, the classic teaching methodology of \"see\none, do one, teach one\" has governed the surgical education systems worldwide.\nWith the advent of Operation Room 2.0, recording video, kinematic and many\nother types of data during the surgery became an easy task, thus allowing\nartificial intelligence systems to be deployed and used in surgical and medical\npractice. Recently, surgical videos has been shown to provide a structure for\npeer coaching enabling novice trainees to learn from experienced surgeons by\nreplaying those videos. However, the high inter-operator variability in\nsurgical gesture duration and execution renders learning from comparing novice\nto expert surgical videos a very difficult task. In this paper, we propose a\nnovel technique to align multiple videos based on the alignment of their\ncorresponding kinematic multivariate time series data. By leveraging the\nDynamic Time Warping measure, our algorithm synchronizes a set of videos in\norder to show the same gesture being performed at different speed. We believe\nthat the proposed approach is a valuable addition to the existing learning\ntools for surgery.\n",
        "published": "2019",
        "authors": [
            "Hassan Ismail Fawaz",
            "Germain Forestier",
            "Jonathan Weber",
            "Fran\u00e7ois Petitjean",
            "Lhassane Idoumghar",
            "Pierre-Alain Muller"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.07451v2",
        "title": "Counterfactual Visual Explanations",
        "abstract": "  In this work, we develop a technique to produce counterfactual visual\nexplanations. Given a 'query' image $I$ for which a vision system predicts\nclass $c$, a counterfactual visual explanation identifies how $I$ could change\nsuch that the system would output a different specified class $c'$. To do this,\nwe select a 'distractor' image $I'$ that the system predicts as class $c'$ and\nidentify spatial regions in $I$ and $I'$ such that replacing the identified\nregion in $I$ with the identified region in $I'$ would push the system towards\nclassifying $I$ as $c'$. We apply our approach to multiple image classification\ndatasets generating qualitative results showcasing the interpretability and\ndiscriminativeness of our counterfactual explanations. To explore the\neffectiveness of our explanations in teaching humans, we present machine\nteaching experiments for the task of fine-grained bird classification. We find\nthat users trained to distinguish bird species fare better when given access to\ncounterfactual explanations in addition to training examples.\n",
        "published": "2019",
        "authors": [
            "Yash Goyal",
            "Ziyan Wu",
            "Jan Ernst",
            "Dhruv Batra",
            "Devi Parikh",
            "Stefan Lee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.07482v4",
        "title": "Object-Oriented Dynamics Learning through Multi-Level Abstraction",
        "abstract": "  Object-based approaches for learning action-conditioned dynamics has\ndemonstrated promise for generalization and interpretability. However, existing\napproaches suffer from structural limitations and optimization difficulties for\ncommon environments with multiple dynamic objects. In this paper, we present a\nnovel self-supervised learning framework, called Multi-level Abstraction\nObject-oriented Predictor (MAOP), which employs a three-level learning\narchitecture that enables efficient object-based dynamics learning from raw\nvisual observations. We also design a spatial-temporal relational reasoning\nmechanism for MAOP to support instance-level dynamics learning and handle\npartial observability. Our results show that MAOP significantly outperforms\nprevious methods in terms of sample efficiency and generalization over novel\nenvironments for learning environment models. We also demonstrate that learned\ndynamics models enable efficient planning in unseen environments, comparable to\ntrue environment models. In addition, MAOP learns semantically and visually\ninterpretable disentangled representations.\n",
        "published": "2019",
        "authors": [
            "Guangxiang Zhu",
            "Jianhao Wang",
            "Zhizhou Ren",
            "Zichuan Lin",
            "Chongjie Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.07734v1",
        "title": "Three scenarios for continual learning",
        "abstract": "  Standard artificial neural networks suffer from the well-known issue of\ncatastrophic forgetting, making continual or lifelong learning difficult for\nmachine learning. In recent years, numerous methods have been proposed for\ncontinual learning, but due to differences in evaluation protocols it is\ndifficult to directly compare their performance. To enable more structured\ncomparisons, we describe three continual learning scenarios based on whether at\ntest time task identity is provided and--in case it is not--whether it must be\ninferred. Any sequence of well-defined tasks can be performed according to each\nscenario. Using the split and permuted MNIST task protocols, for each scenario\nwe carry out an extensive comparison of recently proposed continual learning\nmethods. We demonstrate substantial differences between the three scenarios in\nterms of difficulty and in terms of how efficient different methods are. In\nparticular, when task identity must be inferred (i.e., class incremental\nlearning), we find that regularization-based approaches (e.g., elastic weight\nconsolidation) fail and that replaying representations of previous experiences\nseems required for solving this scenario.\n",
        "published": "2019",
        "authors": [
            "Gido M. van de Ven",
            "Andreas S. Tolias"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.08502v2",
        "title": "Few-Shot Learning with Localization in Realistic Settings",
        "abstract": "  Traditional recognition methods typically require large,\nartificially-balanced training classes, while few-shot learning methods are\ntested on artificially small ones. In contrast to both extremes, real world\nrecognition problems exhibit heavy-tailed class distributions, with cluttered\nscenes and a mix of coarse and fine-grained class distinctions. We show that\nprior methods designed for few-shot learning do not work out of the box in\nthese challenging conditions, based on a new \"meta-iNat\" benchmark. We\nintroduce three parameter-free improvements: (a) better training procedures\nbased on adapting cross-validation to meta-learning, (b) novel architectures\nthat localize objects using limited bounding box annotations before\nclassification, and (c) simple parameter-free expansions of the feature space\nbased on bilinear pooling. Together, these improvements double the accuracy of\nstate-of-the-art models on meta-iNat while generalizing to prior benchmarks,\ncomplex neural architectures, and settings with substantial domain shift.\n",
        "published": "2019",
        "authors": [
            "Davis Wertheimer",
            "Bharath Hariharan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.08939v1",
        "title": "Understanding Neural Networks via Feature Visualization: A survey",
        "abstract": "  A neuroscience method to understanding the brain is to find and study the\npreferred stimuli that highly activate an individual cell or groups of cells.\nRecent advances in machine learning enable a family of methods to synthesize\npreferred stimuli that cause a neuron in an artificial or biological brain to\nfire strongly. Those methods are known as Activation Maximization (AM) or\nFeature Visualization via Optimization. In this chapter, we (1) review existing\nAM techniques in the literature; (2) discuss a probabilistic interpretation for\nAM; and (3) review the applications of AM in debugging and explaining networks.\n",
        "published": "2019",
        "authors": [
            "Anh Nguyen",
            "Jason Yosinski",
            "Jeff Clune"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.00136v1",
        "title": "ResNet Can Be Pruned 60x: Introducing Network Purification and Unused\n  Path Removal (P-RM) after Weight Pruning",
        "abstract": "  The state-of-art DNN structures involve high computation and great demand for\nmemory storage which pose intensive challenge on DNN framework resources. To\nmitigate the challenges, weight pruning techniques has been studied. However,\nhigh accuracy solution for extreme structured pruning that combines different\ntypes of structured sparsity still waiting for unraveling due to the extremely\nreduced weights in DNN networks. In this paper, we propose a DNN framework\nwhich combines two different types of structured weight pruning (filter and\ncolumn prune) by incorporating alternating direction method of multipliers\n(ADMM) algorithm for better prune performance. We are the first to find\nnon-optimality of ADMM process and unused weights in a structured pruned model,\nand further design an optimization framework which contains the first proposed\nNetwork Purification and Unused Path Removal algorithms which are dedicated to\npost-processing an structured pruned model after ADMM steps. Some high lights\nshows we achieve 232x compression on LeNet-5, 60x compression on ResNet-18\nCIFAR-10 and over 5x compression on AlexNet. We share our models at anonymous\nlink http://bit.ly/2VJ5ktv.\n",
        "published": "2019",
        "authors": [
            "Xiaolong Ma",
            "Geng Yuan",
            "Sheng Lin",
            "Zhengang Li",
            "Hao Sun",
            "Yanzhi Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.02185v1",
        "title": "Label-Noise Robust Multi-Domain Image-to-Image Translation",
        "abstract": "  Multi-domain image-to-image translation is a problem where the goal is to\nlearn mappings among multiple domains. This problem is challenging in terms of\nscalability because it requires the learning of numerous mappings, the number\nof which increases proportional to the number of domains. However, generative\nadversarial networks (GANs) have emerged recently as a powerful framework for\nthis problem. In particular, label-conditional extensions (e.g., StarGAN) have\nbecome a promising solution owing to their ability to address this problem\nusing only a single unified model. Nonetheless, a limitation is that they rely\non the availability of large-scale clean-labeled data, which are often\nlaborious or impractical to collect in a real-world scenario. To overcome this\nlimitation, we propose a novel model called the label-noise robust\nimage-to-image translation model (RMIT) that can learn a clean label\nconditional generator even when noisy labeled data are only available. In\nparticular, we propose a novel loss called the virtual cycle consistency loss\nthat is able to regularize cyclic reconstruction independently of noisy labeled\ndata, as well as we introduce advanced techniques to boost the performance in\npractice. Our experimental results demonstrate that RMIT is useful for\nobtaining label-noise robustness in various settings including synthetic and\nreal-world noise.\n",
        "published": "2019",
        "authors": [
            "Takuhiro Kaneko",
            "Tatsuya Harada"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.02249v2",
        "title": "MixMatch: A Holistic Approach to Semi-Supervised Learning",
        "abstract": "  Semi-supervised learning has proven to be a powerful paradigm for leveraging\nunlabeled data to mitigate the reliance on large labeled datasets. In this\nwork, we unify the current dominant approaches for semi-supervised learning to\nproduce a new algorithm, MixMatch, that works by guessing low-entropy labels\nfor data-augmented unlabeled examples and mixing labeled and unlabeled data\nusing MixUp. We show that MixMatch obtains state-of-the-art results by a large\nmargin across many datasets and labeled data amounts. For example, on CIFAR-10\nwith 250 labels, we reduce error rate by a factor of 4 (from 38% to 11%) and by\na factor of 2 on STL-10. We also demonstrate how MixMatch can help achieve a\ndramatically better accuracy-privacy trade-off for differential privacy.\nFinally, we perform an ablation study to tease apart which components of\nMixMatch are most important for its success.\n",
        "published": "2019",
        "authors": [
            "David Berthelot",
            "Nicholas Carlini",
            "Ian Goodfellow",
            "Nicolas Papernot",
            "Avital Oliver",
            "Colin Raffel"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.02845v1",
        "title": "Feature Selection and Feature Extraction in Pattern Analysis: A\n  Literature Review",
        "abstract": "  Pattern analysis often requires a pre-processing stage for extracting or\nselecting features in order to help the classification, prediction, or\nclustering stage discriminate or represent the data in a better way. The reason\nfor this requirement is that the raw data are complex and difficult to process\nwithout extracting or selecting appropriate features beforehand. This paper\nreviews theory and motivation of different common methods of feature selection\nand extraction and introduces some of their applications. Some numerical\nimplementations are also shown for these methods. Finally, the methods in\nfeature selection and extraction are compared.\n",
        "published": "2019",
        "authors": [
            "Benyamin Ghojogh",
            "Maria N. Samad",
            "Sayema Asif Mashhadi",
            "Tania Kapoor",
            "Wahab Ali",
            "Fakhri Karray",
            "Mark Crowley"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.03776v1",
        "title": "The Effect of Network Width on Stochastic Gradient Descent and\n  Generalization: an Empirical Study",
        "abstract": "  We investigate how the final parameters found by stochastic gradient descent\nare influenced by over-parameterization. We generate families of models by\nincreasing the number of channels in a base network, and then perform a large\nhyper-parameter search to study how the test error depends on learning rate,\nbatch size, and network width. We find that the optimal SGD hyper-parameters\nare determined by a \"normalized noise scale,\" which is a function of the batch\nsize, learning rate, and initialization conditions. In the absence of batch\nnormalization, the optimal normalized noise scale is directly proportional to\nwidth. Wider networks, with their higher optimal noise scale, also achieve\nhigher test accuracy. These observations hold for MLPs, ConvNets, and ResNets,\nand for two different parameterization schemes (\"Standard\" and \"NTK\"). We\nobserve a similar trend with batch normalization for ResNets. Surprisingly,\nsince the largest stable learning rate is bounded, the largest batch size\nconsistent with the optimal normalized noise scale decreases as the width\nincreases.\n",
        "published": "2019",
        "authors": [
            "Daniel S. Park",
            "Jascha Sohl-Dickstein",
            "Quoc V. Le",
            "Samuel L. Smith"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.07446v1",
        "title": "Limitations and Biases in Facial Landmark Detection -- An Empirical\n  Study on Older Adults with Dementia",
        "abstract": "  Accurate facial expression analysis is an essential step in various clinical\napplications that involve physical and mental health assessments of older\nadults (e.g. diagnosis of pain or depression). Although remarkable progress has\nbeen achieved toward developing robust facial landmark detection methods,\nstate-of-the-art methods still face many challenges when encountering\nuncontrolled environments, different ranges of facial expressions, and\ndifferent demographics of the population. A recent study has revealed that the\nhealth status of individuals can also affect the performance of facial landmark\ndetection methods on front views of faces. In this work, we investigate this\nmatter in a much greater context using seven facial landmark detection methods.\nWe perform our evaluation not only on frontal faces but also on profile faces\nand in various regions of the face. Our results shed light on limitations of\nthe existing methods and challenges of applying these methods in clinical\nsettings by indicating: 1) a significant difference between the performance of\nstate-of-the-art when tested on the profile or frontal faces of individuals\nwith vs. without dementia; 2) insights on the existing bias for all regions of\nthe face; and 3) the presence of this bias despite re-training/fine-tuning with\nvarious configurations of six datasets.\n",
        "published": "2019",
        "authors": [
            "Azin Asgarian",
            "Shun Zhao",
            "Ahmed B. Ashraf",
            "M. Erin Browne",
            "Kenneth M. Prkachin",
            "Alex Mihailidis",
            "Thomas Hadjistavropoulos",
            "Babak Taati"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.08616v4",
        "title": "Unsupervised Depth Completion from Visual Inertial Odometry",
        "abstract": "  We describe a method to infer dense depth from camera motion and sparse depth\nas estimated using a visual-inertial odometry system. Unlike other scenarios\nusing point clouds from lidar or structured light sensors, we have few hundreds\nto few thousand points, insufficient to inform the topology of the scene. Our\nmethod first constructs a piecewise planar scaffolding of the scene, and then\nuses it to infer dense depth using the image along with the sparse points. We\nuse a predictive cross-modal criterion, akin to `self-supervision,' measuring\nphotometric consistency across time, forward-backward pose consistency, and\ngeometric compatibility with the sparse point cloud. We also launch the first\nvisual-inertial + depth dataset, which we hope will foster additional\nexploration into combining the complementary strengths of visual and inertial\nsensors. To compare our method to prior work, we adopt the unsupervised KITTI\ndepth completion benchmark, and show state-of-the-art performance on it. Code\navailable at:\nhttps://github.com/alexklwong/unsupervised-depth-completion-visual-inertial-odometry.\n",
        "published": "2019",
        "authors": [
            "Alex Wong",
            "Xiaohan Fei",
            "Stephanie Tsuei",
            "Stefano Soatto"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.10710v3",
        "title": "Fixing Bias in Reconstruction-based Anomaly Detection with Lipschitz\n  Discriminators",
        "abstract": "  Anomaly detection is of great interest in fields where abnormalities need to\nbe identified and corrected (e.g., medicine and finance). Deep learning methods\nfor this task often rely on autoencoder reconstruction error, sometimes in\nconjunction with other errors. We show that this approach exhibits intrinsic\nbiases that lead to undesirable results. Reconstruction-based methods are\nsensitive to training-data outliers and simple-to-reconstruct points. Instead,\nwe introduce a new unsupervised Lipschitz anomaly discriminator that does not\nsuffer from these biases. Our anomaly discriminator is trained, similar to the\nones used in GANs, to detect the difference between the training data and\ncorruptions of the training data. We show that this procedure successfully\ndetects unseen anomalies with guarantees on those that have a certain\nWasserstein distance from the data or corrupted training set. These additions\nallow us to show improved performance on MNIST, CIFAR10, and health record\ndata.\n",
        "published": "2019",
        "authors": [
            "Alexander Tong",
            "Guy Wolf",
            "Smita Krishnaswamy"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.13560v1",
        "title": "Evaluating Artificial Systems for Pairwise Ranking Tasks Sensitive to\n  Individual Differences",
        "abstract": "  Owing to the advancement of deep learning, artificial systems are now rival\nto humans in several pattern recognition tasks, such as visual recognition of\nobject categories. However, this is only the case with the tasks for which\ncorrect answers exist independent of human perception. There is another type of\ntasks for which what to predict is human perception itself, in which there are\noften individual differences. Then, there are no longer single \"correct\"\nanswers to predict, which makes evaluation of artificial systems difficult. In\nthis paper, focusing on pairwise ranking tasks sensitive to individual\ndifferences, we propose an evaluation method. Given a ranking result for\nmultiple item pairs that is generated by an artificial system, our method\nquantifies the probability that the same ranking result will be generated by\nhumans, and judges if it is distinguishable from human-generated results. We\nintroduce a probabilistic model of human ranking behavior, and present an\nefficient computation method for the judgment. To estimate model parameters\naccurately from small-size samples, we present a method that uses confidence\nscores given by annotators for ranking each item pair. Taking as an example a\ntask of ranking image pairs according to material attributes of objects, we\ndemonstrate how the proposed method works.\n",
        "published": "2019",
        "authors": [
            "Xing Liu",
            "Takayuki Okatani"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.02355v1",
        "title": "Neural SDE: Stabilizing Neural ODE Networks with Stochastic Noise",
        "abstract": "  Neural Ordinary Differential Equation (Neural ODE) has been proposed as a\ncontinuous approximation to the ResNet architecture. Some commonly used\nregularization mechanisms in discrete neural networks (e.g. dropout, Gaussian\nnoise) are missing in current Neural ODE networks. In this paper, we propose a\nnew continuous neural network framework called Neural Stochastic Differential\nEquation (Neural SDE) network, which naturally incorporates various commonly\nused regularization mechanisms based on random noise injection. Our framework\ncan model various types of noise injection frequently used in discrete networks\nfor regularization purpose, such as dropout and additive/multiplicative noise\nin each block. We provide theoretical analysis explaining the improved\nrobustness of Neural SDE models against input perturbations/adversarial\nattacks. Furthermore, we demonstrate that the Neural SDE network can achieve\nbetter generalization than the Neural ODE and is more resistant to adversarial\nand non-adversarial input perturbations.\n",
        "published": "2019",
        "authors": [
            "Xuanqing Liu",
            "Tesi Xiao",
            "Si Si",
            "Qin Cao",
            "Sanjiv Kumar",
            "Cho-Jui Hsieh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.02425v2",
        "title": "Uncertainty-guided Continual Learning with Bayesian Neural Networks",
        "abstract": "  Continual learning aims to learn new tasks without forgetting previously\nlearned ones. This is especially challenging when one cannot access data from\nprevious tasks and when the model has a fixed capacity. Current\nregularization-based continual learning algorithms need an external\nrepresentation and extra computation to measure the parameters'\n\\textit{importance}. In contrast, we propose Uncertainty-guided Continual\nBayesian Neural Networks (UCB), where the learning rate adapts according to the\nuncertainty defined in the probability distribution of the weights in networks.\nUncertainty is a natural way to identify \\textit{what to remember} and\n\\textit{what to change} as we continually learn, and thus mitigate catastrophic\nforgetting. We also show a variant of our model, which uses uncertainty for\nweight pruning and retains task performance after pruning by saving binary\nmasks per tasks. We evaluate our UCB approach extensively on diverse object\nclassification datasets with short and long sequences of tasks and report\nsuperior or on-par performance compared to existing approaches. Additionally,\nwe show that our model does not necessarily need task information at test time,\ni.e. it does not presume knowledge of which task a sample belongs to.\n",
        "published": "2019",
        "authors": [
            "Sayna Ebrahimi",
            "Mohamed Elhoseiny",
            "Trevor Darrell",
            "Marcus Rohrbach"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.04569v1",
        "title": "DropConnect Is Effective in Modeling Uncertainty of Bayesian Deep\n  Networks",
        "abstract": "  Deep neural networks (DNNs) have achieved state-of-the-art performances in\nmany important domains, including medical diagnosis, security, and autonomous\ndriving. In these domains where safety is highly critical, an erroneous\ndecision can result in serious consequences. While a perfect prediction\naccuracy is not always achievable, recent work on Bayesian deep networks shows\nthat it is possible to know when DNNs are more likely to make mistakes. Knowing\nwhat DNNs do not know is desirable to increase the safety of deep learning\ntechnology in sensitive applications. Bayesian neural networks attempt to\naddress this challenge. However, traditional approaches are computationally\nintractable and do not scale well to large, complex neural network\narchitectures. In this paper, we develop a theoretical framework to approximate\nBayesian inference for DNNs by imposing a Bernoulli distribution on the model\nweights. This method, called MC-DropConnect, gives us a tool to represent the\nmodel uncertainty with little change in the overall model structure or\ncomputational cost. We extensively validate the proposed algorithm on multiple\nnetwork architectures and datasets for classification and semantic segmentation\ntasks. We also propose new metrics to quantify the uncertainty estimates. This\nenables an objective comparison between MC-DropConnect and prior approaches.\nOur empirical results demonstrate that the proposed framework yields\nsignificant improvement in both prediction accuracy and uncertainty estimation\nquality compared to the state of the art.\n",
        "published": "2019",
        "authors": [
            "Aryan Mobiny",
            "Hien V. Nguyen",
            "Supratik Moulik",
            "Naveen Garg",
            "Carol C. Wu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.09744v3",
        "title": "Improving the Effectiveness and Efficiency of Stochastic Neighbour\n  Embedding with Isolation Kernel",
        "abstract": "  This paper presents a new insight into improving the performance of\nStochastic Neighbour Embedding (t-SNE) by using Isolation kernel instead of\nGaussian kernel. Isolation kernel outperforms Gaussian kernel in two aspects.\nFirst, the use of Isolation kernel in t-SNE overcomes the drawback of\nmisrepresenting some structures in the data, which often occurs when Gaussian\nkernel is applied in t-SNE. This is because Gaussian kernel determines each\nlocal bandwidth based on one local point only, while Isolation kernel is\nderived directly from the data based on space partitioning. Second, the use of\nIsolation kernel yields a more efficient similarity computation because\ndata-dependent Isolation kernel has only one parameter that needs to be tuned.\nIn contrast, the use of data-independent Gaussian kernel increases the\ncomputational cost by determining n bandwidths for a dataset of n points. As\nthe root cause of these deficiencies in t-SNE is Gaussian kernel, we show that\nsimply replacing Gaussian kernel with Isolation kernel in t-SNE significantly\nimproves the quality of the final visualisation output (without creating\nmisrepresented structures) and removes one key obstacle that prevents t-SNE\nfrom processing large datasets. Moreover, Isolation kernel enables t-SNE to\ndeal with large-scale datasets in less runtime without trading off accuracy,\nunlike existing methods in speeding up t-SNE.\n",
        "published": "2019",
        "authors": [
            "Ye Zhu",
            "Kai Ming Ting"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.11898v2",
        "title": "InsectUp: Crowdsourcing Insect Observations to Assess Demographic Shifts\n  and Improve Classification",
        "abstract": "  Insects play such a crucial role in ecosystems that a shift in demography of\njust a few species can have devastating consequences at environmental, social\nand economic levels. Despite this, evaluation of insect demography is strongly\nlimited by the difficulty of collecting census data at sufficient scale. We\npropose a method to gather and leverage observations from bystanders, hikers,\nand entomology enthusiasts in order to provide researchers with data that could\nsignificantly help anticipate and identify environmental threats. Finally, we\nshow that there is indeed interest on both sides for such collaboration.\n",
        "published": "2019",
        "authors": [
            "L\u00e9onard Boussioux",
            "Tom\u00e1s Giro-Larraz",
            "Charles Guille-Escuret",
            "Mehdi Cherti",
            "Bal\u00e1zs K\u00e9gl"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1909.03712v1",
        "title": "Latent Multi-view Semi-Supervised Classification",
        "abstract": "  To explore underlying complementary information from multiple views, in this\npaper, we propose a novel Latent Multi-view Semi-Supervised Classification\n(LMSSC) method. Unlike most existing multi-view semi-supervised classification\nmethods that learn the graph using original features, our method seeks an\nunderlying latent representation and performs graph learning and label\npropagation based on the learned latent representation. With the\ncomplementarity of multiple views, the latent representation could depict the\ndata more comprehensively than every single view individually, accordingly\nmaking the graph more accurate and robust as well. Finally, LMSSC integrates\nlatent representation learning, graph construction, and label propagation into\na unified framework, which makes each subtask optimized. Experimental results\non real-world benchmark datasets validate the effectiveness of our proposed\nmethod.\n",
        "published": "2019",
        "authors": [
            "Xiaofan Bo",
            "Zhao Kang",
            "Zhitong Zhao",
            "Yuanzhang Su",
            "Wenyu Chen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1909.05479v2",
        "title": "Generating Accurate Pseudo-labels in Semi-Supervised Learning and\n  Avoiding Overconfident Predictions via Hermite Polynomial Activations",
        "abstract": "  Rectified Linear Units (ReLUs) are among the most widely used activation\nfunction in a broad variety of tasks in vision. Recent theoretical results\nsuggest that despite their excellent practical performance, in various cases, a\nsubstitution with basis expansions (e.g., polynomials) can yield significant\nbenefits from both the optimization and generalization perspective.\nUnfortunately, the existing results remain limited to networks with a couple of\nlayers, and the practical viability of these results is not yet known.\nMotivated by some of these results, we explore the use of Hermite polynomial\nexpansions as a substitute for ReLUs in deep networks. While our experiments\nwith supervised learning do not provide a clear verdict, we find that this\nstrategy offers considerable benefits in semi-supervised learning (SSL) /\ntransductive learning settings. We carefully develop this idea and show how the\nuse of Hermite polynomials based activations can yield improvements in\npseudo-label accuracies and sizable financial savings (due to concurrent\nruntime benefits). Further, we show via theoretical analysis, that the networks\n(with Hermite activations) offer robustness to noise and other attractive\nmathematical properties.\n",
        "published": "2019",
        "authors": [
            "Vishnu Suresh Lokhande",
            "Songwong Tasneeyapant",
            "Abhay Venkatesh",
            "Sathya N. Ravi",
            "Vikas Singh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1909.06008v1",
        "title": "Multiple Partitions Aligned Clustering",
        "abstract": "  Multi-view clustering is an important yet challenging task due to the\ndifficulty of integrating the information from multiple representations. Most\nexisting multi-view clustering methods explore the heterogeneous information in\nthe space where the data points lie. Such common practice may cause significant\ninformation loss because of unavoidable noise or inconsistency among views.\nSince different views admit the same cluster structure, the natural space\nshould be all partitions. Orthogonal to existing techniques, in this paper, we\npropose to leverage the multi-view information by fusing partitions.\nSpecifically, we align each partition to form a consensus cluster indicator\nmatrix through a distinct rotation matrix. Moreover, a weight is assigned for\neach view to account for the clustering capacity differences of views. Finally,\nthe basic partitions, weights, and consensus clustering are jointly learned in\na unified framework. We demonstrate the effectiveness of our approach on\nseveral real datasets, where significant improvement is found over other\nstate-of-the-art multi-view clustering methods.\n",
        "published": "2019",
        "authors": [
            "Zhao Kang",
            "Zipeng Guo",
            "Shudong Huang",
            "Siying Wang",
            "Wenyu Chen",
            "Yuanzhang Su",
            "Zenglin Xu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1909.09656v2",
        "title": "Understanding and Robustifying Differentiable Architecture Search",
        "abstract": "  Differentiable Architecture Search (DARTS) has attracted a lot of attention\ndue to its simplicity and small search costs achieved by a continuous\nrelaxation and an approximation of the resulting bi-level optimization problem.\nHowever, DARTS does not work robustly for new problems: we identify a wide\nrange of search spaces for which DARTS yields degenerate architectures with\nvery poor test performance. We study this failure mode and show that, while\nDARTS successfully minimizes validation loss, the found solutions generalize\npoorly when they coincide with high validation loss curvature in the\narchitecture space. We show that by adding one of various types of\nregularization we can robustify DARTS to find solutions with less curvature and\nbetter generalization properties. Based on these observations, we propose\nseveral simple variations of DARTS that perform substantially more robustly in\npractice. Our observations are robust across five search spaces on three image\nclassification tasks and also hold for the very different domains of disparity\nestimation (a dense regression task) and language modelling.\n",
        "published": "2019",
        "authors": [
            "Arber Zela",
            "Thomas Elsken",
            "Tonmoy Saikia",
            "Yassine Marrakchi",
            "Thomas Brox",
            "Frank Hutter"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1911.03849v5",
        "title": "Minimalistic Attacks: How Little it Takes to Fool a Deep Reinforcement\n  Learning Policy",
        "abstract": "  Recent studies have revealed that neural network-based policies can be easily\nfooled by adversarial examples. However, while most prior works analyze the\neffects of perturbing every pixel of every frame assuming white-box policy\naccess, in this paper we take a more restrictive view towards adversary\ngeneration - with the goal of unveiling the limits of a model's vulnerability.\nIn particular, we explore minimalistic attacks by defining three key settings:\n(1) black-box policy access: where the attacker only has access to the input\n(state) and output (action probability) of an RL policy; (2) fractional-state\nadversary: where only several pixels are perturbed, with the extreme case being\na single-pixel adversary; and (3) tactically-chanced attack: where only\nsignificant frames are tactically chosen to be attacked. We formulate the\nadversarial attack by accommodating the three key settings and explore their\npotency on six Atari games by examining four fully trained state-of-the-art\npolicies. In Breakout, for example, we surprisingly find that: (i) all policies\nshowcase significant performance degradation by merely modifying 0.01% of the\ninput state, and (ii) the policy trained by DQN is totally deceived by\nperturbation to only 1% frames.\n",
        "published": "2019",
        "authors": [
            "Xinghua Qu",
            "Zhu Sun",
            "Yew-Soon Ong",
            "Abhishek Gupta",
            "Pengfei Wei"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1911.05275v1",
        "title": "Learning from a Teacher using Unlabeled Data",
        "abstract": "  Knowledge distillation is a widely used technique for model compression. We\nposit that the teacher model used in a distillation setup, captures\nrelationships between classes, that extend beyond the original dataset. We\nempirically show that a teacher model can transfer this knowledge to a student\nmodel even on an {\\it out-of-distribution} dataset. Using this approach, we\nshow promising results on MNIST, CIFAR-10, and Caltech-256 datasets using\nunlabeled image data from different sources. Our results are encouraging and\nhelp shed further light from the perspective of understanding knowledge\ndistillation and utilizing unlabeled data to improve model quality.\n",
        "published": "2019",
        "authors": [
            "Gaurav Menghani",
            "Sujith Ravi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1911.09017v1",
        "title": "Towards a Unified Evaluation of Explanation Methods without Ground Truth",
        "abstract": "  This paper proposes a set of criteria to evaluate the objectiveness of\nexplanation methods of neural networks, which is crucial for the development of\nexplainable AI, but it also presents significant challenges. The core challenge\nis that people usually cannot obtain ground-truth explanations of the neural\nnetwork. To this end, we design four metrics to evaluate explanation results\nwithout ground-truth explanations. Our metrics can be broadly applied to nine\nbenchmark methods of interpreting neural networks, which provides new insights\nof explanation methods.\n",
        "published": "2019",
        "authors": [
            "Hao Zhang",
            "Jiayi Chen",
            "Haotian Xue",
            "Quanshi Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1911.12126v4",
        "title": "Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture\n  Search",
        "abstract": "  Differentiable Architecture Search (DARTS) is now a widely disseminated\nweight-sharing neural architecture search method. However, it suffers from\nwell-known performance collapse due to an inevitable aggregation of skip\nconnections. In this paper, we first disclose that its root cause lies in an\nunfair advantage in exclusive competition. Through experiments, we show that if\neither of two conditions is broken, the collapse disappears. Thereby, we\npresent a novel approach called Fair DARTS where the exclusive competition is\nrelaxed to be collaborative. Specifically, we let each operation's\narchitectural weight be independent of others. Yet there is still an important\nissue of discretization discrepancy. We then propose a zero-one loss to push\narchitectural weights towards zero or one, which approximates an expected\nmulti-hot solution. Our experiments are performed on two mainstream search\nspaces, and we derive new state-of-the-art results on CIFAR-10 and ImageNet.\nOur code is available on https://github.com/xiaomi-automl/fairdarts .\n",
        "published": "2019",
        "authors": [
            "Xiangxiang Chu",
            "Tianbao Zhou",
            "Bo Zhang",
            "Jixiang Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2002.01650v5",
        "title": "Concept Whitening for Interpretable Image Recognition",
        "abstract": "  What does a neural network encode about a concept as we traverse through the\nlayers? Interpretability in machine learning is undoubtedly important, but the\ncalculations of neural networks are very challenging to understand. Attempts to\nsee inside their hidden layers can either be misleading, unusable, or rely on\nthe latent space to possess properties that it may not have. In this work,\nrather than attempting to analyze a neural network posthoc, we introduce a\nmechanism, called concept whitening (CW), to alter a given layer of the network\nto allow us to better understand the computation leading up to that layer. When\na concept whitening module is added to a CNN, the axes of the latent space are\naligned with known concepts of interest. By experiment, we show that CW can\nprovide us a much clearer understanding for how the network gradually learns\nconcepts over layers. CW is an alternative to a batch normalization layer in\nthat it normalizes, and also decorrelates (whitens) the latent space. CW can be\nused in any layer of the network without hurting predictive performance.\n",
        "published": "2020",
        "authors": [
            "Zhi Chen",
            "Yijie Bei",
            "Cynthia Rudin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2002.08641v2",
        "title": "A Novel Framework for Selection of GANs for an Application",
        "abstract": "  Generative Adversarial Network (GAN) is a current focal point of research.\nThe body of knowledge is fragmented, leading to a trial-error method while\nselecting an appropriate GAN for a given scenario. We provide a comprehensive\nsummary of the evolution of GANs starting from its inception addressing issues\nlike mode collapse, vanishing gradient, unstable training and non-convergence.\nWe also provide a comparison of various GANs from the application point of\nview, its behaviour and implementation details. We propose a novel framework to\nidentify candidate GANs for a specific use case based on architecture, loss,\nregularization and divergence. We also discuss application of the framework\nusing an example, and we demonstrate a significant reduction in search space.\nThis efficient way to determine potential GANs lowers unit economics of AI\ndevelopment for organizations.\n",
        "published": "2020",
        "authors": [
            "Tanya Motwani",
            "Manojkumar Parmar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.00695v3",
        "title": "On the Generalization Effects of Linear Transformations in Data\n  Augmentation",
        "abstract": "  Data augmentation is a powerful technique to improve performance in\napplications such as image and text classification tasks. Yet, there is little\nrigorous understanding of why and how various augmentations work. In this work,\nwe consider a family of linear transformations and study their effects on the\nridge estimator in an over-parametrized linear regression setting. First, we\nshow that transformations that preserve the labels of the data can improve\nestimation by enlarging the span of the training data. Second, we show that\ntransformations that mix data can improve estimation by playing a\nregularization effect. Finally, we validate our theoretical insights on MNIST.\nBased on the insights, we propose an augmentation scheme that searches over the\nspace of transformations by how uncertain the model is about the transformed\ndata. We validate our proposed scheme on image and text datasets. For example,\nour method outperforms random sampling methods by 1.24% on CIFAR-100 using\nWide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA\nAdversarial AutoAugment on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.\n",
        "published": "2020",
        "authors": [
            "Sen Wu",
            "Hongyang R. Zhang",
            "Gregory Valiant",
            "Christopher R\u00e9"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.02269v2",
        "title": "Towards explainable classifiers using the counterfactual approach --\n  global explanations for discovering bias in data",
        "abstract": "  The paper proposes summarized attribution-based post-hoc explanations for the\ndetection and identification of bias in data. A global explanation is proposed,\nand a step-by-step framework on how to detect and test bias is introduced.\nSince removing unwanted bias is often a complicated and tremendous task, it is\nautomatically inserted, instead. Then, the bias is evaluated with the proposed\ncounterfactual approach. The obtained results are validated on a sample skin\nlesion dataset. Using the proposed method, a number of possible bias causing\nartifacts are successfully identified and confirmed in dermoscopy images. In\nparticular, it is confirmed that black frames have a strong influence on\nConvolutional Neural Network's prediction: 22% of them changed the prediction\nfrom benign to malignant.\n",
        "published": "2020",
        "authors": [
            "Agnieszka Miko\u0142ajczyk",
            "Micha\u0142 Grochowski",
            "Arkadiusz Kwasigroch"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.03632v2",
        "title": "Visualisation and knowledge discovery from interpretable models",
        "abstract": "  Increasing number of sectors which affect human lives, are using Machine\nLearning (ML) tools. Hence the need for understanding their working mechanism\nand evaluating their fairness in decision-making, are becoming paramount,\nushering in the era of Explainable AI (XAI). In this contribution we introduced\na few intrinsically interpretable models which are also capable of dealing with\nmissing values, in addition to extracting knowledge from the dataset and about\nthe problem. These models are also capable of visualisation of the classifier\nand decision boundaries: they are the angle based variants of Learning Vector\nQuantization. We have demonstrated the algorithms on a synthetic dataset and a\nreal-world one (heart disease dataset from the UCI repository). The newly\ndeveloped classifiers helped in investigating the complexities of the UCI\ndataset as a multiclass problem. The performance of the developed classifiers\nwere comparable to those reported in literature for this dataset, with\nadditional value of interpretability, when the dataset was treated as a binary\nclass problem.\n",
        "published": "2020",
        "authors": [
            "Sreejita Ghosh",
            "Peter Tino",
            "Kerstin Bunte"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.09162v1",
        "title": "A New Validity Index for Fuzzy-Possibilistic C-Means Clustering",
        "abstract": "  In some complicated datasets, due to the presence of noisy data points and\noutliers, cluster validity indices can give conflicting results in determining\nthe optimal number of clusters. This paper presents a new validity index for\nfuzzy-possibilistic c-means clustering called Fuzzy-Possibilistic (FP) index,\nwhich works well in the presence of clusters that vary in shape and density.\nMoreover, FPCM like most of the clustering algorithms is susceptible to some\ninitial parameters. In this regard, in addition to the number of clusters, FPCM\nrequires a priori selection of the degree of fuzziness and the degree of\ntypicality. Therefore, we presented an efficient procedure for determining\ntheir optimal values. The proposed approach has been evaluated using several\nsynthetic and real-world datasets. Final computational results demonstrate the\ncapabilities and reliability of the proposed approach compared with several\nwell-known fuzzy validity indices in the literature. Furthermore, to clarify\nthe ability of the proposed method in real applications, the proposed method is\nimplemented in microarray gene expression data clustering and medical image\nsegmentation.\n",
        "published": "2020",
        "authors": [
            "Mohammad Hossein Fazel Zarandi",
            "Shahabeddin Sotudian",
            "Oscar Castillo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.10349v2",
        "title": "Adversarial Canonical Correlation Analysis",
        "abstract": "  Canonical Correlation Analysis (CCA) is a statistical technique used to\nextract common information from multiple data sources or views. It has been\nused in various representation learning problems, such as dimensionality\nreduction, word embedding, and clustering. Recent work has given CCA\nprobabilistic footing in a deep learning context and uses a variational lower\nbound for the data log likelihood to estimate model parameters. Alternatively,\nadversarial techniques have arisen in recent years as a powerful alternative to\nvariational Bayesian methods in autoencoders. In this work, we explore\nstraightforward adversarial alternatives to recent work in Deep Variational CCA\n(VCCA and VCCA-Private) we call ACCA and ACCA-Private and show how these\napproaches offer a stronger and more flexible way to match the approximate\nposteriors coming from encoders to much larger classes of priors than the VCCA\nand VCCA-Private models. This allows new priors for what constitutes a good\nrepresentation, such as disentangling underlying factors of variation, to be\nmore directly pursued. We offer further analysis on the multi-level\ndisentangling properties of VCCA-Private and ACCA-Private through the use of a\nnewly designed dataset we call Tangled MNIST. We also design a validation\ncriteria for these models that is theoretically grounded, task-agnostic, and\nworks well in practice. Lastly, we fill a minor research gap by deriving an\nadditional variational lower bound for VCCA that allows the representation to\nuse view-specific information from both input views.\n",
        "published": "2020",
        "authors": [
            "Benjamin Dutton"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.01027v2",
        "title": "DARTS-: Robustly Stepping out of Performance Collapse Without Indicators",
        "abstract": "  Despite the fast development of differentiable architecture search (DARTS),\nit suffers from long-standing performance instability, which extremely limits\nits application. Existing robustifying methods draw clues from the resulting\ndeteriorated behavior instead of finding out its causing factor. Various\nindicators such as Hessian eigenvalues are proposed as a signal to stop\nsearching before the performance collapses. However, these indicator-based\nmethods tend to easily reject good architectures if the thresholds are\ninappropriately set, let alone the searching is intrinsically noisy. In this\npaper, we undertake a more subtle and direct approach to resolve the collapse.\nWe first demonstrate that skip connections have a clear advantage over other\ncandidate operations, where it can easily recover from a disadvantageous state\nand become dominant. We conjecture that this privilege is causing degenerated\nperformance. Therefore, we propose to factor out this benefit with an auxiliary\nskip connection, ensuring a fairer competition for all operations. We call this\napproach DARTS-. Extensive experiments on various datasets verify that it can\nsubstantially improve robustness. Our code is available at\nhttps://github.com/Meituan-AutoML/DARTS- .\n",
        "published": "2020",
        "authors": [
            "Xiangxiang Chu",
            "Xiaoxing Wang",
            "Bo Zhang",
            "Shun Lu",
            "Xiaolin Wei",
            "Junchi Yan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.03651v1",
        "title": "Learning more expressive joint distributions in multimodal variational\n  methods",
        "abstract": "  Data often are formed of multiple modalities, which jointly describe the\nobserved phenomena. Modeling the joint distribution of multimodal data requires\nlarger expressive power to capture high-level concepts and provide better data\nrepresentations. However, multimodal generative models based on variational\ninference are limited due to the lack of flexibility of the approximate\nposterior, which is obtained by searching within a known parametric family of\ndistributions. We introduce a method that improves the representational\ncapacity of multimodal variational methods using normalizing flows. It\napproximates the joint posterior with a simple parametric distribution and\nsubsequently transforms into a more complex one. Through several experiments,\nwe demonstrate that the model improves on state-of-the-art multimodal methods\nbased on variational inference on various computer vision tasks such as\ncolorization, edge and mask detection, and weakly supervised learning. We also\nshow that learning more powerful approximate joint distributions improves the\nquality of the generated samples. The code of our model is publicly available\nat https://github.com/SashoNedelkoski/BPFDMVM.\n",
        "published": "2020",
        "authors": [
            "Sasho Nedelkoski",
            "Mihail Bogojeski",
            "Odej Kao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.06114v1",
        "title": "Towards the Quantification of Safety Risks in Deep Neural Networks",
        "abstract": "  Safety concerns on the deep neural networks (DNNs) have been raised when they\nare applied to critical sectors. In this paper, we define safety risks by\nrequesting the alignment of the network's decision with human perception. To\nenable a general methodology for quantifying safety risks, we define a generic\nsafety property and instantiate it to express various safety risks. For the\nquantification of risks, we take the maximum radius of safe norm balls, in\nwhich no safety risk exists. The computation of the maximum safe radius is\nreduced to the computation of their respective Lipschitz metrics - the\nquantities to be computed. In addition to the known adversarial example,\nreachability example, and invariant example, in this paper we identify a new\nclass of risk - uncertainty example - on which humans can tell easily but the\nnetwork is unsure. We develop an algorithm, inspired by derivative-free\noptimization techniques and accelerated by tensor-based parallelization on\nGPUs, to support efficient computation of the metrics. We perform evaluations\non several benchmark neural networks, including ACSC-Xu, MNIST, CIFAR-10, and\nImageNet networks. The experiments show that, our method can achieve\ncompetitive performance on safety quantification in terms of the tightness and\nthe efficiency of computation. Importantly, as a generic approach, our method\ncan work with a broad class of safety risks and without restrictions on the\nstructure of neural networks.\n",
        "published": "2020",
        "authors": [
            "Peipei Xu",
            "Wenjie Ruan",
            "Xiaowei Huang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.06962v2",
        "title": "Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup",
        "abstract": "  While deep neural networks achieve great performance on fitting the training\ndistribution, the learned networks are prone to overfitting and are susceptible\nto adversarial attacks. In this regard, a number of mixup based augmentation\nmethods have been recently proposed. However, these approaches mainly focus on\ncreating previously unseen virtual examples and can sometimes provide\nmisleading supervisory signal to the network. To this end, we propose Puzzle\nMix, a mixup method for explicitly utilizing the saliency information and the\nunderlying statistics of the natural examples. This leads to an interesting\noptimization problem alternating between the multi-label objective for optimal\nmixing mask and saliency discounted optimal transport objective. Our\nexperiments show Puzzle Mix achieves the state of the art generalization and\nthe adversarial robustness results compared to other mixup methods on\nCIFAR-100, Tiny-ImageNet, and ImageNet datasets. The source code is available\nat https://github.com/snu-mllab/PuzzleMix.\n",
        "published": "2020",
        "authors": [
            "Jang-Hyun Kim",
            "Wonho Choo",
            "Hyun Oh Song"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.07974v1",
        "title": "Analysis of Generalizability of Deep Neural Networks Based on the\n  Complexity of Decision Boundary",
        "abstract": "  For supervised learning models, the analysis of generalization ability\n(generalizability) is vital because the generalizability expresses how well a\nmodel will perform on unseen data. Traditional generalization methods, such as\nthe VC dimension, do not apply to deep neural network (DNN) models. Thus, new\ntheories to explain the generalizability of DNNs are required. In this study,\nwe hypothesize that the DNN with a simpler decision boundary has better\ngeneralizability by the law of parsimony (Occam's Razor). We create the\ndecision boundary complexity (DBC) score to define and measure the complexity\nof decision boundary of DNNs. The idea of the DBC score is to generate data\npoints (called adversarial examples) on or near the decision boundary. Our new\napproach then measures the complexity of the boundary using the entropy of\neigenvalues of these data. The method works equally well for high-dimensional\ndata. We use training data and the trained model to compute the DBC score. And,\nthe ground truth for model's generalizability is its test accuracy. Experiments\nbased on the DBC score have verified our hypothesis. The DBC is shown to\nprovide an effective method to measure the complexity of a decision boundary\nand gives a quantitative measure of the generalizability of DNNs.\n",
        "published": "2020",
        "authors": [
            "Shuyue Guan",
            "Murray Loew"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.08319v3",
        "title": "Decoupling Representation Learning from Reinforcement Learning",
        "abstract": "  In an effort to overcome limitations of reward-driven feature learning in\ndeep reinforcement learning (RL) from images, we propose decoupling\nrepresentation learning from policy learning. To this end, we introduce a new\nunsupervised learning (UL) task, called Augmented Temporal Contrast (ATC),\nwhich trains a convolutional encoder to associate pairs of observations\nseparated by a short time difference, under image augmentations and using a\ncontrastive loss. In online RL experiments, we show that training the encoder\nexclusively using ATC matches or outperforms end-to-end RL in most\nenvironments. Additionally, we benchmark several leading UL algorithms by\npre-training encoders on expert demonstrations and using them, with weights\nfrozen, in RL agents; we find that agents using ATC-trained encoders outperform\nall others. We also train multi-task encoders on data from multiple\nenvironments and show generalization to different downstream RL tasks. Finally,\nwe ablate components of ATC, and introduce a new data augmentation to enable\nreplay of (compressed) latent images from pre-trained encoders when RL requires\naugmentation. Our experiments span visually diverse RL benchmarks in DeepMind\nControl, DeepMind Lab, and Atari, and our complete code is available at\nhttps://github.com/astooke/rlpyt/tree/master/rlpyt/ul.\n",
        "published": "2020",
        "authors": [
            "Adam Stooke",
            "Kimin Lee",
            "Pieter Abbeel",
            "Michael Laskin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.09318v2",
        "title": "Efficient Certification of Spatial Robustness",
        "abstract": "  Recent work has exposed the vulnerability of computer vision models to vector\nfield attacks. Due to the widespread usage of such models in safety-critical\napplications, it is crucial to quantify their robustness against such spatial\ntransformations. However, existing work only provides empirical robustness\nquantification against vector field deformations via adversarial attacks, which\nlack provable guarantees. In this work, we propose novel convex relaxations,\nenabling us, for the first time, to provide a certificate of robustness against\nvector field transformations. Our relaxations are model-agnostic and can be\nleveraged by a wide range of neural network verifiers. Experiments on various\nnetwork architectures and different datasets demonstrate the effectiveness and\nscalability of our method.\n",
        "published": "2020",
        "authors": [
            "Anian Ruoss",
            "Maximilian Baader",
            "Mislav Balunovi\u0107",
            "Martin Vechev"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.09929v1",
        "title": "CVPR 2020 Continual Learning in Computer Vision Competition: Approaches,\n  Results, Current Challenges and Future Directions",
        "abstract": "  In the last few years, we have witnessed a renewed and fast-growing interest\nin continual learning with deep neural networks with the shared objective of\nmaking current AI systems more adaptive, efficient and autonomous. However,\ndespite the significant and undoubted progress of the field in addressing the\nissue of catastrophic forgetting, benchmarking different continual learning\napproaches is a difficult task by itself. In fact, given the proliferation of\ndifferent settings, training and evaluation protocols, metrics and\nnomenclature, it is often tricky to properly characterize a continual learning\nalgorithm, relate it to other solutions and gauge its real-world applicability.\nThe first Continual Learning in Computer Vision challenge held at CVPR in 2020\nhas been one of the first opportunities to evaluate different continual\nlearning algorithms on a common hardware with a large set of shared evaluation\nmetrics and 3 different settings based on the realistic CORe50 video benchmark.\nIn this paper, we report the main results of the competition, which counted\nmore than 79 teams registered, 11 finalists and 2300$ in prizes. We also\nsummarize the winning approaches, current challenges and future research\ndirections.\n",
        "published": "2020",
        "authors": [
            "Vincenzo Lomonaco",
            "Lorenzo Pellegrini",
            "Pau Rodriguez",
            "Massimo Caccia",
            "Qi She",
            "Yu Chen",
            "Quentin Jodelet",
            "Ruiping Wang",
            "Zheda Mai",
            "David Vazquez",
            "German I. Parisi",
            "Nikhil Churamani",
            "Marc Pickett",
            "Issam Laradji",
            "Davide Maltoni"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.10893v1",
        "title": "Pruning Convolutional Filters using Batch Bridgeout",
        "abstract": "  State-of-the-art computer vision models are rapidly increasing in capacity,\nwhere the number of parameters far exceeds the number required to fit the\ntraining set. This results in better optimization and generalization\nperformance. However, the huge size of contemporary models results in large\ninference costs and limits their use on resource-limited devices. In order to\nreduce inference costs, convolutional filters in trained neural networks could\nbe pruned to reduce the run-time memory and computational requirements during\ninference. However, severe post-training pruning results in degraded\nperformance if the training algorithm results in dense weight vectors. We\npropose the use of Batch Bridgeout, a sparsity inducing stochastic\nregularization scheme, to train neural networks so that they could be pruned\nefficiently with minimal degradation in performance. We evaluate the proposed\nmethod on common computer vision models VGGNet, ResNet, and Wide-ResNet on the\nCIFAR image classification task. For all the networks, experimental results\nshow that Batch Bridgeout trained networks achieve higher accuracy across a\nwide range of pruning intensities compared to Dropout and weight decay\nregularization.\n",
        "published": "2020",
        "authors": [
            "Najeeb Khan",
            "Ian Stavness"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.11729v4",
        "title": "Interpreting and Boosting Dropout from a Game-Theoretic View",
        "abstract": "  This paper aims to understand and improve the utility of the dropout\noperation from the perspective of game-theoretic interactions. We prove that\ndropout can suppress the strength of interactions between input variables of\ndeep neural networks (DNNs). The theoretic proof is also verified by various\nexperiments. Furthermore, we find that such interactions were strongly related\nto the over-fitting problem in deep learning. Thus, the utility of dropout can\nbe regarded as decreasing interactions to alleviate the significance of\nover-fitting. Based on this understanding, we propose an interaction loss to\nfurther improve the utility of dropout. Experimental results have shown that\nthe interaction loss can effectively improve the utility of dropout and boost\nthe performance of DNNs.\n",
        "published": "2020",
        "authors": [
            "Hao Zhang",
            "Sen Li",
            "Yinchao Ma",
            "Mingjie Li",
            "Yichen Xie",
            "Quanshi Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.11848v5",
        "title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural\n  Networks",
        "abstract": "  We study how neural networks trained by gradient descent extrapolate, i.e.,\nwhat they learn outside the support of the training distribution. Previous\nworks report mixed empirical results when extrapolating with neural networks:\nwhile feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not\nextrapolate well in certain simple tasks, Graph Neural Networks (GNNs) --\nstructured networks with MLP modules -- have shown some success in more complex\ntasks. Working towards a theoretical explanation, we identify conditions under\nwhich MLPs and GNNs extrapolate well. First, we quantify the observation that\nReLU MLPs quickly converge to linear functions along any direction from the\norigin, which implies that ReLU MLPs do not extrapolate most nonlinear\nfunctions. But, they can provably learn a linear target function when the\ntraining distribution is sufficiently \"diverse\". Second, in connection to\nanalyzing the successes and limitations of GNNs, these results suggest a\nhypothesis for which we provide theoretical and empirical evidence: the success\nof GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or\nedge weights) relies on encoding task-specific non-linearities in the\narchitecture or features. Our theoretical analysis builds on a connection of\nover-parameterized networks to the neural tangent kernel. Empirically, our\ntheory holds across different training settings.\n",
        "published": "2020",
        "authors": [
            "Keyulu Xu",
            "Mozhi Zhang",
            "Jingling Li",
            "Simon S. Du",
            "Ken-ichi Kawarabayashi",
            "Stefanie Jegelka"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.13504v5",
        "title": "Information Obfuscation of Graph Neural Networks",
        "abstract": "  While the advent of Graph Neural Networks (GNNs) has greatly improved node\nand graph representation learning in many applications, the neighborhood\naggregation scheme exposes additional vulnerabilities to adversaries seeking to\nextract node-level information about sensitive attributes. In this paper, we\nstudy the problem of protecting sensitive attributes by information obfuscation\nwhen learning with graph structured data. We propose a framework to locally\nfilter out pre-determined sensitive attributes via adversarial training with\nthe total variation and the Wasserstein distance. Our method creates a strong\ndefense against inference attacks, while only suffering small loss in task\nperformance. Theoretically, we analyze the effectiveness of our framework\nagainst a worst-case adversary, and characterize an inherent trade-off between\nmaximizing predictive accuracy and minimizing information leakage. Experiments\nacross multiple datasets from recommender systems, knowledge graphs and quantum\nchemistry demonstrate that the proposed approach provides a robust defense\nacross various graph structures and tasks, while producing competitive GNN\nencoders for downstream tasks.\n",
        "published": "2020",
        "authors": [
            "Peiyuan Liao",
            "Han Zhao",
            "Keyulu Xu",
            "Tommi Jaakkola",
            "Geoffrey Gordon",
            "Stefanie Jegelka",
            "Ruslan Salakhutdinov"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.13714v4",
        "title": "Learning to Generate Image Source-Agnostic Universal Adversarial\n  Perturbations",
        "abstract": "  Adversarial perturbations are critical for certifying the robustness of deep\nlearning models. A universal adversarial perturbation (UAP) can simultaneously\nattack multiple images, and thus offers a more unified threat model, obviating\nan image-wise attack algorithm. However, the existing UAP generator is\nunderdeveloped when images are drawn from different image sources (e.g., with\ndifferent image resolutions). Towards an authentic universality across image\nsources, we take a novel view of UAP generation as a customized instance of\nfew-shot learning, which leverages bilevel optimization and\nlearning-to-optimize (L2O) techniques for UAP generation with improved attack\nsuccess rate (ASR). We begin by considering the popular model agnostic\nmeta-learning (MAML) framework to meta-learn a UAP generator. However, we see\nthat the MAML framework does not directly offer the universal attack across\nimage sources, requiring us to integrate it with another meta-learning\nframework of L2O. The resulting scheme for meta-learning a UAP generator (i)\nhas better performance (50% higher ASR) than baselines such as Projected\nGradient Descent, (ii) has better performance (37% faster) than the vanilla L2O\nand MAML frameworks (when applicable), and (iii) is able to simultaneously\nhandle UAP generation for different victim models and image data sources.\n",
        "published": "2020",
        "authors": [
            "Pu Zhao",
            "Parikshit Ram",
            "Songtao Lu",
            "Yuguang Yao",
            "Djallel Bouneffouf",
            "Xue Lin",
            "Sijia Liu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.13939v1",
        "title": "Tackling unsupervised multi-source domain adaptation with optimism and\n  consistency",
        "abstract": "  It has been known for a while that the problem of multi-source domain\nadaptation can be regarded as a single source domain adaptation task where the\nsource domain corresponds to a mixture of the original source domains.\nNonetheless, how to adjust the mixture distribution weights remains an open\nquestion. Moreover, most existing work on this topic focuses only on minimizing\nthe error on the source domains and achieving domain-invariant representations,\nwhich is insufficient to ensure low error on the target domain. In this work,\nwe present a novel framework that addresses both problems and beats the current\nstate of the art by using a mildly optimistic objective function and\nconsistency regularization on the target samples.\n",
        "published": "2020",
        "authors": [
            "Diogo Pernes",
            "Jaime S. Cardoso"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.08668v3",
        "title": "Mitigating Bias in Calibration Error Estimation",
        "abstract": "  For an AI system to be reliable, the confidence it expresses in its decisions\nmust match its accuracy. To assess the degree of match, examples are typically\nbinned by confidence and the per-bin mean confidence and accuracy are compared.\nMost research in calibration focuses on techniques to reduce this empirical\nmeasure of calibration error, ECE_bin. We instead focus on assessing\nstatistical bias in this empirical measure, and we identify better estimators.\nWe propose a framework through which we can compute the bias of a particular\nestimator for an evaluation data set of a given size. The framework involves\nsynthesizing model outputs that have the same statistics as common neural\narchitectures on popular data sets. We find that binning-based estimators with\nbins of equal mass (number of instances) have lower bias than estimators with\nbins of equal width. Our results indicate two reliable calibration-error\nestimators: the debiased estimator (Brocker, 2012; Ferro and Fricker, 2012) and\na method we propose, ECE_sweep, which uses equal-mass bins and chooses the\nnumber of bins to be as large as possible while preserving monotonicity in the\ncalibration function. With these estimators, we observe improvements in the\neffectiveness of recalibration methods and in the detection of model\nmiscalibration.\n",
        "published": "2020",
        "authors": [
            "Rebecca Roelofs",
            "Nicholas Cain",
            "Jonathon Shlens",
            "Michael C. Mozer"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.03065v1",
        "title": "Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity",
        "abstract": "  While deep neural networks show great performance on fitting to the training\ndistribution, improving the networks' generalization performance to the test\ndistribution and robustness to the sensitivity to input perturbations still\nremain as a challenge. Although a number of mixup based augmentation strategies\nhave been proposed to partially address them, it remains unclear as to how to\nbest utilize the supervisory signal within each input data for mixup from the\noptimization perspective. We propose a new perspective on batch mixup and\nformulate the optimal construction of a batch of mixup data maximizing the data\nsaliency measure of each individual mixup data and encouraging the supermodular\ndiversity among the constructed mixup data. This leads to a novel discrete\noptimization problem minimizing the difference between submodular functions. We\nalso propose an efficient modular approximation based iterative submodular\nminimization algorithm for efficient mixup computation per each minibatch\nsuitable for minibatch based neural network training. Our experiments show the\nproposed method achieves the state of the art generalization, calibration, and\nweakly supervised localization results compared to other mixup methods. The\nsource code is available at https://github.com/snu-mllab/Co-Mixup.\n",
        "published": "2021",
        "authors": [
            "Jang-Hyun Kim",
            "Wonho Choo",
            "Hosan Jeong",
            "Hyun Oh Song"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.04154v1",
        "title": "Efficient Certified Defenses Against Patch Attacks on Image Classifiers",
        "abstract": "  Adversarial patches pose a realistic threat model for physical world attacks\non autonomous systems via their perception component. Autonomous systems in\nsafety-critical domains such as automated driving should thus contain a\nfail-safe fallback component that combines certifiable robustness against\npatches with efficient inference while maintaining high performance on clean\ninputs. We propose BagCert, a novel combination of model architecture and\ncertification procedure that allows efficient certification. We derive a loss\nthat enables end-to-end optimization of certified robustness against patches of\ndifferent sizes and locations. On CIFAR10, BagCert certifies 10.000 examples in\n43 seconds on a single GPU and obtains 86% clean and 60% certified accuracy\nagainst 5x5 patches.\n",
        "published": "2021",
        "authors": [
            "Jan Hendrik Metzen",
            "Maksym Yatsura"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.08248v7",
        "title": "Hierarchical VAEs Know What They Don't Know",
        "abstract": "  Deep generative models have been demonstrated as state-of-the-art density\nestimators. Yet, recent work has found that they often assign a higher\nlikelihood to data from outside the training distribution. This seemingly\nparadoxical behavior has caused concerns over the quality of the attained\ndensity estimates. In the context of hierarchical variational autoencoders, we\nprovide evidence to explain this behavior by out-of-distribution data having\nin-distribution low-level features. We argue that this is both expected and\ndesirable behavior. With this insight in hand, we develop a fast, scalable and\nfully unsupervised likelihood-ratio score for OOD detection that requires data\nto be in-distribution across all feature-levels. We benchmark the method on a\nvast set of data and model combinations and achieve state-of-the-art results on\nout-of-distribution detection.\n",
        "published": "2021",
        "authors": [
            "Jakob D. Havtorn",
            "Jes Frellsen",
            "S\u00f8ren Hauberg",
            "Lars Maal\u00f8e"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.11856v1",
        "title": "Meta-Learned Attribute Self-Gating for Continual Generalized Zero-Shot\n  Learning",
        "abstract": "  Zero-shot learning (ZSL) has been shown to be a promising approach to\ngeneralizing a model to categories unseen during training by leveraging class\nattributes, but challenges still remain. Recently, methods using generative\nmodels to combat bias towards classes seen during training have pushed the\nstate of the art of ZSL, but these generative models can be slow or\ncomputationally expensive to train. Additionally, while many previous ZSL\nmethods assume a one-time adaptation to unseen classes, in reality, the world\nis always changing, necessitating a constant adjustment for deployed models.\nModels unprepared to handle a sequential stream of data are likely to\nexperience catastrophic forgetting. We propose a meta-continual zero-shot\nlearning (MCZSL) approach to address both these issues. In particular, by\npairing self-gating of attributes and scaled class normalization with\nmeta-learning based training, we are able to outperform state-of-the-art\nresults while being able to train our models substantially faster\n($>100\\times$) than expensive generative-based approaches. We demonstrate this\nby performing experiments on five standard ZSL datasets (CUB, aPY, AWA1, AWA2\nand SUN) in both generalized zero-shot learning and generalized continual\nzero-shot learning settings.\n",
        "published": "2021",
        "authors": [
            "Vinay Kumar Verma",
            "Kevin Liang",
            "Nikhil Mehta",
            "Lawrence Carin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.12781v3",
        "title": "Do Input Gradients Highlight Discriminative Features?",
        "abstract": "  Post-hoc gradient-based interpretability methods [Simonyan et al., 2013,\nSmilkov et al., 2017] that provide instance-specific explanations of model\npredictions are often based on assumption (A): magnitude of input gradients --\ngradients of logits with respect to input -- noisily highlight discriminative\ntask-relevant features. In this work, we test the validity of assumption (A)\nusing a three-pronged approach. First, we develop an evaluation framework,\nDiffROAR, to test assumption (A) on four image classification benchmarks. Our\nresults suggest that (i) input gradients of standard models (i.e., trained on\noriginal data) may grossly violate (A), whereas (ii) input gradients of\nadversarially robust models satisfy (A). Second, we introduce BlockMNIST, an\nMNIST-based semi-real dataset, that by design encodes a priori knowledge of\ndiscriminative features. Our analysis on BlockMNIST leverages this information\nto validate as well as characterize differences between input gradient\nattributions of standard and robust models. Finally, we theoretically prove\nthat our empirical findings hold on a simplified version of the BlockMNIST\ndataset. Specifically, we prove that input gradients of standard\none-hidden-layer MLPs trained on this dataset do not highlight\ninstance-specific signal coordinates, thus grossly violating assumption (A).\nOur findings motivate the need to formalize and test common assumptions in\ninterpretability in a falsifiable manner [Leavitt and Morcos, 2020]. We believe\nthat the DiffROAR evaluation framework and BlockMNIST-based datasets can serve\nas sanity checks to audit instance-specific interpretability methods; code and\ndata available at https://github.com/harshays/inputgradients.\n",
        "published": "2021",
        "authors": [
            "Harshay Shah",
            "Prateek Jain",
            "Praneeth Netrapalli"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2103.01890v1",
        "title": "Have We Learned to Explain?: How Interpretability Methods Can Learn to\n  Encode Predictions in their Interpretations",
        "abstract": "  While the need for interpretable machine learning has been established, many\ncommon approaches are slow, lack fidelity, or hard to evaluate. Amortized\nexplanation methods reduce the cost of providing interpretations by learning a\nglobal selector model that returns feature importances for a single instance of\ndata. The selector model is trained to optimize the fidelity of the\ninterpretations, as evaluated by a predictor model for the target. Popular\nmethods learn the selector and predictor model in concert, which we show allows\npredictions to be encoded within interpretations. We introduce EVAL-X as a\nmethod to quantitatively evaluate interpretations and REAL-X as an amortized\nexplanation method, which learn a predictor model that approximates the true\ndata generating distribution given any subset of the input. We show EVAL-X can\ndetect when predictions are encoded in interpretations and show the advantages\nof REAL-X through quantitative and radiologist evaluation.\n",
        "published": "2021",
        "authors": [
            "Neil Jethani",
            "Mukund Sudarshan",
            "Yindalon Aphinyanaphongs",
            "Rajesh Ranganath"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2103.01933v2",
        "title": "PHASE: PHysically-grounded Abstract Social Events for Machine Social\n  Perception",
        "abstract": "  The ability to perceive and reason about social interactions in the context\nof physical environments is core to human social intelligence and human-machine\ncooperation. However, no prior dataset or benchmark has systematically\nevaluated physically grounded perception of complex social interactions that go\nbeyond short actions, such as high-fiving, or simple group activities, such as\ngathering. In this work, we create a dataset of physically-grounded abstract\nsocial events, PHASE, that resemble a wide range of real-life social\ninteractions by including social concepts such as helping another agent. PHASE\nconsists of 2D animations of pairs of agents moving in a continuous space\ngenerated procedurally using a physics engine and a hierarchical planner.\nAgents have a limited field of view, and can interact with multiple objects, in\nan environment that has multiple landmarks and obstacles. Using PHASE, we\ndesign a social recognition task and a social prediction task. PHASE is\nvalidated with human experiments demonstrating that humans perceive rich\ninteractions in the social events, and that the simulated agents behave\nsimilarly to humans. As a baseline model, we introduce a Bayesian inverse\nplanning approach, SIMPLE (SIMulation, Planning and Local Estimation), which\noutperforms state-of-the-art feed-forward neural networks. We hope that PHASE\ncan serve as a difficult new challenge for developing new models that can\nrecognize complex social interactions.\n",
        "published": "2021",
        "authors": [
            "Aviv Netanyahu",
            "Tianmin Shu",
            "Boris Katz",
            "Andrei Barbu",
            "Joshua B. Tenenbaum"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2103.02325v2",
        "title": "On the effectiveness of adversarial training against common corruptions",
        "abstract": "  The literature on robustness towards common corruptions shows no consensus on\nwhether adversarial training can improve the performance in this setting.\nFirst, we show that, when used with an appropriately selected perturbation\nradius, $\\ell_p$ adversarial training can serve as a strong baseline against\ncommon corruptions improving both accuracy and calibration. Then we explain why\nadversarial training performs better than data augmentation with simple\nGaussian noise which has been observed to be a meaningful baseline on common\ncorruptions. Related to this, we identify the $\\sigma$-overfitting phenomenon\nwhen Gaussian augmentation overfits to a particular standard deviation used for\ntraining which has a significant detrimental effect on common corruption\naccuracy. We discuss how to alleviate this problem and then how to further\nenhance $\\ell_p$ adversarial training by introducing an efficient relaxation of\nadversarial training with learned perceptual image patch similarity as the\ndistance metric. Through experiments on CIFAR-10 and ImageNet-100, we show that\nour approach does not only improve the $\\ell_p$ adversarial training baseline\nbut also has cumulative gains with data augmentation methods such as AugMix,\nDeepAugment, ANT, and SIN, leading to state-of-the-art performance on common\ncorruptions.\n  The code of our experiments is publicly available at\nhttps://github.com/tml-epfl/adv-training-corruptions.\n",
        "published": "2021",
        "authors": [
            "Klim Kireev",
            "Maksym Andriushchenko",
            "Nicolas Flammarion"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2104.00170v2",
        "title": "An Investigation of Critical Issues in Bias Mitigation Techniques",
        "abstract": "  A critical problem in deep learning is that systems learn inappropriate\nbiases, resulting in their inability to perform well on minority groups. This\nhas led to the creation of multiple algorithms that endeavor to mitigate bias.\nHowever, it is not clear how effective these methods are. This is because study\nprotocols differ among papers, systems are tested on datasets that fail to test\nmany forms of bias, and systems have access to hidden knowledge or are tuned\nspecifically to the test set. To address this, we introduce an improved\nevaluation protocol, sensible metrics, and a new dataset, which enables us to\nask and answer critical questions about bias mitigation algorithms. We evaluate\nseven state-of-the-art algorithms using the same network architecture and\nhyperparameter selection policy across three benchmark datasets. We introduce a\nnew dataset called Biased MNIST that enables assessment of robustness to\nmultiple bias sources. We use Biased MNIST and a visual question answering\n(VQA) benchmark to assess robustness to hidden biases. Rather than only tuning\nto the test set distribution, we study robustness across different tuning\ndistributions, which is critical because for many applications the test\ndistribution may not be known during development. We find that algorithms\nexploit hidden biases, are unable to scale to multiple forms of bias, and are\nhighly sensitive to the choice of tuning set. Based on our findings, we implore\nthe community to adopt more rigorous assessment of future bias mitigation\nmethods. All data, code, and results are publicly available at:\nhttps://github.com/erobic/bias-mitigators.\n",
        "published": "2021",
        "authors": [
            "Robik Shrestha",
            "Kushal Kafle",
            "Christopher Kanan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2104.02768v1",
        "title": "Robust Semantic Interpretability: Revisiting Concept Activation Vectors",
        "abstract": "  Interpretability methods for image classification assess model\ntrustworthiness by attempting to expose whether the model is systematically\nbiased or attending to the same cues as a human would. Saliency methods for\nfeature attribution dominate the interpretability literature, but these methods\ndo not address semantic concepts such as the textures, colors, or genders of\nobjects within an image. Our proposed Robust Concept Activation Vectors (RCAV)\nquantifies the effects of semantic concepts on individual model predictions and\non model behavior as a whole. RCAV calculates a concept gradient and takes a\ngradient ascent step to assess model sensitivity to the given concept. By\ngeneralizing previous work on concept activation vectors to account for model\nnon-linearity, and by introducing stricter hypothesis testing, we show that\nRCAV yields interpretations which are both more accurate at the image level and\nrobust at the dataset level. RCAV, like saliency methods, supports the\ninterpretation of individual predictions. To evaluate the practical use of\ninterpretability methods as debugging tools, and the scientific use of\ninterpretability methods for identifying inductive biases (e.g. texture over\nshape), we construct two datasets and accompanying metrics for realistic\nbenchmarking of semantic interpretability methods. Our benchmarks expose the\nimportance of counterfactual augmentation and negative controls for quantifying\nthe practical usability of interpretability methods.\n",
        "published": "2021",
        "authors": [
            "Jacob Pfau",
            "Albert T. Young",
            "Jerome Wei",
            "Maria L. Wei",
            "Michael J. Keiser"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2104.03059v1",
        "title": "Differentiable Patch Selection for Image Recognition",
        "abstract": "  Neural Networks require large amounts of memory and compute to process high\nresolution images, even when only a small part of the image is actually\ninformative for the task at hand. We propose a method based on a differentiable\nTop-K operator to select the most relevant parts of the input to efficiently\nprocess high resolution images. Our method may be interfaced with any\ndownstream neural network, is able to aggregate information from different\npatches in a flexible way, and allows the whole model to be trained end-to-end\nusing backpropagation. We show results for traffic sign recognition,\ninter-patch relationship reasoning, and fine-grained recognition without using\nobject/part bounding box annotations during training.\n",
        "published": "2021",
        "authors": [
            "Jean-Baptiste Cordonnier",
            "Aravindh Mahendran",
            "Alexey Dosovitskiy",
            "Dirk Weissenborn",
            "Jakob Uszkoreit",
            "Thomas Unterthiner"
        ]
    }
]