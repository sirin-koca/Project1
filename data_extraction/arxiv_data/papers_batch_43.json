[
    {
        "id": "http://arxiv.org/abs/1712.08521v2",
        "title": "An Incremental Self-Organizing Architecture for Sensorimotor Learning\n  and Prediction",
        "abstract": "  During visuomotor tasks, robots must compensate for temporal delays inherent\nin their sensorimotor processing systems. Delay compensation becomes crucial in\na dynamic environment where the visual input is constantly changing, e.g.,\nduring the interacting with a human demonstrator. For this purpose, the robot\nmust be equipped with a prediction mechanism for using the acquired perceptual\nexperience to estimate possible future motor commands. In this paper, we\npresent a novel neural network architecture that learns prototypical visuomotor\nrepresentations and provides reliable predictions on the basis of the visual\ninput. These predictions are used to compensate for the delayed motor behavior\nin an online manner. We investigate the performance of our method with a set of\nexperiments comprising a humanoid robot that has to learn and generate visually\nperceived arm motion trajectories. We evaluate the accuracy in terms of mean\nprediction error and analyze the response of the network to novel movement\ndemonstrations. Additionally, we report experiments with incomplete data\nsequences, showing the robustness of the proposed architecture in the case of a\nnoisy and faulty visual sensor.\n",
        "published": "2017",
        "authors": [
            "Luiza Mici",
            "German I. Parisi",
            "Stefan Wermter"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.02790v1",
        "title": "Event-Based Angular Velocity Regression with Spiking Networks",
        "abstract": "  Spiking Neural Networks (SNNs) are bio-inspired networks that process\ninformation conveyed as temporal spikes rather than numeric values. A spiking\nneuron of an SNN only produces a spike whenever a significant number of spikes\noccur within a short period of time. Due to their spike-based computational\nmodel, SNNs can process output from event-based, asynchronous sensors without\nany pre-processing at extremely lower power unlike standard artificial neural\nnetworks. This is possible due to specialized neuromorphic hardware that\nimplements the highly-parallelizable concept of SNNs in silicon. Yet, SNNs have\nnot enjoyed the same rise of popularity as artificial neural networks. This not\nonly stems from the fact that their input format is rather unconventional but\nalso due to the challenges in training spiking networks. Despite their temporal\nnature and recent algorithmic advances, they have been mostly evaluated on\nclassification problems. We propose, for the first time, a temporal regression\nproblem of numerical values given events from an event camera. We specifically\ninvestigate the prediction of the 3-DOF angular velocity of a rotating event\ncamera with an SNN. The difficulty of this problem arises from the prediction\nof angular velocities continuously in time directly from irregular,\nasynchronous event-based input. Directly utilising the output of event cameras\nwithout any pre-processing ensures that we inherit all the benefits that they\nprovide over conventional cameras. That is high-temporal resolution,\nhigh-dynamic range and no motion blur. To assess the performance of SNNs on\nthis task, we introduce a synthetic event camera dataset generated from\nreal-world panoramic images and show that we can successfully train an SNN to\nperform angular velocity regression.\n",
        "published": "2020",
        "authors": [
            "Mathias Gehrig",
            "Sumit Bam Shrestha",
            "Daniel Mouritzen",
            "Davide Scaramuzza"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.13662v3",
        "title": "SCFusion: Real-time Incremental Scene Reconstruction with Semantic\n  Completion",
        "abstract": "  Real-time scene reconstruction from depth data inevitably suffers from\nocclusion, thus leading to incomplete 3D models. Partial reconstructions, in\nturn, limit the performance of algorithms that leverage them for applications\nin the context of, e.g., augmented reality, robotic navigation, and 3D mapping.\nMost methods address this issue by predicting the missing geometry as an\noffline optimization, thus being incompatible with real-time applications. We\npropose a framework that ameliorates this issue by performing scene\nreconstruction and semantic scene completion jointly in an incremental and\nreal-time manner, based on an input sequence of depth maps. Our framework\nrelies on a novel neural architecture designed to process occupancy maps and\nleverages voxel states to accurately and efficiently fuse semantic completion\nwith the 3D global model. We evaluate the proposed approach quantitatively and\nqualitatively, demonstrating that our method can obtain accurate 3D semantic\nscene completion in real-time.\n",
        "published": "2020",
        "authors": [
            "Shun-Cheng Wu",
            "Keisuke Tateno",
            "Nassir Navab",
            "Federico Tombari"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.06562v1",
        "title": "SpikeMS: Deep Spiking Neural Network for Motion Segmentation",
        "abstract": "  Spiking Neural Networks (SNN) are the so-called third generation of neural\nnetworks which attempt to more closely match the functioning of the biological\nbrain. They inherently encode temporal data, allowing for training with less\nenergy usage and can be extremely energy efficient when coded on neuromorphic\nhardware. In addition, they are well suited for tasks involving event-based\nsensors, which match the event-based nature of the SNN. However, SNNs have not\nbeen as effectively applied to real-world, large-scale tasks as standard\nArtificial Neural Networks (ANNs) due to the algorithmic and training\ncomplexity. To exacerbate the situation further, the input representation is\nunconventional and requires careful analysis and deep understanding. In this\npaper, we propose \\textit{SpikeMS}, the first deep encoder-decoder SNN\narchitecture for the real-world large-scale problem of motion segmentation\nusing the event-based DVS camera as input. To accomplish this, we introduce a\nnovel spatio-temporal loss formulation that includes both spike counts and\nclassification labels in conjunction with the use of new techniques for SNN\nbackpropagation. In addition, we show that \\textit{SpikeMS} is capable of\n\\textit{incremental predictions}, or predictions from smaller amounts of test\ndata than it is trained on. This is invaluable for providing outputs even with\npartial input data for low-latency applications and those requiring fast\npredictions. We evaluated \\textit{SpikeMS} on challenging synthetic and\nreal-world sequences from EV-IMO, EED and MOD datasets and achieving results on\na par with a comparable ANN method, but using potentially 50 times less power.\n",
        "published": "2021",
        "authors": [
            "Chethan M. Parameshwara",
            "Simin Li",
            "Cornelia Ferm\u00fcller",
            "Nitin J. Sanket",
            "Matthew S. Evanusa",
            "Yiannis Aloimonos"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.04319v1",
        "title": "ST-MNIST -- The Spiking Tactile MNIST Neuromorphic Dataset",
        "abstract": "  Tactile sensing is an essential modality for smart robots as it enables them\nto interact flexibly with physical objects in their environment. Recent\nadvancements in electronic skins have led to the development of data-driven\nmachine learning methods that exploit this important sensory modality. However,\ncurrent datasets used to train such algorithms are limited to standard\nsynchronous tactile sensors. There is a dearth of neuromorphic event-based\ntactile datasets, principally due to the scarcity of large-scale event-based\ntactile sensors. Having such datasets is crucial for the development and\nevaluation of new algorithms that process spatio-temporal event-based data. For\nexample, evaluating spiking neural networks on conventional frame-based\ndatasets is considered sub-optimal. Here, we debut a novel neuromorphic Spiking\nTactile MNIST (ST-MNIST) dataset, which comprises handwritten digits obtained\nby human participants writing on a neuromorphic tactile sensor array. We also\ndescribe an initial effort to evaluate our ST-MNIST dataset using existing\nartificial and spiking neural network models. The classification accuracies\nprovided herein can serve as performance benchmarks for future work. We\nanticipate that our ST-MNIST dataset will be of interest and useful to the\nneuromorphic and robotics research communities.\n",
        "published": "2020",
        "authors": [
            "Hian Hian See",
            "Brian Lim",
            "Si Li",
            "Haicheng Yao",
            "Wen Cheng",
            "Harold Soh",
            "Benjamin C. K. Tee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2201.05314v4",
        "title": "A Novel Skeleton-Based Human Activity Discovery Using Particle Swarm\n  Optimization with Gaussian Mutation",
        "abstract": "  Human activity discovery aims to cluster the activities performed by humans\nwithout any prior information on what defines each activity. Most methods\npresented in human activity recognition are supervised, where there are labeled\ninputs to train the system. In reality, it is difficult to label activities\ndata because of its huge volume and the variety of human activities. This paper\nproposes an unsupervised framework to perform human activity discovery in 3D\nskeleton sequences. First, an approach for data pre-processing is presented. In\nthis stage, important frames are selected based on kinetic energy. Next, the\ndisplacement of joints, statistical displacements, angles, and orientation\nfeatures are extracted to represent the activities information. Since not all\nextracted features have useful information, the dimension of features is\nreduced using PCA. Most methods proposed for human activity discovery are not\nfully unsupervised. They use pre-segmented videos before categorizing\nactivities. To deal with this, we have used a sliding time window to segment\nthe time series of activities with some overlapping. Then, activities are\ndiscovered by our proposed Hybrid Particle swarm optimization (PSO) with\nGaussian Mutation and K-means (HPGMK) algorithm to provide diverse solutions.\nPSO is used due to its straightforward idea and powerful global search\ncapability which can identify the ideal solution in a few iterations. Finally,\nk-means is applied to the outcome centroids from each iteration of the PSO to\novercome the slow convergence rate of PSO. The experiment results on five\ndatasets show that the proposed framework has superior performance in\ndiscovering activities compared to the other state-of-the-art methods and has\nincreased accuracy of at least 4% on average.\n",
        "published": "2022",
        "authors": [
            "Parham Hadikhani",
            "Daphne Teck Ching Lai",
            "Wee-Hong Ong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2210.04236v1",
        "title": "Fusing Event-based Camera and Radar for SLAM Using Spiking Neural\n  Networks with Continual STDP Learning",
        "abstract": "  This work proposes a first-of-its-kind SLAM architecture fusing an\nevent-based camera and a Frequency Modulated Continuous Wave (FMCW) radar for\ndrone navigation. Each sensor is processed by a bio-inspired Spiking Neural\nNetwork (SNN) with continual Spike-Timing-Dependent Plasticity (STDP) learning,\nas observed in the brain. In contrast to most learning-based SLAM systems%,\nwhich a) require the acquisition of a representative dataset of the environment\nin which navigation must be performed and b) require an off-line training\nphase, our method does not require any offline training phase, but rather the\nSNN continuously learns features from the input data on the fly via STDP. At\nthe same time, the SNN outputs are used as feature descriptors for loop closure\ndetection and map correction. We conduct numerous experiments to benchmark our\nsystem against state-of-the-art RGB methods and we demonstrate the robustness\nof our DVS-Radar SLAM approach under strong lighting variations.\n",
        "published": "2022",
        "authors": [
            "Ali Safa",
            "Tim Verbelen",
            "Ilja Ocket",
            "Andr\u00e9 Bourdoux",
            "Hichem Sahli",
            "Francky Catthoor",
            "Georges Gielen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2212.07560v2",
        "title": "Multi-level and multi-modal feature fusion for accurate 3D object\n  detection in Connected and Automated Vehicles",
        "abstract": "  Aiming at highly accurate object detection for connected and automated\nvehicles (CAVs), this paper presents a Deep Neural Network based 3D object\ndetection model that leverages a three-stage feature extractor by developing a\nnovel LIDAR-Camera fusion scheme. The proposed feature extractor extracts\nhigh-level features from two input sensory modalities and recovers the\nimportant features discarded during the convolutional process. The novel fusion\nscheme effectively fuses features across sensory modalities and convolutional\nlayers to find the best representative global features. The fused features are\nshared by a two-stage network: the region proposal network (RPN) and the\ndetection head (DH). The RPN generates high-recall proposals, and the DH\nproduces final detection results. The experimental results show the proposed\nmodel outperforms more recent research on the KITTI 2D and 3D detection\nbenchmark, particularly for distant and highly occluded instances.\n",
        "published": "2022",
        "authors": [
            "Yiming Hou",
            "Mahdi Rezaei",
            "Richard Romano"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.09225v1",
        "title": "Autonomous Driving using Spiking Neural Networks on Dynamic Vision\n  Sensor Data: A Case Study of Traffic Light Change Detection",
        "abstract": "  Autonomous driving is a challenging task that has gained broad attention from\nboth academia and industry. Current solutions using convolutional neural\nnetworks require large amounts of computational resources, leading to high\npower consumption. Spiking neural networks (SNNs) provide an alternative\ncomputation model to process information and make decisions. This biologically\nplausible model has the advantage of low latency and energy efficiency. Recent\nwork using SNNs for autonomous driving mostly focused on simple tasks like lane\nkeeping in simplified simulation environments. This project studies SNNs on\nphoto-realistic driving scenes in the CARLA simulator, which is an important\nstep toward using SNNs on real vehicles. The efficacy and generalizability of\nthe method will be investigated.\n",
        "published": "2023",
        "authors": [
            "Xuelei Chen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1311.4527v1",
        "title": "A message-passing algorithm for multi-agent trajectory planning",
        "abstract": "  We describe a novel approach for computing collision-free \\emph{global}\ntrajectories for $p$ agents with specified initial and final configurations,\nbased on an improved version of the alternating direction method of multipliers\n(ADMM). Compared with existing methods, our approach is naturally\nparallelizable and allows for incorporating different cost functionals with\nonly minor adjustments. We apply our method to classical challenging instances\nand observe that its computational requirements scale well with $p$ for several\ncost functionals. We also show that a specialization of our algorithm can be\nused for {\\em local} motion planning by solving the problem of joint\noptimization in velocity space.\n",
        "published": "2013",
        "authors": [
            "Jose Bento",
            "Nate Derbinsky",
            "Javier Alonso-Mora",
            "Jonathan Yedidia"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.11262v2",
        "title": "How robots in a large group make decisions as a whole? From biological\n  inspiration to the design of distributed algorithms",
        "abstract": "  Nature provides us with abundant examples of how large numbers of individuals\ncan make decisions without the coordination of a central authority. Social\ninsects, birds, fishes, and many other living collectives, rely on simple\ninteraction mechanisms to do so. They individually gather information from the\nenvironment; small bits of a much larger picture that are then shared locally\namong the members of the collective and processed together to output a commonly\nagreed choice. Throughout evolution, Nature found solutions to collective\ndecision-making problems that are intriguing to engineers for their robustness\nto malfunctioning or lost individuals, their flexibility in face of dynamic\nenvironments, and their ability to scale with large numbers of members. In the\nlast decades, whereas biologists amassed large amounts of experimental\nevidence, engineers took inspiration from these and other examples to design\ndistributed algorithms that, while maintaining the same properties of their\nnatural counterparts, come with guarantees on their performance in the form of\npredictive mathematical models. In this paper, we review the fundamental\nprocesses that lead to a collective decision. We discuss examples of collective\ndecisions in biological systems and show how similar processes can be\nengineered to design artificial ones. During this journey, we review a\nframework to design distributed decision-making algorithms that are modular,\ncan be instantiated and extended in different ways, and are supported by a suit\nof predictive mathematical models.\n",
        "published": "2019",
        "authors": [
            "Gabriele Valentini"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2206.08185v2",
        "title": "UAVs Beneath the Surface: Cooperative Autonomy for Subterranean Search\n  and Rescue in DARPA SubT",
        "abstract": "  This paper presents a novel approach for autonomous cooperating UAVs in\nsearch and rescue operations in subterranean domains with complex topology. The\nproposed system was ranked second in the Virtual Track of the DARPA SubT Finals\nas part of the team CTU-CRAS-NORLAB. In contrast to the winning solution that\nwas developed specifically for the Virtual Track, the proposed solution also\nproved to be a robust system for deployment onboard physical UAVs flying in the\nextremely harsh and confined environment of the real-world competition. The\nproposed approach enables fully autonomous and decentralized deployment of a\nUAV team with seamless simulation-to-world transfer, and proves its advantage\nover less mobile UGV teams in the flyable space of diverse environments. The\nmain contributions of the paper are present in the mapping and navigation\npipelines. The mapping approach employs novel map representations -- SphereMap\nfor efficient risk-aware long-distance planning, FacetMap for surface coverage,\nand the compressed topological-volumetric LTVMap for allowing multi-robot\ncooperation under low-bandwidth communication. These representations are used\nin navigation together with novel methods for visibility-constrained informed\nsearch in a general 3D environment with no assumptions about the environment\nstructure, while balancing deep exploration with sensor-coverage exploitation.\nThe proposed solution also includes a visual-perception pipeline for on-board\ndetection and localization of objects of interest in four RGB stream at 5 Hz\neach without a dedicated GPU. Apart from participation in the DARPA SubT, the\nperformance of the UAV system is supported by extensive experimental\nverification in diverse environments with both qualitative and quantitative\nevaluation.\n",
        "published": "2022",
        "authors": [
            "Matej Petrlik",
            "Pavel Petracek",
            "Vit Kratky",
            "Tomas Musil",
            "Yurii Stasinchuk",
            "Matous Vrba",
            "Tomas Baca",
            "Daniel Hert",
            "Martin Pecka",
            "Tomas Svoboda",
            "Martin Saska"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2306.07142v1",
        "title": "Evolving Testing Scenario Generation Method and Intelligence Evaluation\n  Framework for Automated Vehicles",
        "abstract": "  Interaction between the background vehicles (BVs) and automated vehicles\n(AVs) in scenario-based testing plays a critical role in evaluating the\nintelligence of the AVs. Current testing scenarios typically employ predefined\nor scripted BVs, which inadequately reflect the complexity of human-like social\nbehaviors in real-world driving scenarios, and also lack a systematic metric\nfor evaluating the comprehensive intelligence of AVs. Therefore, this paper\nproposes an evolving scenario generation method that utilizes deep\nreinforcement learning (DRL) to create human-like BVs for testing and\nintelligence evaluation of AVs. Firstly, a class of driver models with\nhuman-like competitive, cooperative, and mutual driving motivations is\ndesigned. Then, utilizing an improved \"level-k\" training procedure, the three\ndistinct driver models acquire game-based interactive driving policies. And\nthese models are assigned to BVs for generating evolving scenarios in which all\nBVs can interact continuously and evolve diverse contents. Next, a framework\nincluding safety, driving efficiency, and interaction utility are presented to\nevaluate and quantify the intelligence performance of 3 systems under test\n(SUTs), indicating the effectiveness of the evolving scenario for intelligence\ntesting. Finally, the complexity and fidelity of the proposed evolving testing\nscenario are validated. The results demonstrate that the proposed evolving\nscenario exhibits the highest level of complexity compared to other baseline\nscenarios and has more than 85% similarity to naturalistic driving data. This\nhighlights the potential of the proposed method to facilitate the development\nand evaluation of high-level AVs in a realistic and challenging environment.\n",
        "published": "2023",
        "authors": [
            "Yining Ma",
            "Wei Jiang",
            "Lingtong Zhang",
            "Junyi Chen",
            "Hong Wang",
            "Chen Lv",
            "Xuesong Wang",
            "Lu Xiong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.12639v2",
        "title": "MAMPS: Safe Multi-Agent Reinforcement Learning via Model Predictive\n  Shielding",
        "abstract": "  Reinforcement learning is a promising approach to learning control policies\nfor performing complex multi-agent robotics tasks. However, a policy learned in\nsimulation often fails to guarantee even simple safety properties such as\nobstacle avoidance. To ensure safety, we propose multi-agent model predictive\nshielding (MAMPS), an algorithm that provably guarantees safety for an\narbitrary learned policy. In particular, it operates by using the learned\npolicy as often as possible, but instead uses a backup policy in cases where it\ncannot guarantee the safety of the learned policy. Using a multi-agent\nsimulation environment, we show how MAMPS can achieve good performance while\nensuring safety.\n",
        "published": "2019",
        "authors": [
            "Wenbo Zhang",
            "Osbert Bastani",
            "Vijay Kumar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.05205v2",
        "title": "Implicit Multiagent Coordination at Unsignalized Intersections via\n  Multimodal Inference Enabled by Topological Braids",
        "abstract": "  We focus on navigation among rational, non-communicating agents at\nunsignalized street intersections. Following collision-free motion under such\nsettings demands nuanced implicit coordination among agents. Often, the\nstructure of these domains constrains multiagent trajectories to belong to a\nfinite set of modes. Our key insight is that empowering agents with a model of\nthese modes can enable effective coordination, realized implicitly via intent\nsignals encoded in agents' actions. In this paper, we represent modes of joint\nbehavior in a compact and interpretable fashion using the formalism of\ntopological braids. We design a decentralized planning algorithm that generates\nactions aimed at reducing the uncertainty over the mode of the emerging\nmultiagent behavior. This mechanism enables agents that individually run our\nalgorithm to collectively reject unsafe intersection crossings. We validate our\napproach in a simulated case study featuring challenging multiagent scenarios\nat a four-way unsignalized intersection. Our model is shown to reduce frequency\nof collisions by >65% over a set of baselines explicitly reasoning over\ntrajectories, while maintaining comparable time efficiency.\n",
        "published": "2020",
        "authors": [
            "Christoforos Mavrogiannis",
            "Jonathan A. DeCastro",
            "Siddhartha S. Srinivasa"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.01925v1",
        "title": "Designing Autonomous Vehicles: Evaluating the Role of Human Emotions and\n  Social Norms",
        "abstract": "  Humans are going to delegate the rights of driving to the autonomous vehicles\nin near future. However, to fulfill this complicated task, there is a need for\na mechanism, which enforces the autonomous vehicles to obey the road and social\nrules that have been practiced by well-behaved drivers. This task can be\nachieved by introducing social norms compliance mechanism in the autonomous\nvehicles. This research paper is proposing an artificial society of autonomous\nvehicles as an analogy of human social society. Each AV has been assigned a\nsocial personality having different social influence. Social norms have been\nintroduced which help the AVs in making the decisions, influenced by emotions,\nregarding road collision avoidance. Furthermore, social norms compliance\nmechanism, by artificial social AVs, has been proposed using prospect based\nemotion i.e. fear, which is conceived from OCC model. Fuzzy logic has been\nemployed to compute the emotions quantitatively. Then, using SimConnect\napproach, fuzzy values of fear has been provided to the Netlogo simulation\nenvironment to simulate artificial society of AVs. Extensive testing has been\nperformed using the behavior space tool to find out the performance of the\nproposed approach in terms of the number of collisions. For comparison, the\nrandom-walk model based artificial society of AVs has been proposed as well. A\ncomparative study with a random walk, prove that proposed approach provides a\nbetter option to tailor the autopilots of future AVS, Which will be more\nsocially acceptable and trustworthy by their riders in terms of safe road\ntravel.\n",
        "published": "2017",
        "authors": [
            "Faisal Riaz",
            "Muaz A. Niazi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.03341v1",
        "title": "Technical Problems With \"Programmable self-assembly in a thousand-robot\n  swarm\"",
        "abstract": "  Rubenstein et al. present an interesting system of programmable\nself-assembled structure formation using 1000 Kilobot robots. The paper claims\nto advance work in artificial swarms similar to capabilities of natural systems\nbesides being highly robust. However, the system lacks in terms of matching\nmotility and complex shapes with holes, thereby limiting practical similarity\nto self-assembly in living systems.\n",
        "published": "2017",
        "authors": [
            "Muaz A. Niazi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.02530v3",
        "title": "Approximation Algorithms for Multi-Robot Patrol-Scheduling with Min-Max\n  Latency",
        "abstract": "  We consider the problem of finding patrol schedules for $k$ robots to visit a\ngiven set of $n$ sites in a metric space. Each robot has the same maximum speed\nand the goal is to minimize the weighted maximum latency of any site, where the\nlatency of a site is defined as the maximum time duration between consecutive\nvisits of that site. The problem is NP-hard, as it has the traveling salesman\nproblem as a special case (when $k=1$ and all sites have the same weight). We\npresent a polynomial-time algorithm with an approximation factor of $O(k^2 \\log\n\\frac{w_{\\max}}{w_{\\min}})$ to the optimal solution, where $w_{\\max}$ and\n$w_{\\min}$ are the maximum and minimum weight of the sites respectively.\nFurther, we consider the special case where the sites are in 1D. When all sites\nhave the same weight, we present a polynomial-time algorithm to solve the\nproblem exactly. If the sites may have different weights, we present a\n$12$-approximate solution, which runs in polynomial time when the number of\nrobots, $k$, is a constant.\n",
        "published": "2020",
        "authors": [
            "Peyman Afshani",
            "Mark De Berg",
            "Kevin Buchin",
            "Jie Gao",
            "Maarten Loffler",
            "Amir Nayyeri",
            "Benjamin Raichel",
            "Rik Sarkar",
            "Haotian Wang",
            "Hao-Tsung Yang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2203.04700v1",
        "title": "Multi-robot Cooperative Pursuit via Potential Field-Enhanced\n  Reinforcement Learning",
        "abstract": "  It is of great challenge, though promising, to coordinate collective robots\nfor hunting an evader in a decentralized manner purely in light of local\nobservations. In this paper, this challenge is addressed by a novel hybrid\ncooperative pursuit algorithm that combines reinforcement learning with the\nartificial potential field method. In the proposed algorithm, decentralized\ndeep reinforcement learning is employed to learn cooperative pursuit policies\nthat are adaptive to dynamic environments. The artificial potential field\nmethod is integrated into the learning process as predefined rules to improve\nthe data efficiency and generalization ability. It is shown by numerical\nsimulations that the proposed hybrid design outperforms the pursuit policies\neither learned from vanilla reinforcement learning or designed by the potential\nfield method. Furthermore, experiments are conducted by transferring the\nlearned pursuit policies into real-world mobile robots. Experimental results\ndemonstrate the feasibility and potential of the proposed algorithm in learning\nmultiple cooperative pursuit strategies.\n",
        "published": "2022",
        "authors": [
            "Zheng Zhang",
            "Xiaohan Wang",
            "Qingrui Zhang",
            "Tianjiang Hu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2210.09378v1",
        "title": "Learning Control Admissibility Models with Graph Neural Networks for\n  Multi-Agent Navigation",
        "abstract": "  Deep reinforcement learning in continuous domains focuses on learning control\npolicies that map states to distributions over actions that ideally concentrate\non the optimal choices in each step. In multi-agent navigation problems, the\noptimal actions depend heavily on the agents' density. Their interaction\npatterns grow exponentially with respect to such density, making it hard for\nlearning-based methods to generalize. We propose to switch the learning\nobjectives from predicting the optimal actions to predicting sets of admissible\nactions, which we call control admissibility models (CAMs), such that they can\nbe easily composed and used for online inference for an arbitrary number of\nagents. We design CAMs using graph neural networks and develop training methods\nthat optimize the CAMs in the standard model-free setting, with the additional\nbenefit of eliminating the need for reward engineering typically required to\nbalance collision avoidance and goal-reaching requirements. We evaluate the\nproposed approach in multi-agent navigation environments. We show that the CAM\nmodels can be trained in environments with only a few agents and be easily\ncomposed for deployment in dense environments with hundreds of agents,\nachieving better performance than state-of-the-art methods.\n",
        "published": "2022",
        "authors": [
            "Chenning Yu",
            "Hongzhan Yu",
            "Sicun Gao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2303.02962v1",
        "title": "New Era in Cultural Heritage Preservation: Cooperative Aerial Autonomy",
        "abstract": "  Digital documentation of large interiors of historical buildings is an\nexhausting task since most of the areas of interest are beyond typical human\nreach. We advocate the use of autonomous teams of multi-rotor Unmanned Aerial\nVehicles (UAVs) to speed up the documentation process by several orders of\nmagnitude while allowing for a repeatable, accurate, and condition-independent\nsolution capable of precise collision-free operation at great heights. The\nproposed multi-robot approach allows for performing tasks requiring dynamic\nscene illumination in large-scale real-world scenarios, a process previously\napplicable only in small-scale laboratory-like conditions. Extensive\nexperimental analyses range from single-UAV imaging to specialized lighting\ntechniques requiring accurate coordination of multiple UAVs. The system's\nrobustness is demonstrated in more than two hundred autonomous flights in\nfifteen historical monuments requiring superior safety while lacking access to\nexternal localization. This unique experimental campaign, cooperated with\nrestorers and conservators, brought numerous lessons transferable to other\nsafety-critical robotic missions in documentation and inspection tasks.\n",
        "published": "2023",
        "authors": [
            "Pavel Petracek",
            "Vit Kratky",
            "Tomas Baca",
            "Matej Petrlik",
            "Martin Saska"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2308.03146v1",
        "title": "Towards socially-competent and culturally-adaptive artificial agents\n  Expressive order, interactional disruptions and recovery strategies",
        "abstract": "  The development of artificial agents for social interaction pushes to enrich\nrobots with social skills and knowledge about (local) social norms. One\npossibility is to distinguish the expressive and the functional orders during a\nhuman-robot interaction. The overarching aim of this work is to set a framework\nto make the artificial agent socially-competent beyond dyadic\ninteraction-interaction in varying multi-party social situations-and beyond\nindividual-based user personalization, thereby enlarging the current conception\nof \"culturally-adaptive\". The core idea is to provide the artificial agent with\nthe capability to handle different kinds of interactional disruptions, and\nassociated recovery strategies, in microsociology. The result is obtained by\nclassifying functional and social disruptions, and by investigating the\nrequirements a robot's architecture should satisfy to exploit such knowledge.\nThe paper also highlights how this level of competence is achieved by focusing\non just three dimensions: (i) social capability, (ii) relational role, and\n(iii) proximity, leaving aside the further complexity of full-fledged\nhuman-human interactions. Without going into technical aspects, End-to-end\nData-driven Architectures and Modular Architectures are discussed to evaluate\nthe degree to which they can exploit this new set of social and cultural\nknowledge. Finally, a list of general requirements for such agents is proposed.\n",
        "published": "2023",
        "authors": [
            "Chiara Bassetti",
            "Enrico Blanzieri",
            "Stefano Borgo",
            "Sofia Marangon"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.06858v1",
        "title": "Scalable Decentralized Cooperative Platoon using Multi-Agent Deep\n  Reinforcement Learning",
        "abstract": "  Cooperative autonomous driving plays a pivotal role in improving road\ncapacity and safety within intelligent transportation systems, particularly\nthrough the deployment of autonomous vehicles on urban streets. By enabling\nvehicle-to-vehicle communication, these systems expand the vehicles\nenvironmental awareness, allowing them to detect hidden obstacles and thereby\nenhancing safety and reducing crash rates compared to human drivers who rely\nsolely on visual perception. A key application of this technology is vehicle\nplatooning, where connected vehicles drive in a coordinated formation. This\npaper introduces a vehicle platooning approach designed to enhance traffic flow\nand safety. Developed using deep reinforcement learning in the Unity 3D game\nengine, known for its advanced physics, this approach aims for a high-fidelity\nphysical simulation that closely mirrors real-world conditions. The proposed\nplatooning model focuses on scalability, decentralization, and fostering\npositive cooperation through the introduced predecessor-follower \"sharing and\ncaring\" communication framework. The study demonstrates how these elements\ncollectively enhance autonomous driving performance and robustness, both for\nindividual vehicles and for the platoon as a whole, in an urban setting. This\nresults in improved road safety and reduced traffic congestion.\n",
        "published": "2023",
        "authors": [
            "Ahmed Abdelrahman",
            "Omar M. Shehata",
            "Yarah Basyoni",
            "Elsayed I. Morgan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1108.3298v1",
        "title": "A Machine Learning Perspective on Predictive Coding with PAQ",
        "abstract": "  PAQ8 is an open source lossless data compression algorithm that currently\nachieves the best compression rates on many benchmarks. This report presents a\ndetailed description of PAQ8 from a statistical machine learning perspective.\nIt shows that it is possible to understand some of the modules of PAQ8 and use\nthis understanding to improve the method. However, intuitive statistical\nexplanations of the behavior of other modules remain elusive. We hope the\ndescription in this report will be a starting point for discussions that will\nincrease our understanding, lead to improvements to PAQ8, and facilitate a\ntransfer of knowledge from PAQ8 to other machine learning methods, such a\nrecurrent neural networks and stochastic memoizers. Finally, the report\npresents a broad range of new applications of PAQ to machine learning tasks\nincluding language modeling and adaptive text prediction, adaptive game\nplaying, classification, and compression using features from the field of deep\nlearning.\n",
        "published": "2011",
        "authors": [
            "Byron Knoll",
            "Nando de Freitas"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1304.1014v2",
        "title": "A Novel Frank-Wolfe Algorithm. Analysis and Applications to Large-Scale\n  SVM Training",
        "abstract": "  Recently, there has been a renewed interest in the machine learning community\nfor variants of a sparse greedy approximation procedure for concave\noptimization known as {the Frank-Wolfe (FW) method}. In particular, this\nprocedure has been successfully applied to train large-scale instances of\nnon-linear Support Vector Machines (SVMs). Specializing FW to SVM training has\nallowed to obtain efficient algorithms but also important theoretical results,\nincluding convergence analysis of training algorithms and new characterizations\nof model sparsity.\n  In this paper, we present and analyze a novel variant of the FW method based\non a new way to perform away steps, a classic strategy used to accelerate the\nconvergence of the basic FW procedure. Our formulation and analysis is focused\non a general concave maximization problem on the simplex. However, the\nspecialization of our algorithm to quadratic forms is strongly related to some\nclassic methods in computational geometry, namely the Gilbert and MDM\nalgorithms.\n  On the theoretical side, we demonstrate that the method matches the\nguarantees in terms of convergence rate and number of iterations obtained by\nusing classic away steps. In particular, the method enjoys a linear rate of\nconvergence, a result that has been recently proved for MDM on quadratic forms.\n  On the practical side, we provide experiments on several classification\ndatasets, and evaluate the results using statistical tests. Experiments show\nthat our method is faster than the FW method with classic away steps, and works\nwell even in the cases in which classic away steps slow down the algorithm.\nFurthermore, these improvements are obtained without sacrificing the predictive\naccuracy of the obtained SVM model.\n",
        "published": "2013",
        "authors": [
            "Hector Allende",
            "Emanuele Frandi",
            "Ricardo Nanculef",
            "Claudio Sartori"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1411.1752v1",
        "title": "Submodular meets Structured: Finding Diverse Subsets in\n  Exponentially-Large Structured Item Sets",
        "abstract": "  To cope with the high level of ambiguity faced in domains such as Computer\nVision or Natural Language processing, robust prediction methods often search\nfor a diverse set of high-quality candidate solutions or proposals. In\nstructured prediction problems, this becomes a daunting task, as the solution\nspace (image labelings, sentence parses, etc.) is exponentially large. We study\ngreedy algorithms for finding a diverse subset of solutions in\nstructured-output spaces by drawing new connections between submodular\nfunctions over combinatorial item sets and High-Order Potentials (HOPs) studied\nfor graphical models. Specifically, we show via examples that when marginal\ngains of submodular diversity functions allow structured representations, this\nenables efficient (sub-linear time) approximate maximization by reducing the\ngreedy augmentation step to inference in a factor graph with appropriately\nconstructed HOPs. We discuss benefits, tradeoffs, and show that our\nconstructions lead to significantly better proposals.\n",
        "published": "2014",
        "authors": [
            "Adarsh Prasad",
            "Stefanie Jegelka",
            "Dhruv Batra"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1705.02894v2",
        "title": "Geometric GAN",
        "abstract": "  Generative Adversarial Nets (GANs) represent an important milestone for\neffective generative models, which has inspired numerous variants seemingly\ndifferent from each other. One of the main contributions of this paper is to\nreveal a unified geometric structure in GAN and its variants. Specifically, we\nshow that the adversarial generative model training can be decomposed into\nthree geometric steps: separating hyperplane search, discriminator parameter\nupdate away from the separating hyperplane, and the generator update along the\nnormal vector direction of the separating hyperplane. This geometric intuition\nreveals the limitations of the existing approaches and leads us to propose a\nnew formulation called geometric GAN using SVM separating hyperplane that\nmaximizes the margin. Our theoretical analysis shows that the geometric GAN\nconverges to a Nash equilibrium between the discriminator and generator. In\naddition, extensive numerical results show that the superior performance of\ngeometric GAN.\n",
        "published": "2017",
        "authors": [
            "Jae Hyun Lim",
            "Jong Chul Ye"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.07247v2",
        "title": "Tensor-Tensor Product Toolbox",
        "abstract": "  The tensor-tensor product (t-product) [M. E. Kilmer and C. D. Martin, 2011]\nis a natural generalization of matrix multiplication. Based on t-product, many\noperations on matrix can be extended to tensor cases, including tensor SVD,\ntensor spectral norm, tensor nuclear norm [C. Lu, et al., 2018] and many\nothers. The linear algebraic structure of tensors are similar to the matrix\ncases. We develop a Matlab toolbox to implement several basic operations on\ntensors based on t-product. The toolbox is available at\nhttps://github.com/canyilu/tproduct.\n",
        "published": "2018",
        "authors": [
            "Canyi Lu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.11987v1",
        "title": "Deep learning for pedestrians: backpropagation in CNNs",
        "abstract": "  The goal of this document is to provide a pedagogical introduction to the\nmain concepts underpinning the training of deep neural networks using gradient\ndescent; a process known as backpropagation. Although we focus on a very\ninfluential class of architectures called \"convolutional neural networks\"\n(CNNs) the approach is generic and useful to the machine learning community as\na whole. Motivated by the observation that derivations of backpropagation are\noften obscured by clumsy index-heavy narratives that appear somewhat\nmathemagical, we aim to offer a conceptually clear, vectorized description that\narticulates well the higher level logic. Following the principle of \"writing is\nnature's way of letting you know how sloppy your thinking is\", we try to make\nthe calculations meticulous, self-contained and yet as intuitive as possible.\nTaking nothing for granted, ample illustrations serve as visual guides and an\nextensive bibliography is provided for further explorations.\n  (For the sake of clarity, long mathematical derivations and visualizations\nhave been broken up into short \"summarized views\" and longer \"detailed views\"\nencoded into the PDF as optional content groups. Some figures contain\nanimations designed to illustrate important concepts in a more engaging style.\nFor these reasons, we advise to download the document locally and open it using\nAdobe Acrobat Reader. Other viewers were not tested and may not render the\ndetailed views, animations correctly.)\n",
        "published": "2018",
        "authors": [
            "Laurent Bou\u00e9"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.00541v2",
        "title": "The Efficacy of SHIELD under Different Threat Models",
        "abstract": "  In this appraisal paper, we evaluate the efficacy of SHIELD, a\ncompression-based defense framework for countering adversarial attacks on image\nclassification models, which was published at KDD 2018. Here, we consider\nalternative threat models not studied in the original work, where we assume\nthat an adaptive adversary is aware of the ensemble defense approach, the\ndefensive pre-processing, and the architecture and weights of the models used\nin the ensemble. We define scenarios with varying levels of threat and\nempirically analyze the proposed defense by varying the degree of information\navailable to the attacker, spanning from a full white-box attack to the\ngray-box threat model described in the original work. To evaluate the\nrobustness of the defense against an adaptive attacker, we consider the\ntargeted-attack success rate of the Projected Gradient Descent (PGD) attack,\nwhich is a strong gradient-based adversarial attack proposed in adversarial\nmachine learning research. We also experiment with training the SHIELD ensemble\nfrom scratch, which is different from re-training using a pre-trained model as\ndone in the original work. We find that the targeted PGD attack has a success\nrate of 64.3% against the original SHIELD ensemble in the full white box\nscenario, but this drops to 48.9% if the models used in the ensemble are\ntrained from scratch instead of being retrained. Our experiments further reveal\nthat an ensemble whose models are re-trained indeed have higher correlation in\nthe cosine similarity space, and models that are trained from scratch are less\nvulnerable to targeted attacks in the white-box and gray-box scenarios.\n",
        "published": "2019",
        "authors": [
            "Cory Cornelius",
            "Nilaksh Das",
            "Shang-Tse Chen",
            "Li Chen",
            "Michael E. Kounavis",
            "Duen Horng Chau"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.08722v5",
        "title": "A Convex Relaxation Barrier to Tight Robustness Verification of Neural\n  Networks",
        "abstract": "  Verification of neural networks enables us to gauge their robustness against\nadversarial attacks. Verification algorithms fall into two categories: exact\nverifiers that run in exponential time and relaxed verifiers that are efficient\nbut incomplete. In this paper, we unify all existing LP-relaxed verifiers, to\nthe best of our knowledge, under a general convex relaxation framework. This\nframework works for neural networks with diverse architectures and\nnonlinearities and covers both primal and dual views of robustness\nverification. We further prove strong duality between the primal and dual\nproblems under very mild conditions. Next, we perform large-scale experiments,\namounting to more than 22 CPU-years, to obtain exact solution to the\nconvex-relaxed problem that is optimal within our framework for ReLU networks.\nWe find the exact solution does not significantly improve upon the gap between\nPGD and existing relaxed verifiers for various networks trained normally or\nrobustly on MNIST and CIFAR datasets. Our results suggest there is an inherent\nbarrier to tight verification for the large class of methods captured by our\nframework. We discuss possible causes of this barrier and potential future\ndirections for bypassing it. Our code and trained models are available at\nhttp://github.com/Hadisalman/robust-verify-benchmark .\n",
        "published": "2019",
        "authors": [
            "Hadi Salman",
            "Greg Yang",
            "Huan Zhang",
            "Cho-Jui Hsieh",
            "Pengchuan Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.00225v2",
        "title": "MetaPoison: Practical General-purpose Clean-label Data Poisoning",
        "abstract": "  Data poisoning -- the process by which an attacker takes control of a model\nby making imperceptible changes to a subset of the training data -- is an\nemerging threat in the context of neural networks. Existing attacks for data\npoisoning neural networks have relied on hand-crafted heuristics, because\nsolving the poisoning problem directly via bilevel optimization is generally\nthought of as intractable for deep models. We propose MetaPoison, a first-order\nmethod that approximates the bilevel problem via meta-learning and crafts\npoisons that fool neural networks. MetaPoison is effective: it outperforms\nprevious clean-label poisoning methods by a large margin. MetaPoison is robust:\npoisoned data made for one model transfer to a variety of victim models with\nunknown training settings and architectures. MetaPoison is general-purpose, it\nworks not only in fine-tuning scenarios, but also for end-to-end training from\nscratch, which till now hasn't been feasible for clean-label attacks with deep\nnets. MetaPoison can achieve arbitrary adversary goals -- like using poisons of\none class to make a target image don the label of another arbitrarily chosen\nclass. Finally, MetaPoison works in the real-world. We demonstrate for the\nfirst time successful data poisoning of models trained on the black-box Google\nCloud AutoML API. Code and premade poisons are provided at\nhttps://github.com/wronnyhuang/metapoison\n",
        "published": "2020",
        "authors": [
            "W. Ronny Huang",
            "Jonas Geiping",
            "Liam Fowl",
            "Gavin Taylor",
            "Tom Goldstein"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.07093v1",
        "title": "Semi-supervised Vocabulary-informed Learning",
        "abstract": "  Despite significant progress in object categorization, in recent years, a\nnumber of important challenges remain, mainly, ability to learn from limited\nlabeled data and ability to recognize object classes within large, potentially\nopen, set of labels. Zero-shot learning is one way of addressing these\nchallenges, but it has only been shown to work with limited sized class\nvocabularies and typically requires separation between supervised and\nunsupervised classes, allowing former to inform the latter but not vice versa.\nWe propose the notion of semi-supervised vocabulary-informed learning to\nalleviate the above mentioned challenges and address problems of supervised,\nzero-shot and open set recognition using a unified framework. Specifically, we\npropose a maximum margin framework for semantic manifold-based recognition that\nincorporates distance constraints from (both supervised and unsupervised)\nvocabulary atoms, ensuring that labeled samples are projected closest to their\ncorrect prototypes, in the embedding space, than to others. We show that\nresulting model shows improvements in supervised, zero-shot, and large open set\nrecognition, with up to 310K class vocabulary on AwA and ImageNet datasets.\n",
        "published": "2016",
        "authors": [
            "Yanwei Fu",
            "Leonid Sigal"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.02786v3",
        "title": "Structure-Preserving Transformation: Generating Diverse and Transferable\n  Adversarial Examples",
        "abstract": "  Adversarial examples are perturbed inputs designed to fool machine learning\nmodels. Most recent works on adversarial examples for image classification\nfocus on directly modifying pixels with minor perturbations. A common\nrequirement in all these works is that the malicious perturbations should be\nsmall enough (measured by an L_p norm for some p) so that they are\nimperceptible to humans. However, small perturbations can be unnecessarily\nrestrictive and limit the diversity of adversarial examples generated. Further,\nan L_p norm based distance metric ignores important structure patterns hidden\nin images that are important to human perception. Consequently, even the minor\nperturbation introduced in recent works often makes the adversarial examples\nless natural to humans. More importantly, they often do not transfer well and\nare therefore less effective when attacking black-box models especially for\nthose protected by a defense mechanism. In this paper, we propose a\nstructure-preserving transformation (SPT) for generating natural and diverse\nadversarial examples with extremely high transferability. The key idea of our\napproach is to allow perceptible deviation in adversarial examples while\nkeeping structure patterns that are central to a human classifier. Empirical\nresults on the MNIST and the fashion-MNIST datasets show that adversarial\nexamples generated by our approach can easily bypass strong adversarial\ntraining. Further, they transfer well to other target models with no loss or\nlittle loss of successful attack rate.\n",
        "published": "2018",
        "authors": [
            "Dan Peng",
            "Zizhan Zheng",
            "Xiaofeng Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.11588v1",
        "title": "Cascaded V-Net using ROI masks for brain tumor segmentation",
        "abstract": "  In this work we approach the brain tumor segmentation problem with a cascade\nof two CNNs inspired in the V-Net architecture \\cite{VNet}, reformulating\nresidual connections and making use of ROI masks to constrain the networks to\ntrain only on relevant voxels. This architecture allows dense training on\nproblems with highly skewed class distributions, such as brain tumor\nsegmentation, by focusing training only on the vecinity of the tumor area. We\nreport results on BraTS2017 Training and Validation sets.\n",
        "published": "2018",
        "authors": [
            "Adri\u00e0 Casamitjana",
            "Marcel Cat\u00e0",
            "Irina S\u00e1nchez",
            "Marc Combalia",
            "Ver\u00f3nica Vilaplana"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.08140v2",
        "title": "On-the-fly Global Embeddings Using Random Projections for Extreme\n  Multi-label Classification",
        "abstract": "  The goal of eXtreme Multi-label Learning (XML) is to automatically annotate a\ngiven data point with the most relevant subset of labels from an extremely\nlarge vocabulary of labels (e.g., a million labels). Lately, many attempts have\nbeen made to address this problem that achieve reasonable performance on\nbenchmark datasets. In this paper, rather than coming-up with an altogether new\nmethod, our objective is to present and validate a simple baseline for this\ntask. Precisely, we investigate an on-the-fly global and structure preserving\nfeature embedding technique using random projections whose learning phase is\nindependent of training samples and label vocabulary. Further, we show how an\nensemble of multiple such learners can be used to achieve further boost in\nprediction accuracy with only linear increase in training and prediction time.\nExperiments on three public XML benchmarks show that the proposed approach\nobtains competitive accuracy compared with many existing methods. Additionally,\nit also provides around 6572x speed-up ratio in terms of training time and\naround 14.7x reduction in model-size compared to the closest competitors on the\nlargest publicly available dataset.\n",
        "published": "2019",
        "authors": [
            "Yashaswi Verma"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2006.07187v2",
        "title": "HMIC: Hierarchical Medical Image Classification, A Deep Learning\n  Approach",
        "abstract": "  Image classification is central to the big data revolution in medicine.\nImproved information processing methods for diagnosis and classification of\ndigital medical images have shown to be successful via deep learning\napproaches. As this field is explored, there are limitations to the performance\nof traditional supervised classifiers. This paper outlines an approach that is\ndifferent from the current medical image classification tasks that view the\nissue as multi-class classification. We performed a hierarchical classification\nusing our Hierarchical Medical Image classification (HMIC) approach. HMIC uses\nstacks of deep learning models to give particular comprehension at each level\nof the clinical picture hierarchy. For testing our performance, we use biopsy\nof the small bowel images that contain three categories in the parent level\n(Celiac Disease, Environmental Enteropathy, and histologically normal\ncontrols). For the child level, Celiac Disease Severity is classified into 4\nclasses (I, IIIa, IIIb, and IIIC).\n",
        "published": "2020",
        "authors": [
            "Kamran Kowsari",
            "Rasoul Sali",
            "Lubaina Ehsan",
            "William Adorno",
            "Asad Ali",
            "Sean Moore",
            "Beatrice Amadi",
            "Paul Kelly",
            "Sana Syed",
            "Donald Brown"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2006.12323v3",
        "title": "Automatic Recall Machines: Internal Replay, Continual Learning and the\n  Brain",
        "abstract": "  Replay in neural networks involves training on sequential data with memorized\nsamples, which counteracts forgetting of previous behavior caused by\nnon-stationarity. We present a method where these auxiliary samples are\ngenerated on the fly, given only the model that is being trained for the\nassessed objective, without extraneous buffers or generator networks. Instead\nthe implicit memory of learned samples within the assessed model itself is\nexploited. Furthermore, whereas existing work focuses on reinforcing the full\nseen data distribution, we show that optimizing for not forgetting calls for\nthe generation of samples that are specialized to each real training batch,\nwhich is more efficient and scalable. We consider high-level parallels with the\nbrain, notably the use of a single model for inference and recall, the\ndependency of recalled samples on the current environment batch, top-down\nmodulation of activations and learning, abstract recall, and the dependency\nbetween the degree to which a task is learned and the degree to which it is\nrecalled. These characteristics emerge naturally from the method without being\ncontrolled for.\n",
        "published": "2020",
        "authors": [
            "Xu Ji",
            "Joao Henriques",
            "Tinne Tuytelaars",
            "Andrea Vedaldi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.00029v5",
        "title": "RG-Flow: A hierarchical and explainable flow model based on\n  renormalization group and sparse prior",
        "abstract": "  Flow-based generative models have become an important class of unsupervised\nlearning approaches. In this work, we incorporate the key ideas of\nrenormalization group (RG) and sparse prior distribution to design a\nhierarchical flow-based generative model, RG-Flow, which can separate\ninformation at different scales of images and extract disentangled\nrepresentations at each scale. We demonstrate our method on synthetic\nmulti-scale image datasets and the CelebA dataset, showing that the\ndisentangled representations enable semantic manipulation and style mixing of\nthe images at different scales. To visualize the latent representations, we\nintroduce receptive fields for flow-based models and show that the receptive\nfields of RG-Flow are similar to those of convolutional neural networks. In\naddition, we replace the widely adopted isotropic Gaussian prior distribution\nby the sparse Laplacian distribution to further enhance the disentanglement of\nrepresentations. From a theoretical perspective, our proposed method has\n$O(\\log L)$ complexity for inpainting of an image with edge length $L$,\ncompared to previous generative models with $O(L^2)$ complexity.\n",
        "published": "2020",
        "authors": [
            "Hong-Ye Hu",
            "Dian Wu",
            "Yi-Zhuang You",
            "Bruno Olshausen",
            "Yubei Chen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.12016v1",
        "title": "Towards falsifiable interpretability research",
        "abstract": "  Methods for understanding the decisions of and mechanisms underlying deep\nneural networks (DNNs) typically rely on building intuition by emphasizing\nsensory or semantic features of individual examples. For instance, methods aim\nto visualize the components of an input which are \"important\" to a network's\ndecision, or to measure the semantic properties of single neurons. Here, we\nargue that interpretability research suffers from an over-reliance on\nintuition-based approaches that risk-and in some cases have caused-illusory\nprogress and misleading conclusions. We identify a set of limitations that we\nargue impede meaningful progress in interpretability research, and examine two\npopular classes of interpretability methods-saliency and single-neuron-based\napproaches-that serve as case studies for how overreliance on intuition and\nlack of falsifiability can undermine interpretability research. To address\nthese concerns, we propose a strategy to address these impediments in the form\nof a framework for strongly falsifiable interpretability research. We encourage\nresearchers to use their intuitions as a starting point to develop and test\nclear, falsifiable hypotheses, and hope that our framework yields robust,\nevidence-based interpretability methods that generate meaningful advances in\nour understanding of DNNs.\n",
        "published": "2020",
        "authors": [
            "Matthew L. Leavitt",
            "Ari Morcos"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2101.02703v3",
        "title": "Distribution-Free, Risk-Controlling Prediction Sets",
        "abstract": "  While improving prediction accuracy has been the focus of machine learning in\nrecent years, this alone does not suffice for reliable decision-making.\nDeploying learning systems in consequential settings also requires calibrating\nand communicating the uncertainty of predictions. To convey instance-wise\nuncertainty for prediction tasks, we show how to generate set-valued\npredictions from a black-box predictor that control the expected loss on future\ntest points at a user-specified level. Our approach provides explicit\nfinite-sample guarantees for any dataset by using a holdout set to calibrate\nthe size of the prediction sets. This framework enables simple,\ndistribution-free, rigorous error control for many tasks, and we demonstrate it\nin five large-scale machine learning problems: (1) classification problems\nwhere some mistakes are more costly than others; (2) multi-label\nclassification, where each observation has multiple associated labels; (3)\nclassification problems where the labels have a hierarchical structure; (4)\nimage segmentation, where we wish to predict a set of pixels containing an\nobject of interest; and (5) protein structure prediction. Lastly, we discuss\nextensions to uncertainty quantification for ranking, metric learning and\ndistributionally robust learning.\n",
        "published": "2021",
        "authors": [
            "Stephen Bates",
            "Anastasios Angelopoulos",
            "Lihua Lei",
            "Jitendra Malik",
            "Michael I. Jordan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2101.07235v2",
        "title": "Reducing bias and increasing utility by federated generative modeling of\n  medical images using a centralized adversary",
        "abstract": "  We introduce FELICIA (FEderated LearnIng with a CentralIzed Adversary) a\ngenerative mechanism enabling collaborative learning. In particular, we show\nhow a data owner with limited and biased data could benefit from other data\nowners while keeping data from all the sources private. This is a common\nscenario in medical image analysis where privacy legislation prevents data from\nbeing shared outside local premises. FELICIA works for a large family of\nGenerative Adversarial Networks (GAN) architectures including vanilla and\nconditional GANs as demonstrated in this work. We show that by using the\nFELICIA mechanism, a data owner with limited image samples can generate\nhigh-quality synthetic images with high utility while neither data owners has\nto provide access to its data. The sharing happens solely through a central\ndiscriminator that has access limited to synthetic data. Here, utility is\ndefined as classification performance on a real test set. We demonstrate these\nbenefits on several realistic healthcare scenarions using benchmark image\ndatasets (MNIST, CIFAR-10) as well as on medical images for the task of skin\nlesion classification. With multiple experiments, we show that even in the\nworst cases, combining FELICIA with real data gracefully achieves performance\non par with real data while most results significantly improves the utility.\n",
        "published": "2021",
        "authors": [
            "Jean-Francois Rajotte",
            "Sumit Mukherjee",
            "Caleb Robinson",
            "Anthony Ortiz",
            "Christopher West",
            "Juan Lavista Ferres",
            "Raymond T Ng"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.03628v2",
        "title": "Graph-Relational Domain Adaptation",
        "abstract": "  Existing domain adaptation methods tend to treat every domain equally and\nalign them all perfectly. Such uniform alignment ignores topological structures\namong different domains; therefore it may be beneficial for nearby domains, but\nnot necessarily for distant domains. In this work, we relax such uniform\nalignment by using a domain graph to encode domain adjacency, e.g., a graph of\nstates in the US with each state as a domain and each edge indicating\nadjacency, thereby allowing domains to align flexibly based on the graph\nstructure. We generalize the existing adversarial learning framework with a\nnovel graph discriminator using encoding-conditioned graph embeddings.\nTheoretical analysis shows that at equilibrium, our method recovers classic\ndomain adaptation when the graph is a clique, and achieves non-trivial\nalignment for other types of graphs. Empirical results show that our approach\nsuccessfully generalizes uniform alignment, naturally incorporates domain\ninformation represented by graphs, and improves upon existing domain adaptation\nmethods on both synthetic and real-world datasets. Code will soon be available\nat https://github.com/Wang-ML-Lab/GRDA.\n",
        "published": "2022",
        "authors": [
            "Zihao Xu",
            "Hao He",
            "Guang-He Lee",
            "Yuyang Wang",
            "Hao Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.02906v3",
        "title": "Multi-Agent Diverse Generative Adversarial Networks",
        "abstract": "  We propose MAD-GAN, an intuitive generalization to the Generative Adversarial\nNetworks (GANs) and its conditional variants to address the well known problem\nof mode collapse. First, MAD-GAN is a multi-agent GAN architecture\nincorporating multiple generators and one discriminator. Second, to enforce\nthat different generators capture diverse high probability modes, the\ndiscriminator of MAD-GAN is designed such that along with finding the real and\nfake samples, it is also required to identify the generator that generated the\ngiven fake sample. Intuitively, to succeed in this task, the discriminator must\nlearn to push different generators towards different identifiable modes. We\nperform extensive experiments on synthetic and real datasets and compare\nMAD-GAN with different variants of GAN. We show high quality diverse sample\ngenerations for challenging tasks such as image-to-image translation and face\ngeneration. In addition, we also show that MAD-GAN is able to disentangle\ndifferent modalities when trained using highly challenging diverse-class\ndataset (e.g. dataset with images of forests, icebergs, and bedrooms). In the\nend, we show its efficacy on the unsupervised feature representation task. In\nAppendix, we introduce a similarity based competing objective (MAD-GAN-Sim)\nwhich encourages different generators to generate diverse samples based on a\nuser defined similarity metric. We show its performance on the image-to-image\ntranslation, and also show its effectiveness on the unsupervised feature\nrepresentation task.\n",
        "published": "2017",
        "authors": [
            "Arnab Ghosh",
            "Viveka Kulharia",
            "Vinay Namboodiri",
            "Philip H. S. Torr",
            "Puneet K. Dokania"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.05840v1",
        "title": "A Data and Model-Parallel, Distributed and Scalable Framework for\n  Training of Deep Networks in Apache Spark",
        "abstract": "  Training deep networks is expensive and time-consuming with the training\nperiod increasing with data size and growth in model parameters. In this paper,\nwe provide a framework for distributed training of deep networks over a cluster\nof CPUs in Apache Spark. The framework implements both Data Parallelism and\nModel Parallelism making it suitable to use for deep networks which require\nhuge training data and model parameters which are too big to fit into the\nmemory of a single machine. It can be scaled easily over a cluster of cheap\ncommodity hardware to attain significant speedup and obtain better results\nmaking it quite economical as compared to farm of GPUs and supercomputers. We\nhave proposed a new algorithm for training of deep networks for the case when\nthe network is partitioned across the machines (Model Parallelism) along with\ndetailed cost analysis and proof of convergence of the same. We have developed\nimplementations for Fully-Connected Feedforward Networks, Convolutional Neural\nNetworks, Recurrent Neural Networks and Long Short-Term Memory architectures.\nWe present the results of extensive simulations demonstrating the speedup and\naccuracy obtained by our framework for different sizes of the data and model\nparameters with variation in the number of worker cores/partitions; thereby\nshowing that our proposed framework can achieve significant speedup (upto 11X\nfor CNN) and is also quite scalable.\n",
        "published": "2017",
        "authors": [
            "Disha Shrivastava",
            "Santanu Chaudhury",
            "Dr. Jayadeva"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.11431v3",
        "title": "Physics-guided Neural Networks (PGNN): An Application in Lake\n  Temperature Modeling",
        "abstract": "  This paper introduces a framework for combining scientific knowledge of\nphysics-based models with neural networks to advance scientific discovery. This\nframework, termed physics-guided neural networks (PGNN), leverages the output\nof physics-based model simulations along with observational features in a\nhybrid modeling setup to generate predictions using a neural network\narchitecture. Further, this framework uses physics-based loss functions in the\nlearning objective of neural networks to ensure that the model predictions not\nonly show lower errors on the training set but are also scientifically\nconsistent with the known physics on the unlabeled set. We illustrate the\neffectiveness of PGNN for the problem of lake temperature modeling, where\nphysical relationships between the temperature, density, and depth of water are\nused to design a physics-based loss function. By using scientific knowledge to\nguide the construction and learning of neural networks, we are able to show\nthat the proposed framework ensures better generalizability as well as\nscientific consistency of results. All the code and datasets used in this study\nhave been made available on this link \\url{https://github.com/arkadaw9/PGNN}.\n",
        "published": "2017",
        "authors": [
            "Arka Daw",
            "Anuj Karpatne",
            "William Watkins",
            "Jordan Read",
            "Vipin Kumar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.07798v2",
        "title": "Improved Learning of One-hidden-layer Convolutional Neural Networks with\n  Overlaps",
        "abstract": "  We propose a new algorithm to learn a one-hidden-layer convolutional neural\nnetwork where both the convolutional weights and the outputs weights are\nparameters to be learned. Our algorithm works for a general class of\n(potentially overlapping) patches, including commonly used structures for\ncomputer vision tasks. Our algorithm draws ideas from (1) isotonic regression\nfor learning neural networks and (2) landscape analysis of non-convex matrix\nfactorization problems. We believe these findings may inspire further\ndevelopment in designing provable algorithms for learning neural networks and\nother complex models.\n",
        "published": "2018",
        "authors": [
            "Simon S. Du",
            "Surbhi Goel"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.12487v2",
        "title": "Sequential Attacks on Agents for Long-Term Adversarial Goals",
        "abstract": "  Reinforcement learning (RL) has advanced greatly in the past few years with\nthe employment of effective deep neural networks (DNNs) on the policy networks.\nWith the great effectiveness came serious vulnerability issues with DNNs that\nsmall adversarial perturbations on the input can change the output of the\nnetwork. Several works have pointed out that learned agents with a DNN policy\nnetwork can be manipulated against achieving the original task through a\nsequence of small perturbations on the input states. In this paper, we\ndemonstrate furthermore that it is also possible to impose an arbitrary\nadversarial reward on the victim policy network through a sequence of attacks.\nOur method involves the latest adversarial attack technique, Adversarial\nTransformer Network (ATN), that learns to generate the attack and is easy to\nintegrate into the policy network. As a result of our attack, the victim agent\nis misguided to optimise for the adversarial reward over time. Our results\nexpose serious security threats for RL applications in safety-critical systems\nincluding drones, medical analysis, and self-driving cars.\n",
        "published": "2018",
        "authors": [
            "Edgar Tretschk",
            "Seong Joon Oh",
            "Mario Fritz"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1808.04228v2",
        "title": "DFTerNet: Towards 2-bit Dynamic Fusion Networks for Accurate Human\n  Activity Recognition",
        "abstract": "  Deep Convolutional Neural Networks (DCNNs) are currently popular in human\nactivity recognition applications. However, in the face of modern artificial\nintelligence sensor-based games, many research achievements cannot be\npractically applied on portable devices. DCNNs are typically resource-intensive\nand too large to be deployed on portable devices, thus this limits the\npractical application of complex activity detection. In addition, since\nportable devices do not possess high-performance Graphic Processing Units\n(GPUs), there is hardly any improvement in Action Game (ACT) experience.\nBesides, in order to deal with multi-sensor collaboration, all previous human\nactivity recognition models typically treated the representations from\ndifferent sensor signal sources equally. However, distinct types of activities\nshould adopt different fusion strategies. In this paper, a novel scheme is\nproposed. This scheme is used to train 2-bit Convolutional Neural Networks with\nweights and activations constrained to {-0.5,0,0.5}. It takes into account the\ncorrelation between different sensor signal sources and the activity types.\nThis model, which we refer to as DFTerNet, aims at producing a more reliable\ninference and better trade-offs for practical applications. Our basic idea is\nto exploit quantization of weights and activations directly in pre-trained\nfilter banks and adopt dynamic fusion strategies for different activity types.\nExperiments demonstrate that by using dynamic fusion strategy can exceed the\nbaseline model performance by up to ~5% on activity recognition like\nOPPORTUNITY and PAMAP2 datasets. Using the quantization method proposed, we\nwere able to achieve performances closer to that of full-precision counterpart.\nThese results were also verified using the UniMiB-SHAR dataset. In addition,\nthe proposed method can achieve ~9x acceleration on CPUs and ~11x memory\nsaving.\n",
        "published": "2018",
        "authors": [
            "Zhan Yang",
            "Osolo Ian Raymond",
            "ChengYuan Zhang",
            "Ying Wan",
            "Jun Long"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1808.08750v3",
        "title": "Generalisation in humans and deep neural networks",
        "abstract": "  We compare the robustness of humans and current convolutional deep neural\nnetworks (DNNs) on object recognition under twelve different types of image\ndegradations. First, using three well known DNNs (ResNet-152, VGG-19,\nGoogLeNet) we find the human visual system to be more robust to nearly all of\nthe tested image manipulations, and we observe progressively diverging\nclassification error-patterns between humans and DNNs when the signal gets\nweaker. Secondly, we show that DNNs trained directly on distorted images\nconsistently surpass human performance on the exact distortion types they were\ntrained on, yet they display extremely poor generalisation abilities when\ntested on other distortion types. For example, training on salt-and-pepper\nnoise does not imply robustness on uniform white noise and vice versa. Thus,\nchanges in the noise distribution between training and testing constitutes a\ncrucial challenge to deep learning vision systems that can be systematically\naddressed in a lifelong machine learning approach. Our new dataset consisting\nof 83K carefully measured human psychophysical trials provide a useful\nreference for lifelong robustness against image degradations set by the human\nvisual system.\n",
        "published": "2018",
        "authors": [
            "Robert Geirhos",
            "Carlos R. Medina Temme",
            "Jonas Rauber",
            "Heiko H. Sch\u00fctt",
            "Matthias Bethge",
            "Felix A. Wichmann"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.13373v1",
        "title": "Analyzing biological and artificial neural networks: challenges with\n  opportunities for synergy?",
        "abstract": "  Deep neural networks (DNNs) transform stimuli across multiple processing\nstages to produce representations that can be used to solve complex tasks, such\nas object recognition in images. However, a full understanding of how they\nachieve this remains elusive. The complexity of biological neural networks\nsubstantially exceeds the complexity of DNNs, making it even more challenging\nto understand the representations that they learn. Thus, both machine learning\nand computational neuroscience are faced with a shared challenge: how can we\nanalyze their representations in order to understand how they solve complex\ntasks?\n  We review how data-analysis concepts and techniques developed by\ncomputational neuroscientists can be useful for analyzing representations in\nDNNs, and in turn, how recently developed techniques for analysis of DNNs can\nbe useful for understanding representations in biological neural networks. We\nexplore opportunities for synergy between the two fields, such as the use of\nDNNs as in-silico model systems for neuroscience, and how this synergy can lead\nto new hypotheses about the operating principles of biological neural networks.\n",
        "published": "2018",
        "authors": [
            "David G. T. Barrett",
            "Ari S. Morcos",
            "Jakob H. Macke"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.12200v3",
        "title": "Missing MRI Pulse Sequence Synthesis using Multi-Modal Generative\n  Adversarial Network",
        "abstract": "  Magnetic resonance imaging (MRI) is being increasingly utilized to assess,\ndiagnose, and plan treatment for a variety of diseases. The ability to\nvisualize tissue in varied contrasts in the form of MR pulse sequences in a\nsingle scan provides valuable insights to physicians, as well as enabling\nautomated systems performing downstream analysis. However many issues like\nprohibitive scan time, image corruption, different acquisition protocols, or\nallergies to certain contrast materials may hinder the process of acquiring\nmultiple sequences for a patient. This poses challenges to both physicians and\nautomated systems since complementary information provided by the missing\nsequences is lost. In this paper, we propose a variant of generative\nadversarial network (GAN) capable of leveraging redundant information contained\nwithin multiple available sequences in order to generate one or more missing\nsequences for a patient scan. The proposed network is designed as a\nmulti-input, multi-output network which combines information from all the\navailable pulse sequences, implicitly infers which sequences are missing, and\nsynthesizes the missing ones in a single forward pass. We demonstrate and\nvalidate our method on two brain MRI datasets each with four sequences, and\nshow the applicability of the proposed method in simultaneously synthesizing\nall missing sequences in any possible scenario where either one, two, or three\nof the four sequences may be missing. We compare our approach with competing\nunimodal and multi-modal methods, and show that we outperform both\nquantitatively and qualitatively.\n",
        "published": "2019",
        "authors": [
            "Anmol Sharma",
            "Ghassan Hamarneh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2005.11212v2",
        "title": "Symbolic Pregression: Discovering Physical Laws from Distorted Video",
        "abstract": "  We present a method for unsupervised learning of equations of motion for\nobjects in raw and optionally distorted unlabeled video. We first train an\nautoencoder that maps each video frame into a low-dimensional latent space\nwhere the laws of motion are as simple as possible, by minimizing a combination\nof non-linearity, acceleration and prediction error. Differential equations\ndescribing the motion are then discovered using Pareto-optimal symbolic\nregression. We find that our pre-regression (\"pregression\") step is able to\nrediscover Cartesian coordinates of unlabeled moving objects even when the\nvideo is distorted by a generalized lens. Using intuition from multidimensional\nknot-theory, we find that the pregression step is facilitated by first adding\nextra latent space dimensions to avoid topological problems during training and\nthen removing these extra dimensions via principal component analysis.\n",
        "published": "2020",
        "authors": [
            "Silviu-Marian Udrescu",
            "Max Tegmark"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.09283v1",
        "title": "Subverting Privacy-Preserving GANs: Hiding Secrets in Sanitized Images",
        "abstract": "  Unprecedented data collection and sharing have exacerbated privacy concerns\nand led to increasing interest in privacy-preserving tools that remove\nsensitive attributes from images while maintaining useful information for other\ntasks. Currently, state-of-the-art approaches use privacy-preserving generative\nadversarial networks (PP-GANs) for this purpose, for instance, to enable\nreliable facial expression recognition without leaking users' identity.\nHowever, PP-GANs do not offer formal proofs of privacy and instead rely on\nexperimentally measuring information leakage using classification accuracy on\nthe sensitive attributes of deep learning (DL)-based discriminators. In this\nwork, we question the rigor of such checks by subverting existing\nprivacy-preserving GANs for facial expression recognition. We show that it is\npossible to hide the sensitive identification data in the sanitized output\nimages of such PP-GANs for later extraction, which can even allow for\nreconstruction of the entire input images, while satisfying privacy checks. We\ndemonstrate our approach via a PP-GAN-based architecture and provide\nqualitative and quantitative evaluations using two public datasets. Our\nexperimental results raise fundamental questions about the need for more\nrigorous privacy checks of PP-GANs, and we provide insights into the social\nimpact of these.\n",
        "published": "2020",
        "authors": [
            "Kang Liu",
            "Benjamin Tan",
            "Siddharth Garg"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.09321v3",
        "title": "Learning a Lie Algebra from Unlabeled Data Pairs",
        "abstract": "  Deep convolutional networks (convnets) show a remarkable ability to learn\ndisentangled representations. In recent years, the generalization of deep\nlearning to Lie groups beyond rigid motion in $\\mathbb{R}^n$ has allowed to\nbuild convnets over datasets with non-trivial symmetries, such as patterns over\nthe surface of a sphere. However, one limitation of this approach is the need\nto explicitly define the Lie group underlying the desired invariance property\nbefore training the convnet. Whereas rotations on the sphere have a well-known\nsymmetry group ($\\mathrm{SO}(3)$), the same cannot be said of many real-world\nfactors of variability. For example, the disentanglement of pitch, intensity\ndynamics, and playing technique remains a challenging task in music information\nretrieval.\n  This article proposes a machine learning method to discover a nonlinear\ntransformation of the space $\\mathbb{R}^n$ which maps a collection of\n$n$-dimensional vectors $(\\boldsymbol{x}_i)_i$ onto a collection of target\nvectors $(\\boldsymbol{y}_i)_i$. The key idea is to approximate every target\n$\\boldsymbol{y}_i$ by a matrix--vector product of the form\n$\\boldsymbol{\\widetilde{y}}_i = \\boldsymbol{\\phi}(t_i) \\boldsymbol{x}_i$, where\nthe matrix $\\boldsymbol{\\phi}(t_i)$ belongs to a one-parameter subgroup of\n$\\mathrm{GL}_n (\\mathbb{R})$. Crucially, the value of the parameter $t_i \\in\n\\mathbb{R}$ may change between data pairs $(\\boldsymbol{x}_i,\n\\boldsymbol{y}_i)$ and does not need to be known in advance.\n",
        "published": "2020",
        "authors": [
            "Christopher Ick",
            "Vincent Lostanlen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.07346v2",
        "title": "On the Theory of Implicit Deep Learning: Global Convergence with\n  Implicit Layers",
        "abstract": "  A deep equilibrium model uses implicit layers, which are implicitly defined\nthrough an equilibrium point of an infinite sequence of computation. It avoids\nany explicit computation of the infinite sequence by finding an equilibrium\npoint directly via root-finding and by computing gradients via implicit\ndifferentiation. In this paper, we analyze the gradient dynamics of deep\nequilibrium models with nonlinearity only on weight matrices and non-convex\nobjective functions of weights for regression and classification. Despite\nnon-convexity, convergence to global optimum at a linear rate is guaranteed\nwithout any assumption on the width of the models, allowing the width to be\nsmaller than the output dimension and the number of data points. Moreover, we\nprove a relation between the gradient dynamics of the deep implicit layer and\nthe dynamics of trust region Newton method of a shallow explicit layer. This\nmathematically proven relation along with our numerical observation suggests\nthe importance of understanding implicit bias of implicit layers and an open\nproblem on the topic. Our proofs deal with implicit layers, weight tying and\nnonlinearity on weights, and differ from those in the related literature.\n",
        "published": "2021",
        "authors": [
            "Kenji Kawaguchi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2102.11158v1",
        "title": "Federated $f$-Differential Privacy",
        "abstract": "  Federated learning (FL) is a training paradigm where the clients\ncollaboratively learn models by repeatedly sharing information without\ncompromising much on the privacy of their local sensitive data. In this paper,\nwe introduce federated $f$-differential privacy, a new notion specifically\ntailored to the federated setting, based on the framework of Gaussian\ndifferential privacy. Federated $f$-differential privacy operates on record\nlevel: it provides the privacy guarantee on each individual record of one\nclient's data against adversaries. We then propose a generic private federated\nlearning framework {PriFedSync} that accommodates a large family of\nstate-of-the-art FL algorithms, which provably achieves federated\n$f$-differential privacy. Finally, we empirically demonstrate the trade-off\nbetween privacy guarantee and prediction performance for models trained by\n{PriFedSync} in computer vision tasks.\n",
        "published": "2021",
        "authors": [
            "Qinqing Zheng",
            "Shuxiao Chen",
            "Qi Long",
            "Weijie J. Su"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2109.13445v2",
        "title": "Emergent Neural Network Mechanisms for Generalization to Objects in\n  Novel Orientations",
        "abstract": "  The capability of Deep Neural Networks (DNNs) to recognize objects in\norientations outside the distribution of the training data is not well\nunderstood. We present evidence that DNNs are capable of generalizing to\nobjects in novel orientations by disseminating orientation-invariance obtained\nfrom familiar objects seen from many viewpoints. This capability strengthens\nwhen training the DNN with an increasing number of familiar objects, but only\nin orientations that involve 2D rotations of familiar orientations. We show\nthat this dissemination is achieved via neurons tuned to common features\nbetween familiar and unfamiliar objects. These results implicate brain-like\nneural mechanisms for generalization.\n",
        "published": "2021",
        "authors": [
            "Avi Cooper",
            "Xavier Boix",
            "Daniel Harari",
            "Spandan Madan",
            "Hanspeter Pfister",
            "Tomotake Sasaki",
            "Pawan Sinha"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2112.08930v1",
        "title": "Intelli-Paint: Towards Developing Human-like Painting Agents",
        "abstract": "  The generation of well-designed artwork is often quite time-consuming and\nassumes a high degree of proficiency on part of the human painter. In order to\nfacilitate the human painting process, substantial research efforts have been\nmade on teaching machines how to \"paint like a human\", and then using the\ntrained agent as a painting assistant tool for human users. However, current\nresearch in this direction is often reliant on a progressive grid-based\ndivision strategy wherein the agent divides the overall image into successively\nfiner grids, and then proceeds to paint each of them in parallel. This\ninevitably leads to artificial painting sequences which are not easily\nintelligible to human users. To address this, we propose a novel painting\napproach which learns to generate output canvases while exhibiting a more\nhuman-like painting style. The proposed painting pipeline Intelli-Paint\nconsists of 1) a progressive layering strategy which allows the agent to first\npaint a natural background scene representation before adding in each of the\nforeground objects in a progressive fashion. 2) We also introduce a novel\nsequential brushstroke guidance strategy which helps the painting agent to\nshift its attention between different image regions in a semantic-aware manner.\n3) Finally, we propose a brushstroke regularization strategy which allows for\n~60-80% reduction in the total number of required brushstrokes without any\nperceivable differences in the quality of the generated canvases. Through both\nquantitative and qualitative results, we show that the resulting agents not\nonly show enhanced efficiency in output canvas generation but also exhibit a\nmore natural-looking painting style which would better assist human users\nexpress their ideas through digital artwork.\n",
        "published": "2021",
        "authors": [
            "Jaskirat Singh",
            "Cameron Smith",
            "Jose Echevarria",
            "Liang Zheng"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2204.02028v2",
        "title": "A Generative Deep Learning Approach to Stochastic Downscaling of\n  Precipitation Forecasts",
        "abstract": "  Despite continuous improvements, precipitation forecasts are still not as\naccurate and reliable as those of other meteorological variables. A major\ncontributing factor to this is that several key processes affecting\nprecipitation distribution and intensity occur below the resolved scale of\nglobal weather models. Generative adversarial networks (GANs) have been\ndemonstrated by the computer vision community to be successful at\nsuper-resolution problems, i.e., learning to add fine-scale structure to coarse\nimages. Leinonen et al. (2020) previously applied a GAN to produce ensembles of\nreconstructed high-resolution atmospheric fields, given coarsened input data.\nIn this paper, we demonstrate this approach can be extended to the more\nchallenging problem of increasing the accuracy and resolution of comparatively\nlow-resolution input from a weather forecasting model, using high-resolution\nradar measurements as a \"ground truth\". The neural network must learn to add\nresolution and structure whilst accounting for non-negligible forecast error.\nWe show that GANs and VAE-GANs can match the statistical properties of\nstate-of-the-art pointwise post-processing methods whilst creating\nhigh-resolution, spatially coherent precipitation maps. Our model compares\nfavourably to the best existing downscaling methods in both pixel-wise and\npooled CRPS scores, power spectrum information and rank histograms (used to\nassess calibration). We test our models and show that they perform in a range\nof scenarios, including heavy rainfall.\n",
        "published": "2022",
        "authors": [
            "Lucy Harris",
            "Andrew T. T. McRae",
            "Matthew Chantry",
            "Peter D. Dueben",
            "Tim N. Palmer"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2206.13497v4",
        "title": "Robustness Implies Generalization via Data-Dependent Generalization\n  Bounds",
        "abstract": "  This paper proves that robustness implies generalization via data-dependent\ngeneralization bounds. As a result, robustness and generalization are shown to\nbe connected closely in a data-dependent manner. Our bounds improve previous\nbounds in two directions, to solve an open problem that has seen little\ndevelopment since 2010. The first is to reduce the dependence on the covering\nnumber. The second is to remove the dependence on the hypothesis space. We\npresent several examples, including ones for lasso and deep learning, in which\nour bounds are provably preferable. The experiments on real-world data and\ntheoretical models demonstrate near-exponential improvements in various\nsituations. To achieve these improvements, we do not require additional\nassumptions on the unknown distribution; instead, we only incorporate an\nobservable and computable property of the training samples. A key technical\ninnovation is an improved concentration bound for multinomial random variables\nthat is of independent interest beyond robustness and generalization.\n",
        "published": "2022",
        "authors": [
            "Kenji Kawaguchi",
            "Zhun Deng",
            "Kyle Luh",
            "Jiaoyang Huang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2207.06684v1",
        "title": "Subgraph Frequency Distribution Estimation using Graph Neural Networks",
        "abstract": "  Small subgraphs (graphlets) are important features to describe fundamental\nunits of a large network. The calculation of the subgraph frequency\ndistributions has a wide application in multiple domains including biology and\nengineering. Unfortunately due to the inherent complexity of this task, most of\nthe existing methods are computationally intensive and inefficient. In this\nwork, we propose GNNS, a novel representational learning framework that\nutilizes graph neural networks to sample subgraphs efficiently for estimating\ntheir frequency distribution. Our framework includes an inference model and a\ngenerative model that learns hierarchical embeddings of nodes, subgraphs, and\ngraph types. With the learned model and embeddings, subgraphs are sampled in a\nhighly scalable and parallel way and the frequency distribution estimation is\nthen performed based on these sampled subgraphs. Eventually, our methods\nachieve comparable accuracy and a significant speedup by three orders of\nmagnitude compared to existing methods.\n",
        "published": "2022",
        "authors": [
            "Zhongren Chen",
            "Xinyue Xu",
            "Shengyi Jiang",
            "Hao Wang",
            "Lu Mi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2207.09336v1",
        "title": "Uncertainty in Contrastive Learning: On the Predictability of Downstream\n  Performance",
        "abstract": "  The superior performance of some of today's state-of-the-art deep learning\nmodels is to some extent owed to extensive (self-)supervised contrastive\npretraining on large-scale datasets. In contrastive learning, the network is\npresented with pairs of positive (similar) and negative (dissimilar) datapoints\nand is trained to find an embedding vector for each datapoint, i.e., a\nrepresentation, which can be further fine-tuned for various downstream tasks.\nIn order to safely deploy these models in critical decision-making systems, it\nis crucial to equip them with a measure of their uncertainty or reliability.\nHowever, due to the pairwise nature of training a contrastive model, and the\nlack of absolute labels on the output (an abstract embedding vector), adapting\nconventional uncertainty estimation techniques to such models is non-trivial.\nIn this work, we study whether the uncertainty of such a representation can be\nquantified for a single datapoint in a meaningful way. In other words, we\nexplore if the downstream performance on a given datapoint is predictable,\ndirectly from its pre-trained embedding. We show that this goal can be achieved\nby directly estimating the distribution of the training data in the embedding\nspace and accounting for the local consistency of the representations. Our\nexperiments show that this notion of uncertainty for an embedding vector often\nstrongly correlates with its downstream accuracy.\n",
        "published": "2022",
        "authors": [
            "Shervin Ardeshir",
            "Navid Azizan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2208.03309v3",
        "title": "Lethal Dose Conjecture on Data Poisoning",
        "abstract": "  Data poisoning considers an adversary that distorts the training set of\nmachine learning algorithms for malicious purposes. In this work, we bring to\nlight one conjecture regarding the fundamentals of data poisoning, which we\ncall the Lethal Dose Conjecture. The conjecture states: If $n$ clean training\nsamples are needed for accurate predictions, then in a size-$N$ training set,\nonly $\\Theta(N/n)$ poisoned samples can be tolerated while ensuring accuracy.\nTheoretically, we verify this conjecture in multiple cases. We also offer a\nmore general perspective of this conjecture through distribution\ndiscrimination. Deep Partition Aggregation (DPA) and its extension, Finite\nAggregation (FA) are recent approaches for provable defenses against data\npoisoning, where they predict through the majority vote of many base models\ntrained from different subsets of training set using a given learner. The\nconjecture implies that both DPA and FA are (asymptotically) optimal -- if we\nhave the most data-efficient learner, they can turn it into one of the most\nrobust defenses against data poisoning. This outlines a practical approach to\ndeveloping stronger defenses against poisoning via finding data-efficient\nlearners. Empirically, as a proof of concept, we show that by simply using\ndifferent data augmentations for base learners, we can respectively double and\ntriple the certified robustness of DPA on CIFAR-10 and GTSRB without\nsacrificing accuracy.\n",
        "published": "2022",
        "authors": [
            "Wenxiao Wang",
            "Alexander Levine",
            "Soheil Feizi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2209.14778v1",
        "title": "Batch Normalization Explained",
        "abstract": "  A critically important, ubiquitous, and yet poorly understood ingredient in\nmodern deep networks (DNs) is batch normalization (BN), which centers and\nnormalizes the feature maps. To date, only limited progress has been made\nunderstanding why BN boosts DN learning and inference performance; work has\nfocused exclusively on showing that BN smooths a DN's loss landscape. In this\npaper, we study BN theoretically from the perspective of function\napproximation; we exploit the fact that most of today's state-of-the-art DNs\nare continuous piecewise affine (CPA) splines that fit a predictor to the\ntraining data via affine mappings defined over a partition of the input space\n(the so-called \"linear regions\"). {\\em We demonstrate that BN is an\nunsupervised learning technique that -- independent of the DN's weights or\ngradient-based learning -- adapts the geometry of a DN's spline partition to\nmatch the data.} BN provides a \"smart initialization\" that boosts the\nperformance of DN learning, because it adapts even a DN initialized with random\nweights to align its spline partition with the data. We also show that the\nvariation of BN statistics between mini-batches introduces a dropout-like\nrandom perturbation to the partition boundaries and hence the decision boundary\nfor classification problems. This per mini-batch perturbation reduces\noverfitting and improves generalization by increasing the margin between the\ntraining samples and the decision boundary.\n",
        "published": "2022",
        "authors": [
            "Randall Balestriero",
            "Richard G. Baraniuk"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2210.03895v1",
        "title": "ViewFool: Evaluating the Robustness of Visual Recognition to Adversarial\n  Viewpoints",
        "abstract": "  Recent studies have demonstrated that visual recognition models lack\nrobustness to distribution shift. However, current work mainly considers model\nrobustness to 2D image transformations, leaving viewpoint changes in the 3D\nworld less explored. In general, viewpoint changes are prevalent in various\nreal-world applications (e.g., autonomous driving), making it imperative to\nevaluate viewpoint robustness. In this paper, we propose a novel method called\nViewFool to find adversarial viewpoints that mislead visual recognition models.\nBy encoding real-world objects as neural radiance fields (NeRF), ViewFool\ncharacterizes a distribution of diverse adversarial viewpoints under an\nentropic regularizer, which helps to handle the fluctuations of the real camera\npose and mitigate the reality gap between the real objects and their neural\nrepresentations. Experiments validate that the common image classifiers are\nextremely vulnerable to the generated adversarial viewpoints, which also\nexhibit high cross-model transferability. Based on ViewFool, we introduce\nImageNet-V, a new out-of-distribution dataset for benchmarking viewpoint\nrobustness of image classifiers. Evaluation results on 40 classifiers with\ndiverse architectures, objective functions, and data augmentations reveal a\nsignificant drop in model performance when tested on ImageNet-V, which provides\na possibility to leverage ViewFool as an effective data augmentation strategy\nto improve viewpoint robustness.\n",
        "published": "2022",
        "authors": [
            "Yinpeng Dong",
            "Shouwei Ruan",
            "Hang Su",
            "Caixin Kang",
            "Xingxing Wei",
            "Jun Zhu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2210.13512v3",
        "title": "Provably Learning Diverse Features in Multi-View Data with Midpoint\n  Mixup",
        "abstract": "  Mixup is a data augmentation technique that relies on training using random\nconvex combinations of data points and their labels. In recent years, Mixup has\nbecome a standard primitive used in the training of state-of-the-art image\nclassification models due to its demonstrated benefits over empirical risk\nminimization with regards to generalization and robustness. In this work, we\ntry to explain some of this success from a feature learning perspective. We\nfocus our attention on classification problems in which each class may have\nmultiple associated features (or views) that can be used to predict the class\ncorrectly. Our main theoretical results demonstrate that, for a non-trivial\nclass of data distributions with two features per class, training a 2-layer\nconvolutional network using empirical risk minimization can lead to learning\nonly one feature for almost all classes while training with a specific\ninstantiation of Mixup succeeds in learning both features for every class. We\nalso show empirically that these theoretical insights extend to the practical\nsettings of image benchmarks modified to have multiple features.\n",
        "published": "2022",
        "authors": [
            "Muthu Chidambaram",
            "Xiang Wang",
            "Chenwei Wu",
            "Rong Ge"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2210.15291v1",
        "title": "Isometric 3D Adversarial Examples in the Physical World",
        "abstract": "  3D deep learning models are shown to be as vulnerable to adversarial examples\nas 2D models. However, existing attack methods are still far from stealthy and\nsuffer from severe performance degradation in the physical world. Although 3D\ndata is highly structured, it is difficult to bound the perturbations with\nsimple metrics in the Euclidean space. In this paper, we propose a novel\n$\\epsilon$-isometric ($\\epsilon$-ISO) attack to generate natural and robust 3D\nadversarial examples in the physical world by considering the geometric\nproperties of 3D objects and the invariance to physical transformations. For\nnaturalness, we constrain the adversarial example to be $\\epsilon$-isometric to\nthe original one by adopting the Gaussian curvature as a surrogate metric\nguaranteed by a theoretical analysis. For invariance to physical\ntransformations, we propose a maxima over transformation (MaxOT) method that\nactively searches for the most harmful transformations rather than random ones\nto make the generated adversarial example more robust in the physical world.\nExperiments on typical point cloud recognition models validate that our\napproach can significantly improve the attack success rate and naturalness of\nthe generated 3D adversarial examples than the state-of-the-art attack methods.\n",
        "published": "2022",
        "authors": [
            "Yibo Miao",
            "Yinpeng Dong",
            "Jun Zhu",
            "Xiao-Shan Gao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2211.14794v2",
        "title": "Traditional Classification Neural Networks are Good Generators: They are\n  Competitive with DDPMs and GANs",
        "abstract": "  Classifiers and generators have long been separated. We break down this\nseparation and showcase that conventional neural network classifiers can\ngenerate high-quality images of a large number of categories, being comparable\nto the state-of-the-art generative models (e.g., DDPMs and GANs). We achieve\nthis by computing the partial derivative of the classification loss function\nwith respect to the input to optimize the input to produce an image. Since it\nis widely known that directly optimizing the inputs is similar to targeted\nadversarial attacks incapable of generating human-meaningful images, we propose\na mask-based stochastic reconstruction module to make the gradients\nsemantic-aware to synthesize plausible images. We further propose a\nprogressive-resolution technique to guarantee fidelity, which produces\nphotorealistic images. Furthermore, we introduce a distance metric loss and a\nnon-trivial distribution loss to ensure classification neural networks can\nsynthesize diverse and high-fidelity images. Using traditional neural network\nclassifiers, we can generate good-quality images of 256$\\times$256 resolution\non ImageNet. Intriguingly, our method is also applicable to text-to-image\ngeneration by regarding image-text foundation models as generalized\nclassifiers.\n  Proving that classifiers have learned the data distribution and are ready for\nimage generation has far-reaching implications, for classifiers are much easier\nto train than generative models like DDPMs and GANs. We don't even need to\ntrain classification models because tons of public ones are available for\ndownload. Also, this holds great potential for the interpretability and\nrobustness of classifiers. Project page is at\n\\url{https://classifier-as-generator.github.io/}.\n",
        "published": "2022",
        "authors": [
            "Guangrun Wang",
            "Philip H. S. Torr"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2211.15597v1",
        "title": "Lightning Fast Video Anomaly Detection via Adversarial Knowledge\n  Distillation",
        "abstract": "  We propose a very fast frame-level model for anomaly detection in video,\nwhich learns to detect anomalies by distilling knowledge from multiple highly\naccurate object-level teacher models. To improve the fidelity of our student,\nwe distill the low-resolution anomaly maps of the teachers by jointly applying\nstandard and adversarial distillation, introducing an adversarial discriminator\nfor each teacher to distinguish between target and generated anomaly maps. We\nconduct experiments on three benchmarks (Avenue, ShanghaiTech, UCSD Ped2),\nshowing that our method is over 7 times faster than the fastest competing\nmethod, and between 28 and 62 times faster than object-centric models, while\nobtaining comparable results to recent methods. Our evaluation also indicates\nthat our model achieves the best trade-off between speed and accuracy, due to\nits previously unheard-of speed of 1480 FPS. In addition, we carry out a\ncomprehensive ablation study to justify our architectural design choices.\n",
        "published": "2022",
        "authors": [
            "Nicolae-Catalin Ristea",
            "Florinel-Alin Croitoru",
            "Dana Dascalescu",
            "Radu Tudor Ionescu",
            "Fahad Shahbaz Khan",
            "Mubarak Shah"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2212.12206v3",
        "title": "Principled and Efficient Transfer Learning of Deep Models via Neural\n  Collapse",
        "abstract": "  As model size continues to grow and access to labeled training data remains\nlimited, transfer learning has become a popular approach in many scientific and\nengineering fields. This study explores the phenomenon of neural collapse (NC)\nin transfer learning for classification problems, which is characterized by the\nlast-layer features and classifiers of deep networks having zero within-class\nvariability in features and maximally and equally separated between-class\nfeature means. Through the lens of NC, in this work the following findings on\ntransfer learning are discovered: (i) preventing within-class variability\ncollapse to a certain extent during model pre-training on source data leads to\nbetter transferability, as it preserves the intrinsic structures of the input\ndata better; (ii) obtaining features with more NC on downstream data during\nfine-tuning results in better test accuracy. These results provide new insight\ninto commonly used heuristics in model pre-training, such as loss design, data\naugmentation, and projection heads, and lead to more efficient and principled\nmethods for fine-tuning large pre-trained models. Compared to full model\nfine-tuning, our proposed fine-tuning methods achieve comparable or even better\nperformance while reducing fine-tuning parameters by at least 70% as well as\nalleviating overfitting.\n",
        "published": "2022",
        "authors": [
            "Xiao Li",
            "Sheng Liu",
            "Jinxin Zhou",
            "Xinyu Lu",
            "Carlos Fernandez-Granda",
            "Zhihui Zhu",
            "Qing Qu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2301.11990v3",
        "title": "Alignment with human representations supports robust few-shot learning",
        "abstract": "  Should we care whether AI systems have representations of the world that are\nsimilar to those of humans? We provide an information-theoretic analysis that\nsuggests that there should be a U-shaped relationship between the degree of\nrepresentational alignment with humans and performance on few-shot learning\ntasks. We confirm this prediction empirically, finding such a relationship in\nan analysis of the performance of 491 computer vision models. We also show that\nhighly-aligned models are more robust to both natural adversarial attacks and\ndomain shifts. Our results suggest that human-alignment is often a sufficient,\nbut not necessary, condition for models to make effective use of limited data,\nbe robust, and generalize well.\n",
        "published": "2023",
        "authors": [
            "Ilia Sucholutsky",
            "Thomas L. Griffiths"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2304.14211v2",
        "title": "LLT: An R package for Linear Law-based Feature Space Transformation",
        "abstract": "  The goal of the linear law-based feature space transformation (LLT) algorithm\nis to assist with the classification of univariate and multivariate time\nseries. The presented R package, called LLT, implements this algorithm in a\nflexible yet user-friendly way. This package first splits the instances into\ntraining and test sets. It then utilizes time-delay embedding and spectral\ndecomposition techniques to identify the governing patterns (called linear\nlaws) of each input sequence (initial feature) within the training set.\nFinally, it applies the linear laws of the training set to transform the\ninitial features of the test set. These steps are performed by three separate\nfunctions called trainTest, trainLaw, and testTrans. Their application requires\na predefined data structure; however, for fast calculation, they use only\nbuilt-in functions. The LLT R package and a sample dataset with the appropriate\ndata structure are publicly available on GitHub.\n",
        "published": "2023",
        "authors": [
            "Marcell T. Kurbucz",
            "P\u00e9ter P\u00f3sfay",
            "Antal Jakov\u00e1c"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2306.03679v1",
        "title": "Human-imperceptible, Machine-recognizable Images",
        "abstract": "  Massive human-related data is collected to train neural networks for computer\nvision tasks. A major conflict is exposed relating to software engineers\nbetween better developing AI systems and distancing from the sensitive training\ndata. To reconcile this conflict, this paper proposes an efficient\nprivacy-preserving learning paradigm, where images are first encrypted to\nbecome ``human-imperceptible, machine-recognizable'' via one of the two\nencryption strategies: (1) random shuffling to a set of equally-sized patches\nand (2) mixing-up sub-patches of the images. Then, minimal adaptations are made\nto vision transformer to enable it to learn on the encrypted images for vision\ntasks, including image classification and object detection. Extensive\nexperiments on ImageNet and COCO show that the proposed paradigm achieves\ncomparable accuracy with the competitive methods. Decrypting the encrypted\nimages requires solving an NP-hard jigsaw puzzle or an ill-posed inverse\nproblem, which is empirically shown intractable to be recovered by various\nattackers, including the powerful vision transformer-based attacker. We thus\nshow that the proposed paradigm can ensure the encrypted images have become\nhuman-imperceptible while preserving machine-recognizable information. The code\nis available at \\url{https://github.com/FushengHao/PrivacyPreservingML.}\n",
        "published": "2023",
        "authors": [
            "Fusheng Hao",
            "Fengxiang He",
            "Yikai Wang",
            "Fuxiang Wu",
            "Jing Zhang",
            "Jun Cheng",
            "Dacheng Tao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2306.16415v1",
        "title": "On Practical Aspects of Aggregation Defenses against Data Poisoning\n  Attacks",
        "abstract": "  The increasing access to data poses both opportunities and risks in deep\nlearning, as one can manipulate the behaviors of deep learning models with\nmalicious training samples. Such attacks are known as data poisoning. Recent\nadvances in defense strategies against data poisoning have highlighted the\neffectiveness of aggregation schemes in achieving state-of-the-art results in\ncertified poisoning robustness. However, the practical implications of these\napproaches remain unclear. Here we focus on Deep Partition Aggregation, a\nrepresentative aggregation defense, and assess its practical aspects, including\nefficiency, performance, and robustness. For evaluations, we use ImageNet\nresized to a resolution of 64 by 64 to enable evaluations at a larger scale\nthan previous ones. Firstly, we demonstrate a simple yet practical approach to\nscaling base models, which improves the efficiency of training and inference\nfor aggregation defenses. Secondly, we provide empirical evidence supporting\nthe data-to-complexity ratio, i.e. the ratio between the data set size and\nsample complexity, as a practical estimation of the maximum number of base\nmodels that can be deployed while preserving accuracy. Last but not least, we\npoint out how aggregation defenses boost poisoning robustness empirically\nthrough the poisoning overfitting phenomenon, which is the key underlying\nmechanism for the empirical poisoning robustness of aggregations. Overall, our\nfindings provide valuable insights for practical implementations of aggregation\ndefenses to mitigate the threat of data poisoning.\n",
        "published": "2023",
        "authors": [
            "Wenxiao Wang",
            "Soheil Feizi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2307.04749v2",
        "title": "Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image\n  Alignment with Iterative VQA Feedback",
        "abstract": "  The field of text-conditioned image generation has made unparalleled progress\nwith the recent advent of latent diffusion models. While remarkable, as the\ncomplexity of given text input increases, the state-of-the-art diffusion models\nmay still fail in generating images which accurately convey the semantics of\nthe given prompt. Furthermore, it has been observed that such misalignments are\noften left undetected by pretrained multi-modal models such as CLIP. To address\nthese problems, in this paper we explore a simple yet effective decompositional\napproach towards both evaluation and improvement of text-to-image alignment. In\nparticular, we first introduce a Decompositional-Alignment-Score which given a\ncomplex prompt decomposes it into a set of disjoint assertions. The alignment\nof each assertion with generated images is then measured using a VQA model.\nFinally, alignment scores for different assertions are combined aposteriori to\ngive the final text-to-image alignment score. Experimental analysis reveals\nthat the proposed alignment metric shows significantly higher correlation with\nhuman ratings as opposed to traditional CLIP, BLIP scores. Furthermore, we also\nfind that the assertion level alignment scores provide a useful feedback which\ncan then be used in a simple iterative procedure to gradually increase the\nexpression of different assertions in the final image outputs. Human user\nstudies indicate that the proposed approach surpasses previous state-of-the-art\nby 8.7% in overall text-to-image alignment accuracy. Project page for our paper\nis available at https://1jsingh.github.io/divide-evaluate-and-refine\n",
        "published": "2023",
        "authors": [
            "Jaskirat Singh",
            "Liang Zheng"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2309.16779v1",
        "title": "Intriguing properties of generative classifiers",
        "abstract": "  What is the best paradigm to recognize objects -- discriminative inference\n(fast but potentially prone to shortcut learning) or using a generative model\n(slow but potentially more robust)? We build on recent advances in generative\nmodeling that turn text-to-image models into classifiers. This allows us to\nstudy their behavior and to compare them against discriminative models and\nhuman psychophysical data. We report four intriguing emergent properties of\ngenerative classifiers: they show a record-breaking human-like shape bias (99%\nfor Imagen), near human-level out-of-distribution accuracy, state-of-the-art\nalignment with human classification errors, and they understand certain\nperceptual illusions. Our results indicate that while the current dominant\nparadigm for modeling human object recognition is discriminative inference,\nzero-shot generative models approximate human object recognition data\nsurprisingly well.\n",
        "published": "2023",
        "authors": [
            "Priyank Jaini",
            "Kevin Clark",
            "Robert Geirhos"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.12975v1",
        "title": "Variational Inference for SDEs Driven by Fractional Noise",
        "abstract": "  We present a novel variational framework for performing inference in (neural)\nstochastic differential equations (SDEs) driven by Markov-approximate\nfractional Brownian motion (fBM). SDEs offer a versatile tool for modeling\nreal-world continuous-time dynamic systems with inherent noise and randomness.\nCombining SDEs with the powerful inference capabilities of variational methods,\nenables the learning of representative function distributions through\nstochastic gradient descent. However, conventional SDEs typically assume the\nunderlying noise to follow a Brownian motion (BM), which hinders their ability\nto capture long-term dependencies. In contrast, fractional Brownian motion\n(fBM) extends BM to encompass non-Markovian dynamics, but existing methods for\ninferring fBM parameters are either computationally demanding or statistically\ninefficient. In this paper, building upon the Markov approximation of fBM, we\nderive the evidence lower bound essential for efficient variational inference\nof posterior path measures, drawing from the well-established field of\nstochastic analysis. Additionally, we provide a closed-form expression to\ndetermine optimal approximation coefficients. Furthermore, we propose the use\nof neural networks to learn the drift, diffusion and control terms within our\nvariational posterior, leading to the variational training of neural-SDEs. In\nthis framework, we also optimize the Hurst index, governing the nature of our\nfractional noise. Beyond validation on synthetic data, we contribute a novel\narchitecture for variational latent video prediction,-an approach that, to the\nbest of our knowledge, enables the first variational neural-SDE application to\nvideo perception.\n",
        "published": "2023",
        "authors": [
            "Rembert Daems",
            "Manfred Opper",
            "Guillaume Crevecoeur",
            "Tolga Birdal"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.15722v1",
        "title": "GLIME: General, Stable and Local LIME Explanation",
        "abstract": "  As black-box machine learning models grow in complexity and find applications\nin high-stakes scenarios, it is imperative to provide explanations for their\npredictions. Although Local Interpretable Model-agnostic Explanations (LIME)\n[22] is a widely adpoted method for understanding model behaviors, it is\nunstable with respect to random seeds [35,24,3] and exhibits low local fidelity\n(i.e., how well the explanation approximates the model's local behaviors)\n[21,16]. Our study shows that this instability problem stems from small sample\nweights, leading to the dominance of regularization and slow convergence.\nAdditionally, LIME's sampling neighborhood is non-local and biased towards the\nreference, resulting in poor local fidelity and sensitivity to reference\nchoice. To tackle these challenges, we introduce GLIME, an enhanced framework\nextending LIME and unifying several prior methods. Within the GLIME framework,\nwe derive an equivalent formulation of LIME that achieves significantly faster\nconvergence and improved stability. By employing a local and unbiased sampling\ndistribution, GLIME generates explanations with higher local fidelity compared\nto LIME. GLIME explanations are independent of reference choice. Moreover,\nGLIME offers users the flexibility to choose a sampling distribution based on\ntheir specific scenarios.\n",
        "published": "2023",
        "authors": [
            "Zeren Tan",
            "Yang Tian",
            "Jian Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.04398v1",
        "title": "Intelligent Anomaly Detection for Lane Rendering Using Transformer with\n  Self-Supervised Pre-Training and Customized Fine-Tuning",
        "abstract": "  The burgeoning navigation services using digital maps provide great\nconvenience to drivers. Nevertheless, the presence of anomalies in lane\nrendering map images occasionally introduces potential hazards, as such\nanomalies can be misleading to human drivers and consequently contribute to\nunsafe driving conditions. In response to this concern and to accurately and\neffectively detect the anomalies, this paper transforms lane rendering image\nanomaly detection into a classification problem and proposes a four-phase\npipeline consisting of data pre-processing, self-supervised pre-training with\nthe masked image modeling (MiM) method, customized fine-tuning using\ncross-entropy based loss with label smoothing, and post-processing to tackle it\nleveraging state-of-the-art deep learning techniques, especially those\ninvolving Transformer models. Various experiments verify the effectiveness of\nthe proposed pipeline. Results indicate that the proposed pipeline exhibits\nsuperior performance in lane rendering image anomaly detection, and notably,\nthe self-supervised pre-training with MiM can greatly enhance the detection\naccuracy while significantly reducing the total training time. For instance,\nemploying the Swin Transformer with Uniform Masking as self-supervised\npretraining (Swin-Trans-UM) yielded a heightened accuracy at 94.77% and an\nimproved Area Under The Curve (AUC) score of 0.9743 compared with the pure Swin\nTransformer without pre-training (Swin-Trans) with an accuracy of 94.01% and an\nAUC of 0.9498. The fine-tuning epochs were dramatically reduced to 41 from the\noriginal 280. In conclusion, the proposed pipeline, with its incorporation of\nself-supervised pre-training using MiM and other advanced deep learning\ntechniques, emerges as a robust solution for enhancing the accuracy and\nefficiency of lane rendering image anomaly detection in digital navigation\nsystems.\n",
        "published": "2023",
        "authors": [
            "Yongqi Dong",
            "Xingmin Lu",
            "Ruohan Li",
            "Wei Song",
            "Bart van Arem",
            "Haneen Farah"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1703.07255v2",
        "title": "ZM-Net: Real-time Zero-shot Image Manipulation Network",
        "abstract": "  Many problems in image processing and computer vision (e.g. colorization,\nstyle transfer) can be posed as 'manipulating' an input image into a\ncorresponding output image given a user-specified guiding signal. A holy-grail\nsolution towards generic image manipulation should be able to efficiently alter\nan input image with any personalized signals (even signals unseen during\ntraining), such as diverse paintings and arbitrary descriptive attributes.\nHowever, existing methods are either inefficient to simultaneously process\nmultiple signals (let alone generalize to unseen signals), or unable to handle\nsignals from other modalities. In this paper, we make the first attempt to\naddress the zero-shot image manipulation task. We cast this problem as\nmanipulating an input image according to a parametric model whose key\nparameters can be conditionally generated from any guiding signal (even unseen\nones). To this end, we propose the Zero-shot Manipulation Net (ZM-Net), a\nfully-differentiable architecture that jointly optimizes an\nimage-transformation network (TNet) and a parameter network (PNet). The PNet\nlearns to generate key transformation parameters for the TNet given any guiding\nsignal while the TNet performs fast zero-shot image manipulation according to\nboth signal-dependent parameters from the PNet and signal-invariant parameters\nfrom the TNet itself. Extensive experiments show that our ZM-Net can perform\nhigh-quality image manipulation conditioned on different forms of guiding\nsignals (e.g. style images and attributes) in real-time (tens of milliseconds\nper image) even for unseen signals. Moreover, a large-scale style dataset with\nover 20,000 style images is also constructed to promote further research.\n",
        "published": "2017",
        "authors": [
            "Hao Wang",
            "Xiaodan Liang",
            "Hao Zhang",
            "Dit-Yan Yeung",
            "Eric P. Xing"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1706.06689v1",
        "title": "Chemception: A Deep Neural Network with Minimal Chemistry Knowledge\n  Matches the Performance of Expert-developed QSAR/QSPR Models",
        "abstract": "  In the last few years, we have seen the transformative impact of deep\nlearning in many applications, particularly in speech recognition and computer\nvision. Inspired by Google's Inception-ResNet deep convolutional neural network\n(CNN) for image classification, we have developed \"Chemception\", a deep CNN for\nthe prediction of chemical properties, using just the images of 2D drawings of\nmolecules. We develop Chemception without providing any additional explicit\nchemistry knowledge, such as basic concepts like periodicity, or advanced\nfeatures like molecular descriptors and fingerprints. We then show how\nChemception can serve as a general-purpose neural network architecture for\npredicting toxicity, activity, and solvation properties when trained on a\nmodest database of 600 to 40,000 compounds. When compared to multi-layer\nperceptron (MLP) deep neural networks trained with ECFP fingerprints,\nChemception slightly outperforms in activity and solvation prediction and\nslightly underperforms in toxicity prediction. Having matched the performance\nof expert-developed QSAR/QSPR deep learning models, our work demonstrates the\nplausibility of using deep neural networks to assist in computational chemistry\nresearch, where the feature engineering process is performed primarily by a\ndeep learning algorithm.\n",
        "published": "2017",
        "authors": [
            "Garrett B. Goh",
            "Charles Siegel",
            "Abhinav Vishnu",
            "Nathan O. Hodas",
            "Nathan Baker"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1707.05373v1",
        "title": "Houdini: Fooling Deep Structured Prediction Models",
        "abstract": "  Generating adversarial examples is a critical step for evaluating and\nimproving the robustness of learning machines. So far, most existing methods\nonly work for classification and are not designed to alter the true performance\nmeasure of the problem at hand. We introduce a novel flexible approach named\nHoudini for generating adversarial examples specifically tailored for the final\nperformance measure of the task considered, be it combinatorial and\nnon-decomposable. We successfully apply Houdini to a range of applications such\nas speech recognition, pose estimation and semantic segmentation. In all cases,\nthe attacks based on Houdini achieve higher success rate than those based on\nthe traditional surrogates used to train the models while using a less\nperceptible adversarial perturbation.\n",
        "published": "2017",
        "authors": [
            "Moustapha Cisse",
            "Yossi Adi",
            "Natalia Neverova",
            "Joseph Keshet"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.02857v1",
        "title": "Learning Sparse Visual Representations with Leaky Capped Norm\n  Regularizers",
        "abstract": "  Sparsity inducing regularization is an important part for learning\nover-complete visual representations. Despite the popularity of $\\ell_1$\nregularization, in this paper, we investigate the usage of non-convex\nregularizations in this problem. Our contribution consists of three parts.\nFirst, we propose the leaky capped norm regularization (LCNR), which allows\nmodel weights below a certain threshold to be regularized more strongly as\nopposed to those above, therefore imposes strong sparsity and only introduces\ncontrollable estimation bias. We propose a majorization-minimization algorithm\nto optimize the joint objective function. Second, our study over monocular 3D\nshape recovery and neural networks with LCNR outperforms $\\ell_1$ and other\nnon-convex regularizations, achieving state-of-the-art performance and faster\nconvergence. Third, we prove a theoretical global convergence speed on the 3D\nrecovery problem. To the best of our knowledge, this is the first convergence\nanalysis of the 3D recovery problem.\n",
        "published": "2017",
        "authors": [
            "Jianqiao Wangni",
            "Dahua Lin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.04258v1",
        "title": "Unified Spectral Clustering with Optimal Graph",
        "abstract": "  Spectral clustering has found extensive use in many areas. Most traditional\nspectral clustering algorithms work in three separate steps: similarity graph\nconstruction; continuous labels learning; discretizing the learned labels by\nk-means clustering. Such common practice has two potential flaws, which may\nlead to severe information loss and performance degradation. First, predefined\nsimilarity graph might not be optimal for subsequent clustering. It is\nwell-accepted that similarity graph highly affects the clustering results. To\nthis end, we propose to automatically learn similarity information from data\nand simultaneously consider the constraint that the similarity matrix has exact\nc connected components if there are c clusters. Second, the discrete solution\nmay deviate from the spectral solution since k-means method is well-known as\nsensitive to the initialization of cluster centers. In this work, we transform\nthe candidate solution into a new one that better approximates the discrete\none. Finally, those three subtasks are integrated into a unified framework,\nwith each subtask iteratively boosted by using the results of the others\ntowards an overall optimal solution. It is known that the performance of a\nkernel method is largely determined by the choice of kernels. To tackle this\npractical problem of how to select the most suitable kernel for a particular\ndata set, we further extend our model to incorporate multiple kernel learning\nability. Extensive experiments demonstrate the superiority of our proposed\nmethod as compared to existing clustering approaches.\n",
        "published": "2017",
        "authors": [
            "Zhao Kang",
            "Chong Peng",
            "Qiang Cheng",
            "Zenglin Xu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.11443v2",
        "title": "ConvNets and ImageNet Beyond Accuracy: Understanding Mistakes and\n  Uncovering Biases",
        "abstract": "  ConvNets and Imagenet have driven the recent success of deep learning for\nimage classification. However, the marked slowdown in performance improvement\ncombined with the lack of robustness of neural networks to adversarial examples\nand their tendency to exhibit undesirable biases question the reliability of\nthese methods. This work investigates these questions from the perspective of\nthe end-user by using human subject studies and explanations. The contribution\nof this study is threefold. We first experimentally demonstrate that the\naccuracy and robustness of ConvNets measured on Imagenet are vastly\nunderestimated. Next, we show that explanations can mitigate the impact of\nmisclassified adversarial examples from the perspective of the end-user. We\nfinally introduce a novel tool for uncovering the undesirable biases learned by\na model. These contributions also show that explanations are a valuable tool\nboth for improving our understanding of ConvNets' predictions and for designing\nmore reliable models.\n",
        "published": "2017",
        "authors": [
            "Pierre Stock",
            "Moustapha Cisse"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.02017v2",
        "title": "A General Theory of Equivariant CNNs on Homogeneous Spaces",
        "abstract": "  We present a general theory of Group equivariant Convolutional Neural\nNetworks (G-CNNs) on homogeneous spaces such as Euclidean space and the sphere.\nFeature maps in these networks represent fields on a homogeneous base space,\nand layers are equivariant maps between spaces of fields. The theory enables a\nsystematic classification of all existing G-CNNs in terms of their symmetry\ngroup, base space, and field type. We also consider a fundamental question:\nwhat is the most general kind of equivariant linear map between feature spaces\n(fields) of given types? Following Mackey, we show that such maps correspond\none-to-one with convolutions using equivariant kernels, and characterize the\nspace of such kernels.\n",
        "published": "2018",
        "authors": [
            "Taco Cohen",
            "Mario Geiger",
            "Maurice Weiler"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.03804v4",
        "title": "Gradient Descent Finds Global Minima of Deep Neural Networks",
        "abstract": "  Gradient descent finds a global minimum in training deep neural networks\ndespite the objective function being non-convex. The current paper proves\ngradient descent achieves zero training loss in polynomial time for a deep\nover-parameterized neural network with residual connections (ResNet). Our\nanalysis relies on the particular structure of the Gram matrix induced by the\nneural network architecture. This structure allows us to show the Gram matrix\nis stable throughout the training process and this stability implies the global\noptimality of the gradient descent algorithm. We further extend our analysis to\ndeep residual convolutional neural networks and obtain a similar convergence\nresult.\n",
        "published": "2018",
        "authors": [
            "Simon S. Du",
            "Jason D. Lee",
            "Haochuan Li",
            "Liwei Wang",
            "Xiyu Zhai"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.12231v3",
        "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias\n  improves accuracy and robustness",
        "abstract": "  Convolutional Neural Networks (CNNs) are commonly thought to recognise\nobjects by learning increasingly complex representations of object shapes. Some\nrecent studies suggest a more important role of image textures. We here put\nthese conflicting hypotheses to a quantitative test by evaluating CNNs and\nhuman observers on images with a texture-shape cue conflict. We show that\nImageNet-trained CNNs are strongly biased towards recognising textures rather\nthan shapes, which is in stark contrast to human behavioural evidence and\nreveals fundamentally different classification strategies. We then demonstrate\nthat the same standard architecture (ResNet-50) that learns a texture-based\nrepresentation on ImageNet is able to learn a shape-based representation\ninstead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.\nThis provides a much better fit for human behavioural performance in our\nwell-controlled psychophysical lab setting (nine experiments totalling 48,560\npsychophysical trials across 97 observers) and comes with a number of\nunexpected emergent benefits such as improved object detection performance and\npreviously unseen robustness towards a wide range of image distortions,\nhighlighting advantages of a shape-based representation.\n",
        "published": "2018",
        "authors": [
            "Robert Geirhos",
            "Patricia Rubisch",
            "Claudio Michaelis",
            "Matthias Bethge",
            "Felix A. Wichmann",
            "Wieland Brendel"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1901.02884v1",
        "title": "Deep Learning for Human Affect Recognition: Insights and New\n  Developments",
        "abstract": "  Automatic human affect recognition is a key step towards more natural\nhuman-computer interaction. Recent trends include recognition in the wild using\na fusion of audiovisual and physiological sensors, a challenging setting for\nconventional machine learning algorithms. Since 2010, novel deep learning\nalgorithms have been applied increasingly in this field. In this paper, we\nreview the literature on human affect recognition between 2010 and 2017, with a\nspecial focus on approaches using deep neural networks. By classifying a total\nof 950 studies according to their usage of shallow or deep architectures, we\nare able to show a trend towards deep learning. Reviewing a subset of 233\nstudies that employ deep neural networks, we comprehensively quantify their\napplications in this field. We find that deep learning is used for learning of\n(i) spatial feature representations, (ii) temporal feature representations, and\n(iii) joint feature representations for multimodal sensor data. Exemplary\nstate-of-the-art architectures illustrate the progress. Our findings show the\nrole deep architectures will play in human affect recognition, and can serve as\na reference point for researchers working on related applications.\n",
        "published": "2019",
        "authors": [
            "Philipp V. Rouast",
            "Marc T. P. Adam",
            "Raymond Chiong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.03932v2",
        "title": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning",
        "abstract": "  The posteriors over neural network weights are high dimensional and\nmultimodal. Each mode typically characterizes a meaningfully different\nrepresentation of the data. We develop Cyclical Stochastic Gradient MCMC\n(SG-MCMC) to automatically explore such distributions. In particular, we\npropose a cyclical stepsize schedule, where larger steps discover new modes,\nand smaller steps characterize each mode. We also prove non-asymptotic\nconvergence of our proposed algorithm. Moreover, we provide extensive\nexperimental results, including ImageNet, to demonstrate the scalability and\neffectiveness of cyclical SG-MCMC in learning complex multimodal distributions,\nespecially for fully Bayesian inference with modern deep neural networks.\n",
        "published": "2019",
        "authors": [
            "Ruqi Zhang",
            "Chunyuan Li",
            "Jianyi Zhang",
            "Changyou Chen",
            "Andrew Gordon Wilson"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1902.04186v1",
        "title": "Riemannian joint dimensionality reduction and dictionary learning on\n  symmetric positive definite manifold",
        "abstract": "  Dictionary leaning (DL) and dimensionality reduction (DR) are powerful tools\nto analyze high-dimensional noisy signals. This paper presents a proposal of a\nnovel Riemannian joint dimensionality reduction and dictionary learning\n(R-JDRDL) on symmetric positive definite (SPD) manifolds for classification\ntasks. The joint learning considers the interaction between dimensionality\nreduction and dictionary learning procedures by connecting them into a unified\nframework. We exploit a Riemannian optimization framework for solving DL and DR\nproblems jointly. Finally, we demonstrate that the proposed R-JDRDL outperforms\nexisting state-of-the-arts algorithms when used for image classification tasks.\n",
        "published": "2019",
        "authors": [
            "Hiroyuki Kasai",
            "Bamdev Mishra"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.09406v3",
        "title": "Five Points to Check when Comparing Visual Perception in Humans and\n  Machines",
        "abstract": "  With the rise of machines to human-level performance in complex recognition\ntasks, a growing amount of work is directed towards comparing information\nprocessing in humans and machines. These studies are an exciting chance to\nlearn about one system by studying the other. Here, we propose ideas on how to\ndesign, conduct and interpret experiments such that they adequately support the\ninvestigation of mechanisms when comparing human and machine perception. We\ndemonstrate and apply these ideas through three case studies. The first case\nstudy shows how human bias can affect how we interpret results, and that\nseveral analytic tools can help to overcome this human reference point. In the\nsecond case study, we highlight the difference between necessary and sufficient\nmechanisms in visual reasoning tasks. Thereby, we show that contrary to\nprevious suggestions, feedback mechanisms might not be necessary for the tasks\nin question. The third case study highlights the importance of aligning\nexperimental conditions. We find that a previously-observed difference in\nobject recognition does not hold when adapting the experiment to make\nconditions more equitable between humans and machines. In presenting a\nchecklist for comparative studies of visual reasoning in humans and machines,\nwe hope to highlight how to overcome potential pitfalls in design or inference.\n",
        "published": "2020",
        "authors": [
            "Christina M. Funke",
            "Judy Borowski",
            "Karolina Stosio",
            "Wieland Brendel",
            "Thomas S. A. Wallis",
            "Matthias Bethge"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1709.06129v2",
        "title": "When is a Convolutional Filter Easy To Learn?",
        "abstract": "  We analyze the convergence of (stochastic) gradient descent algorithm for\nlearning a convolutional filter with Rectified Linear Unit (ReLU) activation\nfunction. Our analysis does not rely on any specific form of the input\ndistribution and our proofs only use the definition of ReLU, in contrast with\nprevious works that are restricted to standard Gaussian input. We show that\n(stochastic) gradient descent with random initialization can learn the\nconvolutional filter in polynomial time and the convergence rate depends on the\nsmoothness of the input distribution and the closeness of patches. To the best\nof our knowledge, this is the first recovery guarantee of gradient-based\nalgorithms for convolutional filter on non-Gaussian input distributions. Our\ntheory also justifies the two-stage learning rate strategy in deep neural\nnetworks. While our focus is theoretical, we also present experiments that\nillustrate our theoretical findings.\n",
        "published": "2017",
        "authors": [
            "Simon S. Du",
            "Jason D. Lee",
            "Yuandong Tian"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1908.05959v2",
        "title": "Multi-Domain Adaptation in Brain MRI through Paired Consistency and\n  Adversarial Learning",
        "abstract": "  Supervised learning algorithms trained on medical images will often fail to\ngeneralize across changes in acquisition parameters. Recent work in domain\nadaptation addresses this challenge and successfully leverages labeled data in\na source domain to perform well on an unlabeled target domain. Inspired by\nrecent work in semi-supervised learning we introduce a novel method to adapt\nfrom one source domain to $n$ target domains (as long as there is paired data\ncovering all domains). Our multi-domain adaptation method utilises a\nconsistency loss combined with adversarial learning. We provide results on\nwhite matter lesion hyperintensity segmentation from brain MRIs using the\nMICCAI 2017 challenge data as the source domain and two target domains. The\nproposed method significantly outperforms other domain adaptation baselines.\n",
        "published": "2019",
        "authors": [
            "Mauricio Orbes-Arteaga",
            "Thomas Varsavsky",
            "Carole H. Sudre",
            "Zach Eaton-Rosen",
            "Lewis J. Haddow",
            "Lauge S\u00f8rensen",
            "Mads Nielsen",
            "Akshay Pai",
            "S\u00e9bastien Ourselin",
            "Marc Modat",
            "Parashkev Nachev",
            "M. Jorge Cardoso"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1908.08992v1",
        "title": "MEx: Multi-modal Exercises Dataset for Human Activity Recognition",
        "abstract": "  MEx: Multi-modal Exercises Dataset is a multi-sensor, multi-modal dataset,\nimplemented to benchmark Human Activity Recognition(HAR) and Multi-modal Fusion\nalgorithms. Collection of this dataset was inspired by the need for recognising\nand evaluating quality of exercise performance to support patients with\nMusculoskeletal Disorders(MSD). We select 7 exercises regularly recommended for\nMSD patients by physiotherapists and collected data with four sensors a\npressure mat, a depth camera and two accelerometers. The dataset contains three\ndata modalities; numerical time-series data, video data and pressure sensor\ndata posing interesting research challenges when reasoning for HAR and Exercise\nQuality Assessment. This paper presents our evaluation of the dataset on number\nof standard classification algorithms for the HAR task by comparing different\nfeature representation algorithms for each sensor. These results set a\nreference performance for each individual sensor that expose their strengths\nand weaknesses for the future tasks. In addition we visualise pressure mat data\nto explore the potential of the sensor to capture exercise performance quality.\nWith the recent advancement in multi-modal fusion, we also believe MEx is a\nsuitable dataset to benchmark not only HAR algorithms, but also fusion\nalgorithms of heterogeneous data types in multiple application domains.\n",
        "published": "2019",
        "authors": [
            "Anjana Wijekoon",
            "Nirmalie Wiratunga",
            "Kay Cooper"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.00779v2",
        "title": "Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of\n  Spurious Local Minima",
        "abstract": "  We consider the problem of learning a one-hidden-layer neural network with\nnon-overlapping convolutional layer and ReLU activation, i.e., $f(\\mathbf{Z},\n\\mathbf{w}, \\mathbf{a}) = \\sum_j a_j\\sigma(\\mathbf{w}^T\\mathbf{Z}_j)$, in which\nboth the convolutional weights $\\mathbf{w}$ and the output weights $\\mathbf{a}$\nare parameters to be learned. When the labels are the outputs from a teacher\nnetwork of the same architecture with fixed weights $(\\mathbf{w}^*,\n\\mathbf{a}^*)$, we prove that with Gaussian input $\\mathbf{Z}$, there is a\nspurious local minimizer. Surprisingly, in the presence of the spurious local\nminimizer, gradient descent with weight normalization from randomly initialized\nweights can still be proven to recover the true parameters with constant\nprobability, which can be boosted to probability $1$ with multiple restarts. We\nalso show that with constant probability, the same procedure could also\nconverge to the spurious local minimum, showing that the local minimum plays a\nnon-trivial role in the dynamics of gradient descent. Furthermore, a\nquantitative analysis shows that the gradient descent dynamics has two phases:\nit starts off slow, but converges much faster after several iterations.\n",
        "published": "2017",
        "authors": [
            "Simon S. Du",
            "Jason D. Lee",
            "Yuandong Tian",
            "Barnabas Poczos",
            "Aarti Singh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.04235v1",
        "title": "Similarity Learning via Kernel Preserving Embedding",
        "abstract": "  Data similarity is a key concept in many data-driven applications. Many\nalgorithms are sensitive to similarity measures. To tackle this fundamental\nproblem, automatically learning of similarity information from data via\nself-expression has been developed and successfully applied in various models,\nsuch as low-rank representation, sparse subspace learning, semi-supervised\nlearning. However, it just tries to reconstruct the original data and some\nvaluable information, e.g., the manifold structure, is largely ignored. In this\npaper, we argue that it is beneficial to preserve the overall relations when we\nextract similarity information. Specifically, we propose a novel similarity\nlearning framework by minimizing the reconstruction error of kernel matrices,\nrather than the reconstruction error of original data adopted by existing work.\nTaking the clustering task as an example to evaluate our method, we observe\nconsiderable improvements compared to other state-of-the-art methods. More\nimportantly, our proposed framework is very general and provides a novel and\nfundamental building block for many other similarity-based tasks. Besides, our\nproposed kernel preserving opens up a large number of possibilities to embed\nhigh-dimensional data into low-dimensional space.\n",
        "published": "2019",
        "authors": [
            "Zhao Kang",
            "Yiwei Lu",
            "Yuanzhang Su",
            "Changsheng Li",
            "Zenglin Xu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.09621v1",
        "title": "Understanding Deep Neural Network Predictions for Medical Imaging\n  Applications",
        "abstract": "  Computer-aided detection has been a research area attracting great interest\nin the past decade. Machine learning algorithms have been utilized extensively\nfor this application as they provide a valuable second opinion to the doctors.\nDespite several machine learning models being available for medical imaging\napplications, not many have been implemented in the real-world due to the\nuninterpretable nature of the decisions made by the network. In this paper, we\ninvestigate the results provided by deep neural networks for the detection of\nmalaria, diabetic retinopathy, brain tumor, and tuberculosis in different\nimaging modalities. We visualize the class activation mappings for all the\napplications in order to enhance the understanding of these networks. This type\nof visualization, along with the corresponding network performance metrics,\nwould aid the data science experts in better understanding of their models as\nwell as assisting doctors in their decision-making process.\n",
        "published": "2019",
        "authors": [
            "Barath Narayanan Narayanan",
            "Manawaduge Supun De Silva",
            "Russell C. Hardie",
            "Nathan K. Kueterman",
            "Redha Ali"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.00827v2",
        "title": "CheXclusion: Fairness gaps in deep chest X-ray classifiers",
        "abstract": "  Machine learning systems have received much attention recently for their\nability to achieve expert-level performance on clinical tasks, particularly in\nmedical imaging. Here, we examine the extent to which state-of-the-art deep\nlearning classifiers trained to yield diagnostic labels from X-ray images are\nbiased with respect to protected attributes. We train convolution neural\nnetworks to predict 14 diagnostic labels in 3 prominent public chest X-ray\ndatasets: MIMIC-CXR, Chest-Xray8, CheXpert, as well as a multi-site aggregation\nof all those datasets. We evaluate the TPR disparity -- the difference in true\npositive rates (TPR) -- among different protected attributes such as patient\nsex, age, race, and insurance type as a proxy for socioeconomic status. We\ndemonstrate that TPR disparities exist in the state-of-the-art classifiers in\nall datasets, for all clinical tasks, and all subgroups. A multi-source dataset\ncorresponds to the smallest disparities, suggesting one way to reduce bias. We\nfind that TPR disparities are not significantly correlated with a subgroup's\nproportional disease burden. As clinical models move from papers to products,\nwe encourage clinical decision makers to carefully audit for algorithmic\ndisparities prior to deployment. Our code can be found at,\nhttps://github.com/LalehSeyyed/CheXclusion\n",
        "published": "2020",
        "authors": [
            "Laleh Seyyed-Kalantari",
            "Guanxiong Liu",
            "Matthew McDermott",
            "Irene Y. Chen",
            "Marzyeh Ghassemi"
        ]
    }
]