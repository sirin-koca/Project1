[
    {
        "id": "http://arxiv.org/abs/2309.10275v1",
        "title": "Crowd-Aware Multi-Agent Pathfinding With Boosted Curriculum\n  Reinforcement Learning",
        "abstract": "  Multi-Agent Path Finding (MAPF) in crowded environments presents a\nchallenging problem in motion planning, aiming to find collision-free paths for\nall agents in the system. MAPF finds a wide range of applications in various\ndomains, including aerial swarms, autonomous warehouse robotics, and\nself-driving vehicles. The current approaches for MAPF can be broadly\ncategorized into two main categories: centralized and decentralized planning.\nCentralized planning suffers from the curse of dimensionality and thus does not\nscale well in large and complex environments. On the other hand, decentralized\nplanning enables agents to engage in real-time path planning within a partially\nobservable environment, demonstrating implicit coordination. However, they\nsuffer from slow convergence and performance degradation in dense environments.\nIn this paper, we introduce CRAMP, a crowd-aware decentralized approach to\naddress this problem by leveraging reinforcement learning guided by a boosted\ncurriculum-based training strategy. We test CRAMP on simulated environments and\ndemonstrate that our method outperforms the state-of-the-art decentralized\nmethods for MAPF on various metrics. CRAMP improves the solution quality up to\n58% measured in makespan and collision count, and up to 5% in success rate in\ncomparison to previous methods.\n",
        "published": "2023-09-19",
        "authors": [
            "Phu Pham",
            "Aniket Bera"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.05430v1",
        "title": "Replication of Multi-agent Reinforcement Learning for the \"Hide and\n  Seek\" Problem",
        "abstract": "  Reinforcement learning generates policies based on reward functions and\nhyperparameters. Slight changes in these can significantly affect results. The\nlack of documentation and reproducibility in Reinforcement learning research\nmakes it difficult to replicate once-deduced strategies. While previous\nresearch has identified strategies using grounded maneuvers, there is limited\nwork in more complex environments. The agents in this study are simulated\nsimilarly to Open Al's hider and seek agents, in addition to a flying\nmechanism, enhancing their mobility, and expanding their range of possible\nactions and strategies. This added functionality improves the Hider agents to\ndevelop a chasing strategy from approximately 2 million steps to 1.6 million\nsteps and hiders\n",
        "published": "2023-10-09",
        "authors": [
            "Haider Kamal",
            "Muaz A. Niazi",
            "Hammad Afzal"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.20024v1",
        "title": "Topology Recoverability Prediction for Ad-Hoc Robot Networks: A\n  Data-Driven Fault-Tolerant Approach",
        "abstract": "  Faults occurring in ad-hoc robot networks may fatally perturb their\ntopologies leading to disconnection of subsets of those networks. Optimal\ntopology synthesis is generally resource-intensive and time-consuming to be\ndone in real time for large ad-hoc robot networks. One should only perform\ntopology re-computations if the probability of topology recoverability after\nthe occurrence of any fault surpasses that of its irrecoverability. We\nformulate this problem as a binary classification problem. Then, we develop a\ntwo-pathway data-driven model based on Bayesian Gaussian mixture models that\npredicts the solution to a typical problem by two different pre-fault and\npost-fault prediction pathways. The results, obtained by the integration of the\npredictions of those pathways, clearly indicate the success of our model in\nsolving the topology (ir)recoverability prediction problem compared to the best\nof current strategies found in the literature.\n",
        "published": "2023-10-30",
        "authors": [
            "Matin Macktoobian",
            "Zhan Shu",
            "Qing Zhao"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.00865v1",
        "title": "Selectively Sharing Experiences Improves Multi-Agent Reinforcement\n  Learning",
        "abstract": "  We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized\nExperience Relay, in which agents share with other agents a limited number of\ntransitions they observe during training. The intuition behind this is that\neven a small number of relevant experiences from other agents could help each\nagent learn. Unlike many other multi-agent RL algorithms, this approach allows\nfor largely decentralized training, requiring only a limited communication\nchannel between agents. We show that our approach outperforms baseline\nno-sharing decentralized training and state-of-the art multi-agent RL\nalgorithms. Further, sharing only a small number of highly relevant experiences\noutperforms sharing all experiences between agents, and the performance uplift\nfrom selective experience sharing is robust across a range of hyperparameters\nand DQN variants. A reference implementation of our algorithm is available at\nhttps://github.com/mgerstgrasser/super.\n",
        "published": "2023-11-01",
        "authors": [
            "Matthias Gerstgrasser",
            "Tom Danino",
            "Sarah Keren"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.12943v1",
        "title": "InteRACT: Transformer Models for Human Intent Prediction Conditioned on\n  Robot Actions",
        "abstract": "  In collaborative human-robot manipulation, a robot must predict human intents\nand adapt its actions accordingly to smoothly execute tasks. However, the\nhuman's intent in turn depends on actions the robot takes, creating a\nchicken-or-egg problem. Prior methods ignore such inter-dependency and instead\ntrain marginal intent prediction models independent of robot actions. This is\nbecause training conditional models is hard given a lack of paired human-robot\ninteraction datasets.\n  Can we instead leverage large-scale human-human interaction data that is more\neasily accessible? Our key insight is to exploit a correspondence between human\nand robot actions that enables transfer learning from human-human to\nhuman-robot data. We propose a novel architecture, InteRACT, that pre-trains a\nconditional intent prediction model on large human-human datasets and\nfine-tunes on a small human-robot dataset. We evaluate on a set of real-world\ncollaborative human-robot manipulation tasks and show that our conditional\nmodel improves over various marginal baselines. We also introduce new\ntechniques to tele-operate a 7-DoF robot arm and collect a diverse range of\nhuman-robot collaborative manipulation data, which we open-source.\n",
        "published": "2023-11-21",
        "authors": [
            "Kushal Kedia",
            "Atiksh Bhardwaj",
            "Prithwish Dan",
            "Sanjiban Choudhury"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.03154v2",
        "title": "Decentralized Multi-Agent Active Search and Tracking when Targets\n  Outnumber Agents",
        "abstract": "  Multi-agent multi-target tracking has a wide range of applications, including\nwildlife patrolling, security surveillance or environment monitoring. Such\nalgorithms often make restrictive assumptions: the number of targets and/or\ntheir initial locations may be assumed known, or agents may be pre-assigned to\nmonitor disjoint partitions of the environment, reducing the burden of\nexploration. This also limits applicability when there are fewer agents than\ntargets, since agents are unable to continuously follow the targets in their\nfields of view. Multi-agent tracking algorithms additionally assume inter-agent\nsynchronization of observations, or the presence of a central controller to\ncoordinate joint actions. Instead, we focus on the setting of decentralized\nmulti-agent, multi-target, simultaneous active search-and-tracking with\nasynchronous inter-agent communication. Our proposed algorithm DecSTER uses a\nsequential monte carlo implementation of the probability hypothesis density\nfilter for posterior inference combined with Thompson sampling for\ndecentralized multi-agent decision making. We compare different action\nselection policies, focusing on scenarios where targets outnumber agents. In\nsimulation, we demonstrate that DecSTER is robust to unreliable inter-agent\ncommunication and outperforms information-greedy baselines in terms of the\nOptimal Sub-Pattern Assignment (OSPA) metric for different numbers of targets\nand varying teamsizes.\n",
        "published": "2024-01-06",
        "authors": [
            "Arundhati Banerjee",
            "Jeff Schneider"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.05572v1",
        "title": "Innate-Values-driven Reinforcement Learning for Cooperative Multi-Agent\n  Systems",
        "abstract": "  Innate values describe agents' intrinsic motivations, which reflect their\ninherent interests and preferences to pursue goals and drive them to develop\ndiverse skills satisfying their various needs. The essence of reinforcement\nlearning (RL) is learning from interaction based on reward-driven (such as\nutilities) behaviors, much like natural agents. It is an excellent model to\ndescribe the innate-values-driven (IV) behaviors of AI agents. Especially in\nmulti-agent systems (MAS), building the awareness of AI agents to balance the\ngroup utilities and system costs and satisfy group members' needs in their\ncooperation is a crucial problem for individuals learning to support their\ncommunity and integrate human society in the long term. This paper proposes a\nhierarchical compound intrinsic value reinforcement learning model --\ninnate-values-driven reinforcement learning termed IVRL to describe the complex\nbehaviors of multi-agent interaction in their cooperation. We implement the\nIVRL architecture in the StarCraft Multi-Agent Challenge (SMAC) environment and\ncompare the cooperative performance within three characteristics of innate\nvalue agents (Coward, Neutral, and Reckless) through three benchmark\nmulti-agent RL algorithms: QMIX, IQL, and QTRAN. The results demonstrate that\nby organizing individual various needs rationally, the group can achieve better\nperformance with lower costs effectively.\n",
        "published": "2024-01-10",
        "authors": [
            "Qin Yang"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1908.02999v1",
        "title": "Learning Vision-based Flight in Drone Swarms by Imitation",
        "abstract": "  Decentralized drone swarms deployed today either rely on sharing of positions\namong agents or detecting swarm members with the help of visual markers. This\nwork proposes an entirely visual approach to coordinate markerless drone swarms\nbased on imitation learning. Each agent is controlled by a small and efficient\nconvolutional neural network that takes raw omnidirectional images as inputs\nand predicts 3D velocity commands that match those computed by a flocking\nalgorithm. We start training in simulation and propose a simple yet effective\nunsupervised domain adaptation approach to transfer the learned controller to\nthe real world. We further train the controller with data collected in our\nmotion capture hall. We show that the convolutional neural network trained on\nthe visual inputs of the drone can learn not only robust inter-agent collision\navoidance but also cohesion of the swarm in a sample-efficient manner. The\nneural controller effectively learns to localize other agents in the visual\ninput, which we show by visualizing the regions with the most influence on the\nmotion of an agent. We remove the dependence on sharing positions among swarm\nmembers by taking only local visual information into account for control. Our\nwork can therefore be seen as the first step towards a fully decentralized,\nvision-based swarm without the need for communication or visual markers.\n",
        "published": "2019-08-08",
        "authors": [
            "Fabian Schilling",
            "Julien Lecoeur",
            "Fabrizio Schiano",
            "Dario Floreano"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.00543v1",
        "title": "Learning Vision-based Cohesive Flight in Drone Swarms",
        "abstract": "  This paper presents a data-driven approach to learning vision-based\ncollective behavior from a simple flocking algorithm. We simulate a swarm of\nquadrotor drones and formulate the controller as a regression problem in which\nwe generate 3D velocity commands directly from raw camera images. The dataset\nis created by simultaneously acquiring omnidirectional images and computing the\ncorresponding control command from the flocking algorithm. We show that a\nconvolutional neural network trained on the visual inputs of the drone can\nlearn not only robust collision avoidance but also coherence of the flock in a\nsample-efficient manner. The neural controller effectively learns to localize\nother agents in the visual input, which we show by visualizing the regions with\nthe most influence on the motion of an agent. This weakly supervised saliency\nmap can be computed efficiently and may be used as a prior for subsequent\ndetection and relative localization of other agents. We remove the dependence\non sharing positions among flock members by taking only local visual\ninformation into account for control. Our work can therefore be seen as the\nfirst step towards a fully decentralized, vision-based flock without the need\nfor communication or visual markers to aid detection of other agents.\n",
        "published": "2018-09-03",
        "authors": [
            "Fabian Schilling",
            "Julien Lecoeur",
            "Fabrizio Schiano",
            "Dario Floreano"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.13924v4",
        "title": "EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational\n  Reasoning",
        "abstract": "  Multi-agent interacting systems are prevalent in the world, from pure\nphysical systems to complicated social dynamic systems. In many applications,\neffective understanding of the situation and accurate trajectory prediction of\ninteractive agents play a significant role in downstream tasks, such as\ndecision making and planning. In this paper, we propose a generic trajectory\nforecasting framework (named EvolveGraph) with explicit relational structure\nrecognition and prediction via latent interaction graphs among multiple\nheterogeneous, interactive agents. Considering the uncertainty of future\nbehaviors, the model is designed to provide multi-modal prediction hypotheses.\nSince the underlying interactions may evolve even with abrupt changes, and\ndifferent modalities of evolution may lead to different outcomes, we address\nthe necessity of dynamic relational reasoning and adaptively evolving the\ninteraction graphs. We also introduce a double-stage training pipeline which\nnot only improves training efficiency and accelerates convergence, but also\nenhances model performance. The proposed framework is evaluated on both\nsynthetic physics simulations and multiple real-world benchmark datasets in\nvarious areas. The experimental results illustrate that our approach achieves\nstate-of-the-art performance in terms of prediction accuracy.\n",
        "published": "2020-03-31",
        "authors": [
            "Jiachen Li",
            "Fan Yang",
            "Masayoshi Tomizuka",
            "Chiho Choi"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2006.13164v3",
        "title": "Joint Object Detection and Multi-Object Tracking with Graph Neural\n  Networks",
        "abstract": "  Object detection and data association are critical components in multi-object\ntracking (MOT) systems. Despite the fact that the two components are dependent\non each other, prior works often design detection and data association modules\nseparately which are trained with separate objectives. As a result, one cannot\nback-propagate the gradients and optimize the entire MOT system, which leads to\nsub-optimal performance. To address this issue, recent works simultaneously\noptimize detection and data association modules under a joint MOT framework,\nwhich has shown improved performance in both modules. In this work, we propose\na new instance of joint MOT approach based on Graph Neural Networks (GNNs). The\nkey idea is that GNNs can model relations between variable-sized objects in\nboth the spatial and temporal domains, which is essential for learning\ndiscriminative features for detection and data association. Through extensive\nexperiments on the MOT15/16/17/20 datasets, we demonstrate the effectiveness of\nour GNN-based joint MOT approach and show state-of-the-art performance for both\ndetection and MOT tasks. Our code is available at:\nhttps://github.com/yongxinw/GSDT\n",
        "published": "2020-06-23",
        "authors": [
            "Yongxin Wang",
            "Kris Kitani",
            "Xinshuo Weng"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.11598v1",
        "title": "End-to-End 3D Multi-Object Tracking and Trajectory Forecasting",
        "abstract": "  3D multi-object tracking (MOT) and trajectory forecasting are two critical\ncomponents in modern 3D perception systems. We hypothesize that it is\nbeneficial to unify both tasks under one framework to learn a shared feature\nrepresentation of agent interaction. To evaluate this hypothesis, we propose a\nunified solution for 3D MOT and trajectory forecasting which also incorporates\ntwo additional novel computational units. First, we employ a feature\ninteraction technique by introducing Graph Neural Networks (GNNs) to capture\nthe way in which multiple agents interact with one another. The GNN is able to\nmodel complex hierarchical interactions, improve the discriminative feature\nlearning for MOT association, and provide socially-aware context for trajectory\nforecasting. Second, we use a diversity sampling function to improve the\nquality and diversity of our forecasted trajectories. The learned sampling\nfunction is trained to efficiently extract a variety of outcomes from a\ngenerative trajectory distribution and helps avoid the problem of generating\nmany duplicate trajectory samples. We show that our method achieves\nstate-of-the-art performance on the KITTI dataset. Our project website is at\nhttp://www.xinshuoweng.com/projects/GNNTrkForecast.\n",
        "published": "2020-08-25",
        "authors": [
            "Xinshuo Weng",
            "Ye Yuan",
            "Kris Kitani"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2002.06241v1",
        "title": "Social-WaGDAT: Interaction-aware Trajectory Prediction via Wasserstein\n  Graph Double-Attention Network",
        "abstract": "  Effective understanding of the environment and accurate trajectory prediction\nof surrounding dynamic obstacles are indispensable for intelligent mobile\nsystems (like autonomous vehicles and social robots) to achieve safe and\nhigh-quality planning when they navigate in highly interactive and crowded\nscenarios. Due to the existence of frequent interactions and uncertainty in the\nscene evolution, it is desired for the prediction system to enable relational\nreasoning on different entities and provide a distribution of future\ntrajectories for each agent. In this paper, we propose a generic generative\nneural system (called Social-WaGDAT) for multi-agent trajectory prediction,\nwhich makes a step forward to explicit interaction modeling by incorporating\nrelational inductive biases with a dynamic graph representation and leverages\nboth trajectory and scene context information. We also employ an efficient\nkinematic constraint layer applied to vehicle trajectory prediction which not\nonly ensures physical feasibility but also enhances model performance. The\nproposed system is evaluated on three public benchmark datasets for trajectory\nprediction, where the agents cover pedestrians, cyclists and on-road vehicles.\nThe experimental results demonstrate that our model achieves better performance\nthan various baseline approaches in terms of prediction accuracy.\n",
        "published": "2020-02-14",
        "authors": [
            "Jiachen Li",
            "Hengbo Ma",
            "Zhihao Zhang",
            "Masayoshi Tomizuka"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.01245v2",
        "title": "Vision-based Drone Flocking in Outdoor Environments",
        "abstract": "  Decentralized deployment of drone swarms usually relies on inter-agent\ncommunication or visual markers that are mounted on the vehicles to simplify\ntheir mutual detection. This letter proposes a vision-based detection and\ntracking algorithm that enables groups of drones to navigate without\ncommunication or visual markers. We employ a convolutional neural network to\ndetect and localize nearby agents onboard the quadcopters in real-time. Rather\nthan manually labeling a dataset, we automatically annotate images to train the\nneural network using background subtraction by systematically flying a\nquadcopter in front of a static camera. We use a multi-agent state tracker to\nestimate the relative positions and velocities of nearby agents, which are\nsubsequently fed to a flocking algorithm for high-level control. The drones are\nequipped with multiple cameras to provide omnidirectional visual inputs. The\ncamera setup ensures the safety of the flock by avoiding blind spots regardless\nof the agent configuration. We evaluate the approach with a group of three real\nquadcopters that are controlled using the proposed vision-based flocking\nalgorithm. The results show that the drones can safely navigate in an outdoor\nenvironment despite substantial background clutter and difficult lighting\nconditions. The source code, image dataset, and trained detection model are\navailable at https://github.com/lis-epfl/vswarm.\n",
        "published": "2020-12-02",
        "authors": [
            "Fabian Schilling",
            "Fabrizio Schiano",
            "Dario Floreano"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.12032v4",
        "title": "The Waymo Open Sim Agents Challenge",
        "abstract": "  Simulation with realistic, interactive agents represents a key task for\nautonomous vehicle software development. In this work, we introduce the Waymo\nOpen Sim Agents Challenge (WOSAC). WOSAC is the first public challenge to\ntackle this task and propose corresponding metrics. The goal of the challenge\nis to stimulate the design of realistic simulators that can be used to evaluate\nand train a behavior model for autonomous driving. We outline our evaluation\nmethodology, present results for a number of different baseline simulation\nagent methods, and analyze several submissions to the 2023 competition which\nran from March 16, 2023 to May 23, 2023. The WOSAC evaluation server remains\nopen for submissions and we discuss open problems for the task.\n",
        "published": "2023-05-19",
        "authors": [
            "Nico Montali",
            "John Lambert",
            "Paul Mougin",
            "Alex Kuefler",
            "Nick Rhinehart",
            "Michelle Li",
            "Cole Gulino",
            "Tristan Emrich",
            "Zoey Yang",
            "Shimon Whiteson",
            "Brandyn White",
            "Dragomir Anguelov"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.01129v1",
        "title": "Towards A Multi-agent System for Online Hate Speech Detection",
        "abstract": "  This paper envisions a multi-agent system for detecting the presence of hate\nspeech in online social media platforms such as Twitter and Facebook. We\nintroduce a novel framework employing deep learning techniques to coordinate\nthe channels of textual and im-age processing. Our experimental results aim to\ndemonstrate the effectiveness of our methods for classifying online content,\ntraining the proposed neural network model to effectively detect hateful\ninstances in the input. We conclude with a discussion of how our system may be\nof use to provide recommendations to users who are managing online social\nnetworks, showcasing the immense potential of intelligent multi-agent systems\ntowards delivering social good.\n",
        "published": "2021-05-03",
        "authors": [
            "Gaurav Sahu",
            "Robin Cohen",
            "Olga Vechtomova"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1808.04359v2",
        "title": "Community Regularization of Visually-Grounded Dialog",
        "abstract": "  The task of conducting visually grounded dialog involves learning\ngoal-oriented cooperative dialog between autonomous agents who exchange\ninformation about a scene through several rounds of questions and answers in\nnatural language. We posit that requiring artificial agents to adhere to the\nrules of human language, while also requiring them to maximize information\nexchange through dialog is an ill-posed problem. We observe that humans do not\nstray from a common language because they are social creatures who live in\ncommunities, and have to communicate with many people everyday, so it is far\neasier to stick to a common language even at the cost of some efficiency loss.\nUsing this as inspiration, we propose and evaluate a multi-agent\ncommunity-based dialog framework where each agent interacts with, and learns\nfrom, multiple agents, and show that this community-enforced regularization\nresults in more relevant and coherent dialog (as judged by human evaluators)\nwithout sacrificing task performance (as judged by quantitative metrics).\n",
        "published": "2018-08-10",
        "authors": [
            "Akshat Agarwal",
            "Swaminathan Gurumurthy",
            "Vasu Sharma",
            "Mike Lewis",
            "Katia Sycara"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2007.02382v2",
        "title": "Decentralized Reinforcement Learning: Global Decision-Making via Local\n  Economic Transactions",
        "abstract": "  This paper seeks to establish a framework for directing a society of simple,\nspecialized, self-interested agents to solve what traditionally are posed as\nmonolithic single-agent sequential decision problems. What makes it challenging\nto use a decentralized approach to collectively optimize a central objective is\nthe difficulty in characterizing the equilibrium strategy profile of\nnon-cooperative games. To overcome this challenge, we design a mechanism for\ndefining the learning environment of each agent for which we know that the\noptimal solution for the global objective coincides with a Nash equilibrium\nstrategy profile of the agents optimizing their own local objectives. The\nsociety functions as an economy of agents that learn the credit assignment\nprocess itself by buying and selling to each other the right to operate on the\nenvironment state. We derive a class of decentralized reinforcement learning\nalgorithms that are broadly applicable not only to standard reinforcement\nlearning but also for selecting options in semi-MDPs and dynamically composing\ncomputation graphs. Lastly, we demonstrate the potential advantages of a\nsociety's inherent modular structure for more efficient transfer learning.\n",
        "published": "2020-07-05",
        "authors": [
            "Michael Chang",
            "Sidhant Kaushik",
            "S. Matthew Weinberg",
            "Thomas L. Griffiths",
            "Sergey Levine"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.04926v1",
        "title": "Differentiable Game Mechanics",
        "abstract": "  Deep learning is built on the foundational guarantee that gradient descent on\nan objective function converges to local minima. Unfortunately, this guarantee\nfails in settings, such as generative adversarial nets, that exhibit multiple\ninteracting losses. The behavior of gradient-based methods in games is not well\nunderstood -- and is becoming increasingly important as adversarial and\nmulti-objective architectures proliferate. In this paper, we develop new tools\nto understand and control the dynamics in n-player differentiable games.\n  The key result is to decompose the game Jacobian into two components. The\nfirst, symmetric component, is related to potential games, which reduce to\ngradient descent on an implicit function. The second, antisymmetric component,\nrelates to Hamiltonian games, a new class of games that obey a conservation law\nakin to conservation laws in classical mechanical systems. The decomposition\nmotivates Symplectic Gradient Adjustment (SGA), a new algorithm for finding\nstable fixed points in differentiable games. Basic experiments show SGA is\ncompetitive with recently proposed algorithms for finding stable fixed points\nin GANs -- while at the same time being applicable to, and having guarantees\nin, much more general cases.\n",
        "published": "2019-05-13",
        "authors": [
            "Alistair Letcher",
            "David Balduzzi",
            "Sebastien Racaniere",
            "James Martens",
            "Jakob Foerster",
            "Karl Tuyls",
            "Thore Graepel"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.01097v2",
        "title": "Learning to cooperate: Emergent communication in multi-agent navigation",
        "abstract": "  Emergent communication in artificial agents has been studied to understand\nlanguage evolution, as well as to develop artificial systems that learn to\ncommunicate with humans. We show that agents performing a cooperative\nnavigation task in various gridworld environments learn an interpretable\ncommunication protocol that enables them to efficiently, and in many cases,\noptimally, solve the task. An analysis of the agents' policies reveals that\nemergent signals spatially cluster the state space, with signals referring to\nspecific locations and spatial directions such as \"left\", \"up\", or \"upper left\nroom\". Using populations of agents, we show that the emergent protocol has\nbasic compositional structure, thus exhibiting a core property of natural\nlanguage.\n",
        "published": "2020-04-02",
        "authors": [
            "Ivana Kaji\u0107",
            "Eser Ayg\u00fcn",
            "Doina Precup"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2110.03861v3",
        "title": "QTN-VQC: An End-to-End Learning framework for Quantum Neural Networks",
        "abstract": "  The advent of noisy intermediate-scale quantum (NISQ) computers raises a\ncrucial challenge to design quantum neural networks for fully quantum learning\ntasks. To bridge the gap, this work proposes an end-to-end learning framework\nnamed QTN-VQC, by introducing a trainable quantum tensor network (QTN) for\nquantum embedding on a variational quantum circuit (VQC). The architecture of\nQTN is composed of a parametric tensor-train network for feature extraction and\na tensor product encoding for quantum embedding. We highlight the QTN for\nquantum embedding in terms of two perspectives: (1) we theoretically\ncharacterize QTN by analyzing its representation power of input features; (2)\nQTN enables an end-to-end parametric model pipeline, namely QTN-VQC, from the\ngeneration of quantum embedding to the output measurement. Our experiments on\nthe MNIST dataset demonstrate the advantages of QTN for quantum embedding over\nother quantum embedding approaches.\n",
        "published": "2021-10-06",
        "authors": [
            "Jun Qi",
            "Chao-Han Huck Yang",
            "Pin-Yu Chen"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2307.16389v1",
        "title": "STL: A Signed and Truncated Logarithm Activation Function for Neural\n  Networks",
        "abstract": "  Activation functions play an essential role in neural networks. They provide\nthe non-linearity for the networks. Therefore, their properties are important\nfor neural networks' accuracy and running performance. In this paper, we\npresent a novel signed and truncated logarithm function as activation function.\nThe proposed activation function has significantly better mathematical\nproperties, such as being odd function, monotone, differentiable, having\nunbounded value range, and a continuous nonzero gradient. These properties make\nit an excellent choice as an activation function. We compare it with other\nwell-known activation functions in several well-known neural networks. The\nresults confirm that it is the state-of-the-art. The suggested activation\nfunction can be applied in a large range of neural networks where activation\nfunctions are necessary.\n",
        "published": "2023-07-31",
        "authors": [
            "Yuanhao Gong"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.12738v1",
        "title": "Self Training Autonomous Driving Agent",
        "abstract": "  Intrinsically, driving is a Markov Decision Process which suits well the\nreinforcement learning paradigm. In this paper, we propose a novel agent which\nlearns to drive a vehicle without any human assistance. We use the concept of\nreinforcement learning and evolutionary strategies to train our agent in a 2D\nsimulation environment. Our model's architecture goes beyond the World Model's\nby introducing difference images in the auto encoder. This novel involvement of\ndifference images in the auto-encoder gives better representation of the latent\nspace with respect to the motion of vehicle and helps an autonomous agent to\nlearn more efficiently how to drive a vehicle. Results show that our method\nrequires fewer (96% less) total agents, (87.5% less) agents per generations,\n(70% less) generations and (90% less) rollouts than the original architecture\nwhile achieving the same accuracy of the original.\n",
        "published": "2019-04-26",
        "authors": [
            "Shashank Kotyan",
            "Danilo Vasconcellos Vargas",
            "Venkanna U"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2205.15864v3",
        "title": "Braille Letter Reading: A Benchmark for Spatio-Temporal Pattern\n  Recognition on Neuromorphic Hardware",
        "abstract": "  Spatio-temporal pattern recognition is a fundamental ability of the brain\nwhich is required for numerous real-world activities. Recent deep learning\napproaches have reached outstanding accuracies in such tasks, but their\nimplementation on conventional embedded solutions is still very computationally\nand energy expensive. Tactile sensing in robotic applications is a\nrepresentative example where real-time processing and energy efficiency are\nrequired. Following a brain-inspired computing approach, we propose a new\nbenchmark for spatio-temporal tactile pattern recognition at the edge through\nBraille letter reading. We recorded a new Braille letters dataset based on the\ncapacitive tactile sensors of the iCub robot's fingertip. We then investigated\nthe importance of spatial and temporal information as well as the impact of\nevent-based encoding on spike-based computation. Afterward, we trained and\ncompared feedforward and recurrent Spiking Neural Networks (SNNs) offline using\nBackpropagation Through Time (BPTT) with surrogate gradients, then we deployed\nthem on the Intel Loihi neuromorphic chip for fast and efficient inference. We\ncompared our approach to standard classifiers, in particular to the Long\nShort-Term Memory (LSTM) deployed on the embedded NVIDIA Jetson GPU, in terms\nof classification accuracy, power, energy consumption, and delay. Our results\nshow that the LSTM reaches ~97% of accuracy, outperforming the recurrent SNN by\n~17% when using continuous frame-based data instead of event-based inputs.\nHowever, the recurrent SNN on Loihi with event-based inputs is ~500 times more\nenergy-efficient than the LSTM on Jetson, requiring a total power of only ~30\nmW. This work proposes a new benchmark for tactile sensing and highlights the\nchallenges and opportunities of event-based encoding, neuromorphic hardware,\nand spike-based computing for spatio-temporal pattern recognition at the edge.\n",
        "published": "2022-05-30",
        "authors": [
            "Simon F Muller-Cleve",
            "Vittorio Fra",
            "Lyes Khacef",
            "Alejandro Pequeno-Zurro",
            "Daniel Klepatsch",
            "Evelina Forno",
            "Diego G Ivanovich",
            "Shavika Rastogi",
            "Gianvito Urgese",
            "Friedemann Zenke",
            "Chiara Bartolozzi"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2209.02000v2",
        "title": "Neuromorphic Visual Odometry with Resonator Networks",
        "abstract": "  Autonomous agents require self-localization to navigate in unknown\nenvironments. They can use Visual Odometry (VO) to estimate self-motion and\nlocalize themselves using visual sensors. This motion-estimation strategy is\nnot compromised by drift as inertial sensors or slippage as wheel encoders.\nHowever, VO with conventional cameras is computationally demanding, limiting\nits application in systems with strict low-latency, -memory, and -energy\nrequirements. Using event-based cameras and neuromorphic computing hardware\noffers a promising low-power solution to the VO problem. However, conventional\nalgorithms for VO are not readily convertible to neuromorphic hardware. In this\nwork, we present a VO algorithm built entirely of neuronal building blocks\nsuitable for neuromorphic implementation. The building blocks are groups of\nneurons representing vectors in the computational framework of Vector Symbolic\nArchitecture (VSA) which was proposed as an abstraction layer to program\nneuromorphic hardware. The VO network we propose generates and stores a working\nmemory of the presented visual environment. It updates this working memory\nwhile at the same time estimating the changing location and orientation of the\ncamera. We demonstrate how VSA can be leveraged as a computing paradigm for\nneuromorphic robotics. Moreover, our results represent an important step\ntowards using neuromorphic computing hardware for fast and power-efficient VO\nand the related task of simultaneous localization and mapping (SLAM). We\nvalidate this approach experimentally in a simple robotic task and with an\nevent-based dataset, demonstrating state-of-the-art performance in these\nsettings.\n",
        "published": "2022-09-05",
        "authors": [
            "Alpha Renner",
            "Lazar Supic",
            "Andreea Danielescu",
            "Giacomo Indiveri",
            "E. Paxon Frady",
            "Friedrich T. Sommer",
            "Yulia Sandamirskaya"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.02884v1",
        "title": "Policy Gradient With Value Function Approximation For Collective\n  Multiagent Planning",
        "abstract": "  Decentralized (PO)MDPs provide an expressive framework for sequential\ndecision making in a multiagent system. Given their computational complexity,\nrecent research has focused on tractable yet practical subclasses of\nDec-POMDPs. We address such a subclass called CDEC-POMDP where the collective\nbehavior of a population of agents affects the joint-reward and environment\ndynamics. Our main contribution is an actor-critic (AC) reinforcement learning\nmethod for optimizing CDEC-POMDP policies. Vanilla AC has slow convergence for\nlarger problems. To address this, we show how a particular decomposition of the\napproximate action-value function over agents leads to effective updates, and\nalso derive a new way to train the critic based on local reward signals.\nComparisons on a synthetic benchmark and a real-world taxi fleet optimization\nproblem show that our new AC approach provides better quality solutions than\nprevious best approaches.\n",
        "published": "2018-04-09",
        "authors": [
            "Duc Thien Nguyen",
            "Akshat Kumar",
            "Hoong Chuin Lau"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.04232v6",
        "title": "Automatic Programming of Cellular Automata and Artificial Neural\n  Networks Guided by Philosophy",
        "abstract": "  Many computer models such as cellular automata and artificial neural networks\nhave been developed and successfully applied. However, in some cases, these\nmodels might be restrictive on the possible solutions or their solutions might\nbe difficult to interpret. To overcome this problem, we outline a new approach,\nthe so-called allagmatic method, that automatically programs and executes\nmodels with as little limitations as possible while maintaining human\ninterpretability. Earlier we described a metamodel and its building blocks\naccording to the philosophical concepts of structure (spatial dimension) and\noperation (temporal dimension). They are entity, milieu, and update function\nthat together abstractly describe cellular automata, artificial neural\nnetworks, and possibly any kind of computer model. By automatically combining\nthese building blocks in an evolutionary computation, interpretability might be\nincreased by the relationship to the metamodel, and models might be translated\ninto more interpretable models via the metamodel. We propose generic and\nobject-oriented programming to implement the entities and their milieus as\ndynamic and generic arrays and the update function as a method. We show two\nexperiments where a simple cellular automaton and an artificial neural network\nare automatically programmed, compiled, and executed. A target state is\nsuccessfully evolved and learned in the cellular automaton and artificial\nneural network, respectively. We conclude that the allagmatic method can create\nand execute cellular automaton and artificial neural network models in an\nautomated manner with the guidance of philosophy.\n",
        "published": "2019-05-10",
        "authors": [
            "Patrik Christen",
            "Olivier Del Fabbro"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.07098v1",
        "title": "Novelty-organizing team of classifiers in noisy and dynamic environments",
        "abstract": "  In the real world, the environment is constantly changing with the input\nvariables under the effect of noise. However, few algorithms were shown to be\nable to work under those circumstances. Here, Novelty-Organizing Team of\nClassifiers (NOTC) is applied to the continuous action mountain car as well as\ntwo variations of it: a noisy mountain car and an unstable weather mountain\ncar. These problems take respectively noise and change of problem dynamics into\naccount. Moreover, NOTC is compared with NeuroEvolution of Augmenting\nTopologies (NEAT) in these problems, revealing a trade-off between the\napproaches. While NOTC achieves the best performance in all of the problems,\nNEAT needs less trials to converge. It is demonstrated that NOTC achieves\nbetter performance because of its division of the input space (creating easier\nproblems). Unfortunately, this division of input space also requires a bit of\ntime to bootstrap.\n",
        "published": "2018-09-19",
        "authors": [
            "Danilo Vasconcellos Vargas",
            "Hirotaka Takano",
            "Junichi Murata"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2307.04287v1",
        "title": "Generalizing Graph ODE for Learning Complex System Dynamics across\n  Environments",
        "abstract": "  Learning multi-agent system dynamics has been extensively studied for various\nreal-world applications, such as molecular dynamics in biology. Most of the\nexisting models are built to learn single system dynamics from observed\nhistorical data and predict the future trajectory. In practice, however, we\nmight observe multiple systems that are generated across different\nenvironments, which differ in latent exogenous factors such as temperature and\ngravity. One simple solution is to learn multiple environment-specific models,\nbut it fails to exploit the potential commonalities among the dynamics across\nenvironments and offers poor prediction results where per-environment data is\nsparse or limited. Here, we present GG-ODE (Generalized Graph Ordinary\nDifferential Equations), a machine learning framework for learning continuous\nmulti-agent system dynamics across environments. Our model learns system\ndynamics using neural ordinary differential equations (ODE) parameterized by\nGraph Neural Networks (GNNs) to capture the continuous interaction among\nagents. We achieve the model generalization by assuming the dynamics across\ndifferent environments are governed by common physics laws that can be captured\nvia learning a shared ODE function. The distinct latent exogenous factors\nlearned for each environment are incorporated into the ODE function to account\nfor their differences. To improve model performance, we additionally design two\nregularization losses to (1) enforce the orthogonality between the learned\ninitial states and exogenous factors via mutual information minimization; and\n(2) reduce the temporal variance of learned exogenous factors within the same\nsystem via contrastive learning. Experiments over various physical simulations\nshow that our model can accurately predict system dynamics, especially in the\nlong range, and can generalize well to new systems with few observations.\n",
        "published": "2023-07-10",
        "authors": [
            "Zijie Huang",
            "Yizhou Sun",
            "Wei Wang"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.09952v1",
        "title": "Seeking Next Layer Neurons' Attention for Error-Backpropagation-Like\n  Training in a Multi-Agent Network Framework",
        "abstract": "  Despite considerable theoretical progress in the training of neural networks\nviewed as a multi-agent system of neurons, particularly concerning biological\nplausibility and decentralized training, their applicability to real-world\nproblems remains limited due to scalability issues. In contrast,\nerror-backpropagation has demonstrated its effectiveness for training deep\nnetworks in practice. In this study, we propose a local objective for neurons\nthat, when pursued by neurons individually, align them to exhibit similarities\nto error-backpropagation in terms of efficiency and scalability during\ntraining. For this purpose, we examine a neural network comprising\ndecentralized, self-interested neurons seeking to maximize their local\nobjective -- attention from subsequent layer neurons -- and identify the\noptimal strategy for neurons. We also analyze the relationship between this\nstrategy and backpropagation, establishing conditions under which the derived\nstrategy is equivalent to error-backpropagation. Lastly, we demonstrate the\nlearning capacity of these multi-agent neural networks through experiments on\nthree datasets and showcase their superior performance relative to\nerror-backpropagation in a catastrophic forgetting benchmark.\n",
        "published": "2023-10-15",
        "authors": [
            "Arshia Soltani Moakhar",
            "Mohammad Azizmalayeri",
            "Hossein Mirzaei",
            "Mohammad Taghi Manzuri",
            "Mohammad Hossein Rohban"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.02553v4",
        "title": "A Closer Look at Deep Policy Gradients",
        "abstract": "  We study how the behavior of deep policy gradient algorithms reflects the\nconceptual framework motivating their development. To this end, we propose a\nfine-grained analysis of state-of-the-art methods based on key elements of this\nframework: gradient estimation, value prediction, and optimization landscapes.\nOur results show that the behavior of deep policy gradient algorithms often\ndeviates from what their motivating framework would predict: the surrogate\nobjective does not match the true reward landscape, learned value estimators\nfail to fit the true value function, and gradient estimates poorly correlate\nwith the \"true\" gradient. The mismatch between predicted and empirical behavior\nwe uncover highlights our poor understanding of current methods, and indicates\nthe need to move beyond current benchmark-centric evaluation methods.\n",
        "published": "2018-11-06",
        "authors": [
            "Andrew Ilyas",
            "Logan Engstrom",
            "Shibani Santurkar",
            "Dimitris Tsipras",
            "Firdaus Janoos",
            "Larry Rudolph",
            "Aleksander Madry"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.14215v2",
        "title": "Multivariate Uncertainty in Deep Learning",
        "abstract": "  Deep learning has the potential to dramatically impact navigation and\ntracking state estimation problems critical to autonomous vehicles and\nrobotics. Measurement uncertainties in state estimation systems based on Kalman\nand other Bayes filters are typically assumed to be a fixed covariance matrix.\nThis assumption is risky, particularly for \"black box\" deep learning models, in\nwhich uncertainty can vary dramatically and unexpectedly. Accurate\nquantification of multivariate uncertainty will allow for the full potential of\ndeep learning to be used more safely and reliably in these applications. We\nshow how to model multivariate uncertainty for regression problems with neural\nnetworks, incorporating both aleatoric and epistemic sources of heteroscedastic\nuncertainty. We train a deep uncertainty covariance matrix model in two ways:\ndirectly using a multivariate Gaussian density loss function, and indirectly\nusing end-to-end training through a Kalman filter. We experimentally show in a\nvisual tracking problem the large impact that accurate multivariate uncertainty\nquantification can have on Kalman filter performance for both in-domain and\nout-of-domain evaluation data. We additionally show in a challenging visual\nodometry problem how end-to-end filter training can allow uncertainty\npredictions to compensate for filter weaknesses.\n",
        "published": "2019-10-31",
        "authors": [
            "Rebecca L. Russell",
            "Christopher Reale"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.00370v1",
        "title": "PlaNet of the Bayesians: Reconsidering and Improving Deep Planning\n  Network by Incorporating Bayesian Inference",
        "abstract": "  In the present paper, we propose an extension of the Deep Planning Network\n(PlaNet), also referred to as PlaNet of the Bayesians (PlaNet-Bayes). There has\nbeen a growing demand in model predictive control (MPC) in partially observable\nenvironments in which complete information is unavailable because of, for\nexample, lack of expensive sensors. PlaNet is a promising solution to realize\nsuch latent MPC, as it is used to train state-space models via model-based\nreinforcement learning (MBRL) and to conduct planning in the latent space.\nHowever, recent state-of-the-art strategies mentioned in MBRR literature, such\nas involving uncertainty into training and planning, have not been considered,\nsignificantly suppressing the training performance. The proposed extension is\nto make PlaNet uncertainty-aware on the basis of Bayesian inference, in which\nboth model and action uncertainty are incorporated. Uncertainty in latent\nmodels is represented using a neural network ensemble to approximately infer\nmodel posteriors. The ensemble of optimal action candidates is also employed to\ncapture multimodal uncertainty in the optimality. The concept of the action\nensemble relies on a general variational inference MPC (VI-MPC) framework and\nits instance, probabilistic action ensemble with trajectory sampling (PaETS).\nIn this paper, we extend VI-MPC and PaETS, which have been originally\nintroduced in previous literature, to address partially observable cases. We\nexperimentally compare the performances on continuous control tasks, and\nconclude that our method can consistently improve the asymptotic performance\ncompared with PlaNet.\n",
        "published": "2020-03-01",
        "authors": [
            "Masashi Okada",
            "Norio Kosaka",
            "Tadahiro Taniguchi"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2006.05725v1",
        "title": "Bayesian Experience Reuse for Learning from Multiple Demonstrators",
        "abstract": "  Learning from demonstrations (LfD) improves the exploration efficiency of a\nlearning agent by incorporating demonstrations from experts. However,\ndemonstration data can often come from multiple experts with conflicting goals,\nmaking it difficult to incorporate safely and effectively in online settings.\nWe address this problem in the static and dynamic optimization settings by\nmodelling the uncertainty in source and target task functions using\nnormal-inverse-gamma priors, whose corresponding posteriors are, respectively,\nlearned from demonstrations and target data using Bayesian neural networks with\nshared features. We use this learned belief to derive a quadratic programming\nproblem whose solution yields a probability distribution over the expert\nmodels. Finally, we propose Bayesian Experience Reuse (BERS) to sample\ndemonstrations in accordance with this distribution and reuse them directly in\nnew tasks. We demonstrate the effectiveness of this approach for static\noptimization of smooth functions, and transfer learning in a high-dimensional\nsupply chain problem with cost uncertainty.\n",
        "published": "2020-06-10",
        "authors": [
            "Michael Gimelfarb",
            "Scott Sanner",
            "Chi-Guhn Lee"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.05370v1",
        "title": "Neural Graph Evolution: Towards Efficient Automatic Robot Design",
        "abstract": "  Despite the recent successes in robotic locomotion control, the design of\nrobot relies heavily on human engineering. Automatic robot design has been a\nlong studied subject, but the recent progress has been slowed due to the large\ncombinatorial search space and the difficulty in evaluating the found\ncandidates. To address the two challenges, we formulate automatic robot design\nas a graph search problem and perform evolution search in graph space. We\npropose Neural Graph Evolution (NGE), which performs selection on current\ncandidates and evolves new ones iteratively. Different from previous\napproaches, NGE uses graph neural networks to parameterize the control\npolicies, which reduces evaluation cost on new candidates with the help of\nskill transfer from previously evaluated designs. In addition, NGE applies\nGraph Mutation with Uncertainty (GM-UC) by incorporating model uncertainty,\nwhich reduces the search space by balancing exploration and exploitation. We\nshow that NGE significantly outperforms previous methods by an order of\nmagnitude. As shown in experiments, NGE is the first algorithm that can\nautomatically discover kinematically preferred robotic graph structures, such\nas a fish with two symmetrical flat side-fins and a tail, or a cheetah with\nathletic front and back legs. Instead of using thousands of cores for weeks,\nNGE efficiently solves searching problem within a day on a single 64 CPU-core\nAmazon EC2 machine.\n",
        "published": "2019-06-12",
        "authors": [
            "Tingwu Wang",
            "Yuhao Zhou",
            "Sanja Fidler",
            "Jimmy Ba"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2308.03574v1",
        "title": "Generalized Early Stopping in Evolutionary Direct Policy Search",
        "abstract": "  Lengthy evaluation times are common in many optimization problems such as\ndirect policy search tasks, especially when they involve conducting evaluations\nin the physical world, e.g. in robotics applications. Often, when evaluating a\nsolution over a fixed time period, it becomes clear that the objective value\nwill not increase with additional computation time (for example, when a\ntwo-wheeled robot continuously spins on the spot). In such cases, it makes\nsense to stop the evaluation early to save computation time. However, most\napproaches to stop the evaluation are problem-specific and need to be\nspecifically designed for the task at hand. Therefore, we propose an early\nstopping method for direct policy search. The proposed method only looks at the\nobjective value at each time step and requires no problem-specific knowledge.\n  We test the introduced stopping criterion in five direct policy search\nenvironments drawn from games, robotics, and classic control domains, and show\nthat it can save up to 75% of the computation time. We also compare it with\nproblem-specific stopping criteria and demonstrate that it performs comparably\nwhile being more generally applicable.\n",
        "published": "2023-08-07",
        "authors": [
            "Etor Arza",
            "Leni K. Le Goff",
            "Emma Hart"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.07477v1",
        "title": "Task-Independent Spiking Central Pattern Generator: A Learning-Based\n  Approach",
        "abstract": "  Legged locomotion is a challenging task in the field of robotics but a rather\nsimple one in nature. This motivates the use of biological methodologies as\nsolutions to this problem. Central pattern generators are neural networks that\nare thought to be responsible for locomotion in humans and some animal species.\nAs for robotics, many attempts were made to reproduce such systems and use them\nfor a similar goal. One interesting design model is based on spiking neural\nnetworks. This model is the main focus of this work, as its contribution is not\nlimited to engineering but also applicable to neuroscience. This paper\nintroduces a new general framework for building central pattern generators that\nare task-independent, biologically plausible, and rely on learning methods. The\nabilities and properties of the presented approach are not only evaluated in\nsimulation but also in a robotic experiment. The results are very promising as\nthe used robot was able to perform stable walking at different speeds and to\nchange speed within the same gait cycle.\n",
        "published": "2020-03-17",
        "authors": [
            "Elie Aljalbout",
            "Florian Walter",
            "Florian R\u00f6hrbein",
            "Alois Knoll"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2110.12894v2",
        "title": "The Efficiency Misnomer",
        "abstract": "  Model efficiency is a critical aspect of developing and deploying machine\nlearning models. Inference time and latency directly affect the user\nexperience, and some applications have hard requirements. In addition to\ninference costs, model training also have direct financial and environmental\nimpacts. Although there are numerous well-established metrics (cost indicators)\nfor measuring model efficiency, researchers and practitioners often assume that\nthese metrics are correlated with each other and report only few of them. In\nthis paper, we thoroughly discuss common cost indicators, their advantages and\ndisadvantages, and how they can contradict each other. We demonstrate how\nincomplete reporting of cost indicators can lead to partial conclusions and a\nblurred or incomplete picture of the practical considerations of different\nmodels. We further present suggestions to improve reporting of efficiency\nmetrics.\n",
        "published": "2021-10-25",
        "authors": [
            "Mostafa Dehghani",
            "Anurag Arnab",
            "Lucas Beyer",
            "Ashish Vaswani",
            "Yi Tay"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1502.08029v5",
        "title": "Describing Videos by Exploiting Temporal Structure",
        "abstract": "  Recent progress in using recurrent neural networks (RNNs) for image\ndescription has motivated the exploration of their application for video\ndescription. However, while images are static, working with videos requires\nmodeling their dynamic temporal structure and then properly integrating that\ninformation into a natural language description. In this context, we propose an\napproach that successfully takes into account both the local and global\ntemporal structure of videos to produce descriptions. First, our approach\nincorporates a spatial temporal 3-D convolutional neural network (3-D CNN)\nrepresentation of the short temporal dynamics. The 3-D CNN representation is\ntrained on video action recognition tasks, so as to produce a representation\nthat is tuned to human motion and behavior. Second we propose a temporal\nattention mechanism that allows to go beyond local temporal modeling and learns\nto automatically select the most relevant temporal segments given the\ntext-generating RNN. Our approach exceeds the current state-of-art for both\nBLEU and METEOR metrics on the Youtube2Text dataset. We also present results on\na new, larger and more challenging dataset of paired video and natural language\ndescriptions.\n",
        "published": "2015-02-27",
        "authors": [
            "Li Yao",
            "Atousa Torabi",
            "Kyunghyun Cho",
            "Nicolas Ballas",
            "Christopher Pal",
            "Hugo Larochelle",
            "Aaron Courville"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.03497v1",
        "title": "Generalized Earley Parser: Bridging Symbolic Grammars and Sequence Data\n  for Future Prediction",
        "abstract": "  Future predictions on sequence data (e.g., videos or audios) require the\nalgorithms to capture non-Markovian and compositional properties of high-level\nsemantics. Context-free grammars are natural choices to capture such\nproperties, but traditional grammar parsers (e.g., Earley parser) only take\nsymbolic sentences as inputs. In this paper, we generalize the Earley parser to\nparse sequence data which is neither segmented nor labeled. This generalized\nEarley parser integrates a grammar parser with a classifier to find the optimal\nsegmentation and labels, and makes top-down future predictions. Experiments\nshow that our method significantly outperforms other approaches for future\nhuman activity prediction.\n",
        "published": "2018-06-09",
        "authors": [
            "Siyuan Qi",
            "Baoxiong Jia",
            "Song-Chun Zhu"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.05337v2",
        "title": "Hierarchical interpretations for neural network predictions",
        "abstract": "  Deep neural networks (DNNs) have achieved impressive predictive performance\ndue to their ability to learn complex, non-linear relationships between\nvariables. However, the inability to effectively visualize these relationships\nhas led to DNNs being characterized as black boxes and consequently limited\ntheir applications. To ameliorate this problem, we introduce the use of\nhierarchical interpretations to explain DNN predictions through our proposed\nmethod, agglomerative contextual decomposition (ACD). Given a prediction from a\ntrained DNN, ACD produces a hierarchical clustering of the input features,\nalong with the contribution of each cluster to the final prediction. This\nhierarchy is optimized to identify clusters of features that the DNN learned\nare predictive. Using examples from Stanford Sentiment Treebank and ImageNet,\nwe show that ACD is effective at diagnosing incorrect predictions and\nidentifying dataset bias. Through human experiments, we demonstrate that ACD\nenables users both to identify the more accurate of two DNNs and to better\ntrust a DNN's outputs. We also find that ACD's hierarchy is largely robust to\nadversarial perturbations, implying that it captures fundamental aspects of the\ninput and ignores spurious noise.\n",
        "published": "2018-06-14",
        "authors": [
            "Chandan Singh",
            "W. James Murdoch",
            "Bin Yu"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.06538v6",
        "title": "Cavity Filling: Pseudo-Feature Generation for Multi-Class Imbalanced\n  Data Problems in Deep Learning",
        "abstract": "  Herein, we generate pseudo-features based on the multivariate probability\ndistributions obtained from the feature maps in layers of trained deep neural\nnetworks. Further, we augment the minor-class data based on these generated\npseudo-features to overcome the imbalanced data problems. The proposed method,\ni.e., cavity filling, improves the deep learning capabilities in several\nproblems because all the real-world data are observed to be imbalanced.\n",
        "published": "2018-07-17",
        "authors": [
            "Tomohiko Konno",
            "Michiaki Iwazume"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.00725v1",
        "title": "Sentiment Classification using Images and Label Embeddings",
        "abstract": "  In this project we analysed how much semantic information images carry, and\nhow much value image data can add to sentiment analysis of the text associated\nwith the images. To better understand the contribution from images, we compared\nmodels which only made use of image data, models which only made use of text\ndata, and models which combined both data types. We also analysed if this\napproach could help sentiment classifiers generalize to unknown sentiments.\n",
        "published": "2017-12-03",
        "authors": [
            "Laura Graesser",
            "Abhinav Gupta",
            "Lakshay Sharma",
            "Evelina Bakhturina"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.10145v3",
        "title": "Cyclical Annealing Schedule: A Simple Approach to Mitigating KL\n  Vanishing",
        "abstract": "  Variational autoencoders (VAEs) with an auto-regressive decoder have been\napplied for many natural language processing (NLP) tasks. The VAE objective\nconsists of two terms, (i) reconstruction and (ii) KL regularization, balanced\nby a weighting hyper-parameter \\beta. One notorious training difficulty is that\nthe KL term tends to vanish. In this paper we study scheduling schemes for\n\\beta, and show that KL vanishing is caused by the lack of good latent codes in\ntraining the decoder at the beginning of optimization. To remedy this, we\npropose a cyclical annealing schedule, which repeats the process of increasing\n\\beta multiple times. This new procedure allows the progressive learning of\nmore meaningful latent codes, by leveraging the informative representations of\nprevious cycles as warm re-starts. The effectiveness of cyclical annealing is\nvalidated on a broad range of NLP tasks, including language modeling, dialog\nresponse generation and unsupervised language pre-training.\n",
        "published": "2019-03-25",
        "authors": [
            "Hao Fu",
            "Chunyuan Li",
            "Xiaodong Liu",
            "Jianfeng Gao",
            "Asli Celikyilmaz",
            "Lawrence Carin"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2006.14032v2",
        "title": "Compositional Explanations of Neurons",
        "abstract": "  We describe a procedure for explaining neurons in deep representations by\nidentifying compositional logical concepts that closely approximate neuron\nbehavior. Compared to prior work that uses atomic labels as explanations,\nanalyzing neurons compositionally allows us to more precisely and expressively\ncharacterize their behavior. We use this procedure to answer several questions\non interpretability in models for vision and natural language processing.\nFirst, we examine the kinds of abstractions learned by neurons. In image\nclassification, we find that many neurons learn highly abstract but\nsemantically coherent visual concepts, while other polysemantic neurons detect\nmultiple unrelated features; in natural language inference (NLI), neurons learn\nshallow lexical heuristics from dataset biases. Second, we see whether\ncompositional explanations give us insight into model performance: vision\nneurons that detect human-interpretable concepts are positively correlated with\ntask performance, while NLI neurons that fire for shallow heuristics are\nnegatively correlated with task performance. Finally, we show how compositional\nexplanations provide an accessible way for end users to produce simple\n\"copy-paste\" adversarial examples that change model behavior in predictable\nways.\n",
        "published": "2020-06-24",
        "authors": [
            "Jesse Mu",
            "Jacob Andreas"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.01029v2",
        "title": "Initialization and Regularization of Factorized Neural Layers",
        "abstract": "  Factorized layers--operations parameterized by products of two or more\nmatrices--occur in a variety of deep learning contexts, including compressed\nmodel training, certain types of knowledge distillation, and multi-head\nself-attention architectures. We study how to initialize and regularize deep\nnets containing such layers, examining two simple, understudied schemes,\nspectral initialization and Frobenius decay, for improving their performance.\nThe guiding insight is to design optimization routines for these networks that\nare as close as possible to that of their well-tuned, non-decomposed\ncounterparts; we back this intuition with an analysis of how the initialization\nand regularization schemes impact training with gradient descent, drawing on\nmodern attempts to understand the interplay of weight-decay and\nbatch-normalization. Empirically, we highlight the benefits of spectral\ninitialization and Frobenius decay across a variety of settings. In model\ncompression, we show that they enable low-rank methods to significantly\noutperform both unstructured sparsity and tensor methods on the task of\ntraining low-memory residual networks; analogs of the schemes also improve the\nperformance of tensor decomposition techniques. For knowledge distillation,\nFrobenius decay enables a simple, overcomplete baseline that yields a compact\nmodel from over-parameterized training without requiring retraining with or\npruning a teacher network. Finally, we show how both schemes applied to\nmulti-head attention lead to improved performance on both translation and\nunsupervised pre-training.\n",
        "published": "2021-05-03",
        "authors": [
            "Mikhail Khodak",
            "Neil Tenenholtz",
            "Lester Mackey",
            "Nicol\u00f2 Fusi"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.00448v1",
        "title": "Natural-Parameter Networks: A Class of Probabilistic Neural Networks",
        "abstract": "  Neural networks (NN) have achieved state-of-the-art performance in various\napplications. Unfortunately in applications where training data is\ninsufficient, they are often prone to overfitting. One effective way to\nalleviate this problem is to exploit the Bayesian approach by using Bayesian\nneural networks (BNN). Another shortcoming of NN is the lack of flexibility to\ncustomize different distributions for the weights and neurons according to the\ndata, as is often done in probabilistic graphical models. To address these\nproblems, we propose a class of probabilistic neural networks, dubbed\nnatural-parameter networks (NPN), as a novel and lightweight Bayesian treatment\nof NN. NPN allows the usage of arbitrary exponential-family distributions to\nmodel the weights and neurons. Different from traditional NN and BNN, NPN takes\ndistributions as input and goes through layers of transformation before\nproducing distributions to match the target output distributions. As a Bayesian\ntreatment, efficient backpropagation (BP) is performed to learn the natural\nparameters for the distributions over both the weights and neurons. The output\ndistributions of each layer, as byproducts, may be used as second-order\nrepresentations for the associated tasks such as link prediction. Experiments\non real-world datasets show that NPN can achieve state-of-the-art performance.\n",
        "published": "2016-11-02",
        "authors": [
            "Hao Wang",
            "Xingjian Shi",
            "Dit-Yan Yeung"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.00454v1",
        "title": "Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in\n  the Blanks",
        "abstract": "  Hybrid methods that utilize both content and rating information are commonly\nused in many recommender systems. However, most of them use either handcrafted\nfeatures or the bag-of-words representation as a surrogate for the content\ninformation but they are neither effective nor natural enough. To address this\nproblem, we develop a collaborative recurrent autoencoder (CRAE) which is a\ndenoising recurrent autoencoder (DRAE) that models the generation of content\nsequences in the collaborative filtering (CF) setting. The model generalizes\nrecent advances in recurrent deep learning from i.i.d. input to non-i.i.d.\n(CF-based) input and provides a new denoising scheme along with a novel\nlearnable pooling scheme for the recurrent autoencoder. To do this, we first\ndevelop a hierarchical Bayesian model for the DRAE and then generalize it to\nthe CF setting. The synergy between denoising and CF enables CRAE to make\naccurate recommendations while learning to fill in the blanks in sequences.\nExperiments on real-world datasets from different domains (CiteULike and\nNetflix) show that, by jointly modeling the order-aware generation of sequences\nfor the content information and performing CF for the ratings, CRAE is able to\nsignificantly outperform the state of the art on both the recommendation task\nbased on ratings and the sequence generation task based on content information.\n",
        "published": "2016-11-02",
        "authors": [
            "Hao Wang",
            "Xingjian Shi",
            "Dit-Yan Yeung"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1904.12848v6",
        "title": "Unsupervised Data Augmentation for Consistency Training",
        "abstract": "  Semi-supervised learning lately has shown much promise in improving deep\nlearning models when labeled data is scarce. Common among recent approaches is\nthe use of consistency training on a large amount of unlabeled data to\nconstrain model predictions to be invariant to input noise. In this work, we\npresent a new perspective on how to effectively noise unlabeled examples and\nargue that the quality of noising, specifically those produced by advanced data\naugmentation methods, plays a crucial role in semi-supervised learning. By\nsubstituting simple noising operations with advanced data augmentation methods\nsuch as RandAugment and back-translation, our method brings substantial\nimprovements across six language and three vision tasks under the same\nconsistency training framework. On the IMDb text classification dataset, with\nonly 20 labeled examples, our method achieves an error rate of 4.20,\noutperforming the state-of-the-art model trained on 25,000 labeled examples. On\na standard semi-supervised learning benchmark, CIFAR-10, our method outperforms\nall previous approaches and achieves an error rate of 5.43 with only 250\nexamples. Our method also combines well with transfer learning, e.g., when\nfinetuning from BERT, and yields improvements in high-data regime, such as\nImageNet, whether when there is only 10% labeled data or when a full labeled\nset with 1.3M extra unlabeled examples is used. Code is available at\nhttps://github.com/google-research/uda.\n",
        "published": "2019-04-29",
        "authors": [
            "Qizhe Xie",
            "Zihang Dai",
            "Eduard Hovy",
            "Minh-Thang Luong",
            "Quoc V. Le"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1909.10470v2",
        "title": "Improving Generative Visual Dialog by Answering Diverse Questions",
        "abstract": "  Prior work on training generative Visual Dialog models with reinforcement\nlearning(Das et al.) has explored a Qbot-Abot image-guessing game and shown\nthat this 'self-talk' approach can lead to improved performance at the\ndownstream dialog-conditioned image-guessing task. However, this improvement\nsaturates and starts degrading after a few rounds of interaction, and does not\nlead to a better Visual Dialog model. We find that this is due in part to\nrepeated interactions between Qbot and Abot during self-talk, which are not\ninformative with respect to the image. To improve this, we devise a simple\nauxiliary objective that incentivizes Qbot to ask diverse questions, thus\nreducing repetitions and in turn enabling Abot to explore a larger state space\nduring RL ie. be exposed to more visual concepts to talk about, and varied\nquestions to answer. We evaluate our approach via a host of automatic metrics\nand human studies, and demonstrate that it leads to better dialog, ie. dialog\nthat is more diverse (ie. less repetitive), consistent (ie. has fewer\nconflicting exchanges), fluent (ie. more human-like),and detailed, while still\nbeing comparably image-relevant as prior work and ablations.\n",
        "published": "2019-09-23",
        "authors": [
            "Vishvak Murahari",
            "Prithvijit Chattopadhyay",
            "Dhruv Batra",
            "Devi Parikh",
            "Abhishek Das"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2002.01464v1",
        "title": "Visual Concept-Metaconcept Learning",
        "abstract": "  Humans reason with concepts and metaconcepts: we recognize red and green from\nvisual input; we also understand that they describe the same property of\nobjects (i.e., the color). In this paper, we propose the visual\nconcept-metaconcept learner (VCML) for joint learning of concepts and\nmetaconcepts from images and associated question-answer pairs. The key is to\nexploit the bidirectional connection between visual concepts and metaconcepts.\nVisual representations provide grounding cues for predicting relations between\nunseen pairs of concepts. Knowing that red and green describe the same property\nof objects, we generalize to the fact that cube and sphere also describe the\nsame property of objects, since they both categorize the shape of objects.\nMeanwhile, knowledge about metaconcepts empowers visual concept learning from\nlimited, noisy, and even biased data. From just a few examples of purple cubes\nwe can understand a new color purple, which resembles the hue of the cubes\ninstead of the shape of them. Evaluation on both synthetic and real-world\ndatasets validates our claims.\n",
        "published": "2020-02-04",
        "authors": [
            "Chi Han",
            "Jiayuan Mao",
            "Chuang Gan",
            "Joshua B. Tenenbaum",
            "Jiajun Wu"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.07847v4",
        "title": "Learning Stable Classifiers by Transferring Unstable Features",
        "abstract": "  While unbiased machine learning models are essential for many applications,\nbias is a human-defined concept that can vary across tasks. Given only\ninput-label pairs, algorithms may lack sufficient information to distinguish\nstable (causal) features from unstable (spurious) features. However, related\ntasks often share similar biases -- an observation we may leverage to develop\nstable classifiers in the transfer setting. In this work, we explicitly inform\nthe target classifier about unstable features in the source tasks.\nSpecifically, we derive a representation that encodes the unstable features by\ncontrasting different data environments in the source task. We achieve\nrobustness by clustering data of the target task according to this\nrepresentation and minimizing the worst-case risk across these clusters. We\nevaluate our method on both text and image classifications. Empirical results\ndemonstrate that our algorithm is able to maintain robustness on the target\ntask for both synthetically generated environments and real-world environments.\nOur code is available at https://github.com/YujiaBao/Tofu.\n",
        "published": "2021-06-15",
        "authors": [
            "Yujia Bao",
            "Shiyu Chang",
            "Regina Barzilay"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2108.03857v2",
        "title": "GAN Computers Generate Arts? A Survey on Visual Arts, Music, and\n  Literary Text Generation using Generative Adversarial Network",
        "abstract": "  \"Art is the lie that enables us to realize the truth.\" - Pablo Picasso. For\ncenturies, humans have dedicated themselves to producing arts to convey their\nimagination. The advancement in technology and deep learning in particular, has\ncaught the attention of many researchers trying to investigate whether art\ngeneration is possible by computers and algorithms. Using generative\nadversarial networks (GANs), applications such as synthesizing photorealistic\nhuman faces and creating captions automatically from images were realized. This\nsurvey takes a comprehensive look at the recent works using GANs for generating\nvisual arts, music, and literary text. A performance comparison and description\nof the various GAN architecture are also presented. Finally, some of the key\nchallenges in art generation using GANs are highlighted along with\nrecommendations for future work.\n",
        "published": "2021-08-09",
        "authors": [
            "Sakib Shahriar"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2110.14182v1",
        "title": "Evidential Softmax for Sparse Multimodal Distributions in Deep\n  Generative Models",
        "abstract": "  Many applications of generative models rely on the marginalization of their\nhigh-dimensional output probability distributions. Normalization functions that\nyield sparse probability distributions can make exact marginalization more\ncomputationally tractable. However, sparse normalization functions usually\nrequire alternative loss functions for training since the log-likelihood is\nundefined for sparse probability distributions. Furthermore, many sparse\nnormalization functions often collapse the multimodality of distributions. In\nthis work, we present $\\textit{ev-softmax}$, a sparse normalization function\nthat preserves the multimodality of probability distributions. We derive its\nproperties, including its gradient in closed-form, and introduce a continuous\nfamily of approximations to $\\textit{ev-softmax}$ that have full support and\ncan be trained with probabilistic loss functions such as negative\nlog-likelihood and Kullback-Leibler divergence. We evaluate our method on a\nvariety of generative models, including variational autoencoders and\nauto-regressive architectures. Our method outperforms existing dense and sparse\nnormalization techniques in distributional accuracy. We demonstrate that\n$\\textit{ev-softmax}$ successfully reduces the dimensionality of probability\ndistributions while maintaining multimodality.\n",
        "published": "2021-10-27",
        "authors": [
            "Phil Chen",
            "Masha Itkina",
            "Ransalu Senanayake",
            "Mykel J. Kochenderfer"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2209.03942v1",
        "title": "Data Feedback Loops: Model-driven Amplification of Dataset Biases",
        "abstract": "  Datasets scraped from the internet have been critical to the successes of\nlarge-scale machine learning. Yet, this very success puts the utility of future\ninternet-derived datasets at potential risk, as model outputs begin to replace\nhuman annotations as a source of supervision.\n  In this work, we first formalize a system where interactions with one model\nare recorded as history and scraped as training data in the future. We then\nanalyze its stability over time by tracking changes to a test-time bias\nstatistic (e.g. gender bias of model predictions). We find that the degree of\nbias amplification is closely linked to whether the model's outputs behave like\nsamples from the training distribution, a behavior which we characterize and\ndefine as consistent calibration. Experiments in three conditional prediction\nscenarios - image classification, visual role-labeling, and language generation\n- demonstrate that models that exhibit a sampling-like behavior are more\ncalibrated and thus more stable. Based on this insight, we propose an\nintervention to help calibrate and stabilize unstable feedback systems.\n  Code is available at https://github.com/rtaori/data_feedback.\n",
        "published": "2022-09-08",
        "authors": [
            "Rohan Taori",
            "Tatsunori B. Hashimoto"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2303.06296v2",
        "title": "Stabilizing Transformer Training by Preventing Attention Entropy\n  Collapse",
        "abstract": "  Training stability is of great importance to Transformers. In this work, we\ninvestigate the training dynamics of Transformers by examining the evolution of\nthe attention layers. In particular, we track the attention entropy for each\nattention head during the course of training, which is a proxy for model\nsharpness. We identify a common pattern across different architectures and\ntasks, where low attention entropy is accompanied by high training instability,\nwhich can take the form of oscillating loss or divergence. We denote the\npathologically low attention entropy, corresponding to highly concentrated\nattention scores, as $\\textit{entropy collapse}$. As a remedy, we propose\n$\\sigma$Reparam, a simple and efficient solution where we reparametrize all\nlinear layers with spectral normalization and an additional learned scalar. We\ndemonstrate that $\\sigma$Reparam successfully prevents entropy collapse in the\nattention layers, promoting more stable training. Additionally, we prove a\ntight lower bound of the attention entropy, which decreases exponentially fast\nwith the spectral norm of the attention logits, providing additional motivation\nfor our approach. We conduct experiments with $\\sigma$Reparam on image\nclassification, image self-supervised learning, machine translation, speech\nrecognition, and language modeling tasks. We show that $\\sigma$Reparam provides\nstability and robustness with respect to the choice of hyperparameters, going\nso far as enabling training (a) a Vision Transformer {to competitive\nperformance} without warmup, weight decay, layer normalization or adaptive\noptimizers; (b) deep architectures in machine translation and (c) speech\nrecognition to competitive performance without warmup and adaptive optimizers.\nCode is available at \\url{https://github.com/apple/ml-sigma-reparam}.\n",
        "published": "2023-03-11",
        "authors": [
            "Shuangfei Zhai",
            "Tatiana Likhomanenko",
            "Etai Littwin",
            "Dan Busbridge",
            "Jason Ramapuram",
            "Yizhe Zhang",
            "Jiatao Gu",
            "Josh Susskind"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2304.06767v4",
        "title": "RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment",
        "abstract": "  Generative foundation models are susceptible to implicit biases that can\narise from extensive unsupervised training data. Such biases can produce\nsuboptimal samples, skewed outcomes, and unfairness, with potentially serious\nconsequences. Consequently, aligning these models with human ethics and\npreferences is an essential step toward ensuring their responsible and\neffective deployment in real-world applications. Prior research has primarily\nemployed Reinforcement Learning from Human Feedback (RLHF) to address this\nproblem, where generative models are fine-tuned with RL algorithms guided by a\nhuman-feedback-informed reward model. However, the inefficiencies and\ninstabilities associated with RL algorithms frequently present substantial\nobstacles to the successful alignment, necessitating the development of a more\nrobust and streamlined approach. To this end, we introduce a new framework,\nReward rAnked FineTuning (RAFT), designed to align generative models\neffectively. Utilizing a reward model and a sufficient number of samples, our\napproach selects the high-quality samples, discarding those that exhibit\nundesired behavior, and subsequently enhancing the model by fine-tuning on\nthese filtered samples. Our studies show that RAFT can effectively improve the\nmodel performance in both reward learning and other automated metrics in both\nlarge language models and diffusion models.\n",
        "published": "2023-04-13",
        "authors": [
            "Hanze Dong",
            "Wei Xiong",
            "Deepanshu Goyal",
            "Yihan Zhang",
            "Winnie Chow",
            "Rui Pan",
            "Shizhe Diao",
            "Jipeng Zhang",
            "Kashun Shum",
            "Tong Zhang"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.00350v1",
        "title": "POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained\n  models",
        "abstract": "  Through prompting, large-scale pre-trained models have become more expressive\nand powerful, gaining significant attention in recent years. Though these big\nmodels have zero-shot capabilities, in general, labeled data are still required\nto adapt them to downstream tasks. To overcome this critical limitation, we\npropose an unsupervised fine-tuning framework to directly fine-tune the model\nor prompt on the unlabeled target data. We demonstrate how to apply our method\nto both language-augmented vision and masked-language models by aligning the\ndiscrete distributions extracted from the prompts and target data. To verify\nour approach's applicability, we conduct extensive experiments on image\nclassification, sentiment analysis, and natural language inference tasks.\nAcross 13 image-related tasks and 15 language-related ones, the proposed\napproach achieves consistent improvements over the baselines.\n",
        "published": "2023-04-29",
        "authors": [
            "Korawat Tanwisuth",
            "Shujian Zhang",
            "Huangjie Zheng",
            "Pengcheng He",
            "Mingyuan Zhou"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.02499v1",
        "title": "AutoML-GPT: Automatic Machine Learning with GPT",
        "abstract": "  AI tasks encompass a wide range of domains and fields. While numerous AI\nmodels have been designed for specific tasks and applications, they often\nrequire considerable human efforts in finding the right model architecture,\noptimization algorithm, and hyperparameters. Recent advances in large language\nmodels (LLMs) like ChatGPT show remarkable capabilities in various aspects of\nreasoning, comprehension, and interaction. Consequently, we propose developing\ntask-oriented prompts and automatically utilizing LLMs to automate the training\npipeline. To implement this concept, we present the AutoML-GPT, which employs\nGPT as the bridge to diverse AI models and dynamically trains models with\noptimized hyperparameters. AutoML-GPT dynamically takes user requests from the\nmodel and data cards and composes the corresponding prompt paragraph.\nUltimately, with this prompt paragraph, AutoML-GPT will automatically conduct\nthe experiments from data processing to model architecture, hyperparameter\ntuning, and predicted training log. By leveraging {\\ours}'s robust language\ncapabilities and the available AI models, AutoML-GPT can tackle numerous\nintricate AI tasks across various tasks and datasets. This approach achieves\nremarkable results in computer vision, natural language processing, and other\nchallenging areas. Extensive experiments and ablation studies demonstrate that\nour method can be general, effective, and beneficial for many AI tasks.\n",
        "published": "2023-05-04",
        "authors": [
            "Shujian Zhang",
            "Chengyue Gong",
            "Lemeng Wu",
            "Xingchao Liu",
            "Mingyuan Zhou"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.03635v1",
        "title": "CLEVRER-Humans: Describing Physical and Causal Events the Human Way",
        "abstract": "  Building machines that can reason about physical events and their causal\nrelationships is crucial for flexible interaction with the physical world.\nHowever, most existing physical and causal reasoning benchmarks are exclusively\nbased on synthetically generated events and synthetic natural language\ndescriptions of causal relationships. This design brings up two issues. First,\nthere is a lack of diversity in both event types and natural language\ndescriptions; second, causal relationships based on manually-defined heuristics\nare different from human judgments. To address both shortcomings, we present\nthe CLEVRER-Humans benchmark, a video reasoning dataset for causal judgment of\nphysical events with human labels. We employ two techniques to improve data\ncollection efficiency: first, a novel iterative event cloze task to elicit a\nnew representation of events in videos, which we term Causal Event Graphs\n(CEGs); second, a data augmentation technique based on neural language\ngenerative models. We convert the collected CEGs into questions and answers to\nbe consistent with prior work. Finally, we study a collection of baseline\napproaches for CLEVRER-Humans question-answering, highlighting the great\nchallenges set forth by our benchmark.\n",
        "published": "2023-10-05",
        "authors": [
            "Jiayuan Mao",
            "Xuelin Yang",
            "Xikun Zhang",
            "Noah D. Goodman",
            "Jiajun Wu"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.16035v1",
        "title": "What's Left? Concept Grounding with Logic-Enhanced Foundation Models",
        "abstract": "  Recent works such as VisProg and ViperGPT have smartly composed foundation\nmodels for visual reasoning-using large language models (LLMs) to produce\nprograms that can be executed by pre-trained vision-language models. However,\nthey operate in limited domains, such as 2D images, not fully exploiting the\ngeneralization of language: abstract concepts like \"left\" can also be grounded\nin 3D, temporal, and action data, as in moving to your left. This limited\ngeneralization stems from these inference-only methods' inability to learn or\nadapt pre-trained models to a new domain. We propose the Logic-Enhanced\nFoundation Model (LEFT), a unified framework that learns to ground and reason\nwith concepts across domains with a differentiable, domain-independent,\nfirst-order logic-based program executor. LEFT has an LLM interpreter that\noutputs a program represented in a general, logic-based reasoning language,\nwhich is shared across all domains and tasks. LEFT's executor then executes the\nprogram with trainable domain-specific grounding modules. We show that LEFT\nflexibly learns concepts in four domains: 2D images, 3D scenes, human motions,\nand robotic manipulation. It exhibits strong reasoning ability in a wide\nvariety of tasks, including those that are complex and not seen during\ntraining, and can be easily applied to new domains.\n",
        "published": "2023-10-24",
        "authors": [
            "Joy Hsu",
            "Jiayuan Mao",
            "Joshua B. Tenenbaum",
            "Jiajun Wu"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2006.11524v3",
        "title": "Neuro-Symbolic Visual Reasoning: Disentangling \"Visual\" from \"Reasoning\"",
        "abstract": "  Visual reasoning tasks such as visual question answering (VQA) require an\ninterplay of visual perception with reasoning about the question semantics\ngrounded in perception. However, recent advances in this area are still\nprimarily driven by perception improvements (e.g. scene graph generation)\nrather than reasoning. Neuro-symbolic models such as Neural Module Networks\nbring the benefits of compositional reasoning to VQA, but they are still\nentangled with visual representation learning, and thus neural reasoning is\nhard to improve and assess on its own. To address this, we propose (1) a\nframework to isolate and evaluate the reasoning aspect of VQA separately from\nits perception, and (2) a novel top-down calibration technique that allows the\nmodel to answer reasoning questions even with imperfect perception. To this\nend, we introduce a differentiable first-order logic formalism for VQA that\nexplicitly decouples question answering from visual perception. On the\nchallenging GQA dataset, this framework is used to perform in-depth,\ndisentangled comparisons between well-known VQA models leading to informative\ninsights regarding the participating models as well as the task.\n",
        "published": "2020-06-20",
        "authors": [
            "Saeed Amizadeh",
            "Hamid Palangi",
            "Oleksandr Polozov",
            "Yichen Huang",
            "Kazuhito Koishida"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.01843v3",
        "title": "Learning to Perform Physics Experiments via Deep Reinforcement Learning",
        "abstract": "  When encountering novel objects, humans are able to infer a wide range of\nphysical properties such as mass, friction and deformability by interacting\nwith them in a goal driven way. This process of active interaction is in the\nsame spirit as a scientist performing experiments to discover hidden facts.\nRecent advances in artificial intelligence have yielded machines that can\nachieve superhuman performance in Go, Atari, natural language processing, and\ncomplex control problems; however, it is not clear that these systems can rival\nthe scientific intuition of even a young child. In this work we introduce a\nbasic set of tasks that require agents to estimate properties such as mass and\ncohesion of objects in an interactive simulated environment where they can\nmanipulate the objects and observe the consequences. We found that state of art\ndeep reinforcement learning methods can learn to perform the experiments\nnecessary to discover such hidden properties. By systematically manipulating\nthe problem difficulty and the cost incurred by the agent for performing\nexperiments, we found that agents learn different strategies that balance the\ncost of gathering information against the cost of making mistakes in different\nsituations.\n",
        "published": "2016-11-06",
        "authors": [
            "Misha Denil",
            "Pulkit Agrawal",
            "Tejas D Kulkarni",
            "Tom Erez",
            "Peter Battaglia",
            "Nando de Freitas"
        ],
        "categories": [
            null,
            null,
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2308.11601v2",
        "title": "Tryage: Real-time, intelligent Routing of User Prompts to Large Language\n  Models",
        "abstract": "  The introduction of the transformer architecture and the self-attention\nmechanism has led to an explosive production of language models trained on\nspecific downstream tasks and data domains. With over 200, 000 models in the\nHugging Face ecosystem, users grapple with selecting and optimizing models to\nsuit multifaceted workflows and data domains while addressing computational,\nsecurity, and recency concerns. There is an urgent need for machine learning\nframeworks that can eliminate the burden of model selection and customization\nand unleash the incredible power of the vast emerging model library for end\nusers. Here, we propose a context-aware routing system, Tryage, that leverages\na language model router for optimal selection of expert models from a model\nlibrary based on analysis of individual input prompts. Inspired by the thalamic\nrouter in the brain, Tryage employs a perceptive router to predict down-stream\nmodel performance on prompts and, then, makes a routing decision using an\nobjective function that integrates performance predictions with user goals and\nconstraints that are incorporated through flags (e.g., model size, model\nrecency). Tryage allows users to explore a Pareto front and automatically\ntrade-off between task accuracy and secondary goals including minimization of\nmodel size, recency, security, verbosity, and readability. Across heterogeneous\ndata sets that include code, text, clinical data, and patents, the Tryage\nframework surpasses Gorilla and GPT3.5 turbo in dynamic model selection\nidentifying the optimal model with an accuracy of 50.9% , compared to 23.6% by\nGPT 3.5 Turbo and 10.8% by Gorilla. Conceptually, Tryage demonstrates how\nrouting models can be applied to program and control the behavior of\nmulti-model LLM systems to maximize efficient use of the expanding and evolving\nlanguage model ecosystem.\n",
        "published": "2023-08-22",
        "authors": [
            "Surya Narayanan Hari",
            "Matt Thomson"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.04722v1",
        "title": "Re-conceptualising the Language Game Paradigm in the Framework of\n  Multi-Agent Reinforcement Learning",
        "abstract": "  In this paper, we formulate the challenge of re-conceptualising the language\ngame experimental paradigm in the framework of multi-agent reinforcement\nlearning (MARL). If successful, future language game experiments will benefit\nfrom the rapid and promising methodological advances in the MARL community,\nwhile future MARL experiments on learning emergent communication will benefit\nfrom the insights and results gained from language game experiments. We\nstrongly believe that this cross-pollination has the potential to lead to major\nbreakthroughs in the modelling of how human-like languages can emerge and\nevolve in multi-agent systems.\n",
        "published": "2020-04-09",
        "authors": [
            "Paul Van Eecke",
            "Katrien Beuls"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.09218v1",
        "title": "A Practical Guide to Studying Emergent Communication through Grounded\n  Language Games",
        "abstract": "  The question of how an effective and efficient communication system can\nemerge in a population of agents that need to solve a particular task attracts\nmore and more attention from researchers in many fields, including artificial\nintelligence, linguistics and statistical physics. A common methodology for\nstudying this question consists of carrying out multi-agent experiments in\nwhich a population of agents takes part in a series of scripted and\ntask-oriented communicative interactions, called 'language games'. While each\nindividual language game is typically played by two agents in the population, a\nlarge series of games allows the population to converge on a shared\ncommunication system. Setting up an experiment in which a rich system for\ncommunicating about the real world emerges is a major enterprise, as it\nrequires a variety of software components for running multi-agent experiments,\nfor interacting with sensors and actuators, for conceptualising and\ninterpreting semantic structures, and for mapping between these semantic\nstructures and linguistic utterances. The aim of this paper is twofold. On the\none hand, it introduces a high-level robot interface that extends the Babel\nsoftware system, presenting for the first time a toolkit that provides flexible\nmodules for dealing with each subtask involved in running advanced grounded\nlanguage game experiments. On the other hand, it provides a practical guide to\nusing the toolkit for implementing such experiments, taking a grounded colour\nnaming game experiment as a didactic example.\n",
        "published": "2020-04-20",
        "authors": [
            "Jens Nevens",
            "Paul Van Eecke",
            "Katrien Beuls"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2001.07752v2",
        "title": "Emergence of Pragmatics from Referential Game between Theory of Mind\n  Agents",
        "abstract": "  Pragmatics studies how context can contribute to language meanings. In human\ncommunication, language is never interpreted out of context, and sentences can\nusually convey more information than their literal meanings. However, this\nmechanism is missing in most multi-agent systems, restricting the communication\nefficiency and the capability of human-agent interaction. In this paper, we\npropose an algorithm, using which agents can spontaneously learn the ability to\n\"read between lines\" without any explicit hand-designed rules. We integrate the\ntheory of mind (ToM) in a cooperative multi-agent pedagogical situation and\npropose an adaptive reinforcement learning (RL) algorithm to develop a\ncommunication protocol. ToM is a profound cognitive science concept, claiming\nthat people regularly reason about other's mental states, including beliefs,\ngoals, and intentions, to obtain performance advantage in competition,\ncooperation or coalition. With this ability, agents consider language as not\nonly messages but also rational acts reflecting others' hidden states. Our\nexperiments demonstrate the advantage of pragmatic protocols over non-pragmatic\nprotocols. We also show the teaching complexity following the pragmatic\nprotocol empirically approximates to recursive teaching dimension (RTD).\n",
        "published": "2020-01-21",
        "authors": [
            "Luyao Yuan",
            "Zipeng Fu",
            "Jingyue Shen",
            "Lu Xu",
            "Junhong Shen",
            "Song-Chun Zhu"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.01848v2",
        "title": "On Emergent Communication in Competitive Multi-Agent Teams",
        "abstract": "  Several recent works have found the emergence of grounded compositional\nlanguage in the communication protocols developed by mostly cooperative\nmulti-agent systems when learned end-to-end to maximize performance on a\ndownstream task. However, human populations learn to solve complex tasks\ninvolving communicative behaviors not only in fully cooperative settings but\nalso in scenarios where competition acts as an additional external pressure for\nimprovement. In this work, we investigate whether competition for performance\nfrom an external, similar agent team could act as a social influence that\nencourages multi-agent populations to develop better communication protocols\nfor improved performance, compositionality, and convergence speed. We start\nfrom Task & Talk, a previously proposed referential game between two\ncooperative agents as our testbed and extend it into Task, Talk & Compete, a\ngame involving two competitive teams each consisting of two aforementioned\ncooperative agents. Using this new setting, we provide an empirical study\ndemonstrating the impact of competitive influence on multi-agent teams. Our\nresults show that an external competitive influence leads to improved accuracy\nand generalization, as well as faster emergence of communicative languages that\nare more informative and compositional.\n",
        "published": "2020-03-04",
        "authors": [
            "Paul Pu Liang",
            "Jeffrey Chen",
            "Ruslan Salakhutdinov",
            "Louis-Philippe Morency",
            "Satwik Kottur"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2007.09820v1",
        "title": "Reinforcement Communication Learning in Different Social Network\n  Structures",
        "abstract": "  Social network structure is one of the key determinants of human language\nevolution. Previous work has shown that the network of social interactions\nshapes decentralized learning in human groups, leading to the emergence of\ndifferent kinds of communicative conventions. We examined the effects of social\nnetwork organization on the properties of communication systems emerging in\ndecentralized, multi-agent reinforcement learning communities. We found that\nthe global connectivity of a social network drives the convergence of\npopulations on shared and symmetric communication systems, preventing the\nagents from forming many local \"dialects\". Moreover, the agent's degree is\ninversely related to the consistency of its use of communicative conventions.\nThese results show the importance of the basic properties of social network\nstructure on reinforcement communication learning and suggest a new\ninterpretation of findings on human convergence on word conventions.\n",
        "published": "2020-07-19",
        "authors": [
            "Marina Dubova",
            "Arseny Moskvichev",
            "Robert Goldstone"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.03218v4",
        "title": "Learning to Play Guess Who? and Inventing a Grounded Language as a\n  Consequence",
        "abstract": "  Acquiring your first language is an incredible feat and not easily\nduplicated. Learning to communicate using nothing but a few pictureless books,\na corpus, would likely be impossible even for humans. Nevertheless, this is the\ndominating approach in most natural language processing today. As an\nalternative, we propose the use of situated interactions between agents as a\ndriving force for communication, and the framework of Deep Recurrent Q-Networks\nfor evolving a shared language grounded in the provided environment. We task\nthe agents with interactive image search in the form of the game Guess Who?.\nThe images from the game provide a non trivial environment for the agents to\ndiscuss and a natural grounding for the concepts they decide to encode in their\ncommunication. Our experiments show that the agents learn not only to encode\nphysical concepts in their words, i.e. grounding, but also that the agents\nlearn to hold a multi-step dialogue remembering the state of the dialogue from\nstep to step.\n",
        "published": "2016-11-10",
        "authors": [
            "Emilio Jorge",
            "Mikael K\u00e5geb\u00e4ck",
            "Fredrik D. Johansson",
            "Emil Gustavsson"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.03980v1",
        "title": "Emergent Communication through Negotiation",
        "abstract": "  Multi-agent reinforcement learning offers a way to study how communication\ncould emerge in communities of agents needing to solve specific problems. In\nthis paper, we study the emergence of communication in the negotiation\nenvironment, a semi-cooperative model of agent interaction. We introduce two\ncommunication protocols -- one grounded in the semantics of the game, and one\nwhich is \\textit{a priori} ungrounded and is a form of cheap talk. We show that\nself-interested agents can use the pre-grounded communication channel to\nnegotiate fairly, but are unable to effectively use the ungrounded channel.\nHowever, prosocial agents do learn to use cheap talk to find an optimal\nnegotiating strategy, suggesting that cooperation is necessary for language to\nemerge. We also study communication behaviour in a setting where one agent\ninteracts with agents in a community with different levels of prosociality and\nshow how agent identifiability can aid negotiation.\n",
        "published": "2018-04-11",
        "authors": [
            "Kris Cao",
            "Angeliki Lazaridou",
            "Marc Lanctot",
            "Joel Z Leibo",
            "Karl Tuyls",
            "Stephen Clark"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.03984v1",
        "title": "Emergence of Linguistic Communication from Referential Games with\n  Symbolic and Pixel Input",
        "abstract": "  The ability of algorithms to evolve or learn (compositional) communication\nprotocols has traditionally been studied in the language evolution literature\nthrough the use of emergent communication tasks. Here we scale up this research\nby using contemporary deep learning methods and by training\nreinforcement-learning neural network agents on referential communication\ngames. We extend previous work, in which agents were trained in symbolic\nenvironments, by developing agents which are able to learn from raw pixel data,\na more challenging and realistic input representation. We find that the degree\nof structure found in the input data affects the nature of the emerged\nprotocols, and thereby corroborate the hypothesis that structured compositional\nlanguage is most likely to emerge when agents perceive the world as being\nstructured.\n",
        "published": "2018-04-11",
        "authors": [
            "Angeliki Lazaridou",
            "Karl Moritz Hermann",
            "Karl Tuyls",
            "Stephen Clark"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1905.12561v4",
        "title": "Anti-efficient encoding in emergent communication",
        "abstract": "  Despite renewed interest in emergent language simulations with neural\nnetworks, little is known about the basic properties of the induced code, and\nhow they compare to human language. One fundamental characteristic of the\nlatter, known as Zipf's Law of Abbreviation (ZLA), is that more frequent words\nare efficiently associated to shorter strings. We study whether the same\npattern emerges when two neural networks, a \"speaker\" and a \"listener\", are\ntrained to play a signaling game. Surprisingly, we find that networks develop\nan \\emph{anti-efficient} encoding scheme, in which the most frequent inputs are\nassociated to the longest messages, and messages in general are skewed towards\nthe maximum length threshold. This anti-efficient code appears easier to\ndiscriminate for the listener, and, unlike in human communication, the speaker\ndoes not impose a contrasting least-effort pressure towards brevity. Indeed,\nwhen the cost function includes a penalty for longer messages, the resulting\nmessage distribution starts respecting ZLA. Our analysis stresses the\nimportance of studying the basic features of emergent communication in a highly\ncontrolled setup, to ensure the latter will not strand too far from human\nlanguage. Moreover, we present a concrete illustration of how different\nfunctional pressures can lead to successful communication codes that lack basic\nproperties of human language, thus highlighting the role such pressures play in\nthe latter.\n",
        "published": "2019-05-29",
        "authors": [
            "Rahma Chaabouni",
            "Eugene Kharitonov",
            "Emmanuel Dupoux",
            "Marco Baroni"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.02403v2",
        "title": "Ease-of-Teaching and Language Structure from Emergent Communication",
        "abstract": "  Artificial agents have been shown to learn to communicate when needed to\ncomplete a cooperative task. Some level of language structure (e.g.,\ncompositionality) has been found in the learned communication protocols. This\nobserved structure is often the result of specific environmental pressures\nduring training. By introducing new agents periodically to replace old ones,\nsequentially and within a population, we explore such a new pressure -- ease of\nteaching -- and show its impact on the structure of the resulting language.\n",
        "published": "2019-06-06",
        "authors": [
            "Fushan Li",
            "Michael Bowling"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1911.03743v1",
        "title": "A perspective on multi-agent communication for information fusion",
        "abstract": "  Collaborative decision making in multi-agent systems typically requires a\npredefined communication protocol among agents. Usually, agent-level\nobservations are locally processed and information is exchanged using the\npredefined protocol, enabling the team to perform more efficiently than each\nagent operating in isolation. In this work, we consider the situation where\nagents, with complementary sensing modalities must co-operate to achieve a\ncommon goal/task by learning an efficient communication protocol. We frame the\nproblem within an actor-critic scheme, where the agents learn optimal policies\nin a centralized fashion, while taking action in a distributed manner. We\nprovide an interpretation of the emergent communication between the agents. We\nobserve that the information exchanged is not just an encoding of the raw\nsensor data but is, rather, a specific set of directive actions that depend on\nthe overall task. Simulation results demonstrate the interpretability of the\nlearnt communication in a variety of tasks.\n",
        "published": "2019-11-09",
        "authors": [
            "Homagni Saha",
            "Vijay Venkataraman",
            "Alberto Speranzon",
            "Soumik Sarkar"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2106.04258v3",
        "title": "Interpretable agent communication from scratch (with a generic visual\n  processor emerging on the side)",
        "abstract": "  As deep networks begin to be deployed as autonomous agents, the issue of how\nthey can communicate with each other becomes important. Here, we train two deep\nnets from scratch to perform realistic referent identification through\nunsupervised emergent communication. We show that the largely interpretable\nemergent protocol allows the nets to successfully communicate even about object\ntypes they did not see at training time. The visual representations induced as\na by-product of our training regime, moreover, show comparable quality, when\nre-used as generic visual features, to a recent self-supervised learning model.\nOur results provide concrete evidence of the viability of (interpretable)\nemergent deep net communication in a more realistic scenario than previously\nconsidered, as well as establishing an intriguing link between this field and\nself-supervised visual learning.\n",
        "published": "2021-06-08",
        "authors": [
            "Roberto Dess\u00ec",
            "Eugene Kharitonov",
            "Marco Baroni"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2110.05422v1",
        "title": "Calibrate your listeners! Robust communication-based training for\n  pragmatic speakers",
        "abstract": "  To be good conversational partners, natural language processing (NLP) systems\nshould be trained to produce contextually useful utterances. Prior work has\ninvestigated training NLP systems with communication-based objectives, where a\nneural listener stands in as a communication partner. However, these systems\ncommonly suffer from semantic drift where the learned language diverges\nradically from natural language. We propose a method that uses a population of\nneural listeners to regularize speaker training. We first show that language\ndrift originates from the poor uncertainty calibration of a neural listener,\nwhich makes high-certainty predictions on novel sentences. We explore ensemble-\nand dropout-based populations of listeners and find that the former results in\nbetter uncertainty quantification. We evaluate both population-based objectives\non reference games, and show that the ensemble method with better calibration\nenables the speaker to generate pragmatic utterances while scaling to a large\nvocabulary and generalizing to new games and listeners.\n",
        "published": "2021-10-11",
        "authors": [
            "Rose E. Wang",
            "Julia White",
            "Jesse Mu",
            "Noah D. Goodman"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2110.15349v1",
        "title": "Learning to Ground Multi-Agent Communication with Autoencoders",
        "abstract": "  Communication requires having a common language, a lingua franca, between\nagents. This language could emerge via a consensus process, but it may require\nmany generations of trial and error. Alternatively, the lingua franca can be\ngiven by the environment, where agents ground their language in representations\nof the observed world. We demonstrate a simple way to ground language in\nlearned representations, which facilitates decentralized multi-agent\ncommunication and coordination. We find that a standard representation learning\nalgorithm -- autoencoding -- is sufficient for arriving at a grounded common\nlanguage. When agents broadcast these representations, they learn to understand\nand respond to each other's utterances and achieve surprisingly strong task\nperformance across a variety of multi-agent communication environments.\n",
        "published": "2021-10-28",
        "authors": [
            "Toru Lin",
            "Minyoung Huh",
            "Chris Stauffer",
            "Ser-Nam Lim",
            "Phillip Isola"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2203.09498v1",
        "title": "The Frost Hollow Experiments: Pavlovian Signalling as a Path to\n  Coordination and Communication Between Agents",
        "abstract": "  Learned communication between agents is a powerful tool when approaching\ndecision-making problems that are hard to overcome by any single agent in\nisolation. However, continual coordination and communication learning between\nmachine agents or human-machine partnerships remains a challenging open\nproblem. As a stepping stone toward solving the continual communication\nlearning problem, in this paper we contribute a multi-faceted study into what\nwe term Pavlovian signalling -- a process by which learned, temporally extended\npredictions made by one agent inform decision-making by another agent with\ndifferent perceptual access to their shared environment. We seek to establish\nhow different temporal processes and representational choices impact Pavlovian\nsignalling between learning agents. To do so, we introduce a partially\nobservable decision-making domain we call the Frost Hollow. In this domain a\nprediction learning agent and a reinforcement learning agent are coupled into a\ntwo-part decision-making system that seeks to acquire sparse reward while\navoiding time-conditional hazards. We evaluate two domain variations: 1)\nmachine prediction and control learning in a linear walk, and 2) a prediction\nlearning machine interacting with a human participant in a virtual reality\nenvironment. Our results showcase the speed of learning for Pavlovian\nsignalling, the impact that different temporal representations do (and do not)\nhave on agent-agent coordination, and how temporal aliasing impacts agent-agent\nand human-agent interactions differently. As a main contribution, we establish\nPavlovian signalling as a natural bridge between fixed signalling paradigms and\nfully adaptive communication learning. Our results therefore point to an\nactionable, constructivist path towards continual communication learning\nbetween reinforcement learning agents, with potential impact in a range of\nreal-world settings.\n",
        "published": "2022-03-17",
        "authors": [
            "Patrick M. Pilarski",
            "Andrew Butcher",
            "Elnaz Davoodi",
            "Michael Bradley Johanson",
            "Dylan J. A. Brenneis",
            "Adam S. R. Parker",
            "Leslie Acker",
            "Matthew M. Botvinick",
            "Joseph Modayil",
            "Adam White"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2303.08127v3",
        "title": "CB2: Collaborative Natural Language Interaction Research Platform",
        "abstract": "  CB2 is a multi-agent platform to study collaborative natural language\ninteraction in a grounded task-oriented scenario. It includes a 3D game\nenvironment, a backend server designed to serve trained models to human agents,\nand various tools and processes to enable scalable studies. We deploy CB2 at\nhttps://cb2.ai as a system demonstration with a learned instruction following\nmodel.\n",
        "published": "2023-03-14",
        "authors": [
            "Jacob Sharf",
            "Mustafa Omer Gul",
            "Yoav Artzi"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2304.07297v2",
        "title": "Language Instructed Reinforcement Learning for Human-AI Coordination",
        "abstract": "  One of the fundamental quests of AI is to produce agents that coordinate well\nwith humans. This problem is challenging, especially in domains that lack high\nquality human behavioral data, because multi-agent reinforcement learning (RL)\noften converges to different equilibria from the ones that humans prefer. We\npropose a novel framework, instructRL, that enables humans to specify what kind\nof strategies they expect from their AI partners through natural language\ninstructions. We use pretrained large language models to generate a prior\npolicy conditioned on the human instruction and use the prior to regularize the\nRL objective. This leads to the RL agent converging to equilibria that are\naligned with human preferences. We show that instructRL converges to human-like\npolicies that satisfy the given instructions in a proof-of-concept environment\nas well as the challenging Hanabi benchmark. Finally, we show that knowing the\nlanguage instruction significantly boosts human-AI coordination performance in\nhuman evaluations in Hanabi.\n",
        "published": "2023-04-13",
        "authors": [
            "Hengyuan Hu",
            "Dorsa Sadigh"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.10865v2",
        "title": "Semantically Aligned Task Decomposition in Multi-Agent Reinforcement\n  Learning",
        "abstract": "  The difficulty of appropriately assigning credit is particularly heightened\nin cooperative MARL with sparse reward, due to the concurrent time and\nstructural scales involved. Automatic subgoal generation (ASG) has recently\nemerged as a viable MARL approach inspired by utilizing subgoals in\nintrinsically motivated reinforcement learning. However, end-to-end learning of\ncomplex task planning from sparse rewards without prior knowledge, undoubtedly\nrequires massive training samples. Moreover, the diversity-promoting nature of\nexisting ASG methods can lead to the \"over-representation\" of subgoals,\ngenerating numerous spurious subgoals of limited relevance to the actual task\nreward and thus decreasing the sample efficiency of the algorithm. To address\nthis problem and inspired by the disentangled representation learning, we\npropose a novel \"disentangled\" decision-making method, Semantically Aligned\ntask decomposition in MARL (SAMA), that prompts pretrained language models with\nchain-of-thought that can suggest potential goals, provide suitable goal\ndecomposition and subgoal allocation as well as self-reflection-based\nreplanning. Additionally, SAMA incorporates language-grounded RL to train each\nagent's subgoal-conditioned policy. SAMA demonstrates considerable advantages\nin sample efficiency compared to state-of-the-art ASG methods, as evidenced by\nits performance on two challenging sparse-reward tasks, Overcooked and MiniRTS.\n",
        "published": "2023-05-18",
        "authors": [
            "Wenhao Li",
            "Dan Qiao",
            "Baoxiang Wang",
            "Xiangfeng Wang",
            "Bo Jin",
            "Hongyuan Zha"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2307.03906v1",
        "title": "ScriptWorld: Text Based Environment For Learning Procedural Knowledge",
        "abstract": "  Text-based games provide a framework for developing natural language\nunderstanding and commonsense knowledge about the world in reinforcement\nlearning based agents. Existing text-based environments often rely on fictional\nsituations and characters to create a gaming framework and are far from\nreal-world scenarios. In this paper, we introduce ScriptWorld: a text-based\nenvironment for teaching agents about real-world daily chores and hence\nimparting commonsense knowledge. To the best of our knowledge, it is the first\ninteractive text-based gaming framework that consists of daily real-world human\nactivities designed using scripts dataset. We provide gaming environments for\n10 daily activities and perform a detailed analysis of the proposed\nenvironment. We develop RL-based baseline models/agents to play the games in\nScriptworld. To understand the role of language models in such environments, we\nleverage features obtained from pre-trained language models in the RL agents.\nOur experiments show that prior knowledge obtained from a pre-trained language\nmodel helps to solve real-world text-based gaming environments. We release the\nenvironment via Github: https://github.com/Exploration-Lab/ScriptWorld\n",
        "published": "2023-07-08",
        "authors": [
            "Abhinav Joshi",
            "Areeb Ahmad",
            "Umang Pandey",
            "Ashutosh Modi"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.06555v1",
        "title": "On Temporal References in Emergent Communication",
        "abstract": "  As humans, we use linguistic elements referencing time, such as before or\ntomorrow, to easily share past experiences and future predictions. While\ntemporal aspects of the language have been considered in computational\nlinguistics, no such exploration has been done within the field of emergent\ncommunication. We research this gap, providing the first reported temporal\nvocabulary within emergent communication literature. Our experimental analysis\nshows that a different agent architecture is sufficient for the natural\nemergence of temporal references, and that no additional losses are necessary.\nOur readily transferable architectural insights provide the basis for the\nincorporation of temporal referencing into other emergent communication\nenvironments.\n",
        "published": "2023-10-10",
        "authors": [
            "Olaf Lipinski",
            "Adam J. Sobey",
            "Federico Cerutti",
            "Timothy J. Norman"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1705.10929v1",
        "title": "Adversarial Generation of Natural Language",
        "abstract": "  Generative Adversarial Networks (GANs) have gathered a lot of attention from\nthe computer vision community, yielding impressive results for image\ngeneration. Advances in the adversarial generation of natural language from\nnoise however are not commensurate with the progress made in generating images,\nand still lag far behind likelihood based methods. In this paper, we take a\nstep towards generating natural language with a GAN objective alone. We\nintroduce a simple baseline that addresses the discrete output space problem\nwithout relying on gradient estimators and show that it is able to achieve\nstate-of-the-art results on a Chinese poem generation dataset. We present\nquantitative results on generating sentences from context-free and\nprobabilistic context-free grammars, and qualitative language modeling results.\nA conditional version is also described that can generate sequences conditioned\non sentence characteristics.\n",
        "published": "2017-05-31",
        "authors": [
            "Sai Rajeswar",
            "Sandeep Subramanian",
            "Francis Dutil",
            "Christopher Pal",
            "Aaron Courville"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1706.07206v2",
        "title": "Explaining Recurrent Neural Network Predictions in Sentiment Analysis",
        "abstract": "  Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown\nto deliver insightful explanations in the form of input space relevances for\nunderstanding feed-forward neural network classification decisions. In the\npresent work, we extend the usage of LRP to recurrent neural networks. We\npropose a specific propagation rule applicable to multiplicative connections as\nthey arise in recurrent network architectures such as LSTMs and GRUs. We apply\nour technique to a word-based bi-directional LSTM model on a five-class\nsentiment prediction task, and evaluate the resulting LRP relevances both\nqualitatively and quantitatively, obtaining better results than a\ngradient-based related method which was used in previous work.\n",
        "published": "2017-06-22",
        "authors": [
            "Leila Arras",
            "Gr\u00e9goire Montavon",
            "Klaus-Robert M\u00fcller",
            "Wojciech Samek"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.03133v1",
        "title": "Building competitive direct acoustics-to-word models for English\n  conversational speech recognition",
        "abstract": "  Direct acoustics-to-word (A2W) models in the end-to-end paradigm have\nreceived increasing attention compared to conventional sub-word based automatic\nspeech recognition models using phones, characters, or context-dependent hidden\nMarkov model states. This is because A2W models recognize words from speech\nwithout any decoder, pronunciation lexicon, or externally-trained language\nmodel, making training and decoding with such models simple. Prior work has\nshown that A2W models require orders of magnitude more training data in order\nto perform comparably to conventional models. Our work also showed this\naccuracy gap when using the English Switchboard-Fisher data set. This paper\ndescribes a recipe to train an A2W model that closes this gap and is at-par\nwith state-of-the-art sub-word based models. We achieve a word error rate of\n8.8%/13.9% on the Hub5-2000 Switchboard/CallHome test sets without any decoder\nor language model. We find that model initialization, training data order, and\nregularization have the most impact on the A2W model performance. Next, we\npresent a joint word-character A2W model that learns to first spell the word\nand then recognize it. This model provides a rich output to the user instead of\nsimple word hypotheses, making it especially useful in the case of words unseen\nor rarely-seen during training.\n",
        "published": "2017-12-08",
        "authors": [
            "Kartik Audhkhasi",
            "Brian Kingsbury",
            "Bhuvana Ramabhadran",
            "George Saon",
            "Michael Picheny"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1606.03475v1",
        "title": "De-identification of Patient Notes with Recurrent Neural Networks",
        "abstract": "  Objective: Patient notes in electronic health records (EHRs) may contain\ncritical information for medical investigations. However, the vast majority of\nmedical investigators can only access de-identified notes, in order to protect\nthe confidentiality of patients. In the United States, the Health Insurance\nPortability and Accountability Act (HIPAA) defines 18 types of protected health\ninformation (PHI) that needs to be removed to de-identify patient notes. Manual\nde-identification is impractical given the size of EHR databases, the limited\nnumber of researchers with access to the non-de-identified notes, and the\nfrequent mistakes of human annotators. A reliable automated de-identification\nsystem would consequently be of high value.\n  Materials and Methods: We introduce the first de-identification system based\non artificial neural networks (ANNs), which requires no handcrafted features or\nrules, unlike existing systems. We compare the performance of the system with\nstate-of-the-art systems on two datasets: the i2b2 2014 de-identification\nchallenge dataset, which is the largest publicly available de-identification\ndataset, and the MIMIC de-identification dataset, which we assembled and is\ntwice as large as the i2b2 2014 dataset.\n  Results: Our ANN model outperforms the state-of-the-art systems. It yields an\nF1-score of 97.85 on the i2b2 2014 dataset, with a recall 97.38 and a precision\nof 97.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, with\na recall 99.25 and a precision of 99.06.\n  Conclusion: Our findings support the use of ANNs for de-identification of\npatient notes, as they show better performance than previously published\nsystems while requiring no feature engineering.\n",
        "published": "2016-06-10",
        "authors": [
            "Franck Dernoncourt",
            "Ji Young Lee",
            "Ozlem Uzuner",
            "Peter Szolovits"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.06454v2",
        "title": "Reasoning with Memory Augmented Neural Networks for Language\n  Comprehension",
        "abstract": "  Hypothesis testing is an important cognitive process that supports human\nreasoning. In this paper, we introduce a computational hypothesis testing\napproach based on memory augmented neural networks. Our approach involves a\nhypothesis testing loop that reconsiders and progressively refines a previously\nformed hypothesis in order to generate new hypotheses to test. We apply the\nproposed approach to language comprehension task by using Neural Semantic\nEncoders (NSE). Our NSE models achieve the state-of-the-art results showing an\nabsolute improvement of 1.2% to 2.6% accuracy over previous results obtained by\nsingle and ensemble systems on standard machine comprehension benchmarks such\nas the Children's Book Test (CBT) and Who-Did-What (WDW) news article datasets.\n",
        "published": "2016-10-20",
        "authors": [
            "Tsendsuren Munkhdalai",
            "Hong Yu"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.05251v1",
        "title": "Neural Networks for Joint Sentence Classification in Medical Paper\n  Abstracts",
        "abstract": "  Existing models based on artificial neural networks (ANNs) for sentence\nclassification often do not incorporate the context in which sentences appear,\nand classify sentences individually. However, traditional sentence\nclassification approaches have been shown to greatly benefit from jointly\nclassifying subsequent sentences, such as with conditional random fields. In\nthis work, we present an ANN architecture that combines the effectiveness of\ntypical ANN models to classify sentences in isolation, with the strength of\nstructured prediction. Our model achieves state-of-the-art results on two\ndifferent datasets for sequential sentence classification in medical abstracts.\n",
        "published": "2016-12-15",
        "authors": [
            "Franck Dernoncourt",
            "Ji Young Lee",
            "Peter Szolovits"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1702.02540v2",
        "title": "Automatic Rule Extraction from Long Short Term Memory Networks",
        "abstract": "  Although deep learning models have proven effective at solving problems in\nnatural language processing, the mechanism by which they come to their\nconclusions is often unclear. As a result, these models are generally treated\nas black boxes, yielding no insight of the underlying learned patterns. In this\npaper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new\napproach for tracking the importance of a given input to the LSTM for a given\noutput. By identifying consistently important patterns of words, we are able to\ndistill state of the art LSTMs on sentiment analysis and question answering\ninto a set of representative phrases. This representation is then\nquantitatively validated by using the extracted phrases to construct a simple,\nrule-based classifier which approximates the output of the LSTM.\n",
        "published": "2017-02-08",
        "authors": [
            "W. James Murdoch",
            "Arthur Szlam"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1703.08705v1",
        "title": "Comparing Rule-Based and Deep Learning Models for Patient Phenotyping",
        "abstract": "  Objective: We investigate whether deep learning techniques for natural\nlanguage processing (NLP) can be used efficiently for patient phenotyping.\nPatient phenotyping is a classification task for determining whether a patient\nhas a medical condition, and is a crucial part of secondary analysis of\nhealthcare data. We assess the performance of deep learning algorithms and\ncompare them with classical NLP approaches.\n  Materials and Methods: We compare convolutional neural networks (CNNs),\nn-gram models, and approaches based on cTAKES that extract pre-defined medical\nconcepts from clinical notes and use them to predict patient phenotypes. The\nperformance is tested on 10 different phenotyping tasks using 1,610 discharge\nsummaries extracted from the MIMIC-III database.\n  Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The\naverage F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our\nmodel having an F1-score up to 37 points higher than alternative approaches. We\nadditionally assess the interpretability of our model by presenting a method\nthat extracts the most salient phrases for a particular prediction.\n  Conclusion: We show that NLP methods based on deep learning improve the\nperformance of patient phenotyping. Our CNN-based algorithm automatically\nlearns the phrases associated with each patient phenotype. As such, it reduces\nthe annotation complexity for clinical domain experts, who are normally\nrequired to develop task-specific annotation rules and identify relevant\nphrases. Our method performs well in terms of both performance and\ninterpretability, which indicates that deep learning is an effective approach\nto patient phenotyping based on clinicians' notes.\n",
        "published": "2017-03-25",
        "authors": [
            "Sebastian Gehrmann",
            "Franck Dernoncourt",
            "Yeran Li",
            "Eric T. Carlson",
            "Joy T. Wu",
            "Jonathan Welt",
            "John Foote Jr.",
            "Edward T. Moseley",
            "David W. Grant",
            "Patrick D. Tyler",
            "Leo Anthony Celi"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1705.06273v1",
        "title": "Transfer Learning for Named-Entity Recognition with Neural Networks",
        "abstract": "  Recent approaches based on artificial neural networks (ANNs) have shown\npromising results for named-entity recognition (NER). In order to achieve high\nperformances, ANNs need to be trained on a large labeled dataset. However,\nlabels might be difficult to obtain for the dataset on which the user wants to\nperform NER: label scarcity is particularly pronounced for patient note\nde-identification, which is an instance of NER. In this work, we analyze to\nwhat extent transfer learning may address this issue. In particular, we\ndemonstrate that transferring an ANN model trained on a large labeled dataset\nto another dataset with a limited number of labels improves upon the\nstate-of-the-art results on two different datasets for patient note\nde-identification.\n",
        "published": "2017-05-17",
        "authors": [
            "Ji Young Lee",
            "Franck Dernoncourt",
            "Peter Szolovits"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1709.06990v1",
        "title": "Text Compression for Sentiment Analysis via Evolutionary Algorithms",
        "abstract": "  Can textual data be compressed intelligently without losing accuracy in\nevaluating sentiment? In this study, we propose a novel evolutionary\ncompression algorithm, PARSEC (PARts-of-Speech for sEntiment Compression),\nwhich makes use of Parts-of-Speech tags to compress text in a way that\nsacrifices minimal classification accuracy when used in conjunction with\nsentiment analysis algorithms. An analysis of PARSEC with eight commercial and\nnon-commercial sentiment analysis algorithms on twelve English sentiment data\nsets reveals that accurate compression is possible with (0%, 1.3%, 3.3%) loss\nin sentiment classification accuracy for (20%, 50%, 75%) data compression with\nPARSEC using LingPipe, the most accurate of the sentiment algorithms. Other\nsentiment analysis algorithms are more severely affected by compression. We\nconclude that significant compression of text data is possible for sentiment\nanalysis depending on the accuracy demands of the specific application and the\nspecific sentiment analysis algorithm used.\n",
        "published": "2017-09-20",
        "authors": [
            "Emmanuel Dufourq",
            "Bruce A. Bassett"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.04562v3",
        "title": "A Network-based End-to-End Trainable Task-oriented Dialogue System",
        "abstract": "  Teaching machines to accomplish tasks by conversing naturally with humans is\nchallenging. Currently, developing task-oriented dialogue systems requires\ncreating multiple components and typically this involves either a large amount\nof handcrafting, or acquiring costly labelled datasets to solve a statistical\nlearning problem for each component. In this work we introduce a neural\nnetwork-based text-in, text-out end-to-end trainable goal-oriented dialogue\nsystem along with a new way of collecting dialogue data based on a novel\npipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue\nsystems easily and without making too many assumptions about the task at hand.\nThe results show that the model can converse with human subjects naturally\nwhilst helping them to accomplish tasks in a restaurant search domain.\n",
        "published": "2016-04-15",
        "authors": [
            "Tsung-Hsien Wen",
            "David Vandyke",
            "Nikola Mrksic",
            "Milica Gasic",
            "Lina M. Rojas-Barahona",
            "Pei-Hao Su",
            "Stefan Ultes",
            "Steve Young"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.05878v1",
        "title": "A Factorization Machine Framework for Testing Bigram Embeddings in\n  Knowledgebase Completion",
        "abstract": "  Embedding-based Knowledge Base Completion models have so far mostly combined\ndistributed representations of individual entities or relations to compute\ntruth scores of missing links. Facts can however also be represented using\npairwise embeddings, i.e. embeddings for pairs of entities and relations. In\nthis paper we explore such bigram embeddings with a flexible Factorization\nMachine model and several ablations from it. We investigate the relevance of\nvarious bigram types on the fb15k237 dataset and find relative improvements\ncompared to a compositional model.\n",
        "published": "2016-04-20",
        "authors": [
            "Johannes Welbl",
            "Guillaume Bouchard",
            "Sebastian Riedel"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.01523v1",
        "title": "MIT at SemEval-2017 Task 10: Relation Extraction with Convolutional\n  Neural Networks",
        "abstract": "  Over 50 million scholarly articles have been published: they constitute a\nunique repository of knowledge. In particular, one may infer from them\nrelations between scientific concepts, such as synonyms and hyponyms.\nArtificial neural networks have been recently explored for relation extraction.\nIn this work, we continue this line of work and present a system based on a\nconvolutional neural network to extract relations. Our model ranked first in\nthe SemEval-2017 task 10 (ScienceIE) for relation extraction in scientific\narticles (subtask C).\n",
        "published": "2017-04-05",
        "authors": [
            "Ji Young Lee",
            "Franck Dernoncourt",
            "Peter Szolovits"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/2109.09371v1",
        "title": "Learning Natural Language Generation from Scratch",
        "abstract": "  This paper introduces TRUncated ReinForcement Learning for Language (TrufLL),\nan original ap-proach to train conditional language models from scratch by only\nusing reinforcement learning (RL). AsRL methods unsuccessfully scale to large\naction spaces, we dynamically truncate the vocabulary spaceusing a generic\nlanguage model. TrufLL thus enables to train a language agent by solely\ninteracting withits environment without any task-specific prior knowledge; it\nis only guided with a task-agnostic languagemodel. Interestingly, this approach\navoids the dependency to labelled datasets and inherently reduces pre-trained\npolicy flaws such as language or exposure biases. We evaluate TrufLL on two\nvisual questiongeneration tasks, for which we report positive results over\nperformance and language metrics, which wethen corroborate with a human\nevaluation. To our knowledge, it is the first approach that successfullylearns\na language generation policy (almost) from scratch.\n",
        "published": "2021-09-20",
        "authors": [
            "Alice Martin Donati",
            "Guillaume Quispe",
            "Charles Ollion",
            "Sylvain Le Corff",
            "Florian Strub",
            "Olivier Pietquin"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1304.2024v3",
        "title": "A General Framework for Interacting Bayes-Optimally with Self-Interested\n  Agents using Arbitrary Parametric Model and Model Prior",
        "abstract": "  Recent advances in Bayesian reinforcement learning (BRL) have shown that\nBayes-optimality is theoretically achievable by modeling the environment's\nlatent dynamics using Flat-Dirichlet-Multinomial (FDM) prior. In\nself-interested multi-agent environments, the transition dynamics are mainly\ncontrolled by the other agent's stochastic behavior for which FDM's\nindependence and modeling assumptions do not hold. As a result, FDM does not\nallow the other agent's behavior to be generalized across different states nor\nspecified using prior domain knowledge. To overcome these practical limitations\nof FDM, we propose a generalization of BRL to integrate the general class of\nparametric models and model priors, thus allowing practitioners' domain\nknowledge to be exploited to produce a fine-grained and compact representation\nof the other agent's behavior. Empirical evaluation shows that our approach\noutperforms existing multi-agent reinforcement learning algorithms.\n",
        "published": "2013-04-07",
        "authors": [
            "Trong Nghia Hoang",
            "Kian Hsiang Low"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    },
    {
        "id": "http://arxiv.org/abs/1806.02256v1",
        "title": "Adversarial Regression with Multiple Learners",
        "abstract": "  Despite the considerable success enjoyed by machine learning techniques in\npractice, numerous studies demonstrated that many approaches are vulnerable to\nattacks. An important class of such attacks involves adversaries changing\nfeatures at test time to cause incorrect predictions. Previous investigations\nof this problem pit a single learner against an adversary. However, in many\nsituations an adversary's decision is aimed at a collection of learners, rather\nthan specifically targeted at each independently. We study the problem of\nadversarial linear regression with multiple learners. We approximate the\nresulting game by exhibiting an upper bound on learner loss functions, and show\nthat the resulting game has a unique symmetric equilibrium. We present an\nalgorithm for computing this equilibrium, and show through extensive\nexperiments that equilibrium models are significantly more robust than\nconventional regularized linear regression.\n",
        "published": "2018-06-06",
        "authors": [
            "Liang Tong",
            "Sixie Yu",
            "Scott Alfeld",
            "Yevgeniy Vorobeychik"
        ],
        "categories": [
            null,
            null,
            null,
            null
        ]
    }
]