[
    {
        "id": "http://arxiv.org/abs/2208.06981v1",
        "title": "Explainable Artificial Intelligence for Assault Sentence Prediction in\n  New Zealand",
        "abstract": "  The judiciary has historically been conservative in its use of Artificial\nIntelligence, but recent advances in machine learning have prompted scholars to\nreconsider such use in tasks like sentence prediction. This paper investigates\nby experimentation the potential use of explainable artificial intelligence for\npredicting imprisonment sentences in assault cases in New Zealand's courts. We\npropose a proof-of-concept explainable model and verify in practice that it is\nfit for purpose, with predicted sentences accurate to within one year. We\nfurther analyse the model to understand the most influential phrases in\nsentence length prediction. We conclude the paper with an evaluative discussion\nof the future benefits and risks of different ways of using such an AI model in\nNew Zealand's courts.\n",
        "published": "2022",
        "authors": [
            "Harry Rodger",
            "Andrew Lensen",
            "Marcin Betkier"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2209.12678v1",
        "title": "Flexible Job Classification with Zero-Shot Learning",
        "abstract": "  Using a taxonomy to organize information requires classifying objects\n(documents, images, etc) with appropriate taxonomic classes. The flexible\nnature of zero-shot learning is appealing for this task because it allows\nclassifiers to naturally adapt to taxonomy modifications. This work studies\nzero-shot multi-label document classification with fine-tuned language models\nunder realistic taxonomy expansion scenarios in the human resource domain.\nExperiments show that zero-shot learning can be highly effective in this\nsetting. When controlling for training data budget, zero-shot classifiers\nachieve a 12% relative increase in macro-AP when compared to a traditional\nmulti-label classifier trained on all classes. Counterintuitively, these\nresults suggest in some settings it would be preferable to adopt zero-shot\ntechniques and spend resources annotating more documents with an incomplete set\nof classes, rather than spreading the labeling budget uniformly over all\nclasses and using traditional classification techniques. Additional experiments\ndemonstrate that adopting the well-known filter/re-rank decomposition from the\nrecommender systems literature can significantly reduce the computational\nburden of high-performance zero-shot classifiers, empirically resulting in a\n98% reduction in computational overhead for only a 2% relative decrease in\nperformance. The evidence presented here demonstrates that zero-shot learning\nhas the potential to significantly increase the flexibility of taxonomies and\nhighlights directions for future research.\n",
        "published": "2022",
        "authors": [
            "Thom Lake"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2211.04427v1",
        "title": "Word Order Matters when you Increase Masking",
        "abstract": "  Word order, an essential property of natural languages, is injected in\nTransformer-based neural language models using position encoding. However,\nrecent experiments have shown that explicit position encoding is not always\nuseful, since some models without such feature managed to achieve state-of-the\nart performance on some tasks. To understand better this phenomenon, we examine\nthe effect of removing position encodings on the pre-training objective itself\n(i.e., masked language modelling), to test whether models can reconstruct\nposition information from co-occurrences alone. We do so by controlling the\namount of masked tokens in the input sentence, as a proxy to affect the\nimportance of position information for the task. We find that the necessity of\nposition information increases with the amount of masking, and that masked\nlanguage models without position encodings are not able to reconstruct this\ninformation on the task. These findings point towards a direct relationship\nbetween the amount of masking and the ability of Transformers to capture\norder-sensitive aspects of language using position encoding.\n",
        "published": "2022",
        "authors": [
            "Karim Lasri",
            "Alessandro Lenci",
            "Thierry Poibeau"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2302.13939v4",
        "title": "SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks",
        "abstract": "  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking Neural Networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, inspired by the Receptance Weighted Key Value (RWKV)\nlanguage model, we successfully implement `SpikeGPT', a generative language\nmodel with binary, event-driven spiking activation units. We train the proposed\nmodel on two model variants: 45M and 216M parameters. To the best of our\nknowledge, SpikeGPT is the largest backpropagation-trained SNN model to date,\nrendering it suitable for both the generation and comprehension of natural\nlanguage. We achieve this by modifying the transformer block to replace\nmulti-head self attention to reduce quadratic computational complexity O(N^2)\nto linear complexity O(N) with increasing sequence length. Input tokens are\ninstead streamed in sequentially to our attention mechanism (as with typical\nSNNs). Our preliminary experiments show that SpikeGPT remains competitive with\nnon-spiking models on tested benchmarks, while maintaining 20x fewer operations\nwhen processed on neuromorphic hardware that can leverage sparse, event-driven\nactivations.\n",
        "published": "2023",
        "authors": [
            "Rui-Jie Zhu",
            "Qihang Zhao",
            "Guoqi Li",
            "Jason K. Eshraghian"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2303.17557v1",
        "title": "Recognition, recall, and retention of few-shot memories in large\n  language models",
        "abstract": "  The training of modern large language models (LLMs) takes place in a regime\nwhere most training examples are seen only a few times by the model during the\ncourse of training. What does a model remember about such examples seen only a\nfew times during training and how long does that memory persist in the face of\ncontinuous training with new examples? Here, we investigate these questions\nthrough simple recognition, recall, and retention experiments with LLMs. In\nrecognition experiments, we ask if the model can distinguish the seen example\nfrom a novel example; in recall experiments, we ask if the model can correctly\nrecall the seen example when cued by a part of it; and in retention\nexperiments, we periodically probe the model's memory for the original examples\nas the model is trained continuously with new examples. We find that a single\nexposure is generally sufficient for a model to achieve near perfect accuracy\neven in very challenging recognition experiments. We estimate that the\nrecognition performance of even small language models easily exceeds human\nrecognition performance reported in similar experiments with humans (Shepard,\n1967). Achieving near perfect recall takes more exposures, but most models can\ndo it in just 3 exposures. The flip side of this remarkable capacity for fast\nlearning is that precise memories are quickly overwritten: recall performance\nfor the original examples drops steeply over the first 10 training updates with\nnew examples, followed by a more gradual decline. Even after 100K updates,\nhowever, some of the original examples are still recalled near perfectly. A\nqualitatively similar retention pattern has been observed in human long-term\nmemory retention studies before (Bahrick, 1984). Finally, recognition is much\nmore robust to interference than recall and memory for natural language\nsentences is generally superior to memory for stimuli without structure.\n",
        "published": "2023",
        "authors": [
            "A. Emin Orhan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2304.03639v1",
        "title": "Theoretical Conditions and Empirical Failure of Bracket Counting on Long\n  Sequences with Linear Recurrent Networks",
        "abstract": "  Previous work has established that RNNs with an unbounded activation function\nhave the capacity to count exactly. However, it has also been shown that RNNs\nare challenging to train effectively and generally do not learn exact counting\nbehaviour. In this paper, we focus on this problem by studying the simplest\npossible RNN, a linear single-cell network. We conduct a theoretical analysis\nof linear RNNs and identify conditions for the models to exhibit exact counting\nbehaviour. We provide a formal proof that these conditions are necessary and\nsufficient. We also conduct an empirical analysis using tasks involving a\nDyck-1-like Balanced Bracket language under two different settings. We observe\nthat linear RNNs generally do not meet the necessary and sufficient conditions\nfor counting behaviour when trained with the standard approach. We investigate\nhow varying the length of training sequences and utilising different target\nclasses impacts model behaviour during training and the ability of linear RNN\nmodels to effectively approximate the indicator conditions.\n",
        "published": "2023",
        "authors": [
            "Nadine El-Naggar",
            "Pranava Madhyastha",
            "Tillman Weyde"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.02374v1",
        "title": "A Novel Plagiarism Detection Approach Combining BERT-based Word\n  Embedding, Attention-based LSTMs and an Improved Differential Evolution\n  Algorithm",
        "abstract": "  Detecting plagiarism involves finding similar items in two different sources.\nIn this article, we propose a novel method for detecting plagiarism that is\nbased on attention mechanism-based long short-term memory (LSTM) and\nbidirectional encoder representations from transformers (BERT) word embedding,\nenhanced with optimized differential evolution (DE) method for pre-training and\na focal loss function for training. BERT could be included in a downstream task\nand fine-tuned as a task-specific BERT can be included in a downstream task and\nfine-tuned as a task-specific structure, while the trained BERT model is\ncapable of detecting various linguistic characteristics. Unbalanced\nclassification is one of the primary issues with plagiarism detection. We\nsuggest a focal loss-based training technique that carefully learns minority\nclass instances to solve this. Another issue that we tackle is the training\nphase itself, which typically employs gradient-based methods like\nback-propagation for the learning process and thus suffers from some drawbacks,\nincluding sensitivity to initialization. To initiate the BP process, we suggest\na novel DE algorithm that makes use of a clustering-based mutation operator.\nHere, a winning cluster is identified for the current DE population, and a\nfresh updating method is used to produce potential answers. We evaluate our\nproposed approach on three benchmark datasets ( MSRP, SNLI, and SemEval2014)\nand demonstrate that it performs well when compared to both conventional and\npopulation-based methods.\n",
        "published": "2023",
        "authors": [
            "Seyed Vahid Moravvej",
            "Seyed Jalaleddin Mousavirad",
            "Diego Oliva",
            "Fardin Mohammadi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2305.14859v2",
        "title": "Utility-Probability Duality of Neural Networks",
        "abstract": "  It is typically understood that the training of modern neural networks is a\nprocess of fitting the probability distribution of desired output. However,\nrecent paradoxical observations in a number of language generation tasks let\none wonder if this canonical probability-based explanation can really account\nfor the empirical success of deep learning. To resolve this issue, we propose\nan alternative utility-based explanation to the standard supervised learning\nprocedure in deep learning. The basic idea is to interpret the learned neural\nnetwork not as a probability model but as an ordinal utility function that\nencodes the preference revealed in training data. In this perspective, training\nof the neural network corresponds to a utility learning process. Specifically,\nwe show that for all neural networks with softmax outputs, the SGD learning\ndynamic of maximum likelihood estimation (MLE) can be seen as an iteration\nprocess that optimizes the neural network toward an optimal utility function.\nThis utility-based interpretation can explain several otherwise-paradoxical\nobservations about the neural networks thus trained. Moreover, our\nutility-based theory also entails an equation that can transform the learned\nutility values back to a new kind of probability estimation with which\nprobability-compatible decision rules enjoy dramatic (double-digits)\nperformance improvements. These evidences collectively reveal a phenomenon of\nutility-probability duality in terms of what modern neural networks are (truly)\nmodeling: We thought they are one thing (probabilities), until the\nunexplainable showed up; changing mindset and treating them as another thing\n(utility values) largely reconcile the theory, despite remaining subtleties\nregarding its original (probabilistic) identity.\n",
        "published": "2023",
        "authors": [
            "Huang Bojun",
            "Fei Yuan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2307.01163v3",
        "title": "Improving Language Plasticity via Pretraining with Active Forgetting",
        "abstract": "  Pretrained language models (PLMs) are today the primary model for natural\nlanguage processing. Despite their impressive downstream performance, it can be\ndifficult to apply PLMs to new languages, a barrier to making their\ncapabilities universally accessible. While prior work has shown it possible to\naddress this issue by learning a new embedding layer for the new language,\ndoing so is both data and compute inefficient. We propose to use an active\nforgetting mechanism during pretraining, as a simple way of creating PLMs that\ncan quickly adapt to new languages. Concretely, by resetting the embedding\nlayer every K updates during pretraining, we encourage the PLM to improve its\nability of learning new embeddings within a limited number of updates, similar\nto a meta-learning effect. Experiments with RoBERTa show that models pretrained\nwith our forgetting mechanism not only demonstrate faster convergence during\nlanguage adaptation but also outperform standard ones in a low-data regime,\nparticularly for languages that are distant from English.\n",
        "published": "2023",
        "authors": [
            "Yihong Chen",
            "Kelly Marchisio",
            "Roberta Raileanu",
            "David Ifeoluwa Adelani",
            "Pontus Stenetorp",
            "Sebastian Riedel",
            "Mikel Artetxe"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2307.01230v1",
        "title": "Large Language and Text-to-3D Models for Engineering Design Optimization",
        "abstract": "  The current advances in generative AI for learning large neural network\nmodels with the capability to produce essays, images, music and even 3D assets\nfrom text prompts create opportunities for a manifold of disciplines. In the\npresent paper, we study the potential of deep text-to-3D models in the\nengineering domain, with focus on the chances and challenges when integrating\nand interacting with 3D assets in computational simulation-based design\noptimization. In contrast to traditional design optimization of 3D geometries\nthat often searches for the optimum designs using numerical representations,\nsuch as B-Spline surface or deformation parameters in vehicle aerodynamic\noptimization, natural language challenges the optimization framework by\nrequiring a different interpretation of variation operators while at the same\ntime may ease and motivate the human user interaction. Here, we propose and\nrealize a fully automated evolutionary design optimization framework using\nShap-E, a recently published text-to-3D asset network by OpenAI, in the context\nof aerodynamic vehicle optimization. For representing text prompts in the\nevolutionary optimization, we evaluate (a) a bag-of-words approach based on\nprompt templates and Wordnet samples, and (b) a tokenisation approach based on\nprompt templates and the byte pair encoding method from GPT4. Our main findings\nfrom the optimizations indicate that, first, it is important to ensure that the\ndesigns generated from prompts are within the object class of application, i.e.\ndiverse and novel designs need to be realistic, and, second, that more research\nis required to develop methods where the strength of text prompt variations and\nthe resulting variations of the 3D designs share causal relations to some\ndegree to improve the optimization.\n",
        "published": "2023",
        "authors": [
            "Thiago Rios",
            "Stefan Menzel",
            "Bernhard Sendhoff"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2308.07661v2",
        "title": "Attention Is Not All You Need Anymore",
        "abstract": "  In recent years, the popular Transformer architecture has achieved great\nsuccess in many application areas, including natural language processing and\ncomputer vision. Many existing works aim to reduce the computational and memory\ncomplexity of the self-attention mechanism in the Transformer by trading off\nperformance. However, performance is key for the continuing success of the\nTransformer. In this paper, a family of drop-in replacements for the\nself-attention mechanism in the Transformer, called the Extractors, is\nproposed. Four types of the Extractors, namely the super high-performance\nExtractor (SHE), the higher-performance Extractor (HE), the worthwhile\nExtractor (WE), and the minimalist Extractor (ME), are proposed as examples.\nExperimental results show that replacing the self-attention mechanism with the\nSHE evidently improves the performance of the Transformer, whereas the\nsimplified versions of the SHE, i.e., the HE, the WE, and the ME, perform close\nto or better than the self-attention mechanism with less computational and\nmemory complexity. Furthermore, the proposed Extractors have the potential or\nare able to run faster than the self-attention mechanism since their critical\npaths of computation are much shorter. Additionally, the sequence prediction\nproblem in the context of text generation is formulated using variable-length\ndiscrete-time Markov chains, and the Transformer is reviewed based on our\nunderstanding.\n",
        "published": "2023",
        "authors": [
            "Zhe Chen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.09406v1",
        "title": "Alternatives to the Scaled Dot Product for Attention in the Transformer\n  Neural Network Architecture",
        "abstract": "  The transformer neural network architecture uses a form of attention in which\nthe dot product of query and key is divided by the square root of the key\ndimension before applying softmax. This scaling of the dot product is designed\nto avoid the absolute value of the dot products becoming so large that applying\nsoftmax leads to vanishing gradients. In this paper, we propose some\nalternative scalings, including dividing the dot product instead by the sum of\nthe key lengths before applying softmax. We use simulated keys and queries to\nshow that in many situations this appears to be more effective at avoiding\nregions where applying softmax leads to vanishing gradients.\n",
        "published": "2023",
        "authors": [
            "James Bernhard"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.16822v1",
        "title": "Large Language Models Suffer From Their Own Output: An Analysis of the\n  Self-Consuming Training Loop",
        "abstract": "  Large language models (LLM) have become state of the art in many benchmarks\nand conversational LLM applications like ChatGPT are now widely used by the\npublic. Those LLMs can be used to generate large amounts of content which is\nposted on the internet to various platforms. As LLMs are trained on datasets\nusually collected from the internet, this LLM-generated content might be used\nto train the next generation of LLMs. Therefore, a self-consuming training loop\nemerges in which new LLM generations are trained on the output from the\nprevious generations. We empirically study this self-consuming training loop\nusing a novel dataset to analytically and accurately measure quality and\ndiversity of generated outputs. We find that this self-consuming training loop\ninitially improves both quality and diversity. However, after a few generations\nthe output inevitably degenerates in diversity. We find that the rate of\ndegeneration depends on the proportion of real and generated data.\n",
        "published": "2023",
        "authors": [
            "Martin Briesch",
            "Dominik Sobania",
            "Franz Rothlauf"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.07987v2",
        "title": "SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention",
        "abstract": "  The costly self-attention layers in modern Transformers require memory and\ncompute quadratic in sequence length. Existing approximation methods usually\nunderperform and fail to obtain significant speedups in practice. Here we\npresent SwitchHead - a novel method that reduces both compute and memory\nrequirements and achieves wall-clock speedup, while matching the language\nmodeling performance of baseline Transformers with the same parameter budget.\nSwitchHead uses Mixture-of-Experts (MoE) layers for the value and output\nprojections and requires 4 to 8 times fewer attention matrices than standard\nTransformers. Our novel attention can also be combined with MoE MLP layers,\nresulting in an efficient fully-MoE \"SwitchAll\" Transformer model. Our code is\npublic.\n",
        "published": "2023",
        "authors": [
            "R\u00f3bert Csord\u00e1s",
            "Piotr Pi\u0119kos",
            "Kazuki Irie",
            "J\u00fcrgen Schmidhuber"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.09084v2",
        "title": "Language Modeling on a SpiNNaker 2 Neuromorphic Chip",
        "abstract": "  As large language models continue to scale in size rapidly, so too does the\ncomputational power required to run them. Event-based networks on neuromorphic\ndevices offer a potential way to reduce energy consumption for inference\nsignificantly. However, to date, most event-based networks that can run on\nneuromorphic hardware, including spiking neural networks (SNNs), have not\nachieved task performance even on par with LSTM models for language modeling.\nAs a result, language modeling on neuromorphic devices has seemed a distant\nprospect. In this work, we demonstrate the first-ever implementation of a\nlanguage model on a neuromorphic device - specifically the SpiNNaker 2 chip -\nbased on a recently published event-based architecture called the EGRU.\nSpiNNaker 2 is a many-core neuromorphic chip designed for large-scale\nasynchronous processing, while the EGRU is architected to leverage such\nhardware efficiently while maintaining competitive task performance. This\nimplementation marks the first time a neuromorphic language model matches\nLSTMs, setting the stage for taking task performance to the level of large\nlanguage models. We also demonstrate results on a gesture recognition task\nbased on inputs from a DVS camera. Overall, our results showcase the\nfeasibility of this neuro-inspired neural network in hardware, highlighting\nsignificant gains versus conventional hardware in energy efficiency for the\ncommon use case of single batch inference.\n",
        "published": "2023",
        "authors": [
            "Khaleelulla Khan Nazeer",
            "Mark Sch\u00f6ne",
            "Rishav Mukherji",
            "Bernhard Vogginger",
            "Christian Mayr",
            "David Kappel",
            "Anand Subramoney"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.10259v1",
        "title": "CRNNet: Copy Recurrent Neural Network Structure Network",
        "abstract": "  The target of Electronic Health Record (EHR) coding is to find the diagnostic\ncodes according to the EHRs. In previous research, researchers have preferred\nto do multi-classification on the EHR coding task; most of them encode the EHR\nfirst and then process it to get the probability of each code based on the EHR\nrepresentation. However, the question of complicating diseases is neglected\namong all these methods. In this paper, we propose a novel EHR coding\nframework, which is the first attempt at detecting complicating diseases,\ncalled Copy Recurrent Neural Network Structure Network (CRNNet). This method\nrefers to the idea of adversarial learning; a Path Generator and a Path\nDiscriminator are designed to more efficiently finish the task of EHR coding.\nWe propose a copy module to detect complicating diseases; by the proposed copy\nmodule and the adversarial learning strategy, we identify complicating diseases\nefficiently. Extensive experiments show that our method achieves a 57.30\\%\nratio of complicating diseases in predictions, demonstrating the effectiveness\nof our proposed model. According to the ablation study, the proposed copy\nmechanism plays a crucial role in detecting complicating diseases.\n",
        "published": "2023",
        "authors": [
            "Xiaofan Zhou",
            "Xunzhu Tang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.16119v1",
        "title": "A bi-objective $\u03b5$-constrained framework for quality-cost\n  optimization in language model ensembles",
        "abstract": "  We propose an ensembling framework that uses diverse open-sourced Large\nLanguage Models (LLMs) to achieve high response quality while maintaining cost\nefficiency. We formulate a bi-objective optimization problem to represent the\nquality-cost tradeoff and then introduce an additional budget constraint that\nreduces the problem to a straightforward 0/1 knapsack problem. We empirically\ndemonstrate that our framework outperforms the existing ensembling approaches\nin response quality while significantly reducing costs.\n",
        "published": "2023",
        "authors": [
            "Aditi Singla",
            "Aditya Singh",
            "Kanishk Kukreja"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1911.05186v1",
        "title": "TCT: A Cross-supervised Learning Method for Multimodal Sequence\n  Representation",
        "abstract": "  Multimodalities provide promising performance than unimodality in most tasks.\nHowever, learning the semantic of the representations from multimodalities\nefficiently is extremely challenging. To tackle this, we propose the\nTransformer based Cross-modal Translator (TCT) to learn unimodal sequence\nrepresentations by translating from other related multimodal sequences on a\nsupervised learning method. Combined TCT with Multimodal Transformer Network\n(MTN), we evaluate MTN-TCT on the video-grounded dialogue which uses\nmultimodality. The proposed method reports new state-of-the-art performance on\nvideo-grounded dialogue which indicates representations learned by TCT are more\nsemantics compared to directly use unimodality.\n",
        "published": "2019",
        "authors": [
            "Wubo Li",
            "Wei Zou",
            "Xiangang Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2306.04539v1",
        "title": "Multimodal Learning Without Labeled Multimodal Data: Guarantees and\n  Applications",
        "abstract": "  In many machine learning systems that jointly learn from multiple modalities,\na core research question is to understand the nature of multimodal\ninteractions: the emergence of new task-relevant information during learning\nfrom both modalities that was not present in either alone. We study this\nchallenge of interaction quantification in a semi-supervised setting with only\nlabeled unimodal data and naturally co-occurring multimodal data (e.g.,\nunlabeled images and captions, video and corresponding audio) but when labeling\nthem is time-consuming. Using a precise information-theoretic definition of\ninteractions, our key contributions are the derivations of lower and upper\nbounds to quantify the amount of multimodal interactions in this\nsemi-supervised setting. We propose two lower bounds based on the amount of\nshared information between modalities and the disagreement between separately\ntrained unimodal classifiers, and derive an upper bound through connections to\napproximate algorithms for min-entropy couplings. We validate these estimated\nbounds and show how they accurately track true interactions. Finally, two\nsemi-supervised multimodal applications are explored based on these theoretical\nresults: (1) analyzing the relationship between multimodal performance and\nestimated interactions, and (2) self-supervised learning that embraces\ndisagreement between modalities beyond agreement as is typically done.\n",
        "published": "2023",
        "authors": [
            "Paul Pu Liang",
            "Chun Kai Ling",
            "Yun Cheng",
            "Alex Obolenskiy",
            "Yudong Liu",
            "Rohan Pandey",
            "Alex Wilf",
            "Louis-Philippe Morency",
            "Ruslan Salakhutdinov"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0910.3348v1",
        "title": "Algorithms for Image Analysis and Combination of Pattern Classifiers\n  with Application to Medical Diagnosis",
        "abstract": "  Medical Informatics and the application of modern signal processing in the\nassistance of the diagnostic process in medical imaging is one of the more\nrecent and active research areas today. This thesis addresses a variety of\nissues related to the general problem of medical image analysis, specifically\nin mammography, and presents a series of algorithms and design approaches for\nall the intermediate levels of a modern system for computer-aided diagnosis\n(CAD). The diagnostic problem is analyzed with a systematic approach, first\ndefining the imaging characteristics and features that are relevant to probable\npathology in mammo-grams. Next, these features are quantified and fused into\nnew, integrated radio-logical systems that exhibit embedded digital signal\nprocessing, in order to improve the final result and minimize the radiological\ndose for the patient. In a higher level, special algorithms are designed for\ndetecting and encoding these clinically interest-ing imaging features, in order\nto be used as input to advanced pattern classifiers and machine learning\nmodels. Finally, these approaches are extended in multi-classifier models under\nthe scope of Game Theory and optimum collective deci-sion, in order to produce\nefficient solutions for combining classifiers with minimum computational costs\nfor advanced diagnostic systems. The material covered in this thesis is related\nto a total of 18 published papers, 6 in scientific journals and 12 in\ninternational conferences.\n",
        "published": "2009",
        "authors": [
            "Harris Georgiou"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1412.1897v4",
        "title": "Deep Neural Networks are Easily Fooled: High Confidence Predictions for\n  Unrecognizable Images",
        "abstract": "  Deep neural networks (DNNs) have recently been achieving state-of-the-art\nperformance on a variety of pattern-recognition tasks, most notably visual\nclassification problems. Given that DNNs are now able to classify objects in\nimages with near-human-level performance, questions naturally arise as to what\ndifferences remain between computer and human vision. A recent study revealed\nthat changing an image (e.g. of a lion) in a way imperceptible to humans can\ncause a DNN to label the image as something else entirely (e.g. mislabeling a\nlion a library). Here we show a related result: it is easy to produce images\nthat are completely unrecognizable to humans, but that state-of-the-art DNNs\nbelieve to be recognizable objects with 99.99% confidence (e.g. labeling with\ncertainty that white noise static is a lion). Specifically, we take\nconvolutional neural networks trained to perform well on either the ImageNet or\nMNIST datasets and then find images with evolutionary algorithms or gradient\nascent that DNNs label with high confidence as belonging to each dataset class.\nIt is possible to produce images totally unrecognizable to human eyes that DNNs\nbelieve with near certainty are familiar objects, which we call \"fooling\nimages\" (more generally, fooling examples). Our results shed light on\ninteresting differences between human vision and current DNNs, and raise\nquestions about the generality of DNN computer vision.\n",
        "published": "2014",
        "authors": [
            "Anh Nguyen",
            "Jason Yosinski",
            "Jeff Clune"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1608.02164v1",
        "title": "Adapting Deep Network Features to Capture Psychological Representations",
        "abstract": "  Deep neural networks have become increasingly successful at solving classic\nperception problems such as object recognition, semantic segmentation, and\nscene understanding, often reaching or surpassing human-level accuracy. This\nsuccess is due in part to the ability of DNNs to learn useful representations\nof high-dimensional inputs, a problem that humans must also solve. We examine\nthe relationship between the representations learned by these networks and\nhuman psychological representations recovered from similarity judgments. We\nfind that deep features learned in service of object classification account for\na significant amount of the variance in human similarity judgments for a set of\nanimal images. However, these features do not capture some qualitative\ndistinctions that are a key part of human representations. To remedy this, we\ndevelop a method for adapting deep features to align with human similarity\njudgments, resulting in image representations that can potentially be used to\nextend the scope of psychological experiments.\n",
        "published": "2016",
        "authors": [
            "Joshua C. Peterson",
            "Joshua T. Abbott",
            "Thomas L. Griffiths"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1703.01041v2",
        "title": "Large-Scale Evolution of Image Classifiers",
        "abstract": "  Neural networks have proven effective at solving difficult problems but\ndesigning their architectures can be challenging, even for image classification\nproblems alone. Our goal is to minimize human participation, so we employ\nevolutionary algorithms to discover such networks automatically. Despite\nsignificant computational requirements, we show that it is now possible to\nevolve models with accuracies within the range of those published in the last\nyear. Specifically, we employ simple evolutionary techniques at unprecedented\nscales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting\nfrom trivial initial conditions and reaching accuracies of 94.6% (95.6% for\nensemble) and 77.0%, respectively. To do this, we use novel and intuitive\nmutation operators that navigate large search spaces; we stress that no human\nparticipation is required once evolution starts and that the output is a\nfully-trained model. Throughout this work, we place special emphasis on the\nrepeatability of results, the variability in the outcomes and the computational\nrequirements.\n",
        "published": "2017",
        "authors": [
            "Esteban Real",
            "Sherry Moore",
            "Andrew Selle",
            "Saurabh Saxena",
            "Yutaka Leon Suematsu",
            "Jie Tan",
            "Quoc Le",
            "Alex Kurakin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1703.03372v3",
        "title": "LesionSeg: Semantic segmentation of skin lesions using Deep\n  Convolutional Neural Network",
        "abstract": "  We present a method for skin lesion segmentation for the ISIC 2017 Skin\nLesion Segmentation Challenge. Our approach is based on a Fully Convolutional\nNetwork architecture which is trained end to end, from scratch, on a limited\ndataset. Our semantic segmentation architecture utilizes several recent\ninnovations in particularly in the combined use of (i) use of atrous\nconvolutions to increase the effective field of view of the network's receptive\nfield without increasing the number of parameters, (ii) the use of\nnetwork-in-network $1\\times1$ convolution layers to add capacity to the network\nand (iii) state-of-art super-resolution upsampling of predictions using\nsubpixel CNN layers. We reported a mean IOU score of 0.642 on the validation\nset provided by the organisers.\n",
        "published": "2017",
        "authors": [
            "Dhanesh Ramachandram",
            "Terrance DeVries"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1703.04071v4",
        "title": "A Compact DNN: Approaching GoogLeNet-Level Accuracy of Classification\n  and Domain Adaptation",
        "abstract": "  Recently, DNN model compression based on network architecture design, e.g.,\nSqueezeNet, attracted a lot attention. No accuracy drop on image classification\nis observed on these extremely compact networks, compared to well-known models.\nAn emerging question, however, is whether these model compression techniques\nhurt DNN's learning ability other than classifying images on a single dataset.\nOur preliminary experiment shows that these compression methods could degrade\ndomain adaptation (DA) ability, though the classification performance is\npreserved. Therefore, we propose a new compact network architecture and\nunsupervised DA method in this paper. The DNN is built on a new basic module\nConv-M which provides more diverse feature extractors without significantly\nincreasing parameters. The unified framework of our DA method will\nsimultaneously learn invariance across domains, reduce divergence of feature\nrepresentations, and adapt label prediction. Our DNN has 4.1M parameters, which\nis only 6.7% of AlexNet or 59% of GoogLeNet. Experiments show that our DNN\nobtains GoogLeNet-level accuracy both on classification and DA, and our DA\nmethod slightly outperforms previous competitive ones. Put all together, our DA\nstrategy based on our DNN achieves state-of-the-art on sixteen of total\neighteen DA tasks on popular Office-31 and Office-Caltech datasets.\n",
        "published": "2017",
        "authors": [
            "Chunpeng Wu",
            "Wei Wen",
            "Tariq Afzal",
            "Yongmei Zhang",
            "Yiran Chen",
            "Hai Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1703.09387v1",
        "title": "Adversarial Transformation Networks: Learning to Generate Adversarial\n  Examples",
        "abstract": "  Multiple different approaches of generating adversarial examples have been\nproposed to attack deep neural networks. These approaches involve either\ndirectly computing gradients with respect to the image pixels, or directly\nsolving an optimization on the image pixels. In this work, we present a\nfundamentally new method for generating adversarial examples that is fast to\nexecute and provides exceptional diversity of output. We efficiently train\nfeed-forward neural networks in a self-supervised manner to generate\nadversarial examples against a target network or set of networks. We call such\na network an Adversarial Transformation Network (ATN). ATNs are trained to\ngenerate adversarial examples that minimally modify the classifier's outputs\ngiven the original input, while constraining the new classification to match an\nadversarial target class. We present methods to train ATNs and analyze their\neffectiveness targeting a variety of MNIST classifiers as well as the latest\nstate-of-the-art ImageNet classifier Inception ResNet v2.\n",
        "published": "2017",
        "authors": [
            "Shumeet Baluja",
            "Ian Fischer"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1707.09899v1",
        "title": "Fashioning with Networks: Neural Style Transfer to Design Clothes",
        "abstract": "  Convolutional Neural Networks have been highly successful in performing a\nhost of computer vision tasks such as object recognition, object detection,\nimage segmentation and texture synthesis. In 2015, Gatys et. al [7] show how\nthe style of a painter can be extracted from an image of the painting and\napplied to another normal photograph, thus recreating the photo in the style of\nthe painter. The method has been successfully applied to a wide range of images\nand has since spawned multiple applications and mobile apps. In this paper, the\nneural style transfer algorithm is applied to fashion so as to synthesize new\ncustom clothes. We construct an approach to personalize and generate new custom\nclothes based on a users preference and by learning the users fashion choices\nfrom a limited set of clothes from their closet. The approach is evaluated by\nanalyzing the generated images of clothes and how well they align with the\nusers fashion style.\n",
        "published": "2017",
        "authors": [
            "Prutha Date",
            "Ashwinkumar Ganesan",
            "Tim Oates"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.02017v3",
        "title": "NeST: A Neural Network Synthesis Tool Based on a Grow-and-Prune Paradigm",
        "abstract": "  Deep neural networks (DNNs) have begun to have a pervasive impact on various\napplications of machine learning. However, the problem of finding an optimal\nDNN architecture for large applications is challenging. Common approaches go\nfor deeper and larger DNN architectures but may incur substantial redundancy.\nTo address these problems, we introduce a network growth algorithm that\ncomplements network pruning to learn both weights and compact DNN architectures\nduring training. We propose a DNN synthesis tool (NeST) that combines both\nmethods to automate the generation of compact and accurate DNNs. NeST starts\nwith a randomly initialized sparse network called the seed architecture. It\niteratively tunes the architecture with gradient-based growth and\nmagnitude-based pruning of neurons and connections. Our experimental results\nshow that NeST yields accurate, yet very compact DNNs, with a wide range of\nseed architecture selection. For the LeNet-300-100 (LeNet-5) architecture, we\nreduce network parameters by 70.2x (74.3x) and floating-point operations\n(FLOPs) by 79.4x (43.7x). For the AlexNet and VGG-16 architectures, we reduce\nnetwork parameters (FLOPs) by 15.7x (4.6x) and 30.2x (8.6x), respectively.\nNeST's grow-and-prune paradigm delivers significant additional parameter and\nFLOPs reduction relative to pruning-only methods.\n",
        "published": "2017",
        "authors": [
            "Xiaoliang Dai",
            "Hongxu Yin",
            "Niraj K. Jha"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.09561v1",
        "title": "HP-GAN: Probabilistic 3D human motion prediction via GAN",
        "abstract": "  Predicting and understanding human motion dynamics has many applications,\nsuch as motion synthesis, augmented reality, security, and autonomous vehicles.\nDue to the recent success of generative adversarial networks (GAN), there has\nbeen much interest in probabilistic estimation and synthetic data generation\nusing deep neural network architectures and learning algorithms.\n  We propose a novel sequence-to-sequence model for probabilistic human motion\nprediction, trained with a modified version of improved Wasserstein generative\nadversarial networks (WGAN-GP), in which we use a custom loss function designed\nfor human motion prediction. Our model, which we call HP-GAN, learns a\nprobability density function of future human poses conditioned on previous\nposes. It predicts multiple sequences of possible future human poses, each from\nthe same input sequence but a different vector z drawn from a random\ndistribution. Furthermore, to quantify the quality of the non-deterministic\npredictions, we simultaneously train a motion-quality-assessment model that\nlearns the probability that a given skeleton sequence is a real human motion.\n  We test our algorithm on two of the largest skeleton datasets: NTURGB-D and\nHuman3.6M. We train our model on both single and multiple action types. Its\npredictive power for long-term motion estimation is demonstrated by generating\nmultiple plausible futures of more than 30 frames from just 10 frames of input.\nWe show that most sequences generated from the same input have more than 50\\%\nprobabilities of being judged as a real human sequence. We will release all the\ncode used in this paper to Github.\n",
        "published": "2017",
        "authors": [
            "Emad Barsoum",
            "John Kender",
            "Zicheng Liu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1801.05156v1",
        "title": "Empirical Explorations in Training Networks with Discrete Activations",
        "abstract": "  We present extensive experiments training and testing hidden units in deep\nnetworks that emit only a predefined, static, number of discretized values.\nThese units provide benefits in real-world deployment in systems in which\nmemory and/or computation may be limited. Additionally, they are particularly\nwell suited for use in large recurrent network models that require the\nmaintenance of large amounts of internal state in memory. Surprisingly, we find\nthat despite reducing the number of values that can be represented in the\noutput activations from $2^{32}-2^{64}$ to between 64 and 256, there is little\nto no degradation in network performance across a variety of different\nsettings. We investigate simple classification and regression tasks, as well as\nmemorization and compression problems. We compare the results with more\nstandard activations, such as tanh and relu. Unlike previous discretization\nstudies which often concentrate only on binary units, we examine the effects of\nvarying the number of allowed activation levels. Compared to existing\napproaches for discretization, the approach presented here is both conceptually\nand programatically simple, has no stochastic component, and allows the\ntraining, testing, and usage phases to be treated in exactly the same manner.\n",
        "published": "2018",
        "authors": [
            "Shumeet Baluja"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.01548v7",
        "title": "Regularized Evolution for Image Classifier Architecture Search",
        "abstract": "  The effort devoted to hand-crafting neural network image classifiers has\nmotivated the use of architecture search to discover them automatically.\nAlthough evolutionary algorithms have been repeatedly applied to neural network\ntopologies, the image classifiers thus discovered have remained inferior to\nhuman-crafted ones. Here, we evolve an image classifier---AmoebaNet-A---that\nsurpasses hand-designs for the first time. To do this, we modify the tournament\nselection evolutionary algorithm by introducing an age property to favor the\nyounger genotypes. Matching size, AmoebaNet-A has comparable accuracy to\ncurrent state-of-the-art ImageNet models discovered with more complex\narchitecture-search methods. Scaled to larger size, AmoebaNet-A sets a new\nstate-of-the-art 83.9% / 96.6% top-5 ImageNet accuracy. In a controlled\ncomparison against a well known reinforcement learning algorithm, we give\nevidence that evolution can obtain results faster with the same hardware,\nespecially at the earlier stages of the search. This is relevant when fewer\ncompute resources are available. Evolution is, thus, a simple method to\neffectively discover high-quality architectures.\n",
        "published": "2018",
        "authors": [
            "Esteban Real",
            "Alok Aggarwal",
            "Yanping Huang",
            "Quoc V Le"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1803.02627v1",
        "title": "Inferencing Based on Unsupervised Learning of Disentangled\n  Representations",
        "abstract": "  Combining Generative Adversarial Networks (GANs) with encoders that learn to\nencode data points has shown promising results in learning data representations\nin an unsupervised way. We propose a framework that combines an encoder and a\ngenerator to learn disentangled representations which encode meaningful\ninformation about the data distribution without the need for any labels. While\ncurrent approaches focus mostly on the generative aspects of GANs, our\nframework can be used to perform inference on both real and generated data\npoints. Experiments on several data sets show that the encoder learns\ninterpretable, disentangled representations which encode descriptive properties\nand can be used to sample images that exhibit specific characteristics.\n",
        "published": "2018",
        "authors": [
            "Tobias Hinz",
            "Stefan Wermter"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.11215v2",
        "title": "CAKE: Compact and Accurate K-dimensional representation of Emotion",
        "abstract": "  Numerous models describing the human emotional states have been built by the\npsychology community. Alongside, Deep Neural Networks (DNN) are reaching\nexcellent performances and are becoming interesting features extraction tools\nin many computer vision tasks.Inspired by works from the psychology community,\nwe first study the link between the compact two-dimensional representation of\nthe emotion known as arousal-valence, and discrete emotion classes (e.g. anger,\nhappiness, sadness, etc.) used in the computer vision community. It enables to\nassess the benefits -- in terms of discrete emotion inference -- of adding an\nextra dimension to arousal-valence (usually named dominance). Building on these\nobservations, we propose CAKE, a 3-dimensional representation of emotion\nlearned in a multi-domain fashion, achieving accurate emotion recognition on\nseveral public datasets. Moreover, we visualize how emotions boundaries are\norganized inside DNN representations and show that DNNs are implicitly learning\narousal-valence-like descriptions of emotions. Finally, we use the CAKE\nrepresentation to compare the quality of the annotations of different public\ndatasets.\n",
        "published": "2018",
        "authors": [
            "Corentin Kervadec",
            "Valentin Vielzeuf",
            "St\u00e9phane Pateux",
            "Alexis Lechervy",
            "Fr\u00e9d\u00e9ric Jurie"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.05817v2",
        "title": "ProstateGAN: Mitigating Data Bias via Prostate Diffusion Imaging\n  Synthesis with Generative Adversarial Networks",
        "abstract": "  Generative Adversarial Networks (GANs) have shown considerable promise for\nmitigating the challenge of data scarcity when building machine learning-driven\nanalysis algorithms. Specifically, a number of studies have shown that\nGAN-based image synthesis for data augmentation can aid in improving\nclassification accuracy in a number of medical image analysis tasks, such as\nbrain and liver image analysis. However, the efficacy of leveraging GANs for\ntackling prostate cancer analysis has not been previously explored. Motivated\nby this, in this study we introduce ProstateGAN, a GAN-based model for\nsynthesizing realistic prostate diffusion imaging data. More specifically, in\norder to generate new diffusion imaging data corresponding to a particular\ncancer grade (Gleason score), we propose a conditional deep convolutional GAN\narchitecture that takes Gleason scores into consideration during the training\nprocess. Experimental results show that high-quality synthetic prostate\ndiffusion imaging data can be generated using the proposed ProstateGAN for\nspecified Gleason scores.\n",
        "published": "2018",
        "authors": [
            "Xiaodan Hu",
            "Audrey G. Chung",
            "Paul Fieguth",
            "Farzad Khalvati",
            "Masoom A. Haider",
            "Alexander Wong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1511.06586v1",
        "title": "Crowd Behavior Analysis: A Review where Physics meets Biology",
        "abstract": "  Although the traits emerged in a mass gathering are often non-deliberative,\nthe act of mass impulse may lead to irre- vocable crowd disasters. The two-fold\nincrease of carnage in crowd since the past two decades has spurred significant\nadvances in the field of computer vision, towards effective and proactive crowd\nsurveillance. Computer vision stud- ies related to crowd are observed to\nresonate with the understanding of the emergent behavior in physics (complex\nsystems) and biology (animal swarm). These studies, which are inspired by\nbiology and physics, share surprisingly common insights, and interesting\ncontradictions. However, this aspect of discussion has not been fully explored.\nTherefore, this survey provides the readers with a review of the\nstate-of-the-art methods in crowd behavior analysis from the physics and\nbiologically inspired perspectives. We provide insights and comprehensive\ndiscussions for a broader understanding of the underlying prospect of blending\nphysics and biology studies in computer vision.\n",
        "published": "2015",
        "authors": [
            "Ven Jyn Kok",
            "Mei Kuan Lim",
            "Chee Seng Chan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1512.05986v1",
        "title": "Can Pretrained Neural Networks Detect Anatomy?",
        "abstract": "  Convolutional neural networks demonstrated outstanding empirical results in\ncomputer vision and speech recognition tasks where labeled training data is\nabundant. In medical imaging, there is a huge variety of possible imaging\nmodalities and contrasts, where annotated data is usually very scarce. We\npresent two approaches to deal with this challenge. A network pretrained in a\ndifferent domain with abundant data is used as a feature extractor, while a\nsubsequent classifier is trained on a small target dataset; and a deep\narchitecture trained with heavy augmentation and equipped with sophisticated\nregularization methods. We test the approaches on a corpus of X-ray images to\ndesign an anatomy detection system.\n",
        "published": "2015",
        "authors": [
            "Vlado Menkovski",
            "Zharko Aleksovski",
            "Axel Saalbach",
            "Hannes Nickisch"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1709.01574v1",
        "title": "Opening the Black Box of Financial AI with CLEAR-Trade: A CLass-Enhanced\n  Attentive Response Approach for Explaining and Visualizing Deep\n  Learning-Driven Stock Market Prediction",
        "abstract": "  Deep learning has been shown to outperform traditional machine learning\nalgorithms across a wide range of problem domains. However, current deep\nlearning algorithms have been criticized as uninterpretable \"black-boxes\" which\ncannot explain their decision making processes. This is a major shortcoming\nthat prevents the widespread application of deep learning to domains with\nregulatory processes such as finance. As such, industries such as finance have\nto rely on traditional models like decision trees that are much more\ninterpretable but less effective than deep learning for complex problems. In\nthis paper, we propose CLEAR-Trade, a novel financial AI visualization\nframework for deep learning-driven stock market prediction that mitigates the\ninterpretability issue of deep learning methods. In particular, CLEAR-Trade\nprovides a effective way to visualize and explain decisions made by deep stock\nmarket prediction models. We show the efficacy of CLEAR-Trade in enhancing the\ninterpretability of stock market prediction by conducting experiments based on\nS&P 500 stock index prediction. The results demonstrate that CLEAR-Trade can\nprovide significant insight into the decision-making process of deep\nlearning-driven financial models, particularly for regulatory processes, thus\nimproving their potential uptake in the financial industry.\n",
        "published": "2017",
        "authors": [
            "Devinder Kumar",
            "Graham W Taylor",
            "Alexander Wong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1709.09902v3",
        "title": "Improving Efficiency in Convolutional Neural Network with Multilinear\n  Filters",
        "abstract": "  The excellent performance of deep neural networks has enabled us to solve\nseveral automatization problems, opening an era of autonomous devices. However,\ncurrent deep net architectures are heavy with millions of parameters and\nrequire billions of floating point operations. Several works have been\ndeveloped to compress a pre-trained deep network to reduce memory footprint\nand, possibly, computation. Instead of compressing a pre-trained network, in\nthis work, we propose a generic neural network layer structure employing\nmultilinear projection as the primary feature extractor. The proposed\narchitecture requires several times less memory as compared to the traditional\nConvolutional Neural Networks (CNN), while inherits the similar design\nprinciples of a CNN. In addition, the proposed architecture is equipped with\ntwo computation schemes that enable computation reduction or scalability.\nExperimental results show the effectiveness of our compact projection that\noutperforms traditional CNN, while requiring far fewer parameters.\n",
        "published": "2017",
        "authors": [
            "Dat Thanh Tran",
            "Alexandros Iosifidis",
            "Moncef Gabbouj"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.07312v1",
        "title": "Analysis of supervised and semi-supervised GrowCut applied to\n  segmentation of masses in mammography images",
        "abstract": "  Breast cancer is already one of the most common form of cancer worldwide.\nMammography image analysis is still the most effective diagnostic method to\npromote the early detection of breast cancer. Accurately segmenting tumors in\ndigital mammography images is important to improve diagnosis capabilities of\nhealth specialists and avoid misdiagnosis. In this work, we evaluate the\nfeasibility of applying GrowCut to segment regions of tumor and we propose two\nGrowCut semi-supervised versions. All the analysis was performed by evaluating\nthe application of segmentation techniques to a set of images obtained from the\nMini-MIAS mammography image database. GrowCut segmentation was compared to\nRegion Growing, Active Contours, Random Walks and Graph Cut techniques.\nExperiments showed that GrowCut, when compared to the other techniques, was\nable to acquire better results for the metrics analyzed. Moreover, the proposed\nsemi-supervised versions of GrowCut was proved to have a clinically\nsatisfactory quality of segmentation.\n",
        "published": "2017",
        "authors": [
            "Filipe Rolim Cordeiro",
            "Wellington Pinheiro dos Santos",
            "Abel Guilhermino da Silva Filho"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2006.05918v1",
        "title": "Deep Learning with Attention Mechanism for Predicting Driver Intention\n  at Intersection",
        "abstract": "  In this paper, a driver's intention prediction near a road intersection is\nproposed. Our approach uses a deep bidirectional Long Short-Term Memory (LSTM)\nwith an attention mechanism model based on a hybrid-state system (HSS)\nframework. As intersection is considered to be as one of the major source of\nroad accidents, predicting a driver's intention at an intersection is very\ncrucial. Our method uses a sequence to sequence modeling with an attention\nmechanism to effectively exploit temporal information out of the time-series\nvehicular data including velocity and yaw-rate. The model then predicts ahead\nof time whether the target vehicle/driver will go straight, stop, or take right\nor left turn. The performance of the proposed approach is evaluated on a\nnaturalistic driving dataset and results show that our method achieves high\naccuracy as well as outperforms other methods. The proposed solution is\npromising to be applied in advanced driver assistance systems (ADAS) and as\npart of active safety system of autonomous vehicles.\n",
        "published": "2020",
        "authors": [
            "Abenezer Girma",
            "Seifemichael Amsalu",
            "Abrham Workineh",
            "Mubbashar Khan",
            "Abdollah Homaifar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.09909v1",
        "title": "PLSM: A Parallelized Liquid State Machine for Unintentional Action\n  Detection",
        "abstract": "  Reservoir Computing (RC) offers a viable option to deploy AI algorithms on\nlow-end embedded system platforms. Liquid State Machine (LSM) is a bio-inspired\nRC model that mimics the cortical microcircuits and uses spiking neural\nnetworks (SNN) that can be directly realized on neuromorphic hardware. In this\npaper, we present a novel Parallelized LSM (PLSM) architecture that\nincorporates spatio-temporal read-out layer and semantic constraints on model\noutput. To the best of our knowledge, such a formulation has been done for the\nfirst time in literature, and it offers a computationally lighter alternative\nto traditional deep-learning models. Additionally, we also present a\ncomprehensive algorithm for the implementation of parallelizable SNNs and LSMs\nthat are GPU-compatible. We implement the PLSM model to classify\nunintentional/accidental video clips, using the Oops dataset. From the\nexperimental results on detecting unintentional action in video, it can be\nobserved that our proposed model outperforms a self-supervised model and a\nfully supervised traditional deep learning model. All the implemented codes can\nbe found at our repository\nhttps://github.com/anonymoussentience2020/Parallelized_LSM_for_Unintentional_Action_Recognition.\n",
        "published": "2021",
        "authors": [
            "Dipayan Das",
            "Saumik Bhattacharya",
            "Umapada Pal",
            "Sukalpa Chanda"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.04890v1",
        "title": "Improving performance of aircraft detection in satellite imagery while\n  limiting the labelling effort: Hybrid active learning",
        "abstract": "  The earth observation industry provides satellite imagery with high spatial\nresolution and short revisit time. To allow efficient operational employment of\nthese images, automating certain tasks has become necessary. In the defense\ndomain, aircraft detection on satellite imagery is a valuable tool for\nanalysts. Obtaining high performance detectors on such a task can only be\nachieved by leveraging deep learning and thus us-ing a large amount of labeled\ndata. To obtain labels of a high enough quality, the knowledge of military\nexperts is needed.We propose a hybrid clustering active learning method to\nselect the most relevant data to label, thus limiting the amount of data\nrequired and further improving the performances. It combines diversity- and\nuncertainty-based active learning selection methods. For aircraft detection by\nsegmentation, we show that this method can provide better or competitive\nresults compared to other active learning methods.\n",
        "published": "2022",
        "authors": [
            "Julie Imbert",
            "Gohar Dashyan",
            "Alex Goupilleau",
            "Tugdual Ceillier",
            "Marie-Caroline Corbineau"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.01925v1",
        "title": "Metaheuristic Algorithms for Convolution Neural Network",
        "abstract": "  A typical modern optimization technique is usually either heuristic or\nmetaheuristic. This technique has managed to solve some optimization problems\nin the research area of science, engineering, and industry. However,\nimplementation strategy of metaheuristic for accuracy improvement on\nconvolution neural networks (CNN), a famous deep learning method, is still\nrarely investigated. Deep learning relates to a type of machine learning\ntechnique, where its aim is to move closer to the goal of artificial\nintelligence of creating a machine that could successfully perform any\nintellectual tasks that can be carried out by a human. In this paper, we\npropose the implementation strategy of three popular metaheuristic approaches,\nthat is, simulated annealing, differential evolution, and harmony search, to\noptimize CNN. The performances of these metaheuristic methods in optimizing CNN\non classifying MNIST and CIFAR dataset were evaluated and compared.\nFurthermore, the proposed methods are also compared with the original CNN.\nAlthough the proposed methods show an increase in the computation time, their\naccuracy has also been improved (up to 7.14 percent).\n",
        "published": "2016",
        "authors": [
            "L. M. Rasdi Rere",
            "Mohamad Ivan Fanany",
            "Aniati Murni Arymurthy"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.03417v1",
        "title": "GlobeNet: Convolutional Neural Networks for Typhoon Eye Tracking from\n  Remote Sensing Imagery",
        "abstract": "  Advances in remote sensing technologies have made it possible to use\nhigh-resolution visual data for weather observation and forecasting tasks. We\npropose the use of multi-layer neural networks for understanding complex\natmospheric dynamics based on multichannel satellite images. The capability of\nour model was evaluated by using a linear regression task for single typhoon\ncoordinates prediction. A specific combination of models and different\nactivation policies enabled us to obtain an interesting prediction result in\nthe northeastern hemisphere (ENH).\n",
        "published": "2017",
        "authors": [
            "Seungkyun Hong",
            "Seongchan Kim",
            "Minsu Joh",
            "Sa-kwang Song"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1810.13197v1",
        "title": "The Many Moods of Emotion",
        "abstract": "  This paper presents a novel approach to the facial expression generation\nproblem. Building upon the assumption of the psychological community that\nemotion is intrinsically continuous, we first design our own continuous emotion\nrepresentation with a 3-dimensional latent space issued from a neural network\ntrained on discrete emotion classification. The so-obtained representation can\nbe used to annotate large in the wild datasets and later used to trained a\nGenerative Adversarial Network. We first show that our model is able to map\nback to discrete emotion classes with a objectively and subjectively better\nquality of the images than usual discrete approaches. But also that we are able\nto pave the larger space of possible facial expressions, generating the many\nmoods of emotion. Moreover, two axis in this space may be found to generate\nsimilar expression changes as in traditional continuous representations such as\narousal-valence. Finally we show from visual interpretation, that the third\nremaining dimension is highly related to the well-known dominance dimension\nfrom psychology.\n",
        "published": "2018",
        "authors": [
            "Valentin Vielzeuf",
            "Corentin Kervadec",
            "St\u00e9phane Pateux",
            "Fr\u00e9d\u00e9ric Jurie"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.00581v1",
        "title": "A Deep 2-Dimensional Dynamical Spiking Neuronal Network for Temporal\n  Encoding trained with STDP",
        "abstract": "  The brain is known to be a highly complex, asynchronous dynamical system that\nis highly tailored to encode temporal information. However, recent deep\nlearning approaches to not take advantage of this temporal coding. Spiking\nNeural Networks (SNNs) can be trained using biologically-realistic learning\nmechanisms, and can have neuronal activation rules that are biologically\nrelevant. This type of network is also structured fundamentally around\naccepting temporal information through a time-decaying voltage update, a kind\nof input that current rate-encoding networks have difficulty with. Here we show\nthat a large, deep layered SNN with dynamical, chaotic activity mimicking the\nmammalian cortex with biologically-inspired learning rules, such as STDP, is\ncapable of encoding information from temporal data. We argue that the\nrandomness inherent in the network weights allow the neurons to form groups\nthat encode the temporal data being inputted after self-organizing with STDP.\nWe aim to show that precise timing of input stimulus is critical in forming\nsynchronous neural groups in a layered network. We analyze the network in terms\nof network entropy as a metric of information transfer. We hope to tackle two\nproblems at once: the creation of artificial temporal neural systems for\nartificial intelligence, as well as solving coding mechanisms in the brain.\n",
        "published": "2020",
        "authors": [
            "Matthew Evanusa",
            "Cornelia Fermuller",
            "Yiannis Aloimonos"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2012.09542v3",
        "title": "Weakly-Supervised Action Localization and Action Recognition using\n  Global-Local Attention of 3D CNN",
        "abstract": "  3D Convolutional Neural Network (3D CNN) captures spatial and temporal\ninformation on 3D data such as video sequences. However, due to the convolution\nand pooling mechanism, the information loss seems unavoidable. To improve the\nvisual explanations and classification in 3D CNN, we propose two approaches; i)\naggregate layer-wise global to local (global-local) discrete gradients using\ntrained 3DResNext network, and ii) implement attention gating network to\nimprove the accuracy of the action recognition. The proposed approach intends\nto show the usefulness of every layer termed as global-local attention in 3D\nCNN via visual attribution, weakly-supervised action localization, and action\nrecognition. Firstly, the 3DResNext is trained and applied for action\nclassification using backpropagation concerning the maximum predicted class.\nThe gradients and activations of every layer are then up-sampled. Later,\naggregation is used to produce more nuanced attention, which points out the\nmost critical part of the predicted class's input videos. We use contour\nthresholding of final attention for final localization. We evaluate spatial and\ntemporal action localization in trimmed videos using fine-grained visual\nexplanation via 3DCam. Experimental results show that the proposed approach\nproduces informative visual explanations and discriminative attention.\nFurthermore, the action recognition via attention gating on each layer produces\nbetter classification results than the baseline model.\n",
        "published": "2020",
        "authors": [
            "Novanto Yudistira",
            "Muthu Subash Kavitha",
            "Takio Kurita"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2103.12544v2",
        "title": "DeepBF: Malicious URL detection using Learned Bloom Filter and\n  Evolutionary Deep Learning",
        "abstract": "  Malicious URL detection is an emerging research area due to continuous\nmodernization of various systems, for instance, Edge Computing. In this\narticle, we present a novel malicious URL detection technique, called deepBF\n(deep learning and Bloom Filter). deepBF is presented in two-fold. Firstly, we\npropose a learned Bloom Filter using 2-dimensional Bloom Filter. We\nexperimentally decide the best non-cryptography string hash function. Then, we\nderive a modified non-cryptography string hash function from the selected hash\nfunction for deepBF by introducing biases in the hashing method and compared\namong the string hash functions. The modified string hash function is compared\nto other variants of diverse non-cryptography string hash functions. It is also\ncompared with various filters, particularly, counting Bloom Filter, Kirsch\n\\textit{et al.}, and Cuckoo Filter using various use cases. The use cases\nunearth weakness and strength of the filters. Secondly, we propose a malicious\nURL detection mechanism using deepBF. We apply the evolutionary convolutional\nneural network to identify the malicious URLs. The evolutionary convolutional\nneural network is trained and tested with malicious URL datasets. The output is\ntested in deepBF for accuracy. We have achieved many conclusions from our\nexperimental evaluation and results and are able to reach various conclusive\ndecisions which are presented in the article.\n",
        "published": "2021",
        "authors": [
            "Ripon Patgiri",
            "Anupam Biswas",
            "Sabuzima Nayak"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2104.04945v3",
        "title": "Enhancing Deep Neural Network Saliency Visualizations with Gradual\n  Extrapolation",
        "abstract": "  In this paper, an enhancement technique for the class activation mapping\nmethods such as gradient-weighted class activation maps or excitation\nbackpropagation is proposed to present the visual explanations of decisions\nfrom convolutional neural network-based models. The proposed idea, called\nGradual Extrapolation, can supplement any method that generates a heatmap\npicture by sharpening the output. Instead of producing a coarse localization\nmap that highlights the important predictive regions in the image, the proposed\nmethod outputs the specific shape that most contributes to the model output.\nThus, the proposed method improves the accuracy of saliency maps. The effect\nhas been achieved by the gradual propagation of the crude map obtained in the\ndeep layer through all preceding layers with respect to their activations. In\nvalidation tests conducted on a selected set of images, the faithfulness,\ninterpretability, and applicability of the method are evaluated. The proposed\ntechnique significantly improves the localization detection of the neural\nnetworks attention at low additional computational costs. Furthermore, the\nproposed method is applicable to a variety deep neural network models. The code\nfor the method can be found at\nhttps://github.com/szandala/gradual-extrapolation\n",
        "published": "2021",
        "authors": [
            "Tomasz Szandala"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2110.06804v4",
        "title": "A comprehensive review of Binary Neural Network",
        "abstract": "  Deep learning (DL) has recently changed the development of intelligent\nsystems and is widely adopted in many real-life applications. Despite their\nvarious benefits and potentials, there is a high demand for DL processing in\ndifferent computationally limited and energy-constrained devices. It is natural\nto study game-changing technologies such as Binary Neural Networks (BNN) to\nincrease deep learning capabilities. Recently remarkable progress has been made\nin BNN since they can be implemented and embedded on tiny restricted devices\nand save a significant amount of storage, computation cost, and energy\nconsumption. However, nearly all BNN acts trade with extra memory, computation\ncost, and higher performance. This article provides a complete overview of\nrecent developments in BNN. This article focuses exclusively on 1-bit\nactivations and weights 1-bit convolution networks, contrary to previous\nsurveys in which low-bit works are mixed in. It conducted a complete\ninvestigation of BNN's development -from their predecessors to the latest BNN\nalgorithms/techniques, presenting a broad design pipeline and discussing each\nmodule's variants. Along the way, it examines BNN (a) purpose: their early\nsuccesses and challenges; (b) BNN optimization: selected representative works\nthat contain essential optimization techniques; (c) deployment: open-source\nframeworks for BNN modeling and development; (d) terminal: efficient computing\narchitectures and devices for BNN and (e) applications: diverse applications\nwith BNN. Moreover, this paper discusses potential directions and future\nresearch opportunities in each section.\n",
        "published": "2021",
        "authors": [
            "Chunyu Yuan",
            "Sos S. Agaian"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2110.11583v1",
        "title": "EvoGAN: An Evolutionary Computation Assisted GAN",
        "abstract": "  The image synthesis technique is relatively well established which can\ngenerate facial images that are indistinguishable even by human beings.\nHowever, all of these approaches uses gradients to condition the output,\nresulting in the outputting the same image with the same input. Also, they can\nonly generate images with basic expression or mimic an expression instead of\ngenerating compound expression. In real life, however, human expressions are of\ngreat diversity and complexity. In this paper, we propose an evolutionary\nalgorithm (EA) assisted GAN, named EvoGAN, to generate various compound\nexpressions with any accurate target compound expression. EvoGAN uses an EA to\nsearch target results in the data distribution learned by GAN. Specifically, we\nuse the Facial Action Coding System (FACS) as the encoding of an EA and use a\npre-trained GAN to generate human facial images, and then use a pre-trained\nclassifier to recognize the expression composition of the synthesized images as\nthe fitness function to guide the search of the EA. Combined random searching\nalgorithm, various images with the target expression can be easily sythesized.\nQuantitative and Qualitative results are presented on several compound\nexpressions, and the experimental results demonstrate the feasibility and the\npotential of EvoGAN.\n",
        "published": "2021",
        "authors": [
            "Feng Liu",
            "HanYang Wang",
            "Jiahao Zhang",
            "Ziwang Fu",
            "Aimin Zhou",
            "Jiayin Qi",
            "Zhibin Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2206.11073v1",
        "title": "A Unified and Biologically-Plausible Relational Graph Representation of\n  Vision Transformers",
        "abstract": "  Vision transformer (ViT) and its variants have achieved remarkable successes\nin various visual tasks. The key characteristic of these ViT models is to adopt\ndifferent aggregation strategies of spatial patch information within the\nartificial neural networks (ANNs). However, there is still a key lack of\nunified representation of different ViT architectures for systematic\nunderstanding and assessment of model representation performance. Moreover, how\nthose well-performing ViT ANNs are similar to real biological neural networks\n(BNNs) is largely unexplored. To answer these fundamental questions, we, for\nthe first time, propose a unified and biologically-plausible relational graph\nrepresentation of ViT models. Specifically, the proposed relational graph\nrepresentation consists of two key sub-graphs: aggregation graph and affine\ngraph. The former one considers ViT tokens as nodes and describes their spatial\ninteraction, while the latter one regards network channels as nodes and\nreflects the information communication between channels. Using this unified\nrelational graph representation, we found that: a) a sweet spot of the\naggregation graph leads to ViTs with significantly improved predictive\nperformance; b) the graph measures of clustering coefficient and average path\nlength are two effective indicators of model prediction performance, especially\nwhen applying on the datasets with small samples; c) our findings are\nconsistent across various ViT architectures and multiple datasets; d) the\nproposed relational graph representation of ViT has high similarity with real\nBNNs derived from brain science data. Overall, our work provides a novel\nunified and biologically-plausible paradigm for more interpretable and\neffective representation of ViT ANNs.\n",
        "published": "2022",
        "authors": [
            "Yuzhong Chen",
            "Yu Du",
            "Zhenxiang Xiao",
            "Lin Zhao",
            "Lu Zhang",
            "David Weizhong Liu",
            "Dajiang Zhu",
            "Tuo Zhang",
            "Xintao Hu",
            "Tianming Liu",
            "Xi Jiang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2208.12880v3",
        "title": "Neuromorphic Visual Scene Understanding with Resonator Networks",
        "abstract": "  Understanding a visual scene by inferring identities and poses of its\nindividual objects is still and open problem. Here we propose a neuromorphic\nsolution that utilizes an efficient factorization network based on three key\nconcepts: (1) a computational framework based on Vector Symbolic Architectures\n(VSA) with complex-valued vectors; (2) the design of Hierarchical Resonator\nNetworks (HRN) to deal with the non-commutative nature of translation and\nrotation in visual scenes, when both are used in combination; (3) the design of\na multi-compartment spiking phasor neuron model for implementing complex-valued\nresonator networks on neuromorphic hardware. The VSA framework uses vector\nbinding operations to produce generative image models in which binding acts as\nthe equivariant operation for geometric transformations. A scene can therefore\nbe described as a sum of vector products, which in turn can be efficiently\nfactorized by a resonator network to infer objects and their poses. The HRN\nenables the definition of a partitioned architecture in which vector binding is\nequivariant for horizontal and vertical translation within one partition and\nfor rotation and scaling within the other partition. The spiking neuron model\nallows mapping the resonator network onto efficient and low-power neuromorphic\nhardware. Our approach is demonstrated on synthetic scenes composed of simple\n2D shapes undergoing rigid geometric transformations and color changes. A\ncompanion paper demonstrates the same approach in real-world application\nscenarios for machine vision and robotics.\n",
        "published": "2022",
        "authors": [
            "Alpha Renner",
            "Lazar Supic",
            "Andreea Danielescu",
            "Giacomo Indiveri",
            "Bruno A. Olshausen",
            "Yulia Sandamirskaya",
            "Friedrich T. Sommer",
            "E. Paxon Frady"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2210.13768v4",
        "title": "GLIF: A Unified Gated Leaky Integrate-and-Fire Neuron for Spiking Neural\n  Networks",
        "abstract": "  Spiking Neural Networks (SNNs) have been studied over decades to incorporate\ntheir biological plausibility and leverage their promising energy efficiency.\nThroughout existing SNNs, the leaky integrate-and-fire (LIF) model is commonly\nadopted to formulate the spiking neuron and evolves into numerous variants with\ndifferent biological features. However, most LIF-based neurons support only\nsingle biological feature in different neuronal behaviors, limiting their\nexpressiveness and neuronal dynamic diversity. In this paper, we propose GLIF,\na unified spiking neuron, to fuse different bio-features in different neuronal\nbehaviors, enlarging the representation space of spiking neurons. In GLIF,\ngating factors, which are exploited to determine the proportion of the fused\nbio-features, are learnable during training. Combining all learnable\nmembrane-related parameters, our method can make spiking neurons different and\nconstantly changing, thus increasing the heterogeneity and adaptivity of\nspiking neurons. Extensive experiments on a variety of datasets demonstrate\nthat our method obtains superior performance compared with other SNNs by simply\nchanging their neuronal formulations to GLIF. In particular, we train a spiking\nResNet-19 with GLIF and achieve $77.35\\%$ top-1 accuracy with six time steps on\nCIFAR-100, which has advanced the state-of-the-art. Codes are available at\n\\url{https://github.com/Ikarosy/Gated-LIF}.\n",
        "published": "2022",
        "authors": [
            "Xingting Yao",
            "Fanrong Li",
            "Zitao Mo",
            "Jian Cheng"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2211.14607v1",
        "title": "Sketch2FullStack: Generating Skeleton Code of Full Stack Website and\n  Application from Sketch using Deep Learning and Computer Vision",
        "abstract": "  For a full-stack web or app development, it requires a software firm or more\nspecifically a team of experienced developers to contribute a large portion of\ntheir time and resources to design the website and then convert it to code. As\na result, the efficiency of the development team is significantly reduced when\nit comes to converting UI wireframes and database schemas into an actual\nworking system. It would save valuable resources and fasten the overall\nworkflow if the clients or developers can automate this process of converting\nthe pre-made full-stack website design to get a partially working if not fully\nworking code. In this paper, we present a novel approach of generating the\nskeleton code from sketched images using Deep Learning and Computer Vision\napproaches. The dataset for training are first-hand sketched images of low\nfidelity wireframes, database schemas and class diagrams. The approach consists\nof three parts. First, the front-end or UI elements detection and extraction\nfrom custom-made UI wireframes. Second, individual database table creation from\nschema designs and lastly, creating a class file from class diagrams.\n",
        "published": "2022",
        "authors": [
            "Somoy Subandhu Barua",
            "Imam Mohammad Zulkarnain",
            "Abhishek Roy",
            "Md. Golam Rabiul Alam",
            "Md Zia Uddin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2301.00897v1",
        "title": "Game of Intelligent Life",
        "abstract": "  Cellular automata (CA) captivate researchers due to teh emergent, complex\nindividualized behavior that simple global rules of interaction enact. Recent\nadvances in the field have combined CA with convolutional neural networks to\nachieve self-regenerating images. This new branch of CA is called neural\ncellular automata [1]. The goal of this project is to use the idea of idea of\nneural cellular automata to grow prediction machines. We place many different\nconvolutional neural networks in a grid. Each conv net cell outputs a\nprediction of what the next state will be, and minimizes predictive error.\nCells received their neighbors' colors and fitnesses as input. Each cell's\nfitness score described how accurate its predictions were. Cells could also\nmove to explore their environment and some stochasticity was applied to\nmovement.\n",
        "published": "2023",
        "authors": [
            "Marlene Grieskamp",
            "Chaytan Inman",
            "Shaun Lee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2302.02091v1",
        "title": "Reducing ANN-SNN Conversion Error through Residual Membrane Potential",
        "abstract": "  Spiking Neural Networks (SNNs) have received extensive academic attention due\nto the unique properties of low power consumption and high-speed computing on\nneuromorphic chips. Among various training methods of SNNs, ANN-SNN conversion\nhas shown the equivalent level of performance as ANNs on large-scale datasets.\nHowever, unevenness error, which refers to the deviation caused by different\ntemporal sequences of spike arrival on activation layers, has not been\neffectively resolved and seriously suffers the performance of SNNs under the\ncondition of short time-steps. In this paper, we make a detailed analysis of\nunevenness error and divide it into four categories. We point out that the case\nof the ANN output being zero while the SNN output being larger than zero\naccounts for the largest percentage. Based on this, we theoretically prove the\nsufficient and necessary conditions of this case and propose an optimization\nstrategy based on residual membrane potential to reduce unevenness error. The\nexperimental results show that the proposed method achieves state-of-the-art\nperformance on CIFAR-10, CIFAR-100, and ImageNet datasets. For example, we\nreach top-1 accuracy of 64.32\\% on ImageNet with 10-steps. To the best of our\nknowledge, this is the first time ANN-SNN conversion can simultaneously achieve\nhigh accuracy and ultra-low-latency on the complex dataset. Code is available\nat https://github.com/hzc1208/ANN2SNN\\_SRP.\n",
        "published": "2023",
        "authors": [
            "Zecheng Hao",
            "Tong Bu",
            "Jianhao Ding",
            "Tiejun Huang",
            "Zhaofei Yu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2303.02490v1",
        "title": "Diffusion Models Generate Images Like Painters: an Analytical Theory of\n  Outline First, Details Later",
        "abstract": "  How do diffusion generative models convert pure noise into meaningful images?\nWe argue that generation involves first committing to an outline, and then to\nfiner and finer details. The corresponding reverse diffusion process can be\nmodeled by dynamics on a (time-dependent) high-dimensional landscape full of\nGaussian-like modes, which makes the following predictions: (i) individual\ntrajectories tend to be very low-dimensional; (ii) scene elements that vary\nmore within training data tend to emerge earlier; and (iii) early perturbations\nsubstantially change image content more often than late perturbations. We show\nthat the behavior of a variety of trained unconditional and conditional\ndiffusion models like Stable Diffusion is consistent with these predictions.\nFinally, we use our theory to search for the latent image manifold of diffusion\nmodels, and propose a new way to generate interpretable image variations. Our\nviewpoint suggests generation by GANs and diffusion models have unexpected\nsimilarities.\n",
        "published": "2023",
        "authors": [
            "Binxu Wang",
            "John J. Vastola"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2303.04238v4",
        "title": "Patch of Invisibility: Naturalistic Physical Black-Box Adversarial\n  Attacks on Object Detectors",
        "abstract": "  Adversarial attacks on deep-learning models have been receiving increased\nattention in recent years. Work in this area has mostly focused on\ngradient-based techniques, so-called ``white-box'' attacks, wherein the\nattacker has access to the targeted model's internal parameters; such an\nassumption is usually unrealistic in the real world. Some attacks additionally\nuse the entire pixel space to fool a given model, which is neither practical\nnor physical (i.e., real-world). On the contrary, we propose herein a direct,\nblack-box, gradient-free method that uses the learned image manifold of a\npretrained generative adversarial network (GAN) to generate naturalistic\nphysical adversarial patches for object detectors. To our knowledge this is the\nfirst and only method that performs black-box physical attacks directly on\nobject-detection models, which results with a model-agnostic attack. We show\nthat our proposed method works both digitally and physically. We compared our\napproach against four different black-box attacks with different\nconfigurations. Our approach outperformed all other approaches that were tested\nin our experiments by a large margin.\n",
        "published": "2023",
        "authors": [
            "Raz Lapid",
            "Eylon Mizrahi",
            "Moshe Sipper"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.10178v1",
        "title": "Neural Echos: Depthwise Convolutional Filters Replicate Biological\n  Receptive Fields",
        "abstract": "  In this study, we present evidence suggesting that depthwise convolutional\nkernels are effectively replicating the structural intricacies of the\nbiological receptive fields observed in the mammalian retina. We provide\nanalytics of trained kernels from various state-of-the-art models\nsubstantiating this evidence. Inspired by this intriguing discovery, we propose\nan initialization scheme that draws inspiration from the biological receptive\nfields. Experimental analysis of the ImageNet dataset with multiple CNN\narchitectures featuring depthwise convolutions reveals a marked enhancement in\nthe accuracy of the learned model when initialized with biologically derived\nweights. This underlies the potential for biologically inspired computational\nmodels to further our understanding of vision processing systems and to improve\nthe efficacy of convolutional networks.\n",
        "published": "2024",
        "authors": [
            "Zahra Babaiee",
            "Peyman M. Kiasari",
            "Daniela Rus",
            "Radu Grosu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0705.0199v2",
        "title": "The Parameter-Less Self-Organizing Map algorithm",
        "abstract": "  The Parameter-Less Self-Organizing Map (PLSOM) is a new neural network\nalgorithm based on the Self-Organizing Map (SOM). It eliminates the need for a\nlearning rate and annealing schemes for learning rate and neighbourhood size.\nWe discuss the relative performance of the PLSOM and the SOM and demonstrate\nsome tasks in which the SOM fails but the PLSOM performs satisfactory. Finally\nwe discuss some example applications of the PLSOM and present a proof of\nordering under certain limited conditions.\n",
        "published": "2007",
        "authors": [
            "Erik Berglund",
            "Joaquin Sitte"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0712.0932v1",
        "title": "Dimensionality Reduction and Reconstruction using Mirroring Neural\n  Networks and Object Recognition based on Reduced Dimension Characteristic\n  Vector",
        "abstract": "  In this paper, we present a Mirroring Neural Network architecture to perform\nnon-linear dimensionality reduction and Object Recognition using a reduced\nlowdimensional characteristic vector. In addition to dimensionality reduction,\nthe network also reconstructs (mirrors) the original high-dimensional input\nvector from the reduced low-dimensional data. The Mirroring Neural Network\narchitecture has more number of processing elements (adalines) in the outer\nlayers and the least number of elements in the central layer to form a\nconverging-diverging shape in its configuration. Since this network is able to\nreconstruct the original image from the output of the innermost layer (which\ncontains all the information about the input pattern), these outputs can be\nused as object signature to classify patterns. The network is trained to\nminimize the discrepancy between actual output and the input by back\npropagating the mean squared error from the output layer to the input layer.\nAfter successfully training the network, it can reduce the dimension of input\nvectors and mirror the patterns fed to it. The Mirroring Neural Network\narchitecture gave very good results on various test patterns.\n",
        "published": "2007",
        "authors": [
            "Dasika Ratna Deepthi",
            "Sujeet Kuchibhotla",
            "K. Eswaran"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1004.3708v1",
        "title": "Parcellation of fMRI Datasets with ICA and PLS-A Data Driven Approach",
        "abstract": "  Inter-subject parcellation of functional Magnetic Resonance Imaging (fMRI)\ndata based on a standard General Linear Model (GLM)and spectral clustering was\nrecently proposed as a means to alleviate the issues associated with spatial\nnormalization in fMRI. However, for all its appeal, a GLM-based parcellation\napproach introduces its own biases, in the form of a priori knowledge about the\nshape of Hemodynamic Response Function (HRF) and task-related signal changes,\nor about the subject behaviour during the task. In this paper, we introduce a\ndata-driven version of the spectral clustering parcellation, based on\nIndependent Component Analysis (ICA) and Partial Least Squares (PLS) instead of\nthe GLM. First, a number of independent components are automatically selected.\nSeed voxels are then obtained from the associated ICA maps and we compute the\nPLS latent variables between the fMRI signal of the seed voxels (which covers\nregional variations of the HRF) and the principal components of the signal\nacross all voxels. Finally, we parcellate all subjects data with a spectral\nclustering of the PLS latent variables. We present results of the application\nof the proposed method on both single-subject and multi-subject fMRI datasets.\nPreliminary experimental results, evaluated with intra-parcel variance of GLM\nt-values and PLS derived t-values, indicate that this data-driven approach\noffers improvement in terms of parcellation accuracy over GLM based techniques.\n",
        "published": "2010",
        "authors": [
            "Yongnan Ji",
            "Pierre-Yves Herve",
            "Uwe Aickelin",
            "Alain Pitiot"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1110.6483v2",
        "title": "Iris Codes Classification Using Discriminant and Witness Directions",
        "abstract": "  The main topic discussed in this paper is how to use intelligence for\nbiometric decision defuzzification. A neural training model is proposed and\ntested here as a possible solution for dealing with natural fuzzification that\nappears between the intra- and inter-class distribution of scores computed\nduring iris recognition tests. It is shown here that the use of proposed neural\nnetwork support leads to an improvement in the artificial perception of the\nseparation between the intra- and inter-class score distributions by moving\nthem away from each other.\n",
        "published": "2011",
        "authors": [
            "N. Popescu-Bodorin",
            "V. E. Balas",
            "I. M. Motoc"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1205.3336v1",
        "title": "Distribution of the search of evolutionary product unit neural networks\n  for classification",
        "abstract": "  This paper deals with the distributed processing in the search for an optimum\nclassification model using evolutionary product unit neural networks. For this\ndistributed search we used a cluster of computers. Our objective is to obtain a\nmore efficient design than those net architectures which do not use a\ndistributed process and which thus result in simpler designs. In order to get\nthe best classification models we use evolutionary algorithms to train and\ndesign neural networks, which require a very time consuming computation. The\nreasons behind the need for this distribution are various. It is complicated to\ntrain this type of nets because of the difficulty entailed in determining their\narchitecture due to the complex error surface. On the other hand, the use of\nevolutionary algorithms involves running a great number of tests with different\nseeds and parameters, thus resulting in a high computational cost\n",
        "published": "2012",
        "authors": [
            "A. J. Tall\u00f3n-Ballesteros",
            "P. A. Guti\u00e9rrez-Pe\u00f1a",
            "C. Herv\u00e1s-Mart\u00ednez"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1412.6464v1",
        "title": "Simplified firefly algorithm for 2D image key-points search",
        "abstract": "  In order to identify an object, human eyes firstly search the field of view\nfor points or areas which have particular properties. These properties are used\nto recognise an image or an object. Then this process could be taken as a model\nto develop computer algorithms for images identification. This paper proposes\nthe idea of applying the simplified firefly algorithm to search for key-areas\nin 2D images. For a set of input test images the proposed version of firefly\nalgorithm has been examined. Research results are presented and discussed to\nshow the efficiency of this evolutionary computation method.\n",
        "published": "2014",
        "authors": [
            "Christian Napoli",
            "Giuseppe Pappalardo",
            "Emiliano Tramontana",
            "Zbigniew Marsza\u0142ek",
            "Dawid Po\u0142ap",
            "Marcin Wo\u017aniak"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1506.01072v2",
        "title": "Homogeneous Spiking Neuromorphic System for Real-World Pattern\n  Recognition",
        "abstract": "  A neuromorphic chip that combines CMOS analog spiking neurons and memristive\nsynapses offers a promising solution to brain-inspired computing, as it can\nprovide massive neural network parallelism and density. Previous hybrid analog\nCMOS-memristor approaches required extensive CMOS circuitry for training, and\nthus eliminated most of the density advantages gained by the adoption of\nmemristor synapses. Further, they used different waveforms for pre and\npost-synaptic spikes that added undesirable circuit overhead. Here we describe\na hardware architecture that can feature a large number of memristor synapses\nto learn real-world patterns. We present a versatile CMOS neuron that combines\nintegrate-and-fire behavior, drives passive memristors and implements\ncompetitive learning in a compact circuit module, and enables in-situ\nplasticity in the memristor synapses. We demonstrate handwritten-digits\nrecognition using the proposed architecture using transistor-level circuit\nsimulations. As the described neuromorphic architecture is homogeneous, it\nrealizes a fundamental building block for large-scale energy-efficient\nbrain-inspired silicon chips that could lead to next-generation cognitive\ncomputing.\n",
        "published": "2015",
        "authors": [
            "Xinyu Wu",
            "Vishal Saxena",
            "Kehan Zhu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1506.08425v1",
        "title": "Deep-Plant: Plant Identification with convolutional neural networks",
        "abstract": "  This paper studies convolutional neural networks (CNN) to learn unsupervised\nfeature representations for 44 different plant species, collected at the Royal\nBotanic Gardens, Kew, England. To gain intuition on the chosen features from\nthe CNN model (opposed to a 'black box' solution), a visualisation technique\nbased on the deconvolutional networks (DN) is utilized. It is found that\nvenations of different order have been chosen to uniquely represent each of the\nplant species. Experimental results using these CNN features with different\nclassifiers show consistency and superiority compared to the state-of-the art\nsolutions which rely on hand-crafted features.\n",
        "published": "2015",
        "authors": [
            "Sue Han Lee",
            "Chee Seng Chan",
            "Paul Wilkin",
            "Paolo Remagnino"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1605.08412v1",
        "title": "CITlab ARGUS for historical handwritten documents",
        "abstract": "  We describe CITlab's recognition system for the HTRtS competition attached to\nthe 13. International Conference on Document Analysis and Recognition, ICDAR\n2015. The task comprises the recognition of historical handwritten documents.\nThe core algorithms of our system are based on multi-dimensional recurrent\nneural networks (MDRNN) and connectionist temporal classification (CTC). The\nsoftware modules behind that as well as the basic utility technologies are\nessentially powered by PLANET's ARGUS framework for intelligent text\nrecognition and image processing.\n",
        "published": "2016",
        "authors": [
            "Gundram Leifert",
            "Tobias Strau\u00df",
            "Tobias Gr\u00fcning",
            "Roger Labahn"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1701.01272v1",
        "title": "Autoencoder Regularized Network For Driving Style Representation\n  Learning",
        "abstract": "  In this paper, we study learning generalized driving style representations\nfrom automobile GPS trip data. We propose a novel Autoencoder Regularized deep\nneural Network (ARNet) and a trip encoding framework trip2vec to learn drivers'\ndriving styles directly from GPS records, by combining supervised and\nunsupervised feature learning in a unified architecture. Experiments on a\nchallenging driver number estimation problem and the driver identification\nproblem show that ARNet can learn a good generalized driving style\nrepresentation: It significantly outperforms existing methods and alternative\narchitectures by reaching the least estimation error on average (0.68, less\nthan one driver) and the highest identification accuracy (by at least 3%\nimprovement) compared with traditional supervised learning methods.\n",
        "published": "2017",
        "authors": [
            "Weishan Dong",
            "Ting Yuan",
            "Kai Yang",
            "Changsheng Li",
            "Shilei Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1702.03044v2",
        "title": "Incremental Network Quantization: Towards Lossless CNNs with\n  Low-Precision Weights",
        "abstract": "  This paper presents incremental network quantization (INQ), a novel method,\ntargeting to efficiently convert any pre-trained full-precision convolutional\nneural network (CNN) model into a low-precision version whose weights are\nconstrained to be either powers of two or zero. Unlike existing methods which\nare struggled in noticeable accuracy loss, our INQ has the potential to resolve\nthis issue, as benefiting from two innovations. On one hand, we introduce three\ninterdependent operations, namely weight partition, group-wise quantization and\nre-training. A well-proven measure is employed to divide the weights in each\nlayer of a pre-trained CNN model into two disjoint groups. The weights in the\nfirst group are responsible to form a low-precision base, thus they are\nquantized by a variable-length encoding method. The weights in the other group\nare responsible to compensate for the accuracy loss from the quantization, thus\nthey are the ones to be re-trained. On the other hand, these three operations\nare repeated on the latest re-trained group in an iterative manner until all\nthe weights are converted into low-precision ones, acting as an incremental\nnetwork quantization and accuracy enhancement procedure. Extensive experiments\non the ImageNet classification task using almost all known deep CNN\narchitectures including AlexNet, VGG-16, GoogleNet and ResNets well testify the\nefficacy of the proposed method. Specifically, at 5-bit quantization, our\nmodels have improved accuracy than the 32-bit floating-point references. Taking\nResNet-18 as an example, we further show that our quantized models with 4-bit,\n3-bit and 2-bit ternary weights have improved or very similar accuracy against\nits 32-bit floating-point baseline. Besides, impressive results with the\ncombination of network pruning and INQ are also reported. The code is available\nat https://github.com/Zhouaojun/Incremental-Network-Quantization.\n",
        "published": "2017",
        "authors": [
            "Aojun Zhou",
            "Anbang Yao",
            "Yiwen Guo",
            "Lin Xu",
            "Yurong Chen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1703.03854v2",
        "title": "Convolutional Spike Timing Dependent Plasticity based Feature Learning\n  in Spiking Neural Networks",
        "abstract": "  Brain-inspired learning models attempt to mimic the cortical architecture and\ncomputations performed in the neurons and synapses constituting the human brain\nto achieve its efficiency in cognitive tasks. In this work, we present\nconvolutional spike timing dependent plasticity based feature learning with\nbiologically plausible leaky-integrate-and-fire neurons in Spiking Neural\nNetworks (SNNs). We use shared weight kernels that are trained to encode\nrepresentative features underlying the input patterns thereby improving the\nsparsity as well as the robustness of the learning model. We demonstrate that\nthe proposed unsupervised learning methodology learns several visual categories\nfor object recognition with fewer number of examples and outperforms\ntraditional fully-connected SNN architectures while yielding competitive\naccuracy. Additionally, we observe that the learning model performs out-of-set\ngeneralization further making the proposed biologically plausible framework a\nviable and efficient architecture for future neuromorphic applications.\n",
        "published": "2017",
        "authors": [
            "Priyadarshini Panda",
            "Gopalakrishnan Srinivasan",
            "Kaushik Roy"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1706.04215v1",
        "title": "Identifying Spatial Relations in Images using Convolutional Neural\n  Networks",
        "abstract": "  Traditional approaches to building a large scale knowledge graph have usually\nrelied on extracting information (entities, their properties, and relations\nbetween them) from unstructured text (e.g. Dbpedia). Recent advances in\nConvolutional Neural Networks (CNN) allow us to shift our focus to learning\nentities and relations from images, as they build robust models that require\nlittle or no pre-processing of the images. In this paper, we present an\napproach to identify and extract spatial relations (e.g., The girl is standing\nbehind the table) from images using CNNs. Our research addresses two specific\nchallenges: providing insight into how spatial relations are learned by the\nnetwork and which parts of the image are used to predict these relations. We\nuse the pre-trained network VGGNet to extract features from an image and train\na Multi-layer Perceptron (MLP) on a set of synthetic images and the sun09\ndataset to extract spatial relations. The MLP predicts spatial relations\nwithout a bounding box around the objects or the space in the image depicting\nthe relation. To understand how the spatial relations are represented in the\nnetwork, a heatmap is overlayed on the image to show the regions that are\ndeemed important by the network. Also, we analyze the MLP to show the\nrelationship between the activation of consistent groups of nodes and the\nprediction of a spatial relation. We show how the loss of these groups affects\nthe networks ability to identify relations.\n",
        "published": "2017",
        "authors": [
            "Mandar Haldekar",
            "Ashwinkumar Ganesan",
            "Tim Oates"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1706.09262v2",
        "title": "Hierarchical Attentive Recurrent Tracking",
        "abstract": "  Class-agnostic object tracking is particularly difficult in cluttered\nenvironments as target specific discriminative models cannot be learned a\npriori. Inspired by how the human visual cortex employs spatial attention and\nseparate \"where\" and \"what\" processing pathways to actively suppress irrelevant\nvisual features, this work develops a hierarchical attentive recurrent model\nfor single object tracking in videos. The first layer of attention discards the\nmajority of background by selecting a region containing the object of interest,\nwhile the subsequent layers tune in on visual features particular to the\ntracked object. This framework is fully differentiable and can be trained in a\npurely data driven fashion by gradient methods. To improve training\nconvergence, we augment the loss function with terms for a number of auxiliary\ntasks relevant for tracking. Evaluation of the proposed model is performed on\ntwo datasets: pedestrian tracking on the KTH activity recognition dataset and\nthe more difficult KITTI object tracking dataset.\n",
        "published": "2017",
        "authors": [
            "Adam R. Kosiorek",
            "Alex Bewley",
            "Ingmar Posner"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1711.10644v2",
        "title": "PSIque: Next Sequence Prediction of Satellite Images using a\n  Convolutional Sequence-to-Sequence Network",
        "abstract": "  Predicting unseen weather phenomena is an important issue for disaster\nmanagement. In this paper, we suggest a model for a convolutional\nsequence-to-sequence autoencoder for predicting undiscovered weather situations\nfrom previous satellite images. We also propose a symmetric skip connection\nbetween encoder and decoder modules to produce more comprehensive image\npredictions. To examine our model performance, we conducted experiments for\neach suggested model to predict future satellite images from historical\nsatellite images. A specific combination of skip connection and\nsequence-to-sequence autoencoder was able to generate closest prediction from\nthe ground truth image.\n",
        "published": "2017",
        "authors": [
            "Seungkyun Hong",
            "Seongchan Kim",
            "Minsu Joh",
            "Sa-kwang Song"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.03318v1",
        "title": "Nature vs. Nurture: The Role of Environmental Resources in Evolutionary\n  Deep Intelligence",
        "abstract": "  Evolutionary deep intelligence synthesizes highly efficient deep neural\nnetworks architectures over successive generations. Inspired by the nature\nversus nurture debate, we propose a study to examine the role of external\nfactors on the network synthesis process by varying the availability of\nsimulated environmental resources. Experimental results were obtained for\nnetworks synthesized via asexual evolutionary synthesis (1-parent) and sexual\nevolutionary synthesis (2-parent, 3-parent, and 5-parent) using a 10% subset of\nthe MNIST dataset. Results show that a lower environmental factor model\nresulted in a more gradual loss in performance accuracy and decrease in storage\nsize. This potentially allows significantly reduced storage size with minimal\nto no drop in performance accuracy, and the best networks were synthesized\nusing the lowest environmental factor models.\n",
        "published": "2018",
        "authors": [
            "Audrey G. Chung",
            "Paul Fieguth",
            "Alexander Wong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1802.06488v1",
        "title": "Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network\n  for Real-time Embedded Object Detection",
        "abstract": "  Object detection is a major challenge in computer vision, involving both\nobject classification and object localization within a scene. While deep neural\nnetworks have been shown in recent years to yield very powerful techniques for\ntackling the challenge of object detection, one of the biggest challenges with\nenabling such object detection networks for widespread deployment on embedded\ndevices is high computational and memory requirements. Recently, there has been\nan increasing focus in exploring small deep neural network architectures for\nobject detection that are more suitable for embedded devices, such as Tiny YOLO\nand SqueezeDet. Inspired by the efficiency of the Fire microarchitecture\nintroduced in SqueezeNet and the object detection performance of the\nsingle-shot detection macroarchitecture introduced in SSD, this paper\nintroduces Tiny SSD, a single-shot detection deep convolutional neural network\nfor real-time embedded object detection that is composed of a highly optimized,\nnon-uniform Fire sub-network stack and a non-uniform sub-network stack of\nhighly optimized SSD-based auxiliary convolutional feature layers designed\nspecifically to minimize model size while maintaining object detection\nperformance. The resulting Tiny SSD possess a model size of 2.3MB (~26X smaller\nthan Tiny YOLO) while still achieving an mAP of 61.3% on VOC 2007 (~4.2% higher\nthan Tiny YOLO). These experimental results show that very small deep neural\nnetwork architectures can be designed for real-time object detection that are\nwell-suited for embedded scenarios.\n",
        "published": "2018",
        "authors": [
            "Alexander Wong",
            "Mohammad Javad Shafiee",
            "Francis Li",
            "Brendan Chwyl"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1803.10567v1",
        "title": "Image Generation and Translation with Disentangled Representations",
        "abstract": "  Generative models have made significant progress in the tasks of modeling\ncomplex data distributions such as natural images. The introduction of\nGenerative Adversarial Networks (GANs) and auto-encoders lead to the\npossibility of training on big data sets in an unsupervised manner. However,\nfor many generative models it is not possible to specify what kind of image\nshould be generated and it is not possible to translate existing images into\nnew images of similar domains. Furthermore, models that can perform\nimage-to-image translation often need distinct models for each domain, making\nit hard to scale these systems to multiple domain image-to-image translation.\nWe introduce a model that can do both, controllable image generation and\nimage-to-image translation between multiple domains. We split our image\nrepresentation into two parts encoding unstructured and structured information\nrespectively. The latter is designed in a disentangled manner, so that\ndifferent parts encode different image characteristics. We train an encoder to\nencode images into these representations and use a small amount of labeled data\nto specify what kind of information should be encoded in the disentangled part.\nA generator is trained to generate images from these representations using the\ncharacteristics provided by the disentangled part of the representation.\nThrough this we can control what kind of images the generator generates,\ntranslate images between different domains, and even learn unknown\ndata-generating factors while only using one single model.\n",
        "published": "2018",
        "authors": [
            "Tobias Hinz",
            "Stefan Wermter"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1807.03215v3",
        "title": "Fuzzy Logic Interpretation of Quadratic Networks",
        "abstract": "  Over past several years, deep learning has achieved huge successes in various\napplications. However, such a data-driven approach is often criticized for lack\nof interpretability. Recently, we proposed artificial quadratic neural networks\nconsisting of second-order neurons in potentially many layers. In each\nsecond-order neuron, a quadratic function is used in the place of the inner\nproduct in a traditional neuron, and then undergoes a nonlinear activation.\nWith a single second-order neuron, any fuzzy logic operation, such as XOR, can\nbe implemented. In this sense, any deep network constructed with quadratic\nneurons can be interpreted as a deep fuzzy logic system. Since traditional\nneural networks and second-order counterparts can represent each other and\nfuzzy logic operations are naturally implemented in second-order neural\nnetworks, it is plausible to explain how a deep neural network works with a\nsecond-order network as the system model. In this paper, we generalize and\ncategorize fuzzy logic operations implementable with individual second-order\nneurons, and then perform statistical/information theoretic analyses of\nexemplary quadratic neural networks.\n",
        "published": "2018",
        "authors": [
            "Fenglei Fan",
            "Ge Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.00482v1",
        "title": "Hybrid Pruning: Thinner Sparse Networks for Fast Inference on Edge\n  Devices",
        "abstract": "  We introduce hybrid pruning which combines both coarse-grained channel and\nfine-grained weight pruning to reduce model size, computation and power demands\nwith no to little loss in accuracy for enabling modern networks deployment on\nresource-constrained devices, such as always-on security cameras and drones.\nAdditionally, to effectively perform channel pruning, we propose a fast\nsensitivity test that helps us quickly identify the sensitivity of within and\nacross layers of a network to the output accuracy for target multiplier\naccumulators (MACs) or accuracy tolerance. Our experiment shows significantly\nbetter results on ResNet50 on ImageNet compared to existing work, even with an\nadditional constraint of channels be hardware-friendly number.\n",
        "published": "2018",
        "authors": [
            "Xiaofan Xu",
            "Mi Sun Park",
            "Cormac Brick"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.04303v1",
        "title": "PolyNeuron: Automatic Neuron Discovery via Learned Polyharmonic Spline\n  Activations",
        "abstract": "  Automated deep neural network architecture design has received a significant\namount of recent attention. However, this attention has not been equally shared\nby one of the fundamental building blocks of a deep neural network, the\nneurons. In this study, we propose PolyNeuron, a novel automatic neuron\ndiscovery approach based on learned polyharmonic spline activations. More\nspecifically, PolyNeuron revolves around learning polyharmonic splines,\ncharacterized by a set of control points, that represent the activation\nfunctions of the neurons in a deep neural network. A relaxed variant of\nPolyNeuron, which we term PolyNeuron-R, loosens the constraints imposed by\nPolyNeuron to reduce the computational complexity for discovering the neuron\nactivation functions in an automated manner. Experiments show both PolyNeuron\nand PolyNeuron-R lead to networks that have improved or comparable performance\non multiple network architectures (LeNet-5 and ResNet-20) using different\ndatasets (MNIST and CIFAR10). As such, automatic neuron discovery approaches\nsuch as PolyNeuron is a worthy direction to explore.\n",
        "published": "2018",
        "authors": [
            "Andrew Hryniowski",
            "Alexander Wong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.07516v2",
        "title": "Unsupervised Learning in Reservoir Computing for EEG-based Emotion\n  Recognition",
        "abstract": "  In real-world applications such as emotion recognition from recorded brain\nactivity, data are captured from electrodes over time. These signals constitute\na multidimensional time series. In this paper, Echo State Network (ESN), a\nrecurrent neural network with a great success in time series prediction and\nclassification, is optimized with different neural plasticity rules for\nclassification of emotions based on electroencephalogram (EEG) time series.\nActually, the neural plasticity rules are a kind of unsupervised learning\nadapted for the reservoir, i.e. the hidden layer of ESN. More specifically, an\ninvestigation of Oja's rule, BCM rule and gaussian intrinsic plasticity rule\nwas carried out in the context of EEG-based emotion recognition. The study,\nalso, includes a comparison of the offline and online training of the ESN. When\ntesting on the well-known affective benchmark \"DEAP dataset\" which contains EEG\nsignals from 32 subjects, we find that pretraining ESN with gaussian intrinsic\nplasticity enhanced the classification accuracy and outperformed the results\nachieved with an ESN pretrained with synaptic plasticity. Four classification\nproblems were conducted in which the system complexity is increased and the\ndiscrimination is more challenging, i.e. inter-subject emotion discrimination.\nOur proposed method achieves higher performance over the state of the art\nmethods.\n",
        "published": "2018",
        "authors": [
            "Rahma Fourati",
            "Boudour Ammar",
            "Javier Sanchez-Medina",
            "Adel M. Alimi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1811.07966v1",
        "title": "Mitigating Architectural Mismatch During the Evolutionary Synthesis of\n  Deep Neural Networks",
        "abstract": "  Evolutionary deep intelligence has recently shown great promise for producing\nsmall, powerful deep neural network models via the organic synthesis of\nincreasingly efficient architectures over successive generations. Existing\nevolutionary synthesis processes, however, have allowed the mating of parent\nnetworks independent of architectural alignment, resulting in a mismatch of\nnetwork structures. We present a preliminary study into the effects of\narchitectural alignment during evolutionary synthesis using a gene tagging\nsystem. Surprisingly, the network architectures synthesized using the gene\ntagging approach resulted in slower decreases in performance accuracy and\nstorage size; however, the resultant networks were comparable in size and\nperformance accuracy to the non-gene tagging networks. Furthermore, we\nspeculate that there is a noticeable decrease in network variability for\nnetworks synthesized with gene tagging, indicating that enforcing a\nlike-with-like mating policy potentially restricts the exploration of the\nsearch space of possible network architectures.\n",
        "published": "2018",
        "authors": [
            "Audrey Chung",
            "Paul Fieguth",
            "Alexander Wong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1709.05943v1",
        "title": "Fast YOLO: A Fast You Only Look Once System for Real-time Embedded\n  Object Detection in Video",
        "abstract": "  Object detection is considered one of the most challenging problems in this\nfield of computer vision, as it involves the combination of object\nclassification and object localization within a scene. Recently, deep neural\nnetworks (DNNs) have been demonstrated to achieve superior object detection\nperformance compared to other approaches, with YOLOv2 (an improved You Only\nLook Once model) being one of the state-of-the-art in DNN-based object\ndetection methods in terms of both speed and accuracy. Although YOLOv2 can\nachieve real-time performance on a powerful GPU, it still remains very\nchallenging for leveraging this approach for real-time object detection in\nvideo on embedded computing devices with limited computational power and\nlimited memory. In this paper, we propose a new framework called Fast YOLO, a\nfast You Only Look Once framework which accelerates YOLOv2 to be able to\nperform object detection in video on embedded devices in a real-time manner.\nFirst, we leverage the evolutionary deep intelligence framework to evolve the\nYOLOv2 network architecture and produce an optimized architecture (referred to\nas O-YOLOv2 here) that has 2.8X fewer parameters with just a ~2% IOU drop. To\nfurther reduce power consumption on embedded devices while maintaining\nperformance, a motion-adaptive inference method is introduced into the proposed\nFast YOLO framework to reduce the frequency of deep inference with O-YOLOv2\nbased on temporal motion characteristics. Experimental results show that the\nproposed Fast YOLO framework can reduce the number of deep inferences by an\naverage of 38.13%, and an average speedup of ~3.3X for objection detection in\nvideo compared to the original YOLOv2, leading Fast YOLO to run an average of\n~18FPS on a Nvidia Jetson TX1 embedded system.\n",
        "published": "2017",
        "authors": [
            "Mohammad Javad Shafiee",
            "Brendan Chywl",
            "Francis Li",
            "Alexander Wong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1406.3793v1",
        "title": "Neural tuning size is a key factor underlying holistic face processing",
        "abstract": "  Faces are a class of visual stimuli with unique significance, for a variety\nof reasons. They are ubiquitous throughout the course of a person's life, and\nface recognition is crucial for daily social interaction. Faces are also unlike\nany other stimulus class in terms of certain physical stimulus characteristics.\nFurthermore, faces have been empirically found to elicit certain characteristic\nbehavioral phenomena, which are widely held to be evidence of \"holistic\"\nprocessing of faces. However, little is known about the neural mechanisms\nunderlying such holistic face processing. In other words, for the processing of\nfaces by the primate visual system, the input and output characteristics are\nrelatively well known, but the internal neural computations are not. The main\naim of this work is to further the fundamental understanding of what causes the\nvisual processing of faces to be different from that of objects. In this\ncomputational modeling work, we show that a single factor - \"neural tuning\nsize\" - is able to account for three key phenomena that are characteristic of\nface processing, namely the Composite Face Effect (CFE), Face Inversion Effect\n(FIE) and Whole-Part Effect (WPE). Our computational proof-of-principle\nprovides specific neural tuning properties that correspond to the\npoorly-understood notion of holistic face processing, and connects these neural\nproperties to psychophysical behavior. Overall, our work provides a unified and\nparsimonious theoretical account for the disparate empirical data on\nface-specific processing, deepening the fundamental understanding of face\nprocessing.\n",
        "published": "2014",
        "authors": [
            "Cheston Tan",
            "Tomaso Poggio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.00712v1",
        "title": "Evaluation of Alzheimer's Disease by Analysis of MR Images using\n  Multilayer Perceptrons and Kohonen SOM Classifiers as an Alternative to the\n  ADC Maps",
        "abstract": "  Alzheimer's disease is the most common cause of dementia, yet hard to\ndiagnose precisely without invasive techniques, particularly at the onset of\nthe disease. This work approaches image analysis and classification of\nsynthetic multispectral images composed by diffusion-weighted magnetic\nresonance (MR) cerebral images for the evaluation of cerebrospinal fluid area\nand measuring the advance of Alzheimer's disease. A clinical 1.5 T MR imaging\nsystem was used to acquire all images presented. The classification methods are\nbased on multilayer perceptrons and Kohonen Self-Organized Map classifiers. We\nassume the classes of interest can be separated by hyperquadrics. Therefore, a\n2-degree polynomial network is used to classify the original image, generating\nthe ground truth image. The classification results are used to improve the\nusual analysis of the apparent diffusion coefficient map.\n",
        "published": "2017",
        "authors": [
            "Wellington Pinheiro dos Santos",
            "Ricardo Emmanuel de Souza",
            "Pl\u00ednio B. dos Santos Filho"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.09709v2",
        "title": "Report: Dynamic Eye Movement Matching and Visualization Tool in Neuro\n  Gesture",
        "abstract": "  In the research of the impact of gestures using by a lecturer, one\nchallenging task is to infer the attention of a group of audiences. Two\nimportant measurements that can help infer the level of attention are eye\nmovement data and Electroencephalography (EEG) data. Under the fundamental\nassumption that a group of people would look at the same place if they all pay\nattention at the same time, we apply a method, \"Time Warp Edit Distance\", to\ncalculate the similarity of their eye movement trajectories. Moreover, we also\ncluster eye movement pattern of audiences based on these pair-wised similarity\nmetrics. Besides, since we don't have a direct metric for the \"attention\"\nground truth, a visual assessment would be beneficial to evaluate the\ngesture-attention relationship. Thus we also implement a visualization tool.\n",
        "published": "2017",
        "authors": [
            "Qiangeng Xu",
            "John Kender"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.05989v2",
        "title": "FermiNets: Learning generative machines to generate efficient neural\n  networks via generative synthesis",
        "abstract": "  The tremendous potential exhibited by deep learning is often offset by\narchitectural and computational complexity, making widespread deployment a\nchallenge for edge scenarios such as mobile and other consumer devices. To\ntackle this challenge, we explore the following idea: Can we learn generative\nmachines to automatically generate deep neural networks with efficient network\narchitectures? In this study, we introduce the idea of generative synthesis,\nwhich is premised on the intricate interplay between a generator-inquisitor\npair that work in tandem to garner insights and learn to generate highly\nefficient deep neural networks that best satisfies operational requirements.\nWhat is most interesting is that, once a generator has been learned through\ngenerative synthesis, it can be used to generate not just one but a large\nvariety of different, unique highly efficient deep neural networks that satisfy\noperational requirements. Experimental results for image classification,\nsemantic segmentation, and object detection tasks illustrate the efficacy of\ngenerative synthesis in producing generators that automatically generate highly\nefficient deep neural networks (which we nickname FermiNets) with higher model\nefficiency and lower computational costs (reaching >10x more efficient and\nfewer multiply-accumulate operations than several tested state-of-the-art\nnetworks), as well as higher energy efficiency (reaching >4x improvements in\nimage inferences per joule consumed on a Nvidia Tegra X2 mobile processor). As\nsuch, generative synthesis can be a powerful, generalized approach for\naccelerating and improving the building of deep neural networks for on-device\nedge scenarios.\n",
        "published": "2018",
        "authors": [
            "Alexander Wong",
            "Mohammad Javad Shafiee",
            "Brendan Chwyl",
            "Francis Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.06426v1",
        "title": "Auto-tuning Neural Network Quantization Framework for Collaborative\n  Inference Between the Cloud and Edge",
        "abstract": "  Recently, deep neural networks (DNNs) have been widely applied in mobile\nintelligent applications. The inference for the DNNs is usually performed in\nthe cloud. However, it leads to a large overhead of transmitting data via\nwireless network. In this paper, we demonstrate the advantages of the\ncloud-edge collaborative inference with quantization. By analyzing the\ncharacteristics of layers in DNNs, an auto-tuning neural network quantization\nframework for collaborative inference is proposed. We study the effectiveness\nof mixed-precision collaborative inference of state-of-the-art DNNs by using\nImageNet dataset. The experimental results show that our framework can generate\nreasonable network partitions and reduce the storage on mobile devices with\ntrivial loss of accuracy.\n",
        "published": "2018",
        "authors": [
            "Guangli Li",
            "Lei Liu",
            "Xueying Wang",
            "Xiao Dong",
            "Peng Zhao",
            "Xiaobing Feng"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2006.05159v1",
        "title": "Physically constrained short-term vehicle trajectory forecasting with\n  naive semantic maps",
        "abstract": "  Urban environments manifest a high level of complexity, and therefore it is\nof vital importance for safety systems embedded within autonomous vehicles\n(AVs) to be able to accurately predict the short-term future motion of nearby\nagents. This problem can be further understood as generating a sequence of\nfuture coordinates for a given agent based on its past motion data e.g.\nposition, velocity, acceleration etc, and whilst current approaches demonstrate\nplausible results they have a propensity to neglect a scene's physical\nconstrains. In this paper we propose the model based on a combination of the\nCNN and LSTM encoder-decoder architecture that learns to extract a relevant\nroad features from semantic maps as well as general motion of agents and uses\nthis learned representation to predict their short-term future trajectories. We\ntrain and validate the model on the publicly available dataset that provides\ndata from urban areas, allowing us to examine it in challenging and uncertain\nscenarios. We show that our model is not only capable of anticipating future\nmotion whilst taking into consideration road boundaries, but can also\neffectively and precisely predict trajectories for a longer time horizon than\ninitially trained for.\n",
        "published": "2020",
        "authors": [
            "Albert Dulian",
            "John C. Murray"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.01729v5",
        "title": "Revisiting Batch Normalization for Training Low-latency Deep Spiking\n  Neural Networks from Scratch",
        "abstract": "  Spiking Neural Networks (SNNs) have recently emerged as an alternative to\ndeep learning owing to sparse, asynchronous and binary event (or spike) driven\nprocessing, that can yield huge energy efficiency benefits on neuromorphic\nhardware. However, training high-accuracy and low-latency SNNs from scratch\nsuffers from non-differentiable nature of a spiking neuron. To address this\ntraining issue in SNNs, we revisit batch normalization and propose a temporal\nBatch Normalization Through Time (BNTT) technique. Most prior SNN works till\nnow have disregarded batch normalization deeming it ineffective for training\ntemporal SNNs. Different from previous works, our proposed BNTT decouples the\nparameters in a BNTT layer along the time axis to capture the temporal dynamics\nof spikes. The temporally evolving learnable parameters in BNTT allow a neuron\nto control its spike rate through different time-steps, enabling low-latency\nand low-energy training from scratch. We conduct experiments on CIFAR-10,\nCIFAR-100, Tiny-ImageNet and event-driven DVS-CIFAR10 datasets. BNTT allows us\nto train deep SNN architectures from scratch, for the first time, on complex\ndatasets with just few 25-30 time-steps. We also propose an early exit\nalgorithm using the distribution of parameters in BNTT to reduce the latency at\ninference, that further improves the energy-efficiency.\n",
        "published": "2020",
        "authors": [
            "Youngeun Kim",
            "Priyadarshini Panda"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2101.06848v4",
        "title": "Faster Convergence in Deep-Predictive-Coding Networks to Learn Deeper\n  Representations",
        "abstract": "  Deep-predictive-coding networks (DPCNs) are hierarchical, generative models.\nThey rely on feed-forward and feed-back connections to modulate latent feature\nrepresentations of stimuli in a dynamic and context-sensitive manner. A crucial\nelement of DPCNs is a forward-backward inference procedure to uncover sparse,\ninvariant features. However, this inference is a major computational\nbottleneck. It severely limits the network depth due to learning stagnation.\nHere, we prove why this bottleneck occurs. We then propose a new\nforward-inference strategy based on accelerated proximal gradients. This\nstrategy has faster theoretical convergence guarantees than the one used for\nDPCNs. It overcomes learning stagnation. We also demonstrate that it permits\nconstructing deep and wide predictive-coding networks. Such convolutional\nnetworks implement receptive fields that capture well the entire classes of\nobjects on which the networks are trained. This improves the feature\nrepresentations compared with our lab's previous non-convolutional and\nconvolutional DPCNs. It yields unsupervised object recognition that surpass\nconvolutional autoencoders and are on par with convolutional networks trained\nin a supervised manner.\n",
        "published": "2021",
        "authors": [
            "Isaac J. Sledge",
            "Jose C. Principe"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.11001v1",
        "title": "Multi-Objective Dual Simplex-Mesh Based Deformable Image Registration\n  for 3D Medical Images -- Proof of Concept",
        "abstract": "  Reliably and physically accurately transferring information between images\nthrough deformable image registration with large anatomical differences is an\nopen challenge in medical image analysis. Most existing methods have two key\nshortcomings: first, they require extensive up-front parameter tuning to each\nspecific registration problem, and second, they have difficulty capturing large\ndeformations and content mismatches between images. There have however been\ndevelopments that have laid the foundation for potential solutions to both\nshortcomings. Towards the first shortcoming, a multi-objective optimization\napproach using the Real-Valued Gene-pool Optimal Mixing Evolutionary Algorithm\n(RV-GOMEA) has been shown to be capable of producing a diverse set of\nregistrations for 2D images in one run of the algorithm, representing different\ntrade-offs between conflicting objectives in the registration problem. This\nallows the user to select a registration afterwards and removes the need for\nup-front tuning. Towards the second shortcoming, a dual-dynamic grid\ntransformation model has proven effective at capturing large differences in 2D\nimages. These two developments have recently been accelerated through GPU\nparallelization, delivering large speed-ups. Based on this accelerated version,\nit is now possible to extend the approach to 3D images. Concordantly, this work\nintroduces the first method for multi-objective 3D deformable image\nregistration, using a 3D dual-dynamic grid transformation model based on\nsimplex meshes while still supporting the incorporation of annotated guidance\ninformation and multi-resolution schemes. Our proof-of-concept prototype shows\npromising results on synthetic and clinical 3D registration problems, forming\nthe foundation for a new, insightful method that can include bio-mechanical\nproperties in the registration.\n",
        "published": "2022",
        "authors": [
            "Georgios Andreadis",
            "Peter A. N. Bosman",
            "Tanja Alderliesten"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.12250v1",
        "title": "BLPnet: A new DNN model and Bengali OCR engine for Automatic License\n  Plate Recognition",
        "abstract": "  The development of the Automatic License Plate Recognition (ALPR) system has\nreceived much attention for the English license plate. However, despite being\nthe sixth largest population around the world, no significant progress can be\ntracked in the Bengali language countries or states for the ALPR system\naddressing their more alarming traffic management with inadequate road-safety\nmeasures. This paper reports a computationally efficient and reasonably\naccurate Automatic License Plate Recognition (ALPR) system for Bengali\ncharacters with a new end-to-end DNN model that we call Bengali License Plate\nNetwork(BLPnet). The cascaded architecture for detecting vehicle regions prior\nto vehicle license plate (VLP) in the model is proposed to eliminate false\npositives resulting in higher detection accuracy of VLP. Besides, a lower set\nof trainable parameters is considered for reducing the computational cost\nmaking the system faster and more compatible for a real-time application. With\na Computational Neural Network (CNN)based new Bengali OCR engine and\nword-mapping process, the model is characters rotation invariant, and can\nreadily extract, detect and output the complete license plate number of a\nvehicle. The model feeding with17 frames per second (fps) on real-time video\nfootage can detect a vehicle with the Mean Squared Error (MSE) of 0.0152, and\nthe mean license plate character recognition accuracy of 95%. While compared to\nthe other models, an improvement of 5% and 20% were recorded for the BLPnetover\nthe prominent YOLO-based ALPR model and the Tesseract model for the\nnumber-plate detection accuracy and time requirement, respectively.\n",
        "published": "2022",
        "authors": [
            "Md. Saif Hassan Onim",
            "Hussain Nyeem",
            "Koushik Roy",
            "Mahmudul Hasan",
            "Abtahi Ishmam",
            "Md. Akiful Hoque Akif",
            "Tareque Bashar Ovi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.04325v4",
        "title": "Hadamard Product for Low-rank Bilinear Pooling",
        "abstract": "  Bilinear models provide rich representations compared with linear models.\nThey have been applied in various visual tasks, such as object recognition,\nsegmentation, and visual question-answering, to get state-of-the-art\nperformances taking advantage of the expanded representations. However,\nbilinear representations tend to be high-dimensional, limiting the\napplicability to computationally complex tasks. We propose low-rank bilinear\npooling using Hadamard product for an efficient attention mechanism of\nmultimodal learning. We show that our model outperforms compact bilinear\npooling in visual question-answering tasks with the state-of-the-art results on\nthe VQA dataset, having a better parsimonious property.\n",
        "published": "2016",
        "authors": [
            "Jin-Hwa Kim",
            "Kyoung-Woon On",
            "Woosang Lim",
            "Jeonghee Kim",
            "Jung-Woo Ha",
            "Byoung-Tak Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.09609v1",
        "title": "Generalized Haar Filter based Deep Networks for Real-Time Object\n  Detection in Traffic Scene",
        "abstract": "  Vision-based object detection is one of the fundamental functions in numerous\ntraffic scene applications such as self-driving vehicle systems and advance\ndriver assistance systems (ADAS). However, it is also a challenging task due to\nthe diversity of traffic scene and the storage, power and computing source\nlimitations of the platforms for traffic scene applications. This paper\npresents a generalized Haar filter based deep network which is suitable for the\nobject detection tasks in traffic scene. In this approach, we first decompose a\nobject detection task into several easier local regression tasks. Then, we\nhandle the local regression tasks by using several tiny deep networks which\nsimultaneously output the bounding boxes, categories and confidence scores of\ndetected objects. To reduce the consumption of storage and computing resources,\nthe weights of the deep networks are constrained to the form of generalized\nHaar filter in training phase. Additionally, we introduce the strategy of\nsparse windows generation to improve the efficiency of the algorithm. Finally,\nwe perform several experiments to validate the performance of our proposed\napproach. Experimental results demonstrate that the proposed approach is both\nefficient and effective in traffic scene compared with the state-of-the-art.\n",
        "published": "2016",
        "authors": [
            "Keyu Lu",
            "Jian Li",
            "Xiangjing An",
            "Hangen He"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.01939v1",
        "title": "Correlation Alignment for Unsupervised Domain Adaptation",
        "abstract": "  In this chapter, we present CORrelation ALignment (CORAL), a simple yet\neffective method for unsupervised domain adaptation. CORAL minimizes domain\nshift by aligning the second-order statistics of source and target\ndistributions, without requiring any target labels. In contrast to subspace\nmanifold methods, it aligns the original feature distributions of the source\nand target domains, rather than the bases of lower-dimensional subspaces. It is\nalso much simpler than other distribution matching methods. CORAL performs\nremarkably well in extensive evaluations on standard benchmark datasets. We\nfirst describe a solution that applies a linear transformation to source\nfeatures to align them with target features before classifier training. For\nlinear classifiers, we propose to equivalently apply CORAL to the classifier\nweights, leading to added efficiency when the number of classifiers is small\nbut the number and dimensionality of target examples are very high. The\nresulting CORAL Linear Discriminant Analysis (CORAL-LDA) outperforms LDA by a\nlarge margin on standard domain adaptation benchmarks. Finally, we extend CORAL\nto learn a nonlinear transformation that aligns correlations of layer\nactivations in deep neural networks (DNNs). The resulting Deep CORAL approach\nworks seamlessly with DNNs and achieves state-of-the-art performance on\nstandard benchmark datasets. Our code is available\nat:~\\url{https://github.com/VisionLearningGroup/CORAL}\n",
        "published": "2016",
        "authors": [
            "Baochen Sun",
            "Jiashi Feng",
            "Kate Saenko"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.10675v1",
        "title": "Discovery Radiomics with CLEAR-DR: Interpretable Computer Aided\n  Diagnosis of Diabetic Retinopathy",
        "abstract": "  Objective: Radiomics-driven Computer Aided Diagnosis (CAD) has shown\nconsiderable promise in recent years as a potential tool for improving clinical\ndecision support in medical oncology, particularly those based around the\nconcept of Discovery Radiomics, where radiomic sequencers are discovered\nthrough the analysis of medical imaging data. One of the main limitations with\ncurrent CAD approaches is that it is very difficult to gain insight or\nrationale as to how decisions are made, thus limiting their utility to\nclinicians. Methods: In this study, we propose CLEAR-DR, a novel interpretable\nCAD system based on the notion of CLass-Enhanced Attentive Response Discovery\nRadiomics for the purpose of clinical decision support for diabetic\nretinopathy. Results: In addition to disease grading via the discovered deep\nradiomic sequencer, the CLEAR-DR system also produces a visual interpretation\nof the decision-making process to provide better insight and understanding into\nthe decision-making process of the system. Conclusion: We demonstrate the\neffectiveness and utility of the proposed CLEAR-DR system of enhancing the\ninterpretability of diagnostic grading results for the application of diabetic\nretinopathy grading. Significance: CLEAR-DR can act as a potential powerful\ntool to address the uninterpretability issue of current CAD systems, thus\nimproving their utility to clinicians.\n",
        "published": "2017",
        "authors": [
            "Devinder Kumar",
            "Graham W. Taylor",
            "Alexander Wong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1804.02816v1",
        "title": "A Generation Method of Immunological Memory in Clonal Selection\n  Algorithm by using Restricted Boltzmann Machines",
        "abstract": "  Recently, a high technique of image processing is required to extract the\nimage features in real time. In our research, the tourist subject data are\ncollected from the Mobile Phone based Participatory Sensing (MPPS) system. Each\nrecord consists of image files with GPS, geographic location name, user's\nnumerical evaluation, and comments written in natural language at sightseeing\nspots where a user really visits. In our previous research, the famous\nlandmarks in sightseeing spot can be detected by Clonal Selection Algorithm\nwith Immunological Memory Cell (CSAIM). However, some landmarks was not\ndetected correctly by the previous method because they didn't have enough\namount of information for the feature extraction. In order to improve the\nweakness, we propose the generation method of immunological memory by\nRestricted Boltzmann Machines. To verify the effectiveness of the method, some\nexperiments for classification of the subjective data are executed by using\nmachine learning tools for Deep Learning.\n",
        "published": "2018",
        "authors": [
            "Shin Kamada",
            "Takumi Ichimura"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1805.11778v2",
        "title": "Object Detection using Domain Randomization and Generative Adversarial\n  Refinement of Synthetic Images",
        "abstract": "  In this work, we present an application of domain randomization and\ngenerative adversarial networks (GAN) to train a near real-time object detector\nfor industrial electric parts, entirely in a simulated environment. Large scale\navailability of labelled real world data is typically rare and difficult to\nobtain in many industrial settings. As such here, only a few hundred of\nunlabelled real images are used to train a Cyclic-GAN network, in combination\nwith various degree of domain randomization procedures. We demonstrate that\nthis enables robust translation of synthetic images to the real world domain.\nWe show that a combination of the original synthetic (simulation) and GAN\ntranslated images, when used for training a Mask-RCNN object detection network\nachieves greater than 0.95 mean average precision in detecting and classifying\na collection of industrial electric parts. We evaluate the performance across\ndifferent combinations of training data.\n",
        "published": "2018",
        "authors": [
            "Fernando Camaro Nogues",
            "Andrew Huie",
            "Sakyasingha Dasgupta"
        ]
    }
]