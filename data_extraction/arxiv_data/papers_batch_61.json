[
    {
        "id": "http://arxiv.org/abs/1301.3833v1",
        "title": "Reversible Jump MCMC Simulated Annealing for Neural Networks",
        "abstract": "  We propose a novel reversible jump Markov chain Monte Carlo (MCMC) simulated\nannealing algorithm to optimize radial basis function (RBF) networks. This\nalgorithm enables us to maximize the joint posterior distribution of the\nnetwork parameters and the number of basis functions. It performs a global\nsearch in the joint space of the parameters and number of parameters, thereby\nsurmounting the problem of local minima. We also show that by calibrating a\nBayesian model, we can obtain the classical AIC, BIC and MDL model selection\ncriteria within a penalized likelihood framework. Finally, we show\ntheoretically and empirically that the algorithm converges to the modes of the\nfull posterior distribution in an efficient way.\n",
        "published": "2013",
        "authors": [
            "Christophe Andrieu",
            "Nando de Freitas",
            "Arnaud Doucet"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1406.1231v1",
        "title": "Multi-task Neural Networks for QSAR Predictions",
        "abstract": "  Although artificial neural networks have occasionally been used for\nQuantitative Structure-Activity/Property Relationship (QSAR/QSPR) studies in\nthe past, the literature has of late been dominated by other machine learning\ntechniques such as random forests. However, a variety of new neural net\ntechniques along with successful applications in other domains have renewed\ninterest in network approaches. In this work, inspired by the winning team's\nuse of neural networks in a recent QSAR competition, we used an artificial\nneural network to learn a function that predicts activities of compounds for\nmultiple assays at the same time. We conducted experiments leveraging recent\nmethods for dealing with overfitting in neural networks as well as other tricks\nfrom the neural networks literature. We compared our methods to alternative\nmethods reported to perform well on these tasks and found that our neural net\nmethods provided superior performance.\n",
        "published": "2014",
        "authors": [
            "George E. Dahl",
            "Navdeep Jaitly",
            "Ruslan Salakhutdinov"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1406.2235v1",
        "title": "A Hybrid Latent Variable Neural Network Model for Item Recommendation",
        "abstract": "  Collaborative filtering is used to recommend items to a user without\nrequiring a knowledge of the item itself and tends to outperform other\ntechniques. However, collaborative filtering suffers from the cold-start\nproblem, which occurs when an item has not yet been rated or a user has not\nrated any items. Incorporating additional information, such as item or user\ndescriptions, into collaborative filtering can address the cold-start problem.\nIn this paper, we present a neural network model with latent input variables\n(latent neural network or LNN) as a hybrid collaborative filtering technique\nthat addresses the cold-start problem. LNN outperforms a broad selection of\ncontent-based filters (which make recommendations based on item descriptions)\nand other hybrid approaches while maintaining the accuracy of state-of-the-art\ncollaborative filtering techniques.\n",
        "published": "2014",
        "authors": [
            "Michael R. Smith",
            "Tony Martinez",
            "Michael Gashler"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1406.2989v3",
        "title": "Techniques for Learning Binary Stochastic Feedforward Neural Networks",
        "abstract": "  Stochastic binary hidden units in a multi-layer perceptron (MLP) network give\nat least three potential benefits when compared to deterministic MLP networks.\n(1) They allow to learn one-to-many type of mappings. (2) They can be used in\nstructured prediction problems, where modeling the internal structure of the\noutput is important. (3) Stochasticity has been shown to be an excellent\nregularizer, which makes generalization performance potentially better in\ngeneral. However, training stochastic networks is considerably more difficult.\nWe study training using M samples of hidden activations per input. We show that\nthe case M=1 leads to a fundamentally different behavior where the network\ntries to avoid stochasticity. We propose two new estimators for the training\ngradient and propose benchmark tests for comparing training algorithms. Our\nexperiments confirm that training stochastic networks is difficult and show\nthat the proposed two estimators perform favorably among all the five known\nestimators.\n",
        "published": "2014",
        "authors": [
            "Tapani Raiko",
            "Mathias Berglund",
            "Guillaume Alain",
            "Laurent Dinh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1406.3100v1",
        "title": "Learning ELM network weights using linear discriminant analysis",
        "abstract": "  We present an alternative to the pseudo-inverse method for determining the\nhidden to output weight values for Extreme Learning Machines performing\nclassification tasks. The method is based on linear discriminant analysis and\nprovides Bayes optimal single point estimates for the weight values.\n",
        "published": "2014",
        "authors": [
            "Philip de Chazal",
            "Jonathan Tapson",
            "Andr\u00e9 van Schaik"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1406.7362v1",
        "title": "Exponentially Increasing the Capacity-to-Computation Ratio for\n  Conditional Computation in Deep Learning",
        "abstract": "  Many state-of-the-art results obtained with deep networks are achieved with\nthe largest models that could be trained, and if more computation power was\navailable, we might be able to exploit much larger datasets in order to improve\ngeneralization ability. Whereas in learning algorithms such as decision trees\nthe ratio of capacity (e.g., the number of parameters) to computation is very\nfavorable (up to exponentially more parameters than computation), the ratio is\nessentially 1 for deep neural networks. Conditional computation has been\nproposed as a way to increase the capacity of a deep neural network without\nincreasing the amount of computation required, by activating some parameters\nand computation \"on-demand\", on a per-example basis. In this note, we propose a\nnovel parametrization of weight matrices in neural networks which has the\npotential to increase up to exponentially the ratio of the number of parameters\nto computation. The proposed approach is based on turning on some parameters\n(weight matrices) when specific bit patterns of hidden unit activations are\nobtained. In order to better control for the overfitting that might result, we\npropose a parametrization that is tree-structured, where each node of the tree\ncorresponds to a prefix of a sequence of sign bits, or gating units, associated\nwith hidden units.\n",
        "published": "2014",
        "authors": [
            "Kyunghyun Cho",
            "Yoshua Bengio"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1504.02462v3",
        "title": "A Group Theoretic Perspective on Unsupervised Deep Learning",
        "abstract": "  Why does Deep Learning work? What representations does it capture? How do\nhigher-order representations emerge? We study these questions from the\nperspective of group theory, thereby opening a new approach towards a theory of\nDeep learning.\n  One factor behind the recent resurgence of the subject is a key algorithmic\nstep called {\\em pretraining}: first search for a good generative model for the\ninput samples, and repeat the process one layer at a time. We show deeper\nimplications of this simple principle, by establishing a connection with the\ninterplay of orbits and stabilizers of group actions. Although the neural\nnetworks themselves may not form groups, we show the existence of {\\em shadow}\ngroups whose elements serve as close approximations.\n  Over the shadow groups, the pre-training step, originally introduced as a\nmechanism to better initialize a network, becomes equivalent to a search for\nfeatures with minimal orbits. Intuitively, these features are in a way the {\\em\nsimplest}. Which explains why a deep learning network learns simple features\nfirst. Next, we show how the same principle, when repeated in the deeper\nlayers, can capture higher order representations, and why representation\ncomplexity increases as the layers get deeper.\n",
        "published": "2015",
        "authors": [
            "Arnab Paul",
            "Suresh Venkatasubramanian"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1504.04054v1",
        "title": "A Generative Model for Deep Convolutional Learning",
        "abstract": "  A generative model is developed for deep (multi-layered) convolutional\ndictionary learning. A novel probabilistic pooling operation is integrated into\nthe deep model, yielding efficient bottom-up (pretraining) and top-down\n(refinement) probabilistic learning. Experimental results demonstrate powerful\ncapabilities of the model to learn multi-layer features from images, and\nexcellent classification results are obtained on the MNIST and Caltech 101\ndatasets.\n",
        "published": "2015",
        "authors": [
            "Yunchen Pu",
            "Xin Yuan",
            "Lawrence Carin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1504.08215v1",
        "title": "Lateral Connections in Denoising Autoencoders Support Supervised\n  Learning",
        "abstract": "  We show how a deep denoising autoencoder with lateral connections can be used\nas an auxiliary unsupervised learning task to support supervised learning. The\nproposed model is trained to minimize simultaneously the sum of supervised and\nunsupervised cost functions by back-propagation, avoiding the need for\nlayer-wise pretraining. It improves the state of the art significantly in the\npermutation-invariant MNIST classification task.\n",
        "published": "2015",
        "authors": [
            "Antti Rasmus",
            "Harri Valpola",
            "Tapani Raiko"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1504.08291v5",
        "title": "Deep Neural Networks with Random Gaussian Weights: A Universal\n  Classification Strategy?",
        "abstract": "  Three important properties of a classification machinery are: (i) the system\npreserves the core information of the input data; (ii) the training examples\nconvey information about unseen data; and (iii) the system is able to treat\ndifferently points from different classes. In this work we show that these\nfundamental properties are satisfied by the architecture of deep neural\nnetworks. We formally prove that these networks with random Gaussian weights\nperform a distance-preserving embedding of the data, with a special treatment\nfor in-class and out-of-class data. Similar points at the input of the network\nare likely to have a similar output. The theoretical analysis of deep networks\nhere presented exploits tools used in the compressed sensing and dictionary\nlearning literature, thereby making a formal connection between these important\ntopics. The derived results allow drawing conclusions on the metric learning\nproperties of the network and their relation to its structure, as well as\nproviding bounds on the required size of the training set such that the\ntraining examples would represent faithfully the unseen data. The results are\nvalidated with state-of-the-art trained networks.\n",
        "published": "2015",
        "authors": [
            "Raja Giryes",
            "Guillermo Sapiro",
            "Alex M. Bronstein"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.01952v1",
        "title": "Deep Online Convex Optimization with Gated Games",
        "abstract": "  Methods from convex optimization are widely used as building blocks for deep\nlearning algorithms. However, the reasons for their empirical success are\nunclear, since modern convolutional networks (convnets), incorporating\nrectifier units and max-pooling, are neither smooth nor convex. Standard\nguarantees therefore do not apply. This paper provides the first convergence\nrates for gradient descent on rectifier convnets. The proof utilizes the\nparticular structure of rectifier networks which consists in binary\nactive/inactive gates applied on top of an underlying linear network. The\napproach generalizes to max-pooling, dropout and maxout. In other words, to\nprecisely the neural networks that perform best empirically. The key step is to\nintroduce gated games, an extension of convex games with similar convergence\nproperties that capture the gating function of rectifiers. The main result is\nthat rectifier convnets converge to a critical point at a rate controlled by\nthe gated-regret of the units in the network. Corollaries of the main result\ninclude: (i) a game-theoretic description of the representations learned by a\nneural network; (ii) a logarithmic-regret algorithm for training neural nets;\nand (iii) a formal setting for analyzing conditional computation in neural nets\nthat can be applied to recently developed models of attention.\n",
        "published": "2016",
        "authors": [
            "David Balduzzi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.05198v1",
        "title": "Locally Imposing Function for Generalized Constraint Neural Networks - A\n  Study on Equality Constraints",
        "abstract": "  This work is a further study on the Generalized Constraint Neural Network\n(GCNN) model [1], [2]. Two challenges are encountered in the study, that is, to\nembed any type of prior information and to select its imposing schemes. The\nwork focuses on the second challenge and studies a new constraint imposing\nscheme for equality constraints. A new method called locally imposing function\n(LIF) is proposed to provide a local correction to the GCNN prediction\nfunction, which therefore falls within Locally Imposing Scheme (LIS). In\ncomparison, the conventional Lagrange multiplier method is considered as\nGlobally Imposing Scheme (GIS) because its added constraint term exhibits a\nglobal impact to its objective function. Two advantages are gained from LIS\nover GIS. First, LIS enables constraints to fire locally and explicitly in the\ndomain only where they need on the prediction function. Second, constraints can\nbe implemented within a network setting directly. We attempt to interpret\nseveral constraint methods graphically from a viewpoint of the locality\nprinciple. Numerical examples confirm the advantages of the proposed method. In\nsolving boundary value problems with Dirichlet and Neumann constraints, the\nGCNN model with LIF is possible to achieve an exact satisfaction of the\nconstraints.\n",
        "published": "2016",
        "authors": [
            "Linlin Cao",
            "Ran He",
            "Bao-Gang Hu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.05377v1",
        "title": "Churn analysis using deep convolutional neural networks and autoencoders",
        "abstract": "  Customer temporal behavioral data was represented as images in order to\nperform churn prediction by leveraging deep learning architectures prominent in\nimage classification. Supervised learning was performed on labeled data of over\n6 million customers using deep convolutional neural networks, which achieved an\nAUC of 0.743 on the test dataset using no more than 12 temporal features for\neach customer. Unsupervised learning was conducted using autoencoders to better\nunderstand the reasons for customer churn. Images that maximally activate the\nhidden units of an autoencoder trained with churned customers reveal ample\nopportunities for action to be taken to prevent churn among strong data, no\nvoice users.\n",
        "published": "2016",
        "authors": [
            "Artit Wangperawong",
            "Cyrille Brun",
            "Olav Laudy",
            "Rujikorn Pavasuthipaisit"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.06730v1",
        "title": "Developing an ICU scoring system with interaction terms using a genetic\n  algorithm",
        "abstract": "  ICU mortality scoring systems attempt to predict patient mortality using\npredictive models with various clinical predictors. Examples of such systems\nare APACHE, SAPS and MPM. However, most such scoring systems do not actively\nlook for and include interaction terms, despite physicians intuitively taking\nsuch interactions into account when making a diagnosis. One barrier to\nincluding such terms in predictive models is the difficulty of using most\nvariable selection methods in high-dimensional datasets. A genetic algorithm\nframework for variable selection with logistic regression models is used to\nsearch for two-way interaction terms in a clinical dataset of adult ICU\npatients, with separate models being built for each category of diagnosis upon\nadmittance to the ICU. The models had good discrimination across all\ncategories, with a weighted average AUC of 0.84 (>0.90 for several categories)\nand the genetic algorithm was able to find several significant interaction\nterms, which may be able to provide greater insight into mortality prediction\nfor health practitioners. The GA selected models had improved performance\nagainst stepwise selection and random forest models, and provides greater\nflexibility in terms of variable selection by being able to optimize over any\nmodeler-defined model performance metric instead of a specific variable\nimportance metric.\n",
        "published": "2016",
        "authors": [
            "Chee Chun Gan",
            "Gerard Learmonth"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1604.07796v1",
        "title": "Scale Normalization",
        "abstract": "  One of the difficulties of training deep neural networks is caused by\nimproper scaling between layers. Scaling issues introduce exploding / gradient\nproblems, and have typically been addressed by careful scale-preserving\ninitialization. We investigate the value of preserving scale, or isometry,\nbeyond the initial weights. We propose two methods of maintaing isometry, one\nexact and one stochastic. Preliminary experiments show that for both\ndeterminant and scale-normalization effectively speeds up learning. Results\nsuggest that isometry is important in the beginning of learning, and\nmaintaining it leads to faster learning.\n",
        "published": "2016",
        "authors": [
            "Henry Z. Lo",
            "Kevin Amaral",
            "Wei Ding"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.01977v1",
        "title": "Single-trial P300 Classification using PCA with LDA, QDA and Neural\n  Networks",
        "abstract": "  The P300 event-related potential (ERP), evoked in scalp-recorded\nelectroencephalography (EEG) by external stimuli, has proven to be a reliable\nresponse for controlling a BCI. The P300 component of an event related\npotential is thus widely used in brain-computer interfaces to translate the\nsubjects' intent by mere thoughts into commands to control artificial devices.\nThe main challenge in the classification of P300 trials in\nelectroencephalographic (EEG) data is the low signal-to-noise ratio (SNR) of\nthe P300 response. To overcome the low SNR of individual trials, it is common\npractice to average together many consecutive trials, which effectively\ndiminishes the random noise. Unfortunately, when more repeated trials are\nrequired for applications such as the P300 speller, the communication rate is\ngreatly reduced. This has resulted in a need for better methods to improve\nsingle-trial classification accuracy of P300 response. In this work, we use\nPrincipal Component Analysis (PCA) as a preprocessing method and use Linear\nDiscriminant Analysis (LDA)and neural networks for classification. The results\nshow that a combination of PCA with these methods provided as high as 13\\%\naccuracy gain for single-trial classification while using only 3 to 4 principal\ncomponents.\n",
        "published": "2017",
        "authors": [
            "Nand Sharma"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.01990v1",
        "title": "A Scalable Deep Neural Network Architecture for Multi-Building and\n  Multi-Floor Indoor Localization Based on Wi-Fi Fingerprinting",
        "abstract": "  One of the key technologies for future large-scale location-aware services\ncovering a complex of multi-story buildings --- e.g., a big shopping mall and a\nuniversity campus --- is a scalable indoor localization technique. In this\npaper, we report the current status of our investigation on the use of deep\nneural networks (DNNs) for scalable building/floor classification and\nfloor-level position estimation based on Wi-Fi fingerprinting. Exploiting the\nhierarchical nature of the building/floor estimation and floor-level\ncoordinates estimation of a location, we propose a new DNN architecture\nconsisting of a stacked autoencoder for the reduction of feature space\ndimension and a feed-forward classifier for multi-label classification of\nbuilding/floor/location, on which the multi-building and multi-floor indoor\nlocalization system based on Wi-Fi fingerprinting is built. Experimental\nresults for the performance of building/floor estimation and floor-level\ncoordinates estimation of a given location demonstrate the feasibility of the\nproposed DNN-based indoor localization system, which can provide near\nstate-of-the-art performance using a single DNN, for the implementation with\nlower complexity and energy consumption at mobile devices.\n",
        "published": "2017",
        "authors": [
            "Kyeong Soo Kim",
            "Sanghyuk Lee",
            "Kaizhu Huang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.04118v1",
        "title": "Neural Component Analysis for Fault Detection",
        "abstract": "  Principal component analysis (PCA) is largely adopted for chemical process\nmonitoring and numerous PCA-based systems have been developed to solve various\nfault detection and diagnosis problems. Since PCA-based methods assume that the\nmonitored process is linear, nonlinear PCA models, such as autoencoder models\nand kernel principal component analysis (KPCA), has been proposed and applied\nto nonlinear process monitoring. However, KPCA-based methods need to perform\neigen-decomposition (ED) on the kernel Gram matrix whose dimensions depend on\nthe number of training data. Moreover, prefixed kernel parameters cannot be\nmost effective for different faults which may need different parameters to\nmaximize their respective detection performances. Autoencoder models lack the\nconsideration of orthogonal constraints which is crucial for PCA-based\nalgorithms. To address these problems, this paper proposes a novel nonlinear\nmethod, called neural component analysis (NCA), which intends to train a\nfeedforward neural work with orthogonal constraints such as those used in PCA.\nNCA can adaptively learn its parameters through backpropagation and the\ndimensionality of the nonlinear features has no relationship with the number of\ntraining samples. Extensive experimental results on the Tennessee Eastman (TE)\nbenchmark process show the superiority of NCA in terms of missed detection rate\n(MDR) and false alarm rate (FAR). The source code of NCA can be found in\nhttps://github.com/haitaozhao/Neural-Component-Analysis.git.\n",
        "published": "2017",
        "authors": [
            "Haitao Zhao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.04195v1",
        "title": "Concept Formation and Dynamics of Repeated Inference in Deep Generative\n  Models",
        "abstract": "  Deep generative models are reported to be useful in broad applications\nincluding image generation. Repeated inference between data space and latent\nspace in these models can denoise cluttered images and improve the quality of\ninferred results. However, previous studies only qualitatively evaluated image\noutputs in data space, and the mechanism behind the inference has not been\ninvestigated. The purpose of the current study is to numerically analyze\nchanges in activity patterns of neurons in the latent space of a deep\ngenerative model called a \"variational auto-encoder\" (VAE). What kinds of\ninference dynamics the VAE demonstrates when noise is added to the input data\nare identified. The VAE embeds a dataset with clear cluster structures in the\nlatent space and the center of each cluster of multiple correlated data points\n(memories) is referred as the concept. Our study demonstrated that transient\ndynamics of inference first approaches a concept, and then moves close to a\nmemory. Moreover, the VAE revealed that the inference dynamics approaches a\nmore abstract concept to the extent that the uncertainty of input data\nincreases due to noise. It was demonstrated that by increasing the number of\nthe latent variables, the trend of the inference dynamics to approach a concept\ncan be enhanced, and the generalization ability of the VAE can be improved.\n",
        "published": "2017",
        "authors": [
            "Yoshihiro Nagano",
            "Ryo Karakida",
            "Masato Okada"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.06132v1",
        "title": "Dynamic Boltzmann Machines for Second Order Moments and Generalized\n  Gaussian Distributions",
        "abstract": "  Dynamic Boltzmann Machine (DyBM) has been shown highly efficient to predict\ntime-series data. Gaussian DyBM is a DyBM that assumes the predicted data is\ngenerated by a Gaussian distribution whose first-order moment (mean)\ndynamically changes over time but its second-order moment (variance) is fixed.\nHowever, in many financial applications, the assumption is quite limiting in\ntwo aspects. First, even when the data follows a Gaussian distribution, its\nvariance may change over time. Such variance is also related to important\ntemporal economic indicators such as the market volatility. Second, financial\ntime-series data often requires learning datasets generated by the generalized\nGaussian distribution with an additional shape parameter that is important to\napproximate heavy-tailed distributions. Addressing those aspects, we show how\nto extend DyBM that results in significant performance improvement in\npredicting financial time-series data.\n",
        "published": "2017",
        "authors": [
            "Rudy Raymond",
            "Takayuki Osogami",
            "Sakyasingha Dasgupta"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.06541v5",
        "title": "Size-Independent Sample Complexity of Neural Networks",
        "abstract": "  We study the sample complexity of learning neural networks, by providing new\nbounds on their Rademacher complexity assuming norm constraints on the\nparameter matrix of each layer. Compared to previous work, these complexity\nbounds have improved dependence on the network depth, and under some additional\nassumptions, are fully independent of the network size (both depth and width).\nThese results are derived using some novel techniques, which may be of\nindependent interest.\n",
        "published": "2017",
        "authors": [
            "Noah Golowich",
            "Alexander Rakhlin",
            "Ohad Shamir"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.09926v3",
        "title": "Rapid Adaptation with Conditionally Shifted Neurons",
        "abstract": "  We describe a mechanism by which artificial neural networks can learn rapid\nadaptation - the ability to adapt on the fly, with little data, to new tasks -\nthat we call conditionally shifted neurons. We apply this mechanism in the\nframework of metalearning, where the aim is to replicate some of the\nflexibility of human learning in machines. Conditionally shifted neurons modify\ntheir activation values with task-specific shifts retrieved from a memory\nmodule, which is populated rapidly based on limited task experience. On\nmetalearning benchmarks from the vision and language domains, models augmented\nwith conditionally shifted neurons achieve state-of-the-art results.\n",
        "published": "2017",
        "authors": [
            "Tsendsuren Munkhdalai",
            "Xingdi Yuan",
            "Soroush Mehri",
            "Adam Trischler"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1712.10062v1",
        "title": "Multi-timescale memory dynamics in a reinforcement learning network with\n  attention-gated memory",
        "abstract": "  Learning and memory are intertwined in our brain and their relationship is at\nthe core of several recent neural network models. In particular, the\nAttention-Gated MEmory Tagging model (AuGMEnT) is a reinforcement learning\nnetwork with an emphasis on biological plausibility of memory dynamics and\nlearning. We find that the AuGMEnT network does not solve some hierarchical\ntasks, where higher-level stimuli have to be maintained over a long time, while\nlower-level stimuli need to be remembered and forgotten over a shorter\ntimescale. To overcome this limitation, we introduce hybrid AuGMEnT, with leaky\nor short-timescale and non-leaky or long-timescale units in memory, that allow\nto exchange lower-level information while maintaining higher-level one, thus\nsolving both hierarchical and distractor tasks.\n",
        "published": "2017",
        "authors": [
            "Marco Martinolli",
            "Wulfram Gerstner",
            "Aditya Gilra"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.03008v3",
        "title": "Training for Faster Adversarial Robustness Verification via Inducing\n  ReLU Stability",
        "abstract": "  We explore the concept of co-design in the context of neural network\nverification. Specifically, we aim to train deep neural networks that not only\nare robust to adversarial perturbations but also whose robustness can be\nverified more easily. To this end, we identify two properties of network models\n- weight sparsity and so-called ReLU stability - that turn out to significantly\nimpact the complexity of the corresponding verification task. We demonstrate\nthat improving weight sparsity alone already enables us to turn computationally\nintractable verification problems into tractable ones. Then, improving ReLU\nstability leads to an additional 4-13x speedup in verification times. An\nimportant feature of our methodology is its \"universality,\" in the sense that\nit can be used with a broad range of training procedures and verification\napproaches.\n",
        "published": "2018",
        "authors": [
            "Kai Y. Xiao",
            "Vincent Tjeng",
            "Nur Muhammad Shafiullah",
            "Aleksander Madry"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.04461v1",
        "title": "DeepProteomics: Protein family classification using Shallow and Deep\n  Networks",
        "abstract": "  The knowledge regarding the function of proteins is necessary as it gives a\nclear picture of biological processes. Nevertheless, there are many protein\nsequences found and added to the databases but lacks functional annotation. The\nlaboratory experiments take a considerable amount of time for annotation of the\nsequences. This arises the need to use computational techniques to classify\nproteins based on their functions. In our work, we have collected the data from\nSwiss-Prot containing 40433 proteins which is grouped into 30 families. We pass\nit to recurrent neural network(RNN), long short term memory(LSTM) and gated\nrecurrent unit(GRU) model and compare it by applying trigram with deep neural\nnetwork and shallow neural network on the same dataset. Through this approach,\nwe could achieve maximum of around 78% accuracy for the classification of\nprotein families.\n",
        "published": "2018",
        "authors": [
            "Anu Vazhayil",
            "Vinayakumar R",
            "Soman KP"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.06463v1",
        "title": "Self Configuration in Machine Learning",
        "abstract": "  In this paper we first present a class of algorithms for training multi-level\nneural networks with a quadratic cost function one layer at a time starting\nfrom the input layer. The algorithm is based on the fact that for any layer to\nbe trained, the effect of a direct connection to an optimized linear output\nlayer can be computed without the connection being made. Thus, starting from\nthe input layer, we can train each layer in succession in isolation from the\nother layers. Once trained, the weights are kept fixed and the outputs of the\ntrained layer then serve as the inputs to the next layer to be trained. The\nresult is a very fast algorithm. The simplicity of this training arrangement\nallows the activation function and step size in weight adjustment to be\nadaptive and self-adjusting. Furthermore, the stability of the training process\nallows relatively large steps to be taken and thereby achieving in even greater\nspeeds. Finally, in our context configuring the network means determining the\nnumber of outputs for each layer. By decomposing the overall cost function into\nseparate components related to approximation and estimation, we obtain an\noptimization formula for determining the number of outputs for each layer. With\nthe ability to self-configure and set parameters, we now have more than a fast\ntraining algorithm, but the ability to build automatically a fully trained deep\nneural network starting with nothing more than data.\n",
        "published": "2018",
        "authors": [
            "Eugene Wong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.08085v1",
        "title": "Short-term Cognitive Networks, Flexible Reasoning and Nonsynaptic\n  Learning",
        "abstract": "  While the machine learning literature dedicated to fully automated reasoning\nalgorithms is abundant, the number of methods enabling the inference process on\nthe basis of previously defined knowledge structures is scanter. Fuzzy\nCognitive Maps (FCMs) are neural networks that can be exploited towards this\ngoal because of their flexibility to handle external knowledge. However, FCMs\nsuffer from a number of issues that range from the limited prediction horizon\nto the absence of theoretically sound learning algorithms able to produce\naccurate predictions. In this paper, we propose a neural network system named\nShort-term Cognitive Networks that tackle some of these limitations. In our\nmodel weights are not constricted and may have a causal nature or not. As a\nsecond contribution, we present a nonsynaptic learning algorithm to improve the\nnetwork performance without modifying the previously defined weights. Moreover,\nwe derive a stop condition to prevent the learning algorithm from iterating\nwithout decreasing the simulation error.\n",
        "published": "2018",
        "authors": [
            "Gonzalo N\u00e1poles",
            "Frank Vanhoenshoven",
            "Koen Vanhoof"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.08587v4",
        "title": "Exponential Convergence Time of Gradient Descent for One-Dimensional\n  Deep Linear Neural Networks",
        "abstract": "  We study the dynamics of gradient descent on objective functions of the form\n$f(\\prod_{i=1}^{k} w_i)$ (with respect to scalar parameters $w_1,\\ldots,w_k$),\nwhich arise in the context of training depth-$k$ linear neural networks. We\nprove that for standard random initializations, and under mild assumptions on\n$f$, the number of iterations required for convergence scales exponentially\nwith the depth $k$. We also show empirically that this phenomenon can occur in\nhigher dimensions, where each $w_i$ is a matrix. This highlights a potential\nobstacle in understanding the convergence of gradient-based methods for deep\nlinear neural networks, where $k$ is large.\n",
        "published": "2018",
        "authors": [
            "Ohad Shamir"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.08660v1",
        "title": "Data-Driven Design: Exploring new Structural Forms using Machine\n  Learning and Graphic Statics",
        "abstract": "  The aim of this research is to introduce a novel structural design process\nthat allows architects and engineers to extend their typical design space\nhorizon and thereby promoting the idea of creativity in structural design. The\ntheoretical base of this work builds on the combination of structural\nform-finding and state-of-the-art machine learning algorithms. In the first\nstep of the process, Combinatorial Equilibrium Modelling (CEM) is used to\ngenerate a large variety of spatial networks in equilibrium for given input\nparameters. In the second step, these networks are clustered and represented in\na form-map through the implementation of a Self Organizing Map (SOM) algorithm.\nIn the third step, the solution space is interpreted with the help of a Uniform\nManifold Approximation and Projection algorithm (UMAP). This allows gaining\nimportant insights in the structure of the solution space. A specific case\nstudy is used to illustrate how the infinite equilibrium states of a given\ntopology can be defined and represented by clusters. Furthermore, three\nclasses, related to the non-linear interaction between the input parameters and\nthe form space, are verified and a statement about the entire manifold of the\nsolution space of the case study is made. To conclude, this work presents an\ninnovative approach on how the manifold of a solution space can be grasped with\na minimum amount of data and how to operate within the manifold in order to\nincrease the diversity of solutions.\n",
        "published": "2018",
        "authors": [
            "Lukas Fuhrimann",
            "Vahid Moosavi",
            "Patrick Ole Ohlbrock",
            "Pierluigi Dacunto"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.09087v2",
        "title": "Implicit Maximum Likelihood Estimation",
        "abstract": "  Implicit probabilistic models are models defined naturally in terms of a\nsampling procedure and often induces a likelihood function that cannot be\nexpressed explicitly. We develop a simple method for estimating parameters in\nimplicit models that does not require knowledge of the form of the likelihood\nfunction or any derived quantities, but can be shown to be equivalent to\nmaximizing likelihood under some conditions. Our result holds in the\nnon-asymptotic parametric setting, where both the capacity of the model and the\nnumber of data examples are finite. We also demonstrate encouraging\nexperimental results.\n",
        "published": "2018",
        "authors": [
            "Ke Li",
            "Jitendra Malik"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.09096v1",
        "title": "Text Summarization as Tree Transduction by Top-Down TreeLSTM",
        "abstract": "  Extractive compression is a challenging natural language processing problem.\nThis work contributes by formulating neural extractive compression as a parse\ntree transduction problem, rather than a sequence transduction task. Motivated\nby this, we introduce a deep neural model for learning\nstructure-to-substructure tree transductions by extending the standard Long\nShort-Term Memory, considering the parent-child relationships in the structural\nrecursion. The proposed model can achieve state of the art performance on\nsentence compression benchmarks, both in terms of accuracy and compression\nrate.\n",
        "published": "2018",
        "authors": [
            "Davide Bacciu",
            "Antonio Bruno"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.09260v1",
        "title": "Low Precision Policy Distillation with Application to Low-Power,\n  Real-time Sensation-Cognition-Action Loop with Neuromorphic Computing",
        "abstract": "  Low precision networks in the reinforcement learning (RL) setting are\nrelatively unexplored because of the limitations of binary activations for\nfunction approximation. Here, in the discrete action ATARI domain, we\ndemonstrate, for the first time, that low precision policy distillation from a\nhigh precision network provides a principled, practical way to train an RL\nagent. As an application, on 10 different ATARI games, we demonstrate real-time\nend-to-end game playing on low-power neuromorphic hardware by converting a\nsequence of game frames into discrete actions.\n",
        "published": "2018",
        "authors": [
            "Jeffrey L Mckinstry",
            "Davis R. Barch",
            "Deepika Bablani",
            "Michael V. Debole",
            "Steven K. Esser",
            "Jeffrey A. Kusnitz",
            "John V. Arthur",
            "Dharmendra S. Modha"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.09262v1",
        "title": "Neural Networks with Structural Resistance to Adversarial Attacks",
        "abstract": "  In adversarial attacks to machine-learning classifiers, small perturbations\nare added to input that is correctly classified. The perturbations yield\nadversarial examples, which are virtually indistinguishable from the\nunperturbed input, and yet are misclassified. In standard neural networks used\nfor deep learning, attackers can craft adversarial examples from most input to\ncause a misclassification of their choice.\n  We introduce a new type of network units, called RBFI units, whose non-linear\nstructure makes them inherently resistant to adversarial attacks. On\npermutation-invariant MNIST, in absence of adversarial attacks, networks using\nRBFI units match the performance of networks using sigmoid units, and are\nslightly below the accuracy of networks with ReLU units. When subjected to\nadversarial attacks, networks with RBFI units retain accuracies above 90% for\nattacks that degrade the accuracy of networks with ReLU or sigmoid units to\nbelow 2%. RBFI networks trained with regular input are superior in their\nresistance to adversarial attacks even to ReLU and sigmoid networks trained\nwith the help of adversarial examples.\n  The non-linear structure of RBFI units makes them difficult to train using\nstandard gradient descent. We show that networks of RBFI units can be\nefficiently trained to high accuracies using pseudogradients, computed using\nfunctions especially crafted to facilitate learning instead of their true\nderivatives. We show that the use of pseudogradients makes training deep RBFI\nnetworks practical, and we compare several structural alternatives of RBFI\nnetworks for their accuracy.\n",
        "published": "2018",
        "authors": [
            "Luca de Alfaro"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.09533v3",
        "title": "An Adaptive Locally Connected Neuron Model: Focusing Neuron",
        "abstract": "  This paper presents a new artificial neuron model capable of learning its\nreceptive field in the topological domain of inputs. The model provides\nadaptive and differentiable local connectivity (plasticity) applicable to any\ndomain. It requires no other tool than the backpropagation algorithm to learn\nits parameters which control the receptive field locations and apertures. This\nresearch explores whether this ability makes the neuron focus on informative\ninputs and yields any advantage over fully connected neurons. The experiments\ninclude tests of focusing neuron networks of one or two hidden layers on\nsynthetic and well-known image recognition data sets. The results demonstrated\nthat the focusing neurons can move their receptive fields towards more\ninformative inputs. In the simple two-hidden layer networks, the focusing\nlayers outperformed the dense layers in the classification of the 2D spatial\ndata sets. Moreover, the focusing networks performed better than the dense\nnetworks even when 70$\\%$ of the weights were pruned. The tests on\nconvolutional networks revealed that using focusing layers instead of dense\nlayers for the classification of convolutional features may work better in some\ndata sets.\n",
        "published": "2018",
        "authors": [
            "F. Boray Tek"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.10847v1",
        "title": "Using Multi-task and Transfer Learning to Solve Working Memory Tasks",
        "abstract": "  We propose a new architecture called Memory-Augmented Encoder-Solver (MAES)\nthat enables transfer learning to solve complex working memory tasks adapted\nfrom cognitive psychology. It uses dual recurrent neural network controllers,\ninside the encoder and solver, respectively, that interface with a shared\nmemory module and is completely differentiable. We study different types of\nencoders in a systematic manner and demonstrate a unique advantage of\nmulti-task learning in obtaining the best possible encoder. We show by\nextensive experimentation that the trained MAES models achieve task-size\ngeneralization, i.e., they are capable of handling sequential inputs 50 times\nlonger than seen during training, with appropriately large memory modules. We\ndemonstrate that the performance achieved by MAES far outperforms existing and\nwell-known models such as the LSTM, NTM and DNC on the entire suite of tasks.\n",
        "published": "2018",
        "authors": [
            "T. S. Jayram",
            "Tomasz Kornuta",
            "Ryan L. McAvoy",
            "Ahmet S. Ozcan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1809.11087v1",
        "title": "Learning to Remember, Forget and Ignore using Attention Control in\n  Memory",
        "abstract": "  Typical neural networks with external memory do not effectively separate\ncapacity for episodic and working memory as is required for reasoning in\nhumans. Applying knowledge gained from psychological studies, we designed a new\nmodel called Differentiable Working Memory (DWM) in order to specifically\nemulate human working memory. As it shows the same functional characteristics\nas working memory, it robustly learns psychology inspired tasks and converges\nfaster than comparable state-of-the-art models. Moreover, the DWM model\nsuccessfully generalizes to sequences two orders of magnitude longer than the\nones used in training. Our in-depth analysis shows that the behavior of DWM is\ninterpretable and that it learns to have fine control over memory, allowing it\nto retain, ignore or forget information based on its relevance.\n",
        "published": "2018",
        "authors": [
            "T. S. Jayram",
            "Younes Bouhadjar",
            "Ryan L. McAvoy",
            "Tomasz Kornuta",
            "Alexis Asseman",
            "Kamil Rocki",
            "Ahmet S. Ozcan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.02637v4",
        "title": "MMA Training: Direct Input Space Margin Maximization through Adversarial\n  Training",
        "abstract": "  We study adversarial robustness of neural networks from a margin maximization\nperspective, where margins are defined as the distances from inputs to a\nclassifier's decision boundary. Our study shows that maximizing margins can be\nachieved by minimizing the adversarial loss on the decision boundary at the\n\"shortest successful perturbation\", demonstrating a close connection between\nadversarial losses and the margins. We propose Max-Margin Adversarial (MMA)\ntraining to directly maximize the margins to achieve adversarial robustness.\nInstead of adversarial training with a fixed $\\epsilon$, MMA offers an\nimprovement by enabling adaptive selection of the \"correct\" $\\epsilon$ as the\nmargin individually for each datapoint. In addition, we rigorously analyze\nadversarial training with the perspective of margin maximization, and provide\nan alternative interpretation for adversarial training, maximizing either a\nlower or an upper bound of the margins. Our experiments empirically confirm our\ntheory and demonstrate MMA training's efficacy on the MNIST and CIFAR10\ndatasets w.r.t. $\\ell_\\infty$ and $\\ell_2$ robustness. Code and models are\navailable at https://github.com/BorealisAI/mma_training.\n",
        "published": "2018",
        "authors": [
            "Gavin Weiguang Ding",
            "Yash Sharma",
            "Kry Yik Chau Lui",
            "Ruitong Huang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.03365v1",
        "title": "Neuromodulated Learning in Deep Neural Networks",
        "abstract": "  In the brain, learning signals change over time and synaptic location, and\nare applied based on the learning history at the synapse, in the complex\nprocess of neuromodulation. Learning in artificial neural networks, on the\nother hand, is shaped by hyper-parameters set before learning starts, which\nremain static throughout learning, and which are uniform for the entire\nnetwork. In this work, we propose a method of deep artificial neuromodulation\nwhich applies the concepts of biological neuromodulation to stochastic gradient\ndescent. Evolved neuromodulatory dynamics modify learning parameters at each\nlayer in a deep neural network over the course of the network's training. We\nshow that the same neuromodulatory dynamics can be applied to different models\nand can scale to new problems not encountered during evolution. Finally, we\nexamine the evolved neuromodulation, showing that evolution found dynamic,\nlocation-specific learning strategies.\n",
        "published": "2018",
        "authors": [
            "Dennis G Wilson",
            "Sylvain Cussat-Blanc",
            "Herv\u00e9 Luga",
            "Kyle Harrington"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.04948v3",
        "title": "A Style-Based Generator Architecture for Generative Adversarial Networks",
        "abstract": "  We propose an alternative generator architecture for generative adversarial\nnetworks, borrowing from style transfer literature. The new architecture leads\nto an automatically learned, unsupervised separation of high-level attributes\n(e.g., pose and identity when trained on human faces) and stochastic variation\nin the generated images (e.g., freckles, hair), and it enables intuitive,\nscale-specific control of the synthesis. The new generator improves the\nstate-of-the-art in terms of traditional distribution quality metrics, leads to\ndemonstrably better interpolation properties, and also better disentangles the\nlatent factors of variation. To quantify interpolation quality and\ndisentanglement, we propose two new, automated methods that are applicable to\nany generator architecture. Finally, we introduce a new, highly varied and\nhigh-quality dataset of human faces.\n",
        "published": "2018",
        "authors": [
            "Tero Karras",
            "Samuli Laine",
            "Timo Aila"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.04998v2",
        "title": "Neural Processes Mixed-Effect Models for Deep Normative Modeling of\n  Clinical Neuroimaging Data",
        "abstract": "  Normative modeling has recently been introduced as a promising approach for\nmodeling variation of neuroimaging measures across individuals in order to\nderive biomarkers of psychiatric disorders. Current implementations rely on\nGaussian process regression, which provides coherent estimates of uncertainty\nneeded for the method but also suffers from drawbacks including poor scaling to\nlarge datasets and a reliance on fixed parametric kernels. In this paper, we\npropose a deep normative modeling framework based on neural processes (NPs) to\nsolve these problems. To achieve this, we define a stochastic process\nformulation for mixed-effect models and show how NPs can be adopted for\nspatially structured mixed-effect modeling of neuroimaging data. This enables\nus to learn optimal feature representations and covariance structure for the\nrandom-effect and noise via global latent variables. In this scheme, predictive\nuncertainty can be approximated by sampling from the distribution of these\nglobal latent variables. On a publicly available clinical fMRI dataset, we\ncompare the novelty detection performance of multivariate normative models\nestimated by the proposed NP approach to a baseline multi-task Gaussian process\nregression approach and show substantial improvements for certain diagnostic\nproblems.\n",
        "published": "2018",
        "authors": [
            "Seyed Mostafa Kia",
            "Andre F. Marquand"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.06247v1",
        "title": "Flatten-T Swish: a thresholded ReLU-Swish-like activation function for\n  deep learning",
        "abstract": "  Activation functions are essential for deep learning methods to learn and\nperform complex tasks such as image classification. Rectified Linear Unit\n(ReLU) has been widely used and become the default activation function across\nthe deep learning community since 2012. Although ReLU has been popular,\nhowever, the hard zero property of the ReLU has heavily hindered the negative\nvalues from propagating through the network. Consequently, the deep neural\nnetwork has not been benefited from the negative representations. In this work,\nan activation function called Flatten-T Swish (FTS) that leverage the benefit\nof the negative values is proposed. To verify its performance, this study\nevaluates FTS with ReLU and several recent activation functions. Each\nactivation function is trained using MNIST dataset on five different deep fully\nconnected neural networks (DFNNs) with depth vary from five to eight layers.\nFor a fair evaluation, all DFNNs are using the same configuration settings.\nBased on the experimental results, FTS with a threshold value, T=-0.20 has the\nbest overall performance. As compared with ReLU, FTS (T=-0.20) improves MNIST\nclassification accuracy by 0.13%, 0.70%, 0.67%, 1.07% and 1.15% on wider 5\nlayers, slimmer 5 layers, 6 layers, 7 layers and 8 layers DFNNs respectively.\nApart from this, the study also noticed that FTS converges twice as fast as\nReLU. Although there are other existing activation functions are also\nevaluated, this study elects ReLU as the baseline activation function.\n",
        "published": "2018",
        "authors": [
            "Hock Hung Chieng",
            "Noorhaniza Wahid",
            "Pauline Ong",
            "Sai Raj Kishore Perla"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.06303v2",
        "title": "Multi-Tasking Genetic Algorithm (MTGA) for Fuzzy System Optimization",
        "abstract": "  Multi-task learning uses auxiliary data or knowledge from relevant tasks to\nfacilitate the learning in a new task. Multi-task optimization applies\nmulti-task learning to optimization to study how to effectively and efficiently\ntackle multiple optimization problems simultaneously. Evolutionary\nmulti-tasking, or multi-factorial optimization, is an emerging subfield of\nmulti-task optimization, which integrates evolutionary computation and\nmulti-task learning. This paper proposes a novel and easy-to-implement\nmulti-tasking genetic algorithm (MTGA), which copes well with significantly\ndifferent optimization tasks by estimating and using the bias among them.\nComparative studies with eight state-of-the-art single- and multi-task\napproaches in the literature on nine benchmarks demonstrated that on average\nthe MTGA outperformed all of them, and had lower computational cost than six of\nthem. Based on the MTGA, a simultaneous optimization strategy for fuzzy system\ndesign is also proposed. Experiments on simultaneous optimization of type-1 and\ninterval type-2 fuzzy logic controllers for couple-tank water level control\ndemonstrated that the MTGA can find better fuzzy logic controllers than other\napproaches.\n",
        "published": "2018",
        "authors": [
            "Dongrui Wu",
            "Xianfeng Tan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.06488v2",
        "title": "Feedback alignment in deep convolutional networks",
        "abstract": "  Ongoing studies have identified similarities between neural representations\nin biological networks and in deep artificial neural networks. This has led to\nrenewed interest in developing analogies between the backpropagation learning\nalgorithm used to train artificial networks and the synaptic plasticity rules\noperative in the brain. These efforts are challenged by biologically\nimplausible features of backpropagation, one of which is a reliance on\nsymmetric forward and backward synaptic weights. A number of methods have been\nproposed that do not rely on weight symmetry but, thus far, these have failed\nto scale to deep convolutional networks and complex data. We identify principal\nobstacles to the scalability of such algorithms and introduce several\ntechniques to mitigate them. We demonstrate that a modification of the feedback\nalignment method that enforces a weaker form of weight symmetry, one that\nrequires agreement of weight sign but not magnitude, can achieve performance\ncompetitive with backpropagation. Our results complement those of Bartunov et\nal. (2018) and Xiao et al. (2018b) and suggest that mechanisms that promote\nalignment of feedforward and feedback weights are critical for learning in deep\nnetworks.\n",
        "published": "2018",
        "authors": [
            "Theodore H. Moskovitz",
            "Ashok Litwin-Kumar",
            "L. F. Abbott"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.07520v2",
        "title": "Entropy-Constrained Training of Deep Neural Networks",
        "abstract": "  We propose a general framework for neural network compression that is\nmotivated by the Minimum Description Length (MDL) principle. For that we first\nderive an expression for the entropy of a neural network, which measures its\ncomplexity explicitly in terms of its bit-size. Then, we formalize the problem\nof neural network compression as an entropy-constrained optimization objective.\nThis objective generalizes many of the compression techniques proposed in the\nliterature, in that pruning or reducing the cardinality of the weight elements\nof the network can be seen special cases of entropy-minimization techniques.\nFurthermore, we derive a continuous relaxation of the objective, which allows\nus to minimize it using gradient based optimization techniques. Finally, we\nshow that we can reach state-of-the-art compression results on different\nnetwork architectures and data sets, e.g. achieving x71 compression gains on a\nVGG-like architecture.\n",
        "published": "2018",
        "authors": [
            "Simon Wiedemann",
            "Arturo Marban",
            "Klaus-Robert M\u00fcller",
            "Wojciech Samek"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.07965v2",
        "title": "Deep learning with asymmetric connections and Hebbian updates",
        "abstract": "  We show that deep networks can be trained using Hebbian updates yielding\nsimilar performance to ordinary back-propagation on challenging image datasets.\nTo overcome the unrealistic symmetry in connections between layers, implicit in\nback-propagation, the feedback weights are separate from the feedforward\nweights. The feedback weights are also updated with a local rule, the same as\nthe feedforward weights - a weight is updated solely based on the product of\nactivity of the units it connects. With fixed feedback weights as proposed in\nLillicrap et. al (2016) performance degrades quickly as the depth of the\nnetwork increases. If the feedforward and feedback weights are initialized with\nthe same values, as proposed in Zipser and Rumelhart (1990), they remain the\nsame throughout training thus precisely implementing back-propagation. We show\nthat even when the weights are initialized differently and at random, and the\nalgorithm is no longer performing back-propagation, performance is comparable\non challenging datasets. We also propose a cost function whose derivative can\nbe represented as a local Hebbian update on the last layer. Convolutional\nlayers are updated with tied weights across space, which is not biologically\nplausible. We show that similar performance is achieved with untied layers,\nalso known as locally connected layers, corresponding to the connectivity\nimplied by the convolutional layers, but where weights are untied and updated\nseparately. In the linear case we show theoretically that the convergence of\nthe error to zero is accelerated by the update of the feedback weights.\n",
        "published": "2018",
        "authors": [
            "Yali Amit"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.09113v3",
        "title": "Introducing Neuromodulation in Deep Neural Networks to Learn Adaptive\n  Behaviours",
        "abstract": "  Animals excel at adapting their intentions, attention, and actions to the\nenvironment, making them remarkably efficient at interacting with a rich,\nunpredictable and ever-changing external world, a property that intelligent\nmachines currently lack. Such an adaptation property relies heavily on cellular\nneuromodulation, the biological mechanism that dynamically controls intrinsic\nproperties of neurons and their response to external stimuli in a\ncontext-dependent manner. In this paper, we take inspiration from cellular\nneuromodulation to construct a new deep neural network architecture that is\nspecifically designed to learn adaptive behaviours. The network adaptation\ncapabilities are tested on navigation benchmarks in a meta-reinforcement\nlearning context and compared with state-of-the-art approaches. Results show\nthat neuromodulation is capable of adapting an agent to different tasks and\nthat neuromodulation-based approaches provide a promising way of improving\nadaptation of artificial systems.\n",
        "published": "2018",
        "authors": [
            "Nicolas Vecoven",
            "Damien Ernst",
            "Antoine Wehenkel",
            "Guillaume Drion"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.10539v3",
        "title": "Uncertainty Autoencoders: Learning Compressed Representations via\n  Variational Information Maximization",
        "abstract": "  Compressed sensing techniques enable efficient acquisition and recovery of\nsparse, high-dimensional data signals via low-dimensional projections. In this\nwork, we propose Uncertainty Autoencoders, a learning framework for\nunsupervised representation learning inspired by compressed sensing. We treat\nthe low-dimensional projections as noisy latent representations of an\nautoencoder and directly learn both the acquisition (i.e., encoding) and\namortized recovery (i.e., decoding) procedures. Our learning objective\noptimizes for a tractable variational lower bound to the mutual information\nbetween the datapoints and the latent representations. We show how our\nframework provides a unified treatment to several lines of research in\ndimensionality reduction, compressed sensing, and generative modeling.\nEmpirically, we demonstrate a 32% improvement on average over competing\napproaches for the task of statistical compressed sensing of high-dimensional\ndatasets.\n",
        "published": "2018",
        "authors": [
            "Aditya Grover",
            "Stefano Ermon"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1812.11527v2",
        "title": "Comparison between DeepESNs and gated RNNs on multivariate time-series\n  prediction",
        "abstract": "  We propose an experimental comparison between Deep Echo State Networks\n(DeepESNs) and gated Recurrent Neural Networks (RNNs) on multivariate\ntime-series prediction tasks. In particular, we compare reservoir and\nfully-trained RNNs able to represent signals featured by multiple time-scales\ndynamics. The analysis is performed in terms of efficiency and prediction\naccuracy on 4 polyphonic music tasks. Our results show that DeepESN is able to\noutperform ESN in terms of prediction accuracy and efficiency. Whereas, between\nfully-trained approaches, Gated Recurrent Units (GRU) outperforms Long\nShort-Term Memory (LSTM) and simple RNN models in most cases. Overall, DeepESN\nturned out to be extremely more efficient than others RNN approaches and the\nbest solution in terms of prediction accuracy on 3 out of 4 tasks.\n",
        "published": "2018",
        "authors": [
            "Claudio Gallicchio",
            "Alessio Micheli",
            "Luca Pedrelli"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.01341v1",
        "title": "Using stigmergy as a computational memory in the design of recurrent\n  neural networks",
        "abstract": "  In this paper, a novel architecture of Recurrent Neural Network (RNN) is\ndesigned and experimented. The proposed RNN adopts a computational memory based\non the concept of stigmergy. The basic principle of a Stigmergic Memory (SM) is\nthat the activity of deposit/removal of a quantity in the SM stimulates the\nnext activities of deposit/removal. Accordingly, subsequent SM activities tend\nto reinforce/weaken each other, generating a coherent coordination between the\nSM activities and the input temporal stimulus. We show that, in a problem of\nsupervised classification, the SM encodes the temporal input in an emergent\nrepresentational model, by coordinating the deposit, removal and classification\nactivities. This study lays down a basic framework for the derivation of a\nSM-RNN. A formal ontology of SM is discussed, and the SM-RNN architecture is\ndetailed. To appreciate the computational power of an SM-RNN, comparative NNs\nhave been selected and trained to solve the MNIST handwritten digits\nrecognition benchmark in its two variants: spatial (sequences of bitmap rows)\nand temporal (sequences of pen strokes).\n",
        "published": "2019",
        "authors": [
            "Federico A. Galatolo",
            "Mario G. C. A. Cimino",
            "Gigliola Vaglini"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.01886v1",
        "title": "Genetic-Gated Networks for Deep Reinforcement",
        "abstract": "  We introduce the Genetic-Gated Networks (G2Ns), simple neural networks that\ncombine a gate vector composed of binary genetic genes in the hidden layer(s)\nof networks. Our method can take both advantages of gradient-free optimization\nand gradient-based optimization methods, of which the former is effective for\nproblems with multiple local minima, while the latter can quickly find local\nminima. In addition, multiple chromosomes can define different models, making\nit easy to construct multiple models and can be effectively applied to problems\nthat require multiple models. We show that this G2N can be applied to typical\nreinforcement learning algorithms to achieve a large improvement in sample\nefficiency and performance.\n",
        "published": "2018",
        "authors": [
            "Simyung Chang",
            "John Yang",
            "Jaeseok Choi",
            "Nojun Kwak"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.01895v1",
        "title": "Evolutionary Construction of Convolutional Neural Networks",
        "abstract": "  Neuro-Evolution is a field of study that has recently gained significantly\nincreased traction in the deep learning community. It combines deep neural\nnetworks and evolutionary algorithms to improve and/or automate the\nconstruction of neural networks. Recent Neuro-Evolution approaches have shown\npromising results, rivaling hand-crafted neural networks in terms of accuracy.\nA two-step approach is introduced where a convolutional autoencoder is created\nthat efficiently compresses the input data in the first step, and a\nconvolutional neural network is created to classify the compressed data in the\nsecond step. The creation of networks in both steps is guided by by an\nevolutionary process, where new networks are constantly being generated by\nmutating members of a collection of existing networks. Additionally, a method\nis introduced that considers the trade-off between compression and information\nloss of different convolutional autoencoders. This is used to select the\noptimal convolutional autoencoder from among those evolved to compress the data\nfor the second step. The complete framework is implemented, tested on the\npopular CIFAR-10 data set, and the results are discussed. Finally, a number of\npossible directions for future work with this particular framework in mind are\nconsidered, including opportunities to improve its efficiency and its\napplication in particular areas.\n",
        "published": "2019",
        "authors": [
            "Marijn van Knippenberg",
            "Vlado Menkovski",
            "Sergio Consoli"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.01969v1",
        "title": "PDP: A General Neural Framework for Learning Constraint Satisfaction\n  Solvers",
        "abstract": "  There have been recent efforts for incorporating Graph Neural Network models\nfor learning full-stack solvers for constraint satisfaction problems (CSP) and\nparticularly Boolean satisfiability (SAT). Despite the unique representational\npower of these neural embedding models, it is not clear how the search strategy\nin the learned models actually works. On the other hand, by fixing the search\nstrategy (e.g. greedy search), we would effectively deprive the neural models\nof learning better strategies than those given. In this paper, we propose a\ngeneric neural framework for learning CSP solvers that can be described in\nterms of probabilistic inference and yet learn search strategies beyond greedy\nsearch. Our framework is based on the idea of propagation, decimation and\nprediction (and hence the name PDP) in graphical models, and can be trained\ndirectly toward solving CSP in a fully unsupervised manner via energy\nminimization, as shown in the paper. Our experimental results demonstrate the\neffectiveness of our framework for SAT solving compared to both neural and the\nstate-of-the-art baselines.\n",
        "published": "2019",
        "authors": [
            "Saeed Amizadeh",
            "Sergiy Matusevych",
            "Markus Weimer"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.02081v1",
        "title": "A GA-based feature selection of the EEG signals by classification\n  evaluation: Application in BCI systems",
        "abstract": "  In electroencephalogram (EEG) signal processing, finding the appropriate\ninformation from a dataset has been a big challenge for successful signal\nclassification. The feature selection methods make it possible to solve this\nproblem; however, the method selection is still under investigation to find out\nwhich feature can perform the best to extract the most proper features of the\nsignal to improve the classification performance. In this study, we use the\ngenetic algorithm (GA), a heuristic searching algorithm, to find the optimum\ncombination of the feature extraction methods and the classifiers, in the\nbrain-computer interface (BCI) applications. A BCI system can be practical if\nand only if it performs with high accuracy and high speed alongside each other.\nIn the proposed method, GA performs as a searching engine to find the best\ncombination of the features and classifications. The features used here are\nKatz, Higuchi, Petrosian, Sevcik, and box-counting dimension (BCD) feature\nextraction methods. These features are applied to the wavelet subbands and are\nclassified with four classifiers such as adaptive neuro-fuzzy inference system\n(ANFIS), fuzzy k-nearest neighbors (FKNN), support vector machine (SVM) and\nlinear discriminant analysis (LDA). Due to the huge number of features, the GA\noptimization is used to find the features with the optimum fitness value (FV).\nResults reveal that Katz fractal feature estimation method with LDA\nclassification has the best FV. Consequently, due to the low computation time\nof the first Daubechies wavelet transformation in comparison to the original\nsignal, the final selected methods contain the fractal features of the first\ncoefficient of the detail subbands.\n",
        "published": "2019",
        "authors": [
            "Samira Vafay Eslahi",
            "Nader Jafarnia Dabanloo",
            "Keivan Maghooli"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.02082v1",
        "title": "DA-LSTM: A Long Short-Term Memory with Depth Adaptive to Non-uniform\n  Information Flow in Sequential Data",
        "abstract": "  Much sequential data exhibits highly non-uniform information distribution.\nThis cannot be correctly modeled by traditional Long Short-Term Memory (LSTM).\nTo address that, recent works have extended LSTM by adding more activations\nbetween adjacent inputs. However, the approaches often use a fixed depth, which\nis at the step of the most information content. This one-size-fits-all\nworst-case approach is not satisfactory, because when little information is\ndistributed to some steps, shallow structures can achieve faster convergence\nand consume less computation resource. In this paper, we develop a\nDepth-Adaptive Long Short-Term Memory (DA-LSTM) architecture, which can\ndynamically adjust the structure depending on information distribution without\nprior knowledge. Experimental results on real-world datasets show that DA-LSTM\ncosts much less computation resource and substantially reduce convergence time\nby $41.78\\%$ and $46.01 \\%$, compared with Stacked LSTM and Deep Transition\nLSTM, respectively.\n",
        "published": "2019",
        "authors": [
            "Yifeng Zhang",
            "Ka-Ho Chow",
            "S. -H. Gary Chan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.02083v2",
        "title": "Direct Feedback Alignment with Sparse Connections for Local Learning",
        "abstract": "  Recent advances in deep neural networks (DNNs) owe their success to training\nalgorithms that use backpropagation and gradient-descent. Backpropagation,\nwhile highly effective on von Neumann architectures, becomes inefficient when\nscaling to large networks. Commonly referred to as the weight transport\nproblem, each neuron's dependence on the weights and errors located deeper in\nthe network require exhaustive data movement which presents a key problem in\nenhancing the performance and energy-efficiency of machine-learning hardware.\nIn this work, we propose a bio-plausible alternative to backpropagation drawing\nfrom advances in feedback alignment algorithms in which the error computation\nat a single synapse reduces to the product of three scalar values. Using a\nsparse feedback matrix, we show that a neuron needs only a fraction of the\ninformation previously used by the feedback alignment algorithms. Consequently,\nmemory and compute can be partitioned and distributed whichever way produces\nthe most efficient forward pass so long as a single error can be delivered to\neach neuron. Our results show orders of magnitude improvement in data movement\nand $2\\times$ improvement in multiply-and-accumulate operations over\nbackpropagation. Like previous work, we observe that any variant of feedback\nalignment suffers significant losses in classification accuracy on deep\nconvolutional neural networks. By transferring trained convolutional layers and\ntraining the fully connected layers using direct feedback alignment, we\ndemonstrate that direct feedback alignment can obtain results competitive with\nbackpropagation. Furthermore, we observe that using an extremely sparse\nfeedback matrix, rather than a dense one, results in a small accuracy drop\nwhile yielding hardware advantages. All the code and results are available\nunder https://github.com/bcrafton/ssdfa.\n",
        "published": "2019",
        "authors": [
            "Brian Crafton",
            "Abhinav Parihar",
            "Evan Gebhardt",
            "Arijit Raychowdhury"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.04337v3",
        "title": "Labeler-hot Detection of EEG Epileptic Transients",
        "abstract": "  Preventing early progression of epilepsy and so the severity of seizures\nrequires an effective diagnosis. Epileptic transients indicate the ability to\ndevelop seizures but humans overlook such brief events in an\nelectroencephalogram (EEG) what compromises patient treatment. Traditionally,\ntraining of the EEG event detection algorithms has relied on ground truth\nlabels, obtained from the consensus of the majority of labelers. In this work,\nwe go beyond labeler consensus on EEG data. Our event descriptor integrates EEG\nsignal features with one-hot encoded labeler category that is a key to improved\ngeneralization performance. Notably, boosted decision trees take advantage of\nsingly-labeled but more varied training sets. Our quantitative experiments show\nthe proposed labeler-hot epileptic event detector consistently outperforms a\nconsensus-trained detector and maintains confidence bounds of the detection.\nThe results on our infant EEG recordings suggest datasets can gain higher event\nvariety faster and thus better performance by shifting available human effort\nfrom consensus-oriented to separate labeling when labels include both, the\nevent and the labeler category.\n",
        "published": "2019",
        "authors": [
            "Lukasz Czekaj",
            "Wojciech Ziembla",
            "Pawel Jezierski",
            "Pawel Swiniarski",
            "Anna Kolodziejak",
            "Pawel Ogniewski",
            "Pawel Niedbalski",
            "Anna Jezierska",
            "Daniel Wesierski"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.04377v2",
        "title": "SleepNet: Automated Sleep Analysis via Dense Convolutional Neural\n  Network Using Physiological Time Series",
        "abstract": "  In this work, a dense recurrent convolutional neural network (DRCNN) was\nconstructed to detect sleep disorders including arousal, apnea and hypopnea\nusing Polysomnography (PSG) measurement channels provided in the 2018 Physionet\nchallenge database. Our model structure is composed of multiple dense\nconvolutional units (DCU) followed by a bidirectional long-short term memory\n(LSTM) layer followed by a softmax output layer. The sleep events including\nsleep stages, arousal regions and multiple types of apnea and hypopnea are\nmanually annotated by experts which enables us to train our proposed network\nusing a multi-task learning mechanism. Three binary cross-entropy loss\nfunctions corresponding to sleep/wake, target arousal and apnea-hypopnea/normal\ndetection tasks are summed up to generate our overall network loss function\nthat is optimized using the Adam method. Our model performance was evaluated\nusing two metrics: the area under the precision-recall curve (AUPRC) and the\narea under the receiver operating characteristic curve (AUROC). To measure our\nmodel generalization, 4-fold cross-validation was also performed. For training,\nour model was applied to full night recording data. Finally, the average AUPRC\nand AUROC values associated with the arousal detection task were 0.505 and\n0.922, respectively on our testing dataset. An ensemble of four models trained\non different data folds improved the AUPRC and AUROC to 0.543 and 0.931,\nrespectively. Our proposed algorithm achieved the first place in the official\nstage of the 2018 Physionet challenge for detecting sleep arousals with AUPRC\nof 0.54 on the blind testing dataset.\n",
        "published": "2019",
        "authors": [
            "Bahareh Pourbabaee",
            "Matthew Howe-Patterson",
            "Matthew Patterson",
            "Frederic Benard"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.04476v1",
        "title": "Continual Learning via Neural Pruning",
        "abstract": "  We introduce Continual Learning via Neural Pruning (CLNP), a new method aimed\nat lifelong learning in fixed capacity models based on neuronal model\nsparsification. In this method, subsequent tasks are trained using the inactive\nneurons and filters of the sparsified network and cause zero deterioration to\nthe performance of previous tasks. In order to deal with the possible\ncompromise between model sparsity and performance, we formalize and incorporate\nthe concept of graceful forgetting: the idea that it is preferable to suffer a\nsmall amount of forgetting in a controlled manner if it helps regain network\ncapacity and prevents uncontrolled loss of performance during the training of\nfuture tasks. CLNP also provides simple continual learning diagnostic tools in\nterms of the number of free neurons left for the training of future tasks as\nwell as the number of neurons that are being reused. In particular, we see in\nexperiments that CLNP verifies and automatically takes advantage of the fact\nthat the features of earlier layers are more transferable. We show empirically\nthat CLNP leads to significantly improved results over current weight\nelasticity based methods.\n",
        "published": "2019",
        "authors": [
            "Siavash Golkar",
            "Michael Kagan",
            "Kyunghyun Cho"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.04598v2",
        "title": "Graph Colouring Meets Deep Learning: Effective Graph Neural Network\n  Models for Combinatorial Problems",
        "abstract": "  Deep learning has consistently defied state-of-the-art techniques in many\nfields over the last decade. However, we are just beginning to understand the\ncapabilities of neural learning in symbolic domains. Deep learning\narchitectures that employ parameter sharing over graphs can produce models\nwhich can be trained on complex properties of relational data. These include\nhighly relevant NP-Complete problems, such as SAT and TSP. In this work, we\nshowcase how Graph Neural Networks (GNN) can be engineered -- with a very\nsimple architecture -- to solve the fundamental combinatorial problem of graph\ncolouring. Our results show that the model, which achieves high accuracy upon\ntraining on random instances, is able to generalise to graph distributions\ndifferent from those seen at training time. Further, it performs better than\nthe Neurosat, Tabucol and greedy baselines for some distributions. In addition,\nwe show how vertex embeddings can be clustered in multidimensional spaces to\nyield constructive solutions even though our model is only trained as a binary\nclassifier. In summary, our results contribute to shorten the gap in our\nunderstanding of the algorithms learned by GNNs, as well as hoarding empirical\nevidence for their capability on hard combinatorial problems. Our results thus\ncontribute to the standing challenge of integrating robust learning and\nsymbolic reasoning in Deep Learning systems.\n",
        "published": "2019",
        "authors": [
            "Henrique Lemos",
            "Marcelo Prates",
            "Pedro Avelar",
            "Luis Lamb"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.05071v1",
        "title": "Efficient Optimization of Echo State Networks for Time Series Datasets",
        "abstract": "  Echo State Networks (ESNs) are recurrent neural networks that only train\ntheir output layer, thereby precluding the need to backpropagate gradients\nthrough time, which leads to significant computational gains. Nevertheless, a\ncommon issue in ESNs is determining its hyperparameters, which are crucial in\ninstantiating a well performing reservoir, but are often set manually or using\nheuristics. In this work we optimize the ESN hyperparameters using Bayesian\noptimization which, given a limited budget of function evaluations, outperforms\na grid search strategy. In the context of large volumes of time series data,\nsuch as light curves in the field of astronomy, we can further reduce the\noptimization cost of ESNs. In particular, we wish to avoid tuning\nhyperparameters per individual time series as this is costly; instead, we want\nto find ESNs with hyperparameters that perform well not just on individual time\nseries but rather on groups of similar time series without sacrificing\npredictive performance significantly. This naturally leads to a notion of\nclusters, where each cluster is represented by an ESN tuned to model a group of\ntime series of similar temporal behavior. We demonstrate this approach both on\nsynthetic datasets and real world light curves from the MACHO survey. We show\nthat our approach results in a significant reduction in the number of ESN\nmodels required to model a whole dataset, while retaining predictive\nperformance for the series in each cluster.\n",
        "published": "2019",
        "authors": [
            "Jacob Reinier Maat",
            "Nikos Gianniotis",
            "Pavlos Protopapas"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.06070v1",
        "title": "Attention-Based Structural-Plasticity",
        "abstract": "  Catastrophic forgetting/interference is a critical problem for lifelong\nlearning machines, which impedes the agents from maintaining their previously\nlearned knowledge while learning new tasks. Neural networks, in particular,\nsuffer plenty from the catastrophic forgetting phenomenon. Recently there has\nbeen several efforts towards overcoming catastrophic forgetting in neural\nnetworks. Here, we propose a biologically inspired method toward overcoming\ncatastrophic forgetting. Specifically, we define an attention-based selective\nplasticity of synapses based on the cholinergic neuromodulatory system in the\nbrain. We define synaptic importance parameters in addition to synaptic weights\nand then use Hebbian learning in parallel with backpropagation algorithm to\nlearn synaptic importances in an online and seamless manner. We test our\nproposed method on benchmark tasks including the Permuted MNIST and the Split\nMNIST problems and show competitive performance compared to the\nstate-of-the-art methods.\n",
        "published": "2019",
        "authors": [
            "Soheil Kolouri",
            "Nicholas Ketz",
            "Xinyun Zou",
            "Jeffrey Krichmar",
            "Praveen Pilly"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.07461v2",
        "title": "Evolutionary Deep Learning to Identify Galaxies in the Zone of Avoidance",
        "abstract": "  The Zone of Avoidance makes it difficult for astronomers to catalogue\ngalaxies at low latitudes to our galactic plane due to high star densities and\nextinction. However, having a complete sky map of galaxies is important in a\nnumber of fields of research in astronomy. There are many unclassified sources\nof light in the Zone of Avoidance and it is therefore important that there\nexists an accurate automated system to identify and classify galaxies in this\nregion. This study aims to evaluate the efficiency and accuracy of using an\nevolutionary algorithm to evolve the topology and configuration of\nConvolutional Neural Network (CNNs) to automatically identify galaxies in the\nZone of Avoidance. A supervised learning method is used with data containing\nnear-infrared images. Input image resolution and number of near-infrared\npassbands needed by the evolutionary algorithm is also analyzed while the\naccuracy of the best evolved CNN is compared to other CNN variants.\n",
        "published": "2019",
        "authors": [
            "David Jones",
            "Anja Schroeder",
            "Geoff Nitschke"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.08850v2",
        "title": "Stochastic Optimization of Sorting Networks via Continuous Relaxations",
        "abstract": "  Sorting input objects is an important step in many machine learning\npipelines. However, the sorting operator is non-differentiable with respect to\nits inputs, which prohibits end-to-end gradient-based optimization. In this\nwork, we propose NeuralSort, a general-purpose continuous relaxation of the\noutput of the sorting operator from permutation matrices to the set of unimodal\nrow-stochastic matrices, where every row sums to one and has a distinct arg\nmax. This relaxation permits straight-through optimization of any computational\ngraph involve a sorting operation. Further, we use this relaxation to enable\ngradient-based stochastic optimization over the combinatorially large space of\npermutations by deriving a reparameterized gradient estimator for the\nPlackett-Luce family of distributions over permutations. We demonstrate the\nusefulness of our framework on three tasks that require learning semantic\norderings of high-dimensional objects, including a fully differentiable,\nparameterized extension of the k-nearest neighbors algorithm.\n",
        "published": "2019",
        "authors": [
            "Aditya Grover",
            "Eric Wang",
            "Aaron Zweig",
            "Stefano Ermon"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1903.11012v3",
        "title": "Improved robustness of reinforcement learning policies upon conversion\n  to spiking neuronal network platforms applied to ATARI games",
        "abstract": "  Deep Reinforcement Learning (RL) demonstrates excellent performance on tasks\nthat can be solved by trained policy. It plays a dominant role among\ncutting-edge machine learning approaches using multi-layer Neural networks\n(NNs). At the same time, Deep RL suffers from high sensitivity to noisy,\nincomplete, and misleading input data. Following biological intuition, we\ninvolve Spiking Neural Networks (SNNs) to address some deficiencies of deep RL\nsolutions. Previous studies in image classification domain demonstrated that\nstandard NNs (with ReLU nonlinearity) trained using supervised learning can be\nconverted to SNNs with negligible deterioration in performance. In this paper,\nwe extend those conversion results to the domain of Q-Learning NNs trained\nusing RL. We provide a proof of principle of the conversion of standard NN to\nSNN. In addition, we show that the SNN has improved robustness to occlusion in\nthe input image. Finally, we introduce results with converting full-scale Deep\nQ-network to SNN, paving the way for future research to robust Deep RL\napplications.\n",
        "published": "2019",
        "authors": [
            "Devdhar Patel",
            "Hananel Hazan",
            "Daniel J. Saunders",
            "Hava Siegelmann",
            "Robert Kozma"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.00009v2",
        "title": "MSTDP: A More Biologically Plausible Learning",
        "abstract": "  Spike-timing dependent plasticity (STDP) which observed in the brain has\nproven to be important in biological learning. On the other hand, artificial\nneural networks use a different way to learn, such as Back-Propagation or\nContrastive Hebbian Learning. In this work, we propose a new framework called\nmstdp that learn almost the same way biological learning use, it only uses STDP\nrules for supervised and unsupervised learning and don' t need a global loss or\nother supervise information. The framework works like an auto-encoder by making\neach input neuron also an output neuron. It can make predictions or generate\npatterns in one model without additional configuration. We also brought a new\niterative inference method using momentum to make the framework more efficient,\nwhich can be used in training and testing phases. Finally, we verified our\nframework on MNIST dataset for classification and generation task.\n",
        "published": "2019",
        "authors": [
            "Shiyuan Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.00079v1",
        "title": "DeepMimic: Mentor-Student Unlabeled Data Based Training",
        "abstract": "  In this paper, we present a deep neural network (DNN) training approach\ncalled the \"DeepMimic\" training method. Enormous amounts of data are available\nnowadays for training usage. Yet, only a tiny portion of these data is manually\nlabeled, whereas almost all of the data are unlabeled. The training approach\npresented utilizes, in a most simplified manner, the unlabeled data to the\nfullest, in order to achieve remarkable (classification) results. Our DeepMimic\nmethod uses a small portion of labeled data and a large amount of unlabeled\ndata for the training process, as expected in a real-world scenario. It\nconsists of a mentor model and a student model. Employing a mentor model\ntrained on a small portion of the labeled data and then feeding it only with\nunlabeled data, we show how to obtain a (simplified) student model that reaches\nthe same accuracy and loss as the mentor model, on the same test set, without\nusing any of the original data labels in the training of the student model. Our\nexperiments demonstrate that even on challenging classification tasks the\nstudent network architecture can be simplified significantly with a minor\ninfluence on the performance, i.e., we need not even know the original network\narchitecture of the mentor. In addition, the time required for training the\nstudent model to reach the mentor's performance level is shorter, as a result\nof a simplified architecture and more available data. The proposed method\nhighlights the disadvantages of regular supervised training and demonstrates\nthe benefits of a less traditional training approach.\n",
        "published": "2019",
        "authors": [
            "Itay Mosafi",
            "Eli David",
            "Nathan S. Netanyahu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.01105v1",
        "title": "Clustering via Ant Colonies: Parameter Analysis and Improvement of the\n  Algorithm",
        "abstract": "  An ant colony optimization approach for partitioning a set of objects is\nproposed. In order to minimize the intra-variance, or within sum-of-squares, of\nthe partitioned classes, we construct ant-like solutions by a constructive\napproach that selects objects to be put in a class with a probability that\ndepends on the distance between the object and the centroid of the class\n(visibility) and the pheromone trail; the latter depends on the class\nmemberships that have been defined along the iterations. The procedure is\nimproved with the application of K-means algorithm in some iterations of the\nant colony method. We performed a simulation study in order to evaluate the\nmethod with a Monte Carlo experiment that controls some sensitive parameters of\nthe clustering problem. After some tuning of the parameters, the method has\nalso been applied to some benchmark real-data sets. Encouraging results were\nobtained in nearly all cases.\n",
        "published": "2019",
        "authors": [
            "Jeffry Chavarria-Molina",
            "Juan Jose Fallas-Monge",
            "Javier Trejos-Zelaya"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.01493v1",
        "title": "End-to-End Deep Neural Networks and Transfer Learning for Automatic\n  Analysis of Nation-State Malware",
        "abstract": "  Malware allegedly developed by nation-states, also known as advanced\npersistent threats (APT), are becoming more common. The task of attributing an\nAPT to a specific nation-state or classifying it to the correct APT family is\nchallenging for several reasons. First, each nation-state has more than a\nsingle cyber unit that develops such malware, rendering traditional authorship\nattribution algorithms useless. Furthermore, the dataset of such available APTs\nis still extremely small. Finally, those APTs use state-of-the-art evasion\ntechniques, making feature extraction challenging. In this paper, we use a deep\nneural network (DNN) as a classifier for nation-state APT attribution. We\nrecord the dynamic behavior of the APT when run in a sandbox and use it as raw\ninput for the neural network, allowing the DNN to learn high level feature\nabstractions of the APTs itself. We also use the same raw features for APT\nfamily classification. Finally, we use the feature abstractions learned by the\nAPT family classifier to solve the attribution problem. Using a test set of\n1000 Chinese and Russian developed APTs, we achieved an accuracy rate of 98.6%.\n",
        "published": "2019",
        "authors": [
            "Ishai Rosenberg",
            "Guillaume Sicard",
            "Eli David"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.01792v2",
        "title": "Learn Electronic Health Records by Fully Decentralized Federated\n  Learning",
        "abstract": "  Federated learning opens a number of research opportunities due to its high\ncommunication efficiency in distributed training problems within a star\nnetwork. In this paper, we focus on improving the communication efficiency for\nfully decentralized federated learning over a graph, where the algorithm\nperforms local updates for several iterations and then enables communications\namong the nodes. In such a way, the communication rounds of exchanging the\ncommon interest of parameters can be saved significantly without loss of\noptimality of the solutions. Multiple numerical simulations based on large,\nreal-world electronic health record databases showcase the superiority of the\ndecentralized federated learning compared with classic methods.\n",
        "published": "2019",
        "authors": [
            "Songtao Lu",
            "Yawen Zhang",
            "Yunlong Wang",
            "Christina Mack"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.02405v1",
        "title": "Clustering Time-Series by a Novel Slope-Based Similarity Measure\n  Considering Particle Swarm Optimization",
        "abstract": "  Recently there has been an increase in the studies on time-series data mining\nspecifically time-series clustering due to the vast existence of time-series in\nvarious domains. The large volume of data in the form of time-series makes it\nnecessary to employ various techniques such as clustering to understand the\ndata and to extract information and hidden patterns. In the field of clustering\nspecifically, time-series clustering, the most important aspects are the\nsimilarity measure used and the algorithm employed to conduct the clustering.\nIn this paper, a new similarity measure for time-series clustering is developed\nbased on a combination of a simple representation of time-series, slope of each\nsegment of time-series, Euclidean distance and the so-called dynamic time\nwarping. It is proved in this paper that the proposed distance measure is\nmetric and thus indexing can be applied. For the task of clustering, the\nParticle Swarm Optimization algorithm is employed. The proposed similarity\nmeasure is compared to three existing measures in terms of various criteria\nused for the evaluation of clustering algorithms. The results indicate that the\nproposed similarity measure outperforms the rest in almost every dataset used\nin this paper.\n",
        "published": "2019",
        "authors": [
            "Hossein Kamalzadeh",
            "Abbas Ahmadi",
            "Saeed Mansour"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.02574v1",
        "title": "Data-Driven Optimization of Public Transit Schedule",
        "abstract": "  Bus transit systems are the backbone of public transportation in the United\nStates. An important indicator of the quality of service in such\ninfrastructures is on-time performance at stops, with published transit\nschedules playing an integral role governing the level of success of the\nservice. However there are relatively few optimization architectures leveraging\nstochastic search that focus on optimizing bus timetables with the objective of\nmaximizing probability of bus arrivals at timepoints with delays within desired\non-time ranges. In addition to this, there is a lack of substantial research\nconsidering monthly and seasonal variations of delay patterns integrated with\nsuch optimization strategies. To address these,this paper makes the following\ncontributions to the corpus of studies on transit on-time performance\noptimization: (a) an unsupervised clustering mechanism is presented which\ngroups months with similar seasonal delay patterns, (b) the problem is\nformulated as a single-objective optimization task and a greedy algorithm, a\ngenetic algorithm (GA) as well as a particle swarm optimization (PSO) algorithm\nare employed to solve it, (c) a detailed discussion on empirical results\ncomparing the algorithms are provided and sensitivity analysis on\nhyper-parameters of the heuristics are presented along with execution times,\nwhich will help practitioners looking at similar problems. The analyses\nconducted are insightful in the local context of improving public transit\nscheduling in the Nashville metro region as well as informative from a global\nperspective as an elaborate case study which builds upon the growing corpus of\nempirical studies using nature-inspired approaches to transit schedule\noptimization.\n",
        "published": "2019",
        "authors": [
            "Sanchita Basak",
            "Fangzhou Sun",
            "Saptarshi Sengupta",
            "Abhishek Dubey"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.03126v1",
        "title": "Knowledge extraction from the learning of sequences in a long short term\n  memory (LSTM) architecture",
        "abstract": "  We introduce a general method to extract knowledge from a recurrent neural\nnetwork (Long Short Term Memory) that has learnt to detect if a given input\nsequence is valid or not, according to an unknown generative automaton. Based\non the clustering of the hidden states, we explain how to build and validate an\nautomaton that corresponds to the underlying (unknown) automaton, and allows to\npredict if a given sequence is valid or not. The method is illustrated on\nartificial grammars (Reber's grammar variations) as well as on a real use-case\nwhose underlying grammar is unknown.\n",
        "published": "2019",
        "authors": [
            "Ikram Chraibi Kaadoud",
            "Nicolas P. Rougier",
            "Fr\u00e9d\u00e9ric Alexandre"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.03959v1",
        "title": "Stealing Knowledge from Protected Deep Neural Networks Using Composite\n  Unlabeled Data",
        "abstract": "  As state-of-the-art deep neural networks are deployed at the core of more\nadvanced Al-based products and services, the incentive for copying them (i.e.,\ntheir intellectual properties) by rival adversaries is expected to increase\nconsiderably over time. The best way to extract or steal knowledge from such\nnetworks is by querying them using a large dataset of random samples and\nrecording their output, followed by training a student network to mimic these\noutputs, without making any assumption about the original networks. The most\neffective way to protect against such a mimicking attack is to provide only the\nclassification result, without confidence values associated with the softmax\nlayer.In this paper, we present a novel method for generating composite images\nfor attacking a mentor neural network using a student model. Our method assumes\nno information regarding the mentor's training dataset, architecture, or\nweights. Further assuming no information regarding the mentor's softmax output\nvalues, our method successfully mimics the given neural network and steals all\nof its knowledge. We also demonstrate that our student network (which copies\nthe mentor) is impervious to watermarking protection methods, and thus would\nnot be detected as a stolen model.Our results imply, essentially, that all\ncurrent neural networks are vulnerable to mimicking attacks, even if they do\nnot divulge anything but the most basic required output, and that the student\nmodel which mimics them cannot be easily detected and singled out as a stolen\ncopy using currently available techniques.\n",
        "published": "2019",
        "authors": [
            "Itay Mosafi",
            "Eli David",
            "Nathan S. Netanyahu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.04508v1",
        "title": "Reducing Catastrophic Forgetting in Modular Neural Networks by Dynamic\n  Information Balancing",
        "abstract": "  Lifelong learning is a very important step toward realizing robust autonomous\nartificial agents. Neural networks are the main engine of deep learning, which\nis the current state-of-the-art technique in formulating adaptive artificial\nintelligent systems. However, neural networks suffer from catastrophic\nforgetting when stressed with the challenge of continual learning. We\ninvestigate how to exploit modular topology in neural networks in order to\ndynamically balance the information load between different modules by routing\ninputs based on the information content in each module so that information\ninterference is minimized. Our dynamic information balancing (DIB) technique\nadapts a reinforcement learning technique to guide the routing of different\ninputs based on a reward signal derived from a measure of the information load\nin each module. Our empirical results show that DIB combined with elastic\nweight consolidation (EWC) regularization outperforms models with similar\ncapacity and EWC regularization across different task formulations and\ndatasets.\n",
        "published": "2019",
        "authors": [
            "Mohammed Amer",
            "Tom\u00e1s Maul"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.04635v2",
        "title": "Backprop Diffusion is Biologically Plausible",
        "abstract": "  The Backpropagation algorithm relies on the abstraction of using a neural\nmodel that gets rid of the notion of time, since the input is mapped\ninstantaneously to the output. In this paper, we claim that this abstraction of\nignoring time, along with the abrupt input changes that occur when feeding the\ntraining set, are in fact the reasons why, in some papers, Backprop biological\nplausibility is regarded as an arguable issue. We show that as soon as a deep\nfeedforward network operates with neurons with time-delayed response, the\nbackprop weight update turns out to be the basic equation of a biologically\nplausible diffusion process based on forward-backward waves. We also show that\nsuch a process very well approximates the gradient for inputs that are not too\nfast with respect to the depth of the network. These remarks somewhat disclose\nthe diffusion process behind the backprop equation and leads us to interpret\nthe corresponding algorithm as a degeneration of a more general diffusion\nprocess that takes place also in neural networks with cyclic connections.\n",
        "published": "2019",
        "authors": [
            "Alessandro Betti",
            "Marco Gori"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.04825v2",
        "title": "Integration of Neural Network-Based Symbolic Regression in Deep Learning\n  for Scientific Discovery",
        "abstract": "  Symbolic regression is a powerful technique that can discover analytical\nequations that describe data, which can lead to explainable models and\ngeneralizability outside of the training data set. In contrast, neural networks\nhave achieved amazing levels of accuracy on image recognition and natural\nlanguage processing tasks, but are often seen as black-box models that are\ndifficult to interpret and typically extrapolate poorly. Here we use a neural\nnetwork-based architecture for symbolic regression called the Equation Learner\n(EQL) network and integrate it with other deep learning architectures such that\nthe whole system can be trained end-to-end through backpropagation. To\ndemonstrate the power of such systems, we study their performance on several\nsubstantially different tasks. First, we show that the neural network can\nperform symbolic regression and learn the form of several functions. Next, we\npresent an MNIST arithmetic task where a separate part of the neural network\nextracts the digits. Finally, we demonstrate prediction of dynamical systems\nwhere an unknown parameter is extracted through an encoder. We find that the\nEQL-based architecture can extrapolate quite well outside of the training data\nset compared to a standard neural network-based architecture, paving the way\nfor deep learning to be applied in scientific exploration and discovery.\n",
        "published": "2019",
        "authors": [
            "Samuel Kim",
            "Peter Y. Lu",
            "Srijon Mukherjee",
            "Michael Gilbert",
            "Li Jing",
            "Vladimir \u010ceperi\u0107",
            "Marin Solja\u010di\u0107"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.04968v2",
        "title": "Neural Memory Networks for Seizure Type Classification",
        "abstract": "  Classification of seizure type is a key step in the clinical process for\nevaluating an individual who presents with seizures. It determines the course\nof clinical diagnosis and treatment, and its impact stretches beyond the\nclinical domain to epilepsy research and the development of novel therapies.\nAutomated identification of seizure type may facilitate understanding of the\ndisease, and seizure detection and prediction has been the focus of recent\nresearch that has sought to exploit the benefits of machine learning and deep\nlearning architectures. Nevertheless, there is not yet a definitive solution\nfor automating the classification of seizure type, a task that must currently\nbe performed by an expert epileptologist. Inspired by recent advances in neural\nmemory networks (NMNs), we introduce a novel approach for the classification of\nseizure type using electrophysiological data. We first explore the performance\nof traditional deep learning techniques which use convolutional and recurrent\nneural networks, and enhance these architectures by using external memory\nmodules with trainable neural plasticity. We show that our model achieves a\nstate-of-the-art weighted F1 score of 0.945 for seizure type classification on\nthe TUH EEG Seizure Corpus with the IBM TUSZ preprocessed data. This work\nhighlights the potential of neural memory networks to support the field of\nepilepsy research, along with biomedical research and signal analysis more\nbroadly.\n",
        "published": "2019",
        "authors": [
            "David Ahmedt-Aristizabal",
            "Tharindu Fernando",
            "Simon Denman",
            "Lars Petersson",
            "Matthew J. Aburn",
            "Clinton Fookes"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.05198v1",
        "title": "Recurrent Transform Learning",
        "abstract": "  The objective of this work is to improve the accuracy of building demand\nforecasting. This is a more challenging task than grid level forecasting. For\nthe said purpose, we develop a new technique called recurrent transform\nlearning (RTL). Two versions are proposed. The first one (RTL) is unsupervised;\nthis is used as a feature extraction tool that is further fed into a regression\nmodel. The second formulation embeds regression into the RTL framework leading\nto regressing recurrent transform learning (R2TL). Forecasting experiments have\nbeen carried out on three popular publicly available datasets. Both of our\nproposed techniques yield results superior to the state-of-the-art like long\nshort term memory network, echo state network and sparse coding regression.\n",
        "published": "2019",
        "authors": [
            "Megha Gupta",
            "Angshul Majumdar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.05671v4",
        "title": "Linear Mode Connectivity and the Lottery Ticket Hypothesis",
        "abstract": "  We study whether a neural network optimizes to the same, linearly connected\nminimum under different samples of SGD noise (e.g., random data order and\naugmentation). We find that standard vision models become stable to SGD noise\nin this way early in training. From then on, the outcome of optimization is\ndetermined to a linearly connected region. We use this technique to study\niterative magnitude pruning (IMP), the procedure used by work on the lottery\nticket hypothesis to identify subnetworks that could have trained in isolation\nto full accuracy. We find that these subnetworks only reach full accuracy when\nthey are stable to SGD noise, which either occurs at initialization for\nsmall-scale settings (MNIST) or early in training for large-scale settings\n(ResNet-50 and Inception-v3 on ImageNet).\n",
        "published": "2019",
        "authors": [
            "Jonathan Frankle",
            "Gintare Karolina Dziugaite",
            "Daniel M. Roy",
            "Michael Carbin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.06059v1",
        "title": "Grid Search, Random Search, Genetic Algorithm: A Big Comparison for NAS",
        "abstract": "  In this paper, we compare the three most popular algorithms for\nhyperparameter optimization (Grid Search, Random Search, and Genetic Algorithm)\nand attempt to use them for neural architecture search (NAS). We use these\nalgorithms for building a convolutional neural network (search architecture).\nExperimental results on CIFAR-10 dataset further demonstrate the performance\ndifference between compared algorithms. The comparison results are based on the\nexecution time of the above algorithms and accuracy of the proposed models.\n",
        "published": "2019",
        "authors": [
            "Petro Liashchynskyi",
            "Pavlo Liashchynskyi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.06472v1",
        "title": "Dimension of Reservoir Computers",
        "abstract": "  A reservoir computer is a complex dynamical system, often created by coupling\nnonlinear nodes in a network. The nodes are all driven by a common driving\nsignal. In this work, three dimension estimation methods, false nearest\nneighbor, covariance and Kaplan-Yorke dimensions, are used to estimate the\ndimension of the reservoir dynamical system. It is shown that the signals in\nthe reservoir system exist on a relatively low dimensional surface. Changing\nthe spectral radius of the reservoir network can increase the fractal dimension\nof the reservoir signals, leading to an increase in testing error.\n",
        "published": "2019",
        "authors": [
            "Thomas L. Carroll"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.07589v1",
        "title": "Network of Evolvable Neural Units: Evolving to Learn at a Synaptic Level",
        "abstract": "  Although Deep Neural Networks have seen great success in recent years through\nvarious changes in overall architectures and optimization strategies, their\nfundamental underlying design remains largely unchanged. Computational\nneuroscience on the other hand provides more biologically realistic models of\nneural processing mechanisms, but they are still high level abstractions of the\nactual experimentally observed behaviour. Here a model is proposed that bridges\nNeuroscience, Machine Learning and Evolutionary Algorithms to evolve individual\nsoma and synaptic compartment models of neurons in a scalable manner. Instead\nof attempting to manually derive models for all the observed complexity and\ndiversity in neural processing, we propose an Evolvable Neural Unit (ENU) that\ncan approximate the function of each individual neuron and synapse. We\ndemonstrate that this type of unit can be evolved to mimic Integrate-And-Fire\nneurons and synaptic Spike-Timing-Dependent Plasticity. Additionally, by\nconstructing a new type of neural network where each synapse and neuron is such\nan evolvable neural unit, we show it is possible to evolve an agent capable of\nlearning to solve a T-maze environment task. This network independently\ndiscovers spiking dynamics and reinforcement type learning rules, opening up a\nnew path towards biologically inspired artificial intelligence.\n",
        "published": "2019",
        "authors": [
            "Paul Bertens",
            "Seong-Whan Lee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.08124v4",
        "title": "SpaRCe: Improved Learning of Reservoir Computing Systems through Sparse\n  Representations",
        "abstract": "  \"Sparse\" neural networks, in which relatively few neurons or connections are\nactive, are common in both machine learning and neuroscience. Whereas in\nmachine learning, \"sparsity\" is related to a penalty term that leads to some\nconnecting weights becoming small or zero, in biological brains, sparsity is\noften created when high spiking thresholds prevent neuronal activity. Here we\nintroduce sparsity into a reservoir computing network via neuron-specific\nlearnable thresholds of activity, allowing neurons with low thresholds to\ncontribute to decision-making but suppressing information from neurons with\nhigh thresholds. This approach, which we term \"SpaRCe\", optimises the sparsity\nlevel of the reservoir without affecting the reservoir dynamics. The read-out\nweights and the thresholds are learned by an on-line gradient rule that\nminimises an error function on the outputs of the network. Threshold learning\noccurs by the balance of two opposing forces: reducing inter-neuronal\ncorrelations in the reservoir by deactivating redundant neurons, while\nincreasing the activity of neurons participating in correct decisions. We test\nSpaRCe on classification problems and find that threshold learning improves\nperformance compared to standard reservoir computing. SpaRCe alleviates the\nproblem of catastrophic forgetting, a problem most evident in standard echo\nstate networks and recurrent neural networks in general, due to increasing the\nnumber of task-specialised neurons that are included in the network decisions.\n",
        "published": "2019",
        "authors": [
            "Luca Manneschi",
            "Andrew C. Lin",
            "Eleni Vasilaki"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.08881v3",
        "title": "Pruning by Explaining: A Novel Criterion for Deep Neural Network Pruning",
        "abstract": "  The success of convolutional neural networks (CNNs) in various applications\nis accompanied by a significant increase in computation and parameter storage\ncosts. Recent efforts to reduce these overheads involve pruning and compressing\nthe weights of various layers while at the same time aiming to not sacrifice\nperformance. In this paper, we propose a novel criterion for CNN pruning\ninspired by neural network interpretability: The most relevant units, i.e.\nweights or filters, are automatically found using their relevance scores\nobtained from concepts of explainable AI (XAI). By exploring this idea, we\nconnect the lines of interpretability and model compression research. We show\nthat our proposed method can efficiently prune CNN models in transfer-learning\nsetups in which networks pre-trained on large corpora are adapted to\nspecialized tasks. The method is evaluated on a broad range of computer vision\ndatasets. Notably, our novel criterion is not only competitive or better\ncompared to state-of-the-art pruning criteria when successive retraining is\nperformed, but clearly outperforms these previous criteria in the\nresource-constrained application scenario in which the data of the task to be\ntransferred to is very scarce and one chooses to refrain from fine-tuning. Our\nmethod is able to compress the model iteratively while maintaining or even\nimproving accuracy. At the same time, it has a computational cost in the order\nof gradient computation and is comparatively simple to apply without the need\nfor tuning hyperparameters for pruning.\n",
        "published": "2019",
        "authors": [
            "Seul-Ki Yeom",
            "Philipp Seegerer",
            "Sebastian Lapuschkin",
            "Alexander Binder",
            "Simon Wiedemann",
            "Klaus-Robert M\u00fcller",
            "Wojciech Samek"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.08986v1",
        "title": "Deep Connectomics Networks: Neural Network Architectures Inspired by\n  Neuronal Networks",
        "abstract": "  The interplay between inter-neuronal network topology and cognition has been\nstudied deeply by connectomics researchers and network scientists, which is\ncrucial towards understanding the remarkable efficacy of biological neural\nnetworks. Curiously, the deep learning revolution that revived neural networks\nhas not paid much attention to topological aspects. The architectures of deep\nneural networks (DNNs) do not resemble their biological counterparts in the\ntopological sense. We bridge this gap by presenting initial results of Deep\nConnectomics Networks (DCNs) as DNNs with topologies inspired by real-world\nneuronal networks. We show high classification accuracy obtained by DCNs whose\narchitecture was inspired by the biological neuronal networks of C. Elegans and\nthe mouse visual cortex.\n",
        "published": "2019",
        "authors": [
            "Nicholas Roberts",
            "Dian Ang Yap",
            "Vinay Uday Prabhu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.09399v1",
        "title": "Quantifying the effect of representations on task complexity",
        "abstract": "  We examine the influence of input data representations on learning\ncomplexity. For learning, we posit that each model implicitly uses a candidate\nmodel distribution for unexplained variations in the data, its noise model. If\nthe model distribution is not well aligned to the true distribution, then even\nrelevant variations will be treated as noise. Crucially however, the alignment\nof model and true distribution can be changed, albeit implicitly, by changing\ndata representations. \"Better\" representations can better align the model to\nthe true distribution, making it easier to approximate the input-output\nrelationship in the data without discarding useful data variations. To quantify\nthis alignment effect of data representations on the difficulty of a learning\ntask, we make use of an existing task complexity score and show its connection\nto the representation-dependent information coding length of the input.\nEmpirically we extract the necessary statistics from a linear regression\napproximation and show that these are sufficient to predict relative learning\nperformance outcomes of different data representations and neural network types\nobtained when utilizing an extensive neural network architecture search. We\nconclude that to ensure better learning outcomes, representations may need to\nbe tailored to both task and model to align with the implicit distribution of\nmodel and task.\n",
        "published": "2019",
        "authors": [
            "Julian Zilly",
            "Lorenz Hetzel",
            "Andrea Censi",
            "Emilio Frazzoli"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.09423v1",
        "title": "Pseudo-Encoded Stochastic Variational Inference",
        "abstract": "  Posterior inference in directed graphical models is commonly done using a\nprobabilistic encoder (a.k.a inference model) conditioned on the input. Often\nthis inference model is trained jointly with the probabilistic decoder (a.k.a\ngenerator model). If probabilistic encoder encounters complexities during\ntraining (e.g. suboptimal complxity or parameterization), then learning reaches\na suboptimal objective; a phenomena commonly called inference suboptimality. In\nVariational Inference (VI), optimizing the ELBo using Stochastic Variational\nInference (SVI) can eliminate the inference suboptimality (as demonstrated in\nthis paper), however, this solution comes at a substantial computational cost\nwhen inference needs to be done on new data points. Essentially, a long\nsequential chain of gradient updates is required to fully optimize approximate\nposteriors. In this paper, we present an approach called Pseudo-Encoded\nStochastic Variational Inference (PE-SVI), to reduce the inference complexity\nof SVI during test time. Our approach relies on finding a suitable initial\nstart point for gradient operations, which naturally reduces the required\ngradient steps. Furthermore, this initialization allows for adopting larger\nstep sizes (compared to random initialization used in SVI), which further\nreduces the inference time complexity. PE-SVI reaches the same ELBo objective\nas SVI using less than one percent of required steps, on average.\n",
        "published": "2019",
        "authors": [
            "Amir Zadeh",
            "Smon Hessner",
            "Yao-Chong Lim",
            "Louis-Phlippe Morency"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.09600v3",
        "title": "Group-Connected Multilayer Perceptron Networks",
        "abstract": "  Despite the success of deep learning in domains such as image, voice, and\ngraphs, there has been little progress in deep representation learning for\ndomains without a known structure between features. For instance, a tabular\ndataset of different demographic and clinical factors where the feature\ninteractions are not given as a prior. In this paper, we propose\nGroup-Connected Multilayer Perceptron (GMLP) networks to enable deep\nrepresentation learning in these domains. GMLP is based on the idea of learning\nexpressive feature combinations (groups) and exploiting them to reduce the\nnetwork complexity by defining local group-wise operations. During the training\nphase, GMLP learns a sparse feature grouping matrix using temperature annealing\nsoftmax with an added entropy loss term to encourage the sparsity. Furthermore,\nan architecture is suggested which resembles binary trees, where group-wise\noperations are followed by pooling operations to combine information; reducing\nthe number of groups as the network grows in depth. To evaluate the proposed\nmethod, we conducted experiments on different real-world datasets covering\nvarious application areas. Additionally, we provide visualizations on MNIST and\nsynthesized data. According to the results, GMLP is able to successfully learn\nand exploit expressive feature combinations and achieve state-of-the-art\nclassification performance on different datasets.\n",
        "published": "2019",
        "authors": [
            "Mohammad Kachuee",
            "Sajad Darabi",
            "Shayan Fazeli",
            "Majid Sarrafzadeh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.10189v2",
        "title": "Emergence of functional and structural properties of the head direction\n  system by optimization of recurrent neural networks",
        "abstract": "  Recent work suggests goal-driven training of neural networks can be used to\nmodel neural activity in the brain. While response properties of neurons in\nartificial neural networks bear similarities to those in the brain, the network\narchitectures are often constrained to be different. Here we ask if a neural\nnetwork can recover both neural representations and, if the architecture is\nunconstrained and optimized, the anatomical properties of neural circuits. We\ndemonstrate this in a system where the connectivity and the functional\norganization have been characterized, namely, the head direction circuits of\nthe rodent and fruit fly. We trained recurrent neural networks (RNNs) to\nestimate head direction through integration of angular velocity. We found that\nthe two distinct classes of neurons observed in the head direction system, the\nCompass neurons and the Shifter neurons, emerged naturally in artificial neural\nnetworks as a result of training. Furthermore, connectivity analysis and\nin-silico neurophysiology revealed structural and mechanistic similarities\nbetween artificial networks and the head direction system. Overall, our results\nshow that optimization of RNNs in a goal-driven task can recapitulate the\nstructure and function of biological circuits, suggesting that artificial\nneural networks can be used to study the brain at the level of both neural\nactivity and anatomical organization.\n",
        "published": "2019",
        "authors": [
            "Christopher J. Cueva",
            "Peter Y. Wang",
            "Matthew Chin",
            "Xue-Xin Wei"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.10730v1",
        "title": "An optical diffractive deep neural network with multiple\n  frequency-channels",
        "abstract": "  Diffractive deep neural network (DNNet) is a novel machine learning framework\non the modulation of optical transmission. Diffractive network would get\npredictions at the speed of light. It's pure passive architecture, no\nadditional power consumption. We improved the accuracy of diffractive network\nwith optical waves at different frequency. Each layers have multiple\nfrequency-channels (optical distributions at different frequency). These\nchannels are merged at the output plane to get final output. The experiment in\nthe fasion-MNIST and EMNIST datasets showed multiple frequency-channels would\nincrease the accuracy a lot. We also give detailed analysis to show the\ndifference between DNNet and MLP. The modulation process in DNNet is actually\noptical activation function. We develop an open source package ONNet. The\nsource codes are available at https://github.com/closest-git/ONNet.\n",
        "published": "2019",
        "authors": [
            "Yingshi Chen",
            "Jinfeng Zhu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.12049v1",
        "title": "Projection pursuit based on Gaussian mixtures and evolutionary\n  algorithms",
        "abstract": "  We propose a projection pursuit (PP) algorithm based on Gaussian mixture\nmodels (GMMs). The negentropy obtained from a multivariate density estimated by\nGMMs is adopted as the PP index to be maximised. For a fixed dimension of the\nprojection subspace, the GMM-based density estimation is projected onto that\nsubspace, where an approximation of the negentropy for Gaussian mixtures is\ncomputed. Then, Genetic Algorithms (GAs) are used to find the optimal,\northogonal projection basis by maximising the former approximation. We show\nthat this semi-parametric approach to PP is flexible and allows highly\ninformative structures to be detected, by projecting multivariate datasets onto\na subspace, where the data can be feasibly visualised. The performance of the\nproposed approach is shown on both artificial and real datasets.\n",
        "published": "2019",
        "authors": [
            "Luca Scrucca",
            "Alessio Serafini"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1912.12187v1",
        "title": "Learning Neural Activations",
        "abstract": "  An artificial neuron is modelled as a weighted summation followed by an\nactivation function which determines its output. A wide variety of activation\nfunctions such as rectified linear units (ReLU), leaky-ReLU, Swish, MISH, etc.\nhave been explored in the literature. In this short paper, we explore what\nhappens when the activation function of each neuron in an artificial neural\nnetwork is learned natively from data alone. This is achieved by modelling the\nactivation function of each neuron as a small neural network whose weights are\nshared by all neurons in the original network. We list our primary findings in\nthe conclusions section. The code for our analysis is available at:\nhttps://github.com/amina01/Learning-Neural-Activations.\n",
        "published": "2019",
        "authors": [
            "Fayyaz ul Amir Afsar Minhas",
            "Amina Asif"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2001.00689v2",
        "title": "A Neural Dirichlet Process Mixture Model for Task-Free Continual\n  Learning",
        "abstract": "  Despite the growing interest in continual learning, most of its contemporary\nworks have been studied in a rather restricted setting where tasks are clearly\ndistinguishable, and task boundaries are known during training. However, if our\ngoal is to develop an algorithm that learns as humans do, this setting is far\nfrom realistic, and it is essential to develop a methodology that works in a\ntask-free manner. Meanwhile, among several branches of continual learning,\nexpansion-based methods have the advantage of eliminating catastrophic\nforgetting by allocating new resources to learn new data. In this work, we\npropose an expansion-based approach for task-free continual learning. Our\nmodel, named Continual Neural Dirichlet Process Mixture (CN-DPM), consists of a\nset of neural network experts that are in charge of a subset of the data.\nCN-DPM expands the number of experts in a principled way under the Bayesian\nnonparametric framework. With extensive experiments, we show that our model\nsuccessfully performs task-free continual learning for both discriminative and\ngenerative tasks such as image classification and image generation.\n",
        "published": "2020",
        "authors": [
            "Soochan Lee",
            "Junsoo Ha",
            "Dongsu Zhang",
            "Gunhee Kim"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2001.01559v1",
        "title": "Universal Hysteresis Identification Using Extended Preisach Neural\n  Network",
        "abstract": "  Hysteresis phenomena have been observed in different branches of physics and\nengineering sciences. Therefore, several models have been proposed for\nhysteresis simulation in different fields; however, almost neither of them can\nbe utilized universally. In this paper by inspiring of Preisach Neural Network\nwhich was inspired by the Preisach model that basically stemmed from Madelungs\nrules and using the learning capability of the neural networks, an adaptive\nuniversal model for hysteresis is introduced and called Extended Preisach\nNeural Network Model. It is comprised of input, output and, two hidden layers.\nThe input and output layers contain linear neurons while the first hidden layer\nincorporates neurons called Deteriorating Stop neurons, which their activation\nfunction follows Deteriorating Stop operator. Deteriorating Stop operators can\ngenerate non-congruent hysteresis loops. The second hidden layer includes\nSigmoidal neurons. Adding the second hidden layer, helps the neural network\nlearn non-Masing and asymmetric hysteresis loops very smoothly. At the input\nlayer, besides input data the rate at which input data changes, is included as\nwell in order to give the model the capability of learning rate-dependent\nhysteresis loops. Hence, the proposed approach has the capability of the\nsimulation of both rate-independent and rate-dependent hysteresis with either\ncongruent or non-congruent loops as well as symmetric and asymmetric loops. A\nnew hybridized algorithm has been adopted for training the model which is based\non a combination of the Genetic Algorithm and the optimization method of\nsub-gradient with space dilatation. The generality of the proposed model has\nbeen evaluated by applying it to various hysteresis from different areas of\nengineering with different characteristics. The results show that the model is\nsuccessful in the identification of the considered hystereses.\n",
        "published": "2019",
        "authors": [
            "Mojtaba Farrokh",
            "Mehrdad Shafiei Dizaji",
            "Farzad Shafiei Dizaji",
            "Nazanin Moradinasab"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2001.01647v1",
        "title": "Are skip connections necessary for biologically plausible learning\n  rules?",
        "abstract": "  Backpropagation is the workhorse of deep learning, however, several other\nbiologically-motivated learning rules have been introduced, such as random\nfeedback alignment and difference target propagation. None of these methods\nhave produced a competitive performance against backpropagation. In this paper,\nwe show that biologically-motivated learning rules with skip connections\nbetween intermediate layers can perform as well as backpropagation on the MNIST\ndataset and are robust to various sets of hyper-parameters.\n",
        "published": "2019",
        "authors": [
            "Daniel Jiwoong Im",
            "Rutuja Patil",
            "Kristin Branson"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2001.01680v5",
        "title": "High-parallelism Inception-like Spiking Neural Networks for Unsupervised\n  Feature Learning",
        "abstract": "  Spiking Neural Networks (SNNs) are brain-inspired, event-driven machine\nlearning algorithms that have been widely recognized in producing\nultra-high-energy-efficient hardware. Among existing SNNs, unsupervised SNNs\nbased on synaptic plasticity, especially Spike-Timing-Dependent Plasticity\n(STDP), are considered to have great potential in imitating the learning\nprocess of the biological brain. Nevertheless, the existing STDP-based SNNs\nhave limitations in constrained learning capability and/or slow learning speed.\nMost STDP-based SNNs adopted a slow-learning Fully-Connected (FC) architecture\nand used a sub-optimal vote-based scheme for spike decoding. In this paper, we\novercome these limitations with: 1) a design of high-parallelism network\narchitecture, inspired by the Inception module in Artificial Neural Networks\n(ANNs); 2) use of a Vote-for-All (VFA) decoding layer as a replacement to the\nstandard vote-based spike decoding scheme, to reduce the information loss in\nspike decoding and, 3) a proposed adaptive repolarization (resetting) mechanism\nthat accelerates SNNs' learning by enhancing spiking activities. Our\nexperimental results on two established benchmark datasets (MNIST/EMNIST) show\nthat our network architecture resulted in superior performance compared to the\nwidely used FC architecture and a more advanced Locally-Connected (LC)\narchitecture, and that our SNN achieved competitive results with\nstate-of-the-art unsupervised SNNs (95.64%/80.11% accuracy on the MNIST/EMNISE\ndataset) while having superior learning efficiency and robustness against\nhardware damage. Our SNN achieved great classification accuracy with only\nhundreds of training iterations, and random destruction of large numbers of\nsynapses or neurons only led to negligible performance degradation.\n",
        "published": "2019",
        "authors": [
            "Mingyuan Meng",
            "Xingyu Yang",
            "Lei Bi",
            "Jinman Kim",
            "Shanlin Xiao",
            "Zhiyi Yu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2001.01682v3",
        "title": "Recognizing Images with at most one Spike per Neuron",
        "abstract": "  In order to port the performance of trained artificial neural networks (ANNs)\nto spiking neural networks (SNNs), which can be implemented in neuromorphic\nhardware with a drastically reduced energy consumption, an efficient ANN to SNN\nconversion is needed. Previous conversion schemes focused on the representation\nof the analog output of a rectified linear (ReLU) gate in the ANN by the firing\nrate of a spiking neuron. But this is not possible for other commonly used ANN\ngates, and it reduces the throughput even for ReLU gates. We introduce a new\nconversion method where a gate in the ANN, which can basically be of any type,\nis emulated by a small circuit of spiking neurons, with At Most One Spike\n(AMOS) per neuron. We show that this AMOS conversion improves the accuracy of\nSNNs for ImageNet from 74.60% to 80.97%, thereby bringing it within reach of\nthe best available ANN accuracy (85.0%). The Top5 accuracy of SNNs is raised to\n95.82%, getting even closer to the best Top5 performance of 97.2% for ANNs. In\naddition, AMOS conversion improves latency and throughput of spike-based image\nclassification by several orders of magnitude. Hence these results suggest that\nSNNs provide a viable direction for developing highly energy efficient hardware\nfor AI that combines high performance with versatility of applications.\n",
        "published": "2019",
        "authors": [
            "Christoph St\u00f6ckl",
            "Wolfgang Maass"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2001.01683v2",
        "title": "Deep Innovation Protection: Confronting the Credit Assignment Problem in\n  Training Heterogeneous Neural Architectures",
        "abstract": "  Deep reinforcement learning approaches have shown impressive results in a\nvariety of different domains, however, more complex heterogeneous architectures\nsuch as world models require the different neural components to be trained\nseparately instead of end-to-end. While a simple genetic algorithm recently\nshowed end-to-end training is possible, it failed to solve a more complex 3D\ntask. This paper presents a method called Deep Innovation Protection (DIP) that\naddresses the credit assignment problem in training complex heterogenous neural\nnetwork models end-to-end for such environments. The main idea behind the\napproach is to employ multiobjective optimization to temporally reduce the\nselection pressure on specific components in multi-component network, allowing\nother components to adapt. We investigate the emergent representations of these\nevolved networks, which learn to predict properties important for the survival\nof the agent, without the need for a specific forward-prediction loss.\n",
        "published": "2019",
        "authors": [
            "Sebastian Risi",
            "Kenneth O. Stanley"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2001.01684v1",
        "title": "Evolution Strategies Converges to Finite Differences",
        "abstract": "  Since the debut of Evolution Strategies (ES) as a tool for Reinforcement\nLearning by Salimans et al. 2017, there has been interest in determining the\nexact relationship between the Evolution Strategies gradient and the gradient\nof a similar class of algorithms, Finite Differences (FD).(Zhang et al. 2017,\nLehman et al. 2018) Several investigations into the subject have been\nperformed, investigating the formal motivational differences(Lehman et al.\n2018) between ES and FD, as well as the differences in a standard benchmark\nproblem in Machine Learning, the MNIST classification problem(Zhang et al.\n2017). This paper proves that while the gradients are different, they converge\nas the dimension of the vector under optimization increases.\n",
        "published": "2019",
        "authors": [
            "John C. Raisbeck",
            "Matthew Allen",
            "Ralph Weissleder",
            "Hyungsoon Im",
            "Hakho Lee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2001.01829v1",
        "title": "Frosting Weights for Better Continual Training",
        "abstract": "  Training a neural network model can be a lifelong learning process and is a\ncomputationally intensive one. A severe adverse effect that may occur in deep\nneural network models is that they can suffer from catastrophic forgetting\nduring retraining on new data. To avoid such disruptions in the continuous\nlearning, one appealing property is the additive nature of ensemble models. In\nthis paper, we propose two generic ensemble approaches, gradient boosting and\nmeta-learning, to solve the catastrophic forgetting problem in tuning\npre-trained neural network models.\n",
        "published": "2020",
        "authors": [
            "Xiaofeng Zhu",
            "Feng Liu",
            "Goce Trajcevski",
            "Dingding Wang"
        ]
    }
]