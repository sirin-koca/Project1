[
    {
        "id": "http://arxiv.org/abs/2008.00741v1",
        "title": "Low-loss connection of weight vectors: distribution-based approaches",
        "abstract": "  Recent research shows that sublevel sets of the loss surfaces of\noverparameterized networks are connected, exactly or approximately. We describe\nand compare experimentally a panel of methods used to connect two low-loss\npoints by a low-loss curve on this surface. Our methods vary in accuracy and\ncomplexity. Most of our methods are based on \"macroscopic\" distributional\nassumptions, and some are insensitive to the detailed properties of the points\nto be connected. Some methods require a prior training of a \"global connection\nmodel\" which can then be applied to any pair of points. The accuracy of the\nmethod generally correlates with its complexity and sensitivity to the endpoint\ndetail.\n",
        "published": "2020",
        "authors": [
            "Ivan Anokhin",
            "Dmitry Yarotsky"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.01352v3",
        "title": "PDE-Driven Spatiotemporal Disentanglement",
        "abstract": "  A recent line of work in the machine learning community addresses the problem\nof predicting high-dimensional spatiotemporal phenomena by leveraging specific\ntools from the differential equations theory. Following this direction, we\npropose in this article a novel and general paradigm for this task based on a\nresolution method for partial differential equations: the separation of\nvariables. This inspiration allows us to introduce a dynamical interpretation\nof spatiotemporal disentanglement. It induces a principled model based on\nlearning disentangled spatial and temporal representations of a phenomenon to\naccurately predict future observations. We experimentally demonstrate the\nperformance and broad applicability of our method against prior\nstate-of-the-art models on physical and synthetic video datasets.\n",
        "published": "2020",
        "authors": [
            "J\u00e9r\u00e9mie Don\u00e0",
            "Jean-Yves Franceschi",
            "Sylvain Lamprier",
            "Patrick Gallinari"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.01531v1",
        "title": "TOAD-GAN: Coherent Style Level Generation from a Single Example",
        "abstract": "  In this work, we present TOAD-GAN (Token-based One-shot Arbitrary Dimension\nGenerative Adversarial Network), a novel Procedural Content Generation (PCG)\nalgorithm that generates token-based video game levels. TOAD-GAN follows the\nSinGAN architecture and can be trained using only one example. We demonstrate\nits application for Super Mario Bros. levels and are able to generate new\nlevels of similar style in arbitrary sizes. We achieve state-of-the-art results\nin modeling the patterns of the training level and provide a comparison with\ndifferent baselines under several metrics. Additionally, we present an\nextension of the method that allows the user to control the generation process\nof certain token structures to ensure a coherent global level layout. We\nprovide this tool to the community to spur further research by publishing our\nsource code.\n",
        "published": "2020",
        "authors": [
            "Maren Awiszus",
            "Frederik Schubert",
            "Bodo Rosenhahn"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.01967v1",
        "title": "Annealing Genetic GAN for Minority Oversampling",
        "abstract": "  The key to overcome class imbalance problems is to capture the distribution\nof minority class accurately. Generative Adversarial Networks (GANs) have shown\nsome potentials to tackle class imbalance problems due to their capability of\nreproducing data distributions given ample training data samples. However, the\nscarce samples of one or more classes still pose a great challenge for GANs to\nlearn accurate distributions for the minority classes. In this work, we propose\nan Annealing Genetic GAN (AGGAN) method, which aims to reproduce the\ndistributions closest to the ones of the minority classes using only limited\ndata samples. Our AGGAN renovates the training of GANs as an evolutionary\nprocess that incorporates the mechanism of simulated annealing. In particular,\nthe generator uses different training strategies to generate multiple offspring\nand retain the best. Then, we use the Metropolis criterion in the simulated\nannealing to decide whether we should update the best offspring for the\ngenerator. As the Metropolis criterion allows a certain chance to accept the\nworse solutions, it enables our AGGAN steering away from the local optimum.\nAccording to both theoretical analysis and experimental studies on multiple\nimbalanced image datasets, we prove that the proposed training strategy can\nenable our AGGAN to reproduce the distributions of minority classes from scarce\nsamples and provide an effective and robust solution for the class imbalance\nproblem.\n",
        "published": "2020",
        "authors": [
            "Jingyu Hao",
            "Chengjia Wang",
            "Heye Zhang",
            "Guang Yang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.03501v1",
        "title": "Why to \"grow\" and \"harvest\" deep learning models?",
        "abstract": "  Current expectations from training deep learning models with gradient-based\nmethods include: 1) transparency; 2) high convergence rates; 3) high inductive\nbiases. While the state-of-art methods with adaptive learning rate schedules\nare fast, they still fail to meet the other two requirements. We suggest\nreconsidering neural network models in terms of single-species population\ndynamics where adaptation comes naturally from open-ended processes of \"growth\"\nand \"harvesting\". We show that the stochastic gradient descent (SGD) with two\nbalanced pre-defined values of per capita growth and harvesting rates\noutperform the most common adaptive gradient methods in all of the three\nrequirements.\n",
        "published": "2020",
        "authors": [
            "Ilona Kulikovskikh",
            "Tarzan Legovi\u0107"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.03543v1",
        "title": "A Novel Community Detection Based Genetic Algorithm for Feature\n  Selection",
        "abstract": "  The selection of features is an essential data preprocessing stage in data\nmining. The core principle of feature selection seems to be to pick a subset of\npossible features by excluding features with almost no predictive information\nas well as highly associated redundant features. In the past several years, a\nvariety of meta-heuristic methods were introduced to eliminate redundant and\nirrelevant features as much as possible from high-dimensional datasets. Among\nthe main disadvantages of present meta-heuristic based approaches is that they\nare often neglecting the correlation between a set of selected features. In\nthis article, for the purpose of feature selection, the authors propose a\ngenetic algorithm based on community detection, which functions in three steps.\nThe feature similarities are calculated in the first step. The features are\nclassified by community detection algorithms into clusters throughout the\nsecond step. In the third step, features are picked by a genetic algorithm with\na new community-based repair operation. Nine benchmark classification problems\nwere analyzed in terms of the performance of the presented approach. Also, the\nauthors have compared the efficiency of the proposed approach with the findings\nfrom four available algorithms for feature selection. The findings indicate\nthat the new approach continuously yields improved classification accuracy.\n",
        "published": "2020",
        "authors": [
            "Mehrdad Rostami",
            "Kamal Berahmand",
            "Saman Forouzandeh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.03658v3",
        "title": "DIET-SNN: Direct Input Encoding With Leakage and Threshold Optimization\n  in Deep Spiking Neural Networks",
        "abstract": "  Bio-inspired spiking neural networks (SNNs), operating with asynchronous\nbinary signals (or spikes) distributed over time, can potentially lead to\ngreater computational efficiency on event-driven hardware. The state-of-the-art\nSNNs suffer from high inference latency, resulting from inefficient input\nencoding, and sub-optimal settings of the neuron parameters (firing threshold,\nand membrane leak). We propose DIET-SNN, a low-latency deep spiking network\nthat is trained with gradient descent to optimize the membrane leak and the\nfiring threshold along with other network parameters (weights). The membrane\nleak and threshold for each layer of the SNN are optimized with end-to-end\nbackpropagation to achieve competitive accuracy at reduced latency. The analog\npixel values of an image are directly applied to the input layer of DIET-SNN\nwithout the need to convert to spike-train. The first convolutional layer is\ntrained to convert inputs into spikes where leaky-integrate-and-fire (LIF)\nneurons integrate the weighted inputs and generate an output spike when the\nmembrane potential crosses the trained firing threshold. The trained membrane\nleak controls the flow of input information and attenuates irrelevant inputs to\nincrease the activation sparsity in the convolutional and dense layers of the\nnetwork. The reduced latency combined with high activation sparsity provides\nlarge improvements in computational efficiency. We evaluate DIET-SNN on image\nclassification tasks from CIFAR and ImageNet datasets on VGG and ResNet\narchitectures. We achieve top-1 accuracy of 69% with 5 timesteps (inference\nlatency) on the ImageNet dataset with 12x less compute energy than an\nequivalent standard ANN. Additionally, DIET-SNN performs 20-500x faster\ninference compared to other state-of-the-art SNN models.\n",
        "published": "2020",
        "authors": [
            "Nitin Rathi",
            "Kaushik Roy"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.03936v1",
        "title": "Intelligent Matrix Exponentiation",
        "abstract": "  We present a novel machine learning architecture that uses the exponential of\na single input-dependent matrix as its only nonlinearity. The mathematical\nsimplicity of this architecture allows a detailed analysis of its behaviour,\nproviding robustness guarantees via Lipschitz bounds. Despite its simplicity, a\nsingle matrix exponential layer already provides universal approximation\nproperties and can learn fundamental functions of the input, such as periodic\nfunctions or multivariate polynomials. This architecture outperforms other\ngeneral-purpose architectures on benchmark problems, including CIFAR-10, using\nsubstantially fewer parameters.\n",
        "published": "2020",
        "authors": [
            "Thomas Fischbacher",
            "Iulia M. Comsa",
            "Krzysztof Potempa",
            "Moritz Firsching",
            "Luca Versari",
            "Jyrki Alakuijala"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.04103v1",
        "title": "Review of Swarm Intelligence-based Feature Selection Methods",
        "abstract": "  In the past decades, the rapid growth of computer and database technologies\nhas led to the rapid growth of large-scale datasets. On the other hand, data\nmining applications with high dimensional datasets that require high speed and\naccuracy are rapidly increasing. An important issue with these applications is\nthe curse of dimensionality, where the number of features is much higher than\nthe number of patterns. One of the dimensionality reduction approaches is\nfeature selection that can increase the accuracy of the data mining task and\nreduce its computational complexity. The feature selection method aims at\nselecting a subset of features with the lowest inner similarity and highest\nrelevancy to the target class. It reduces the dimensionality of the data by\neliminating irrelevant, redundant, or noisy data. In this paper, a comparative\nanalysis of different feature selection methods is presented, and a general\ncategorization of these methods is performed. Moreover, in this paper,\nstate-of-the-art swarm intelligence are studied, and the recent feature\nselection methods based on these algorithms are reviewed. Furthermore, the\nstrengths and weaknesses of the different studied swarm intelligence-based\nfeature selection methods are evaluated.\n",
        "published": "2020",
        "authors": [
            "Mehrdad Rostami",
            "Kamal Berahmand",
            "Saman Forouzandeh"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.06395v3",
        "title": "Supervised Topological Maps",
        "abstract": "  Controlling the internal representation space of a neural network is a\ndesirable feature because it allows to generate new data in a supervised\nmanner. In this paper we will show how this can be achieved while building a\nlow-dimensional mapping of the input stream, by deriving a generalized\nalgorithm starting from Self Organizing Maps (SOMs). SOMs are a kind of neural\nnetwork which can be trained with unsupervised learning to produce a\nlow-dimensional discretized mapping of the input space. They can be used for\nthe generation of new data through backward propagation of interpolations made\nfrom the mapping grid. Unfortunately the final topology of the mapping space of\na SOM is not known before learning, so interpolating new data in a supervised\nway is not an easy task. Here we will show a variation from the SOM algorithm\nconsisting in constraining the update of prototypes so that it is also a\nfunction of the distance of its prototypes from extrinsically given targets in\nthe mapping space. We will demonstrate how such variants, that we will call\nSupervised Topological Maps (STMs), allow for a supervised mapping where the\nposition of internal representations in the mapping space is determined by the\nexperimenter. Controlling the internal representation space in STMs reveals to\nbe an easier task than what is currently done using other algorithms such as\nvariational or adversarial autoencoders.\n",
        "published": "2020",
        "authors": [
            "Francesco Mannella"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.06885v2",
        "title": "Adaptive Signal Variances: CNN Initialization Through Modern\n  Architectures",
        "abstract": "  Deep convolutional neural networks (CNN) have achieved the unwavering\nconfidence in its performance on image processing tasks. The CNN architecture\nconstitutes a variety of different types of layers including the convolution\nlayer and the max-pooling layer. CNN practitioners widely understand the fact\nthat the stability of learning depends on how to initialize the model\nparameters in each layer. Nowadays, no one doubts that the de facto standard\nscheme for initialization is the so-called Kaiming initialization that has been\ndeveloped by He et al. The Kaiming scheme was derived from a much simpler model\nthan the currently used CNN structure having evolved since the emergence of the\nKaiming scheme. The Kaiming model consists only of the convolution and fully\nconnected layers, ignoring the max-pooling layer and the global average pooling\nlayer. In this study, we derived the initialization scheme again not from the\nsimplified Kaiming model, but precisely from the modern CNN architectures, and\nempirically investigated how the new initialization method performs compared to\nthe de facto standard ones that are widely used today.\n",
        "published": "2020",
        "authors": [
            "Takahiko Henmi",
            "Esmeraldo Ronnie Rey Zara",
            "Yoshihiro Hirohashi",
            "Tsuyoshi Kato"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.08750v1",
        "title": "Prototype-based interpretation of the functionality of neurons in\n  winner-take-all neural networks",
        "abstract": "  Prototype-based learning (PbL) using a winner-take-all (WTA) network based on\nminimum Euclidean distance (ED-WTA) is an intuitive approach to multiclass\nclassification. By constructing meaningful class centers, PbL provides higher\ninterpretability and generalization than hyperplane-based learning (HbL)\nmethods based on maximum Inner Product (IP-WTA) and can efficiently detect and\nreject samples that do not belong to any classes. In this paper, we first prove\nthe equivalence of IP-WTA and ED-WTA from a representational point of view.\nThen, we show that naively using this equivalence leads to unintuitive ED-WTA\nnetworks in which the centers have high distances to data that they represent.\nWe propose $\\pm$ED-WTA which models each neuron with two prototypes: one\npositive prototype representing samples that are modeled by this neuron and a\nnegative prototype representing the samples that are erroneously won by that\nneuron during training. We propose a novel training algorithm for the\n$\\pm$ED-WTA network, which cleverly switches between updating the positive and\nnegative prototypes and is essential to the emergence of interpretable\nprototypes. Unexpectedly, we observed that the negative prototype of each\nneuron is indistinguishably similar to the positive one. The rationale behind\nthis observation is that the training data that are mistaken with a prototype\nare indeed similar to it. The main finding of this paper is this interpretation\nof the functionality of neurons as computing the difference between the\ndistances to a positive and a negative prototype, which is in agreement with\nthe BCM theory. In our experiments, we show that the proposed $\\pm$ED-WTA\nmethod constructs highly interpretable prototypes that can be successfully used\nfor detecting outlier and adversarial examples.\n",
        "published": "2020",
        "authors": [
            "Ramin Zarei Sabzevar",
            "Kamaledin Ghiasi-Shirazi",
            "Ahad Harati"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.09903v1",
        "title": "iCVI-ARTMAP: Accelerating and improving clustering using adaptive\n  resonance theory predictive mapping and incremental cluster validity indices",
        "abstract": "  This paper presents an adaptive resonance theory predictive mapping (ARTMAP)\nmodel which uses incremental cluster validity indices (iCVIs) to perform\nunsupervised learning, namely iCVI-ARTMAP. Incorporating iCVIs to the\ndecision-making and many-to-one mapping capabilities of ARTMAP can improve the\nchoices of clusters to which samples are incrementally assigned. These\nimprovements are accomplished by intelligently performing the operations of\nswapping sample assignments between clusters, splitting and merging clusters,\nand caching the values of variables when iCVI values need to be recomputed.\nUsing recursive formulations enables iCVI-ARTMAP to considerably reduce the\ncomputational burden associated with cluster validity index (CVI)-based offline\nclustering. Depending on the iCVI and the data set, it can achieve running\ntimes up to two orders of magnitude shorter than when using batch CVI\ncomputations. In this work, the incremental versions of Calinski-Harabasz,\nWB-index, Xie-Beni, Davies-Bouldin, Pakhira-Bandyopadhyay-Maulik, and\nnegentropy increment were integrated into fuzzy ARTMAP. Experimental results\nshow that, with proper choice of iCVI, iCVI-ARTMAP outperformed fuzzy adaptive\nresonance theory (ART), dual vigilance fuzzy ART, kmeans, spectral clustering,\nGaussian mixture models and hierarchical agglomerative clustering algorithms in\nmost of the synthetic benchmark data sets. It also performed competitively on\nreal world image benchmark data sets when clustering on projections and on\nlatent spaces generated by a deep clustering model. Naturally, the performance\nof iCVI-ARTMAP is subject to the selected iCVI and its suitability to the data\nat hand; fortunately, it is a general model wherein other iCVIs can be easily\nembedded.\n",
        "published": "2020",
        "authors": [
            "Leonardo Enzo Brito da Silva",
            "Nagasharath Rayapati",
            "Donald C. Wunsch II"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2008.10425v1",
        "title": "Efficient Design of Neural Networks with Random Weights",
        "abstract": "  Single layer feedforward networks with random weights are known for their\nnon-iterative and fast training algorithms and are successful in a variety of\nclassification and regression problems. A major drawback of these networks is\nthat they require a large number of hidden units. In this paper, we propose a\ntechnique to reduce the number of hidden units substantially without affecting\nthe accuracy of the networks significantly. We introduce the concept of primary\nand secondary hidden units. The weights for the primary hidden units are chosen\nrandomly while the secondary hidden units are derived using pairwise\ncombinations of the primary hidden units. Using this technique, we show that\nthe number of hidden units can be reduced by at least one order of magnitude.\nWe experimentally show that this technique leads to significant drop in\ncomputations at inference time and has only a minor impact on network accuracy.\nA huge reduction in computations is possible if slightly lower accuracy is\nacceptable.\n",
        "published": "2020",
        "authors": [
            "Ajay M. Patrikar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.00788v2",
        "title": "Effective Regularization Through Loss-Function Metalearning",
        "abstract": "  Evolutionary optimization, such as the TaylorGLO method, can be used to\ndiscover novel, customized loss functions for deep neural networks, resulting\nin improved performance, faster training, and improved data utilization. A\nlikely explanation is that such functions discourage overfitting, leading to\neffective regularization. This paper demonstrates theoretically that this is\nindeed the case for TaylorGLO: Decomposition of learning rules makes it\npossible to characterize the training dynamics and show that the loss functions\nevolved by TaylorGLO balance the pull to zero error, and a push away from it to\navoid overfitting. They may also automatically take advantage of label\nsmoothing. This analysis leads to an invariant that can be utilized to make the\nmetalearning process more efficient in practice; the mechanism also results in\nnetworks that are robust against adversarial attacks. Loss-function evolution\ncan thus be seen as a well-founded new aspect of metalearning in neural\nnetworks.\n",
        "published": "2020",
        "authors": [
            "Santiago Gonzalez",
            "Risto Miikkulainen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.00951v2",
        "title": "Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and\n  (gradient) stable architecture for learning long time dependencies",
        "abstract": "  Circuits of biological neurons, such as in the functional parts of the brain\ncan be modeled as networks of coupled oscillators. Inspired by the ability of\nthese systems to express a rich set of outputs while keeping (gradients of)\nstate variables bounded, we propose a novel architecture for recurrent neural\nnetworks. Our proposed RNN is based on a time-discretization of a system of\nsecond-order ordinary differential equations, modeling networks of controlled\nnonlinear oscillators. We prove precise bounds on the gradients of the hidden\nstates, leading to the mitigation of the exploding and vanishing gradient\nproblem for this RNN. Experiments show that the proposed RNN is comparable in\nperformance to the state of the art on a variety of benchmarks, demonstrating\nthe potential of this architecture to provide stable and accurate RNNs for\nprocessing complex sequential data.\n",
        "published": "2020",
        "authors": [
            "T. Konstantin Rusch",
            "Siddhartha Mishra"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.01039v2",
        "title": "Query complexity of adversarial attacks",
        "abstract": "  There are two main attack models considered in the adversarial robustness\nliterature: black-box and white-box. We consider these threat models as two\nends of a fine-grained spectrum, indexed by the number of queries the adversary\ncan ask. Using this point of view we investigate how many queries the adversary\nneeds to make to design an attack that is comparable to the best possible\nattack in the white-box model. We give a lower bound on that number of queries\nin terms of entropy of decision boundaries of the classifier. Using this result\nwe analyze two classical learning algorithms on two synthetic tasks for which\nwe prove meaningful security guarantees. The obtained bounds suggest that some\nlearning algorithms are inherently more robust against query-bounded\nadversaries than others.\n",
        "published": "2020",
        "authors": [
            "Grzegorz G\u0142uch",
            "R\u00fcdiger Urbanke"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.03733v1",
        "title": "Neural Group Actions",
        "abstract": "  We introduce an algorithm for designing Neural Group Actions, collections of\ndeep neural network architectures which model symmetric transformations\nsatisfying the laws of a given finite group. This generalizes involutive neural\nnetworks $\\mathcal{N}$, which satisfy $\\mathcal{N}(\\mathcal{N}(x))=x$ for any\ndata $x$, the group law of $\\mathbb{Z}_2$. We show how to optionally enforce an\nadditional constraint that the group action be volume-preserving. We\nconjecture, by analogy to a universality result for involutive neural networks,\nthat generative models built from Neural Group Actions are universal\napproximators for collections of probabilistic transitions adhering to the\ngroup laws. We demonstrate experimentally that a Neural Group Action for the\nquaternion group $Q_8$ can learn how a set of nonuniversal quantum gates\nsatisfying the $Q_8$ group laws act on single qubit quantum states.\n",
        "published": "2020",
        "authors": [
            "Span Spanbauer",
            "Luke Sciarappa"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.04216v1",
        "title": "Affine-Invariant Robust Training",
        "abstract": "  The field of adversarial robustness has attracted significant attention in\nmachine learning. Contrary to the common approach of training models that are\naccurate in average case, it aims at training models that are accurate for\nworst case inputs, hence it yields more robust and reliable models. Put\ndifferently, it tries to prevent an adversary from fooling a model. The study\nof adversarial robustness is largely focused on $\\ell_p-$bounded adversarial\nperturbations, i.e. modifications of the inputs, bounded in some $\\ell_p$ norm.\nNevertheless, it has been shown that state-of-the-art models are also\nvulnerable to other more natural perturbations such as affine transformations,\nwhich were already considered in machine learning within data augmentation.\nThis project reviews previous work in spatial robustness methods and proposes\nevolution strategies as zeroth order optimization algorithms to find the worst\naffine transforms for each input. The proposed method effectively yields robust\nmodels and allows introducing non-parametric adversarial perturbations.\n",
        "published": "2020",
        "authors": [
            "Oriol Barbany Mayor"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.04261v6",
        "title": "Dissecting Hessian: Understanding Common Structure of Hessian in Neural\n  Networks",
        "abstract": "  Hessian captures important properties of the deep neural network loss\nlandscape. Previous works have observed low rank structure in the Hessians of\nneural networks. In this paper, we propose a decoupling conjecture that\ndecomposes the layer-wise Hessians of a network as the Kronecker product of two\nsmaller matrices. We can analyze the properties of these smaller matrices and\nprove the structure of top eigenspace random 2-layer networks. The decoupling\nconjecture has several other interesting implications - top eigenspaces for\ndifferent models have surprisingly high overlap, and top eigenvectors form low\nrank matrices when they are reshaped into the same shape as the corresponding\nweight matrix. All of these can be verified empirically for deeper networks.\nFinally, we use the structure of layer-wise Hessian to get better explicit\ngeneralization bounds for neural networks.\n",
        "published": "2020",
        "authors": [
            "Yikai Wu",
            "Xingyu Zhu",
            "Chenwei Wu",
            "Annie Wang",
            "Rong Ge"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.08508v1",
        "title": "For self-supervised learning, Rationality implies generalization,\n  provably",
        "abstract": "  We prove a new upper bound on the generalization gap of classifiers that are\nobtained by first using self-supervision to learn a representation $r$ of the\ntraining data, and then fitting a simple (e.g., linear) classifier $g$ to the\nlabels. Specifically, we show that (under the assumptions described below) the\ngeneralization gap of such classifiers tends to zero if $\\mathsf{C}(g) \\ll n$,\nwhere $\\mathsf{C}(g)$ is an appropriately-defined measure of the simple\nclassifier $g$'s complexity, and $n$ is the number of training samples. We\nstress that our bound is independent of the complexity of the representation\n$r$. We do not make any structural or conditional-independence assumptions on\nthe representation-learning task, which can use the same training dataset that\nis later used for classification. Rather, we assume that the training procedure\nsatisfies certain natural noise-robustness (adding small amount of label noise\ncauses small degradation in performance) and rationality (getting the wrong\nlabel is not better than getting no label at all) conditions that widely hold\nacross many standard architectures. We show that our bound is non-vacuous for\nmany popular representation-learning based classifiers on CIFAR-10 and\nImageNet, including SimCLR, AMDIM and MoCo.\n",
        "published": "2020",
        "authors": [
            "Yamini Bansal",
            "Gal Kaplun",
            "Boaz Barak"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.08853v3",
        "title": "From Local Structures to Size Generalization in Graph Neural Networks",
        "abstract": "  Graph neural networks (GNNs) can process graphs of different sizes, but their\nability to generalize across sizes, specifically from small to large graphs, is\nstill not well understood. In this paper, we identify an important type of data\nwhere generalization from small to large graphs is challenging: graph\ndistributions for which the local structure depends on the graph size. This\neffect occurs in multiple important graph learning domains, including social\nand biological networks. We first prove that when there is a difference between\nthe local structures, GNNs are not guaranteed to generalize across sizes: there\nare \"bad\" global minima that do well on small graphs but fail on large graphs.\nWe then study the size-generalization problem empirically and demonstrate that\nwhen there is a discrepancy in local structure, GNNs tend to converge to\nnon-generalizing solutions. Finally, we suggest two approaches for improving\nsize generalization, motivated by our findings. Notably, we propose a novel\nSelf-Supervised Learning (SSL) task aimed at learning meaningful\nrepresentations of local structures that appear in large graphs. Our SSL task\nimproves classification accuracy on several popular datasets.\n",
        "published": "2020",
        "authors": [
            "Gilad Yehudai",
            "Ethan Fetaya",
            "Eli Meirom",
            "Gal Chechik",
            "Haggai Maron"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.09923v1",
        "title": "Anti-Distillation: Improving reproducibility of deep networks",
        "abstract": "  Deep networks have been revolutionary in improving performance of machine\nlearning and artificial intelligence systems. Their high prediction accuracy,\nhowever, comes at a price of \\emph{model irreproducibility\\/} in very high\nlevels that do not occur with classical linear models. Two models, even if they\nare supposedly identical, with identical architecture and identical trained\nparameter sets, and that are trained on the same set of training examples,\nwhile possibly providing identical average prediction accuracies, may predict\nvery differently on individual, previously unseen, examples. \\emph{Prediction\ndifferences\\/} may be as large as the order of magnitude of the predictions\nthemselves. Ensembles have been shown to somewhat mitigate this behavior, but\nwithout an extra push, may not be utilizing their full potential. In this work,\na novel approach, \\emph{Anti-Distillation\\/}, is proposed to address\nirreproducibility in deep networks, where ensemble models are used to generate\npredictions. Anti-Distillation forces ensemble components away from one another\nby techniques like de-correlating their outputs over mini-batches of examples,\nforcing them to become even more different and more diverse. Doing so enhances\nthe benefit of ensembles, making the final predictions more reproducible.\nEmpirical results demonstrate substantial prediction difference reductions\nachieved by Anti-Distillation on benchmark and real datasets.\n",
        "published": "2020",
        "authors": [
            "Gil I. Shamir",
            "Lorenzo Coviello"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.09931v2",
        "title": "Smooth activations and reproducibility in deep networks",
        "abstract": "  Deep networks are gradually penetrating almost every domain in our lives due\nto their amazing success. However, with substantive performance accuracy\nimprovements comes the price of \\emph{irreproducibility}. Two identical models,\ntrained on the exact same training dataset may exhibit large differences in\npredictions on individual examples even when average accuracy is similar,\nespecially when trained on highly distributed parallel systems. The popular\nRectified Linear Unit (ReLU) activation has been key to recent success of deep\nnetworks. We demonstrate, however, that ReLU is also a catalyzer to\nirreproducibility in deep networks. We show that not only can activations\nsmoother than ReLU provide better accuracy, but they can also provide better\naccuracy-reproducibility tradeoffs. We propose a new family of activations;\nSmooth ReLU (\\emph{SmeLU}), designed to give such better tradeoffs, while also\nkeeping the mathematical expression simple, and thus implementation cheap.\nSmeLU is monotonic, mimics ReLU, while providing continuous gradients, yielding\nbetter reproducibility. We generalize SmeLU to give even more flexibility and\nthen demonstrate that SmeLU and its generalized form are special cases of a\nmore general methodology of REctified Smooth Continuous Unit (RESCU)\nactivations. Empirical results demonstrate the superior\naccuracy-reproducibility tradeoffs with smooth activations, SmeLU in\nparticular.\n",
        "published": "2020",
        "authors": [
            "Gil I. Shamir",
            "Dong Lin",
            "Lorenzo Coviello"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.10177v2",
        "title": "Sparse Gaussian Process Variational Autoencoders",
        "abstract": "  Large, multi-dimensional spatio-temporal datasets are omnipresent in modern\nscience and engineering. An effective framework for handling such data are\nGaussian process deep generative models (GP-DGMs), which employ GP priors over\nthe latent variables of DGMs. Existing approaches for performing inference in\nGP-DGMs do not support sparse GP approximations based on inducing points, which\nare essential for the computational efficiency of GPs, nor do they handle\nmissing data -- a natural occurrence in many spatio-temporal datasets -- in a\nprincipled manner. We address these shortcomings with the development of the\nsparse Gaussian process variational autoencoder (SGP-VAE), characterised by the\nuse of partial inference networks for parameterising sparse GP approximations.\nLeveraging the benefits of amortised variational inference, the SGP-VAE enables\ninference in multi-output sparse GPs on previously unobserved data with no\nadditional training. The SGP-VAE is evaluated in a variety of experiments where\nit outperforms alternative approaches including multi-output GPs and structured\nVAEs.\n",
        "published": "2020",
        "authors": [
            "Matthew Ashman",
            "Jonathan So",
            "Will Tebbutt",
            "Vincent Fortuin",
            "Michael Pearce",
            "Richard E. Turner"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.10604v1",
        "title": "Bayesian Attention Modules",
        "abstract": "  Attention modules, as simple and effective tools, have not only enabled deep\nneural networks to achieve state-of-the-art results in many domains, but also\nenhanced their interpretability. Most current models use deterministic\nattention modules due to their simplicity and ease of optimization. Stochastic\ncounterparts, on the other hand, are less popular despite their potential\nbenefits. The main reason is that stochastic attention often introduces\noptimization issues or requires significant model changes. In this paper, we\npropose a scalable stochastic version of attention that is easy to implement\nand optimize. We construct simplex-constrained attention distributions by\nnormalizing reparameterizable distributions, making the training process\ndifferentiable. We learn their parameters in a Bayesian framework where a\ndata-dependent prior is introduced for regularization. We apply the proposed\nstochastic attention modules to various attention-based models, with\napplications to graph node classification, visual question answering, image\ncaptioning, machine translation, and language understanding. Our experiments\nshow the proposed method brings consistent improvements over the corresponding\nbaselines.\n",
        "published": "2020",
        "authors": [
            "Xinjie Fan",
            "Shujian Zhang",
            "Bo Chen",
            "Mingyuan Zhou"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.12644v1",
        "title": "A biologically plausible neural network for Slow Feature Analysis",
        "abstract": "  Learning latent features from time series data is an important problem in\nboth machine learning and brain function. One approach, called Slow Feature\nAnalysis (SFA), leverages the slowness of many salient features relative to the\nrapidly varying input signals. Furthermore, when trained on naturalistic\nstimuli, SFA reproduces interesting properties of cells in the primary visual\ncortex and hippocampus, suggesting that the brain uses temporal slowness as a\ncomputational principle for learning latent features. However, despite the\npotential relevance of SFA for modeling brain function, there is currently no\nSFA algorithm with a biologically plausible neural network implementation, by\nwhich we mean an algorithm operates in the online setting and can be mapped\nonto a neural network with local synaptic updates. In this work, starting from\nan SFA objective, we derive an SFA algorithm, called Bio-SFA, with a\nbiologically plausible neural network implementation. We validate Bio-SFA on\nnaturalistic stimuli.\n",
        "published": "2020",
        "authors": [
            "David Lipshutz",
            "Charlie Windolf",
            "Siavash Golkar",
            "Dmitri B. Chklovskii"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.14075v4",
        "title": "Neural Network Approximation: Three Hidden Layers Are Enough",
        "abstract": "  A three-hidden-layer neural network with super approximation power is\nintroduced. This network is built with the floor function ($\\lfloor x\\rfloor$),\nthe exponential function ($2^x$), the step function ($1_{x\\geq 0}$), or their\ncompositions as the activation function in each neuron and hence we call such\nnetworks as Floor-Exponential-Step (FLES) networks. For any width\nhyper-parameter $N\\in\\mathbb{N}^+$, it is shown that FLES networks with width\n$\\max\\{d,N\\}$ and three hidden layers can uniformly approximate a H\\\"older\ncontinuous function $f$ on $[0,1]^d$ with an exponential approximation rate\n$3\\lambda (2\\sqrt{d})^{\\alpha} 2^{-\\alpha N}$, where $\\alpha \\in(0,1]$ and\n$\\lambda>0$ are the H\\\"older order and constant, respectively. More generally\nfor an arbitrary continuous function $f$ on $[0,1]^d$ with a modulus of\ncontinuity $\\omega_f(\\cdot)$, the constructive approximation rate is\n$2\\omega_f(2\\sqrt{d}){2^{-N}}+\\omega_f(2\\sqrt{d}\\,2^{-N})$. Moreover, we extend\nsuch a result to general bounded continuous functions on a bounded set\n$E\\subseteq\\mathbb{R}^d$. As a consequence, this new class of networks\novercomes the curse of dimensionality in approximation power when the variation\nof $\\omega_f(r)$ as $r\\rightarrow 0$ is moderate (e.g., $\\omega_f(r)\\lesssim\nr^\\alpha$ for H\\\"older continuous functions), since the major term to be\nconcerned in our approximation rate is essentially $\\sqrt{d}$ times a function\nof $N$ independent of $d$ within the modulus of continuity. Finally, we extend\nour analysis to derive similar approximation results in the $L^p$-norm for\n$p\\in[1,\\infty)$ via replacing Floor-Exponential-Step activation functions by\ncontinuous activation functions.\n",
        "published": "2020",
        "authors": [
            "Zuowei Shen",
            "Haizhao Yang",
            "Shijun Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.14615v1",
        "title": "Discrete-time signatures and randomness in reservoir computing",
        "abstract": "  A new explanation of geometric nature of the reservoir computing phenomenon\nis presented. Reservoir computing is understood in the literature as the\npossibility of approximating input/output systems with randomly chosen\nrecurrent neural systems and a trained linear readout layer. Light is shed on\nthis phenomenon by constructing what is called strongly universal reservoir\nsystems as random projections of a family of state-space systems that generate\nVolterra series expansions. This procedure yields a state-affine reservoir\nsystem with randomly generated coefficients in a dimension that is\nlogarithmically reduced with respect to the original system. This reservoir\nsystem is able to approximate any element in the fading memory filters class\njust by training a different linear readout for each different filter. Explicit\nexpressions for the probability distributions needed in the generation of the\nprojected reservoir system are stated and bounds for the committed\napproximation error are provided.\n",
        "published": "2020",
        "authors": [
            "Christa Cuchiero",
            "Lukas Gonon",
            "Lyudmila Grigoryeva",
            "Juan-Pablo Ortega",
            "Josef Teichmann"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.15571v4",
        "title": "Learning Sub-Patterns in Piecewise Continuous Functions",
        "abstract": "  Most stochastic gradient descent algorithms can optimize neural networks that\nare sub-differentiable in their parameters; however, this implies that the\nneural network's activation function must exhibit a degree of continuity which\nlimits the neural network model's uniform approximation capacity to continuous\nfunctions. This paper focuses on the case where the discontinuities arise from\ndistinct sub-patterns, each defined on different parts of the input space. We\npropose a new discontinuous deep neural network model trainable via a decoupled\ntwo-step procedure that avoids passing gradient updates through the network's\nonly and strategically placed, discontinuous unit. We provide approximation\nguarantees for our architecture in the space of bounded continuous functions\nand universal approximation guarantees in the space of piecewise continuous\nfunctions which we introduced herein. We present a novel semi-supervised\ntwo-step training procedure for our discontinuous deep learning model, tailored\nto its structure, and we provide theoretical support for its effectiveness. The\nperformance of our model and trained with the propose procedure is evaluated\nexperimentally on both real-world financial datasets and synthetic datasets.\n",
        "published": "2020",
        "authors": [
            "Anastasis Kratsios",
            "Behnoosh Zamanlooy"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.16358v2",
        "title": "AgEBO-Tabular: Joint Neural Architecture and Hyperparameter Search with\n  Autotuned Data-Parallel Training for Tabular Data",
        "abstract": "  Developing high-performing predictive models for large tabular data sets is a\nchallenging task. The state-of-the-art methods are based on expert-developed\nmodel ensembles from different supervised learning methods. Recently, automated\nmachine learning (AutoML) is emerging as a promising approach to automate\npredictive model development. Neural architecture search (NAS) is an AutoML\napproach that generates and evaluates multiple neural network architectures\nconcurrently and improves the accuracy of the generated models iteratively. A\nkey issue in NAS, particularly for large data sets, is the large computation\ntime required to evaluate each generated architecture. While data-parallel\ntraining is a promising approach that can address this issue, its use within\nNAS is difficult. For different data sets, the data-parallel training settings\nsuch as the number of parallel processes, learning rate, and batch size need to\nbe adapted to achieve high accuracy and reduction in training time. To that\nend, we have developed AgEBO-Tabular, an approach to combine aging evolution\n(AgE), a parallel NAS method that searches over neural architecture space, and\nan asynchronous Bayesian optimization method for tuning the hyperparameters of\nthe data-parallel training simultaneously. We demonstrate the efficacy of the\nproposed method to generate high-performing neural network models for large\ntabular benchmark data sets. Furthermore, we demonstrate that the automatically\ndiscovered neural network models using our method outperform the\nstate-of-the-art AutoML ensemble models in inference speed by two orders of\nmagnitude while reaching similar accuracy values.\n",
        "published": "2020",
        "authors": [
            "Romain Egele",
            "Prasanna Balaprakash",
            "Venkatram Vishwanath",
            "Isabelle Guyon",
            "Zhengying Liu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2101.02333v1",
        "title": "Infinitely Wide Tensor Networks as Gaussian Process",
        "abstract": "  Gaussian Process is a non-parametric prior which can be understood as a\ndistribution on the function space intuitively. It is known that by introducing\nappropriate prior to the weights of the neural networks, Gaussian Process can\nbe obtained by taking the infinite-width limit of the Bayesian neural networks\nfrom a Bayesian perspective. In this paper, we explore the infinitely wide\nTensor Networks and show the equivalence of the infinitely wide Tensor Networks\nand the Gaussian Process. We study the pure Tensor Network and another two\nextended Tensor Network structures: Neural Kernel Tensor Network and Tensor\nNetwork hidden layer Neural Network and prove that each one will converge to\nthe Gaussian Process as the width of each model goes to infinity. (We note here\nthat Gaussian Process can also be obtained by taking the infinite limit of at\nleast one of the bond dimensions $\\alpha_{i}$ in the product of tensor nodes,\nand the proofs can be done with the same ideas in the proofs of the\ninfinite-width cases.) We calculate the mean function (mean vector) and the\ncovariance function (covariance matrix) of the finite dimensional distribution\nof the induced Gaussian Process by the infinite-width tensor network with a\ngeneral set-up. We study the properties of the covariance function and derive\nthe approximation of the covariance function when the integral in the\nexpectation operator is intractable. In the numerical experiments, we implement\nthe Gaussian Process corresponding to the infinite limit tensor networks and\nplot the sample paths of these models. We study the hyperparameters and plot\nthe sample path families in the induced Gaussian Process by varying the\nstandard deviations of the prior distributions. As expected, the parameters in\nthe prior distribution namely the hyper-parameters in the induced Gaussian\nProcess controls the characteristic lengthscales of the Gaussian Process.\n",
        "published": "2021",
        "authors": [
            "Erdong Guo",
            "David Draper"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2101.03419v3",
        "title": "Training Deep Architectures Without End-to-End Backpropagation: A Survey\n  on the Provably Optimal Methods",
        "abstract": "  This tutorial paper surveys provably optimal alternatives to end-to-end\nbackpropagation (E2EBP) -- the de facto standard for training deep\narchitectures. Modular training refers to strictly local training without both\nthe forward and the backward pass, i.e., dividing a deep architecture into\nseveral nonoverlapping modules and training them separately without any\nend-to-end operation. Between the fully global E2EBP and the strictly local\nmodular training, there are weakly modular hybrids performing training without\nthe backward pass only. These alternatives can match or surpass the performance\nof E2EBP on challenging datasets such as ImageNet, and are gaining increasing\nattention primarily because they offer practical advantages over E2EBP, which\nwill be enumerated herein. In particular, they allow for greater modularity and\ntransparency in deep learning workflows, aligning deep learning with the\nmainstream computer science engineering that heavily exploits modularization\nfor scalability. Modular training has also revealed novel insights about\nlearning and has further implications on other important research domains.\nSpecifically, it induces natural and effective solutions to some important\npractical problems such as data efficiency and transferability estimation.\n",
        "published": "2021",
        "authors": [
            "Shiyu Duan",
            "Jose C. Principe"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2101.10427v1",
        "title": "Finding hidden-feature depending laws inside a data set and classifying\n  it using Neural Network",
        "abstract": "  The logcosh loss function for neural networks has been developed to combine\nthe advantage of the absolute error loss function of not overweighting outliers\nwith the advantage of the mean square error of continuous derivative near the\nmean, which makes the last phase of learning easier. It is clear, and one\nexperiences it soon, that in the case of clustered data, an artificial neural\nnetwork with logcosh loss learns the bigger cluster rather than the mean of the\ntwo. Even more so, the ANN, when used for regression of a set-valued function,\nwill learn a value close to one of the choices, in other words, one branch of\nthe set-valued function, while a mean-square-error NN will learn the value in\nbetween. This work suggests a method that uses artificial neural networks with\nlogcosh loss to find the branches of set-valued mappings in parameter-outcome\nsample sets and classifies the samples according to those branches.\n",
        "published": "2021",
        "authors": [
            "Thilo Moshagen",
            "Nihal Acharya Adde",
            "Ajay Navilarekal Rajgopal"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.00507v1",
        "title": "Universal scaling laws in the gradient descent training of neural\n  networks",
        "abstract": "  Current theoretical results on optimization trajectories of neural networks\ntrained by gradient descent typically have the form of rigorous but potentially\nloose bounds on the loss values. In the present work we take a different\napproach and show that the learning trajectory can be characterized by an\nexplicit asymptotic at large training times. Specifically, the leading term in\nthe asymptotic expansion of the loss behaves as a power law $L(t) \\sim\nt^{-\\xi}$ with exponent $\\xi$ expressed only through the data dimension, the\nsmoothness of the activation function, and the class of function being\napproximated. Our results are based on spectral analysis of the integral\noperator representing the linearized evolution of a large network trained on\nthe expected loss. Importantly, the techniques we employ do not require\nspecific form of a data distribution, for example Gaussian, thus making our\nfindings sufficiently universal.\n",
        "published": "2021",
        "authors": [
            "Maksim Velikanov",
            "Dmitry Yarotsky"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2105.10190v2",
        "title": "AngularGrad: A New Optimization Technique for Angular Convergence of\n  Convolutional Neural Networks",
        "abstract": "  Convolutional neural networks (CNNs) are trained using stochastic gradient\ndescent (SGD)-based optimizers. Recently, the adaptive moment estimation (Adam)\noptimizer has become very popular due to its adaptive momentum, which tackles\nthe dying gradient problem of SGD. Nevertheless, existing optimizers are still\nunable to exploit the optimization curvature information efficiently. This\npaper proposes a new AngularGrad optimizer that considers the behavior of the\ndirection/angle of consecutive gradients. This is the first attempt in the\nliterature to exploit the gradient angular information apart from its\nmagnitude. The proposed AngularGrad generates a score to control the step size\nbased on the gradient angular information of previous iterations. Thus, the\noptimization steps become smoother as a more accurate step size of immediate\npast gradients is captured through the angular information. Two variants of\nAngularGrad are developed based on the use of Tangent or Cosine functions for\ncomputing the gradient angular information. Theoretically, AngularGrad exhibits\nthe same regret bound as Adam for convergence purposes. Nevertheless, extensive\nexperiments conducted on benchmark data sets against state-of-the-art methods\nreveal a superior performance of AngularGrad. The source code will be made\npublicly available at: https://github.com/mhaut/AngularGrad.\n",
        "published": "2021",
        "authors": [
            "S. K. Roy",
            "M. E. Paoletti",
            "J. M. Haut",
            "S. R. Dubey",
            "P. Kar",
            "A. Plaza",
            "B. B. Chaudhuri"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2107.10030v1",
        "title": "Differentiable Feature Selection, a Reparameterization Approach",
        "abstract": "  We consider the task of feature selection for reconstruction which consists\nin choosing a small subset of features from which whole data instances can be\nreconstructed. This is of particular importance in several contexts involving\nfor example costly physical measurements, sensor placement or information\ncompression. To break the intrinsic combinatorial nature of this problem, we\nformulate the task as optimizing a binary mask distribution enabling an\naccurate reconstruction. We then face two main challenges. One concerns\ndifferentiability issues due to the binary distribution. The second one\ncorresponds to the elimination of redundant information by selecting variables\nin a correlated fashion which requires modeling the covariance of the binary\ndistribution. We address both issues by introducing a relaxation of the problem\nvia a novel reparameterization of the logitNormal distribution. We demonstrate\nthat the proposed method provides an effective exploration scheme and leads to\nefficient feature selection for reconstruction through evaluation on several\nhigh dimensional image benchmarks. We show that the method leverages the\nintrinsic geometry of the data, facilitating reconstruction.\n",
        "published": "2021",
        "authors": [
            "J\u00e9r\u00e9mie Dona",
            "Patrick Gallinari"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2107.12521v2",
        "title": "Restricted Boltzmann Machine and Deep Belief Network: Tutorial and\n  Survey",
        "abstract": "  This is a tutorial and survey paper on Boltzmann Machine (BM), Restricted\nBoltzmann Machine (RBM), and Deep Belief Network (DBN). We start with the\nrequired background on probabilistic graphical models, Markov random field,\nGibbs sampling, statistical physics, Ising model, and the Hopfield network.\nThen, we introduce the structures of BM and RBM. The conditional distributions\nof visible and hidden variables, Gibbs sampling in RBM for generating\nvariables, training BM and RBM by maximum likelihood estimation, and\ncontrastive divergence are explained. Then, we discuss different possible\ndiscrete and continuous distributions for the variables. We introduce\nconditional RBM and how it is trained. Finally, we explain deep belief network\nas a stack of RBM models. This paper on Boltzmann machines can be useful in\nvarious fields including data science, statistics, neural computation, and\nstatistical physics.\n",
        "published": "2021",
        "authors": [
            "Benyamin Ghojogh",
            "Ali Ghodsi",
            "Fakhri Karray",
            "Mark Crowley"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.03841v2",
        "title": "Width is Less Important than Depth in ReLU Neural Networks",
        "abstract": "  We solve an open question from Lu et al. (2017), by showing that any target\nnetwork with inputs in $\\mathbb{R}^d$ can be approximated by a width $O(d)$\nnetwork (independent of the target network's architecture), whose number of\nparameters is essentially larger only by a linear factor. In light of previous\ndepth separation theorems, which imply that a similar result cannot hold when\nthe roles of width and depth are interchanged, it follows that depth plays a\nmore significant role than width in the expressive power of neural networks.\n  We extend our results to constructing networks with bounded weights, and to\nconstructing networks with width at most $d+2$, which is close to the minimal\npossible width due to previous lower bounds. Both of these constructions cause\nan extra polynomial factor in the number of parameters over the target network.\nWe also show an exact representation of wide and shallow networks using deep\nand narrow networks which, in certain cases, does not increase the number of\nparameters over the target network.\n",
        "published": "2022",
        "authors": [
            "Gal Vardi",
            "Gilad Yehudai",
            "Ohad Shamir"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.08064v1",
        "title": "Learning a Single Neuron for Non-monotonic Activation Functions",
        "abstract": "  We study the problem of learning a single neuron $\\mathbf{x}\\mapsto\n\\sigma(\\mathbf{w}^T\\mathbf{x})$ with gradient descent (GD). All the existing\npositive results are limited to the case where $\\sigma$ is monotonic. However,\nit is recently observed that non-monotonic activation functions outperform the\ntraditional monotonic ones in many applications. To fill this gap, we establish\nlearnability without assuming monotonicity. Specifically, when the input\ndistribution is the standard Gaussian, we show that mild conditions on $\\sigma$\n(e.g., $\\sigma$ has a dominating linear part) are sufficient to guarantee the\nlearnability in polynomial time and polynomial samples. Moreover, with a\nstronger assumption on the activation function, the condition of input\ndistribution can be relaxed to a non-degeneracy of the marginal distribution.\nWe remark that our conditions on $\\sigma$ are satisfied by practical\nnon-monotonic activation functions, such as SiLU/Swish and GELU. We also\ndiscuss how our positive results are related to existing negative results on\ntraining two-layer neural networks.\n",
        "published": "2022",
        "authors": [
            "Lei Wu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.10464v1",
        "title": "A Globally Convergent Evolutionary Strategy for Stochastic Constrained\n  Optimization with Applications to Reinforcement Learning",
        "abstract": "  Evolutionary strategies have recently been shown to achieve competing levels\nof performance for complex optimization problems in reinforcement learning. In\nsuch problems, one often needs to optimize an objective function subject to a\nset of constraints, including for instance constraints on the entropy of a\npolicy or to restrict the possible set of actions or states accessible to an\nagent. Convergence guarantees for evolutionary strategies to optimize\nstochastic constrained problems are however lacking in the literature. In this\nwork, we address this problem by designing a novel optimization algorithm with\na sufficient decrease mechanism that ensures convergence and that is based only\non estimates of the functions. We demonstrate the applicability of this\nalgorithm on two types of experiments: i) a control task for maximizing rewards\nand ii) maximizing rewards subject to a non-relaxable set of constraints.\n",
        "published": "2022",
        "authors": [
            "Youssef Diouane",
            "Aurelien Lucchi",
            "Vihang Patil"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.12887v2",
        "title": "Biological error correction codes generate fault-tolerant neural\n  networks",
        "abstract": "  It has been an open question in deep learning if fault-tolerant computation\nis possible: can arbitrarily reliable computation be achieved using only\nunreliable neurons? In the grid cells of the mammalian cortex, analog error\ncorrection codes have been observed to protect states against neural spiking\nnoise, but their role in information processing is unclear. Here, we use these\nbiological codes to show that a universal fault-tolerant neural network can be\nachieved if the faultiness of each neuron lies below a sharp threshold;\nmoreover, we find that noisy biological neurons fall below this threshold. The\ndiscovery of a phase transition from faulty to fault-tolerant neural\ncomputation suggests a mechanism for reliable computation in the cortex and\nopens a path towards understanding noisy analog systems relevant to artificial\nintelligence and neuromorphic computing.\n",
        "published": "2022",
        "authors": [
            "Alexander Zlokapa",
            "Andrew K. Tan",
            "John M. Martyn",
            "Ila R. Fiete",
            "Max Tegmark",
            "Isaac L. Chuang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2202.13778v1",
        "title": "Rule-based Evolutionary Bayesian Learning",
        "abstract": "  In our previous work, we introduced the rule-based Bayesian Regression, a\nmethodology that leverages two concepts: (i) Bayesian inference, for the\ngeneral framework and uncertainty quantification and (ii) rule-based systems\nfor the incorporation of expert knowledge and intuition. The resulting method\ncreates a penalty equivalent to a common Bayesian prior, but it also includes\ninformation that typically would not be available within a standard Bayesian\ncontext. In this work, we extend the aforementioned methodology with\ngrammatical evolution, a symbolic genetic programming technique that we utilise\nfor automating the rules' derivation. Our motivation is that grammatical\nevolution can potentially detect patterns from the data with valuable\ninformation, equivalent to that of expert knowledge. We illustrate the use of\nthe rule-based Evolutionary Bayesian learning technique by applying it to\nsynthetic as well as real data, and examine the results in terms of point\npredictions and associated uncertainty.\n",
        "published": "2022",
        "authors": [
            "Themistoklis Botsas",
            "Lachlan R. Mason",
            "Omar K. Matar",
            "Indranil Pan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1503.00778v1",
        "title": "Simple, Efficient, and Neural Algorithms for Sparse Coding",
        "abstract": "  Sparse coding is a basic task in many fields including signal processing,\nneuroscience and machine learning where the goal is to learn a basis that\nenables a sparse representation of a given set of data, if one exists. Its\nstandard formulation is as a non-convex optimization problem which is solved in\npractice by heuristics based on alternating minimization. Re- cent work has\nresulted in several algorithms for sparse coding with provable guarantees, but\nsomewhat surprisingly these are outperformed by the simple alternating\nminimization heuristics. Here we give a general framework for understanding\nalternating minimization which we leverage to analyze existing heuristics and\nto design new ones also with provable guarantees. Some of these algorithms seem\nimplementable on simple neural architectures, which was the original motivation\nof Olshausen and Field (1997a) in introducing sparse coding. We also give the\nfirst efficient algorithm for sparse coding that works almost up to the\ninformation theoretic limit for sparse recovery on incoherent dictionaries. All\nprevious algorithms that approached or surpassed this limit run in time\nexponential in some natural parameter. Finally, our algorithms improve upon the\nsample complexity of existing approaches. We believe that our analysis\nframework will have applications in other settings where simple iterative\nalgorithms are used.\n",
        "published": "2015",
        "authors": [
            "Sanjeev Arora",
            "Rong Ge",
            "Tengyu Ma",
            "Ankur Moitra"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1503.01445v1",
        "title": "Toxicity Prediction using Deep Learning",
        "abstract": "  Everyday we are exposed to various chemicals via food additives, cleaning and\ncosmetic products and medicines -- and some of them might be toxic. However\ntesting the toxicity of all existing compounds by biological experiments is\nneither financially nor logistically feasible. Therefore the government\nagencies NIH, EPA and FDA launched the Tox21 Data Challenge within the\n\"Toxicology in the 21st Century\" (Tox21) initiative. The goal of this challenge\nwas to assess the performance of computational methods in predicting the\ntoxicity of chemical compounds. State of the art toxicity prediction methods\nbuild upon specifically-designed chemical descriptors developed over decades.\nThough Deep Learning is new to the field and was never applied to toxicity\nprediction before, it clearly outperformed all other participating methods. In\nthis application paper we show that deep nets automatically learn features\nresembling well-established toxicophores. In total, our Deep Learning approach\nwon both of the panel-challenges (nuclear receptors and stress response) as\nwell as the overall Grand Challenge, and thereby sets a new standard in tox\nprediction.\n",
        "published": "2015",
        "authors": [
            "Thomas Unterthiner",
            "Andreas Mayr",
            "G\u00fcnter Klambauer",
            "Sepp Hochreiter"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1503.02031v1",
        "title": "To Drop or Not to Drop: Robustness, Consistency and Differential Privacy\n  Properties of Dropout",
        "abstract": "  Training deep belief networks (DBNs) requires optimizing a non-convex\nfunction with an extremely large number of parameters. Naturally, existing\ngradient descent (GD) based methods are prone to arbitrarily poor local minima.\nIn this paper, we rigorously show that such local minima can be avoided (upto\nan approximation error) by using the dropout technique, a widely used heuristic\nin this domain. In particular, we show that by randomly dropping a few nodes of\na one-hidden layer neural network, the training objective function, up to a\ncertain approximation error, decreases by a multiplicative factor.\n  On the flip side, we show that for training convex empirical risk minimizers\n(ERM), dropout in fact acts as a \"stabilizer\" or regularizer. That is, a simple\ndropout based GD method for convex ERMs is stable in the face of arbitrary\nchanges to any one of the training points. Using the above assertion, we show\nthat dropout provides fast rates for generalization error in learning (convex)\ngeneralized linear models (GLM). Moreover, using the above mentioned stability\nproperties of dropout, we design dropout based differentially private\nalgorithms for solving ERMs. The learned GLM thus, preserves privacy of each of\nthe individual training points while providing accurate predictions for new\ntest points. Finally, we empirically validate our stability assertions for\ndropout in the context of convex ERMs and show that surprisingly, dropout\nsignificantly outperforms (in terms of prediction accuracy) the L2\nregularization based methods for several benchmark datasets.\n",
        "published": "2015",
        "authors": [
            "Prateek Jain",
            "Vivek Kulkarni",
            "Abhradeep Thakurta",
            "Oliver Williams"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1503.02531v1",
        "title": "Distilling the Knowledge in a Neural Network",
        "abstract": "  A very simple way to improve the performance of almost any machine learning\nalgorithm is to train many different models on the same data and then to\naverage their predictions. Unfortunately, making predictions using a whole\nensemble of models is cumbersome and may be too computationally expensive to\nallow deployment to a large number of users, especially if the individual\nmodels are large neural nets. Caruana and his collaborators have shown that it\nis possible to compress the knowledge in an ensemble into a single model which\nis much easier to deploy and we develop this approach further using a different\ncompression technique. We achieve some surprising results on MNIST and we show\nthat we can significantly improve the acoustic model of a heavily used\ncommercial system by distilling the knowledge in an ensemble of models into a\nsingle model. We also introduce a new type of ensemble composed of one or more\nfull models and many specialist models which learn to distinguish fine-grained\nclasses that the full models confuse. Unlike a mixture of experts, these\nspecialist models can be trained rapidly and in parallel.\n",
        "published": "2015",
        "authors": [
            "Geoffrey Hinton",
            "Oriol Vinyals",
            "Jeff Dean"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1503.03438v3",
        "title": "A mathematical motivation for complex-valued convolutional networks",
        "abstract": "  A complex-valued convolutional network (convnet) implements the repeated\napplication of the following composition of three operations, recursively\napplying the composition to an input vector of nonnegative real numbers: (1)\nconvolution with complex-valued vectors followed by (2) taking the absolute\nvalue of every entry of the resulting vectors followed by (3) local averaging.\nFor processing real-valued random vectors, complex-valued convnets can be\nviewed as \"data-driven multiscale windowed power spectra,\" \"data-driven\nmultiscale windowed absolute spectra,\" \"data-driven multiwavelet absolute\nvalues,\" or (in their most general configuration) \"data-driven nonlinear\nmultiwavelet packets.\" Indeed, complex-valued convnets can calculate multiscale\nwindowed spectra when the convnet filters are windowed complex-valued\nexponentials. Standard real-valued convnets, using rectified linear units\n(ReLUs), sigmoidal (for example, logistic or tanh) nonlinearities, max.\npooling, etc., do not obviously exhibit the same exact correspondence with\ndata-driven wavelets (whereas for complex-valued convnets, the correspondence\nis much more than just a vague analogy). Courtesy of the exact correspondence,\nthe remarkably rich and rigorous body of mathematical analysis for wavelets\napplies directly to (complex-valued) convnets.\n",
        "published": "2015",
        "authors": [
            "Joan Bruna",
            "Soumith Chintala",
            "Yann LeCun",
            "Serkan Piantino",
            "Arthur Szlam",
            "Mark Tygert"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1503.05471v1",
        "title": "Shared latent subspace modelling within Gaussian-Binary Restricted\n  Boltzmann Machines for NIST i-Vector Challenge 2014",
        "abstract": "  This paper presents a novel approach to speaker subspace modelling based on\nGaussian-Binary Restricted Boltzmann Machines (GRBM). The proposed model is\nbased on the idea of shared factors as in the Probabilistic Linear Discriminant\nAnalysis (PLDA). GRBM hidden layer is divided into speaker and channel factors,\nherein the speaker factor is shared over all vectors of the speaker. Then\nMaximum Likelihood Parameter Estimation (MLE) for proposed model is introduced.\nVarious new scoring techniques for speaker verification using GRBM are\nproposed. The results for NIST i-vector Challenge 2014 dataset are presented.\n",
        "published": "2015",
        "authors": [
            "Danila Doroshin",
            "Alexander Yamshinin",
            "Nikolay Lubimov",
            "Marina Nastasenko",
            "Mikhail Kotov",
            "Maxim Tkachenko"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1503.05671v7",
        "title": "Optimizing Neural Networks with Kronecker-factored Approximate Curvature",
        "abstract": "  We propose an efficient method for approximating natural gradient descent in\nneural networks which we call Kronecker-Factored Approximate Curvature (K-FAC).\nK-FAC is based on an efficiently invertible approximation of a neural network's\nFisher information matrix which is neither diagonal nor low-rank, and in some\ncases is completely non-sparse. It is derived by approximating various large\nblocks of the Fisher (corresponding to entire layers) as being the Kronecker\nproduct of two much smaller matrices. While only several times more expensive\nto compute than the plain stochastic gradient, the updates produced by K-FAC\nmake much more progress optimizing the objective, which results in an algorithm\nthat can be much faster than stochastic gradient descent with momentum in\npractice. And unlike some previously proposed approximate\nnatural-gradient/Newton methods which use high-quality non-diagonal curvature\nmatrices (such as Hessian-free optimization), K-FAC works very well in highly\nstochastic optimization regimes. This is because the cost of storing and\ninverting K-FAC's approximation to the curvature matrix does not depend on the\namount of data used to estimate it, which is a feature typically associated\nonly with diagonal or low-rank approximations to the curvature matrix.\n",
        "published": "2015",
        "authors": [
            "James Martens",
            "Roger Grosse"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1503.05724v3",
        "title": "A Neural Transfer Function for a Smooth and Differentiable Transition\n  Between Additive and Multiplicative Interactions",
        "abstract": "  Existing approaches to combine both additive and multiplicative neural units\neither use a fixed assignment of operations or require discrete optimization to\ndetermine what function a neuron should perform. This leads either to an\ninefficient distribution of computational resources or an extensive increase in\nthe computational complexity of the training procedure.\n  We present a novel, parameterizable transfer function based on the\nmathematical concept of non-integer functional iteration that allows the\noperation each neuron performs to be smoothly and, most importantly,\ndifferentiablely adjusted between addition and multiplication. This allows the\ndecision between addition and multiplication to be integrated into the standard\nbackpropagation training procedure.\n",
        "published": "2015",
        "authors": [
            "Sebastian Urban",
            "Patrick van der Smagt"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1503.06452v1",
        "title": "Unsupervised model compression for multilayer bootstrap networks",
        "abstract": "  Recently, multilayer bootstrap network (MBN) has demonstrated promising\nperformance in unsupervised dimensionality reduction. It can learn compact\nrepresentations in standard data sets, i.e. MNIST and RCV1. However, as a\nbootstrap method, the prediction complexity of MBN is high. In this paper, we\npropose an unsupervised model compression framework for this general problem of\nunsupervised bootstrap methods. The framework compresses a large unsupervised\nbootstrap model into a small model by taking the bootstrap model and its\napplication together as a black box and learning a mapping function from the\ninput of the bootstrap model to the output of the application by a supervised\nlearner. To specialize the framework, we propose a new technique, named\ncompressive MBN. It takes MBN as the unsupervised bootstrap model and deep\nneural network (DNN) as the supervised learner. Our initial result on MNIST\nshowed that compressive MBN not only maintains the high prediction accuracy of\nMBN but also is over thousands of times faster than MBN at the prediction\nstage. Our result suggests that the new technique integrates the effectiveness\nof MBN on unsupervised learning and the effectiveness and efficiency of DNN on\nsupervised learning together for the effectiveness and efficiency of\ncompressive MBN on unsupervised learning.\n",
        "published": "2015",
        "authors": [
            "Xiao-Lei Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1606.01865v2",
        "title": "Recurrent Neural Networks for Multivariate Time Series with Missing\n  Values",
        "abstract": "  Multivariate time series data in practical applications, such as health care,\ngeoscience, and biology, are characterized by a variety of missing values. In\ntime series prediction and other related tasks, it has been noted that missing\nvalues and their missing patterns are often correlated with the target labels,\na.k.a., informative missingness. There is very limited work on exploiting the\nmissing patterns for effective imputation and improving prediction performance.\nIn this paper, we develop novel deep learning models, namely GRU-D, as one of\nthe early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a\nstate-of-the-art recurrent neural network. It takes two representations of\nmissing patterns, i.e., masking and time interval, and effectively incorporates\nthem into a deep model architecture so that it not only captures the long-term\ntemporal dependencies in time series, but also utilizes the missing patterns to\nachieve better prediction results. Experiments of time series classification\ntasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic\ndatasets demonstrate that our models achieve state-of-the-art performance and\nprovides useful insights for better understanding and utilization of missing\nvalues in time series analysis.\n",
        "published": "2016",
        "authors": [
            "Zhengping Che",
            "Sanjay Purushotham",
            "Kyunghyun Cho",
            "David Sontag",
            "Yan Liu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1606.04130v5",
        "title": "Modeling Missing Data in Clinical Time Series with RNNs",
        "abstract": "  We demonstrate a simple strategy to cope with missing data in sequential\ninputs, addressing the task of multilabel classification of diagnoses given\nclinical time series. Collected from the pediatric intensive care unit (PICU)\nat Children's Hospital Los Angeles, our data consists of multivariate time\nseries of observations. The measurements are irregularly spaced, leading to\nmissingness patterns in temporally discretized sequences. While these artifacts\nare typically handled by imputation, we achieve superior predictive performance\nby treating the artifacts as features. Unlike linear models, recurrent neural\nnetworks can realize this improvement using only simple binary indicators of\nmissingness. For linear models, we show an alternative strategy to capture this\nsignal. Training models on missingness patterns only, we show that for some\ndiseases, what tests are run can be as predictive as the results themselves.\n",
        "published": "2016",
        "authors": [
            "Zachary C. Lipton",
            "David C. Kale",
            "Randall Wetzel"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1606.05018v1",
        "title": "Improving Power Generation Efficiency using Deep Neural Networks",
        "abstract": "  Recently there has been significant research on power generation,\ndistribution and transmission efficiency especially in the case of renewable\nresources. The main objective is reduction of energy losses and this requires\nimprovements on data acquisition and analysis. In this paper we address these\nconcerns by using consumers' electrical smart meter readings to estimate\nnetwork loading and this information can then be used for better capacity\nplanning. We compare Deep Neural Network (DNN) methods with traditional methods\nfor load forecasting. Our results indicate that DNN methods outperform most\ntraditional methods. This comes at the cost of additional computational\ncomplexity but this can be addressed with the use of cloud resources. We also\nillustrate how these results can be used to better support dynamic pricing.\n",
        "published": "2016",
        "authors": [
            "Stefan Hosein",
            "Patrick Hosein"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.01989v1",
        "title": "Regularized Dynamic Boltzmann Machine with Delay Pruning for\n  Unsupervised Learning of Temporal Sequences",
        "abstract": "  We introduce Delay Pruning, a simple yet powerful technique to regularize\ndynamic Boltzmann machines (DyBM). The recently introduced DyBM provides a\nparticularly structured Boltzmann machine, as a generative model of a\nmulti-dimensional time-series. This Boltzmann machine can have infinitely many\nlayers of units but allows exact inference and learning based on its\nbiologically motivated structure. DyBM uses the idea of conduction delays in\nthe form of fixed length first-in first-out (FIFO) queues, with a neuron\nconnected to another via this FIFO queue, and spikes from a pre-synaptic neuron\ntravel along the queue to the post-synaptic neuron with a constant period of\ndelay. Here, we present Delay Pruning as a mechanism to prune the lengths of\nthe FIFO queues (making them zero) by setting some delay lengths to one with a\nfixed probability, and finally selecting the best performing model with fixed\ndelays. The uniqueness of structure and a non-sampling based learning rule in\nDyBM, make the application of previously proposed regularization techniques\nlike Dropout or DropConnect difficult, leading to poor generalization. First,\nwe evaluate the performance of Delay Pruning to let DyBM learn a\nmultidimensional temporal sequence generated by a Markov chain. Finally, we\nshow the effectiveness of delay pruning in learning high dimensional sequences\nusing the moving MNIST dataset, and compare it with Dropout and DropConnect\nmethods.\n",
        "published": "2016",
        "authors": [
            "Sakyasingha Dasgupta",
            "Takayuki Yoshizumi",
            "Takayuki Osogami"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.04167v5",
        "title": "Tensorial Mixture Models",
        "abstract": "  Casting neural networks in generative frameworks is a highly sought-after\nendeavor these days. Contemporary methods, such as Generative Adversarial\nNetworks, capture some of the generative capabilities, but not all. In\nparticular, they lack the ability of tractable marginalization, and thus are\nnot suitable for many tasks. Other methods, based on arithmetic circuits and\nsum-product networks, do allow tractable marginalization, but their performance\nis challenged by the need to learn the structure of a circuit. Building on the\ntractability of arithmetic circuits, we leverage concepts from tensor analysis,\nand derive a family of generative models we call Tensorial Mixture Models\n(TMMs). TMMs assume a simple convolutional network structure, and in addition,\nlend themselves to theoretical analyses that allow comprehensive understanding\nof the relation between their structure and their expressive properties. We\nthus obtain a generative model that is tractable on one hand, and on the other\nhand, allows effective representation of rich distributions in an easily\ncontrolled manner. These two capabilities are brought together in the task of\nclassification under missing data, where TMMs deliver state of the art\naccuracies with seamless implementation and design.\n",
        "published": "2016",
        "authors": [
            "Or Sharir",
            "Ronen Tamari",
            "Nadav Cohen",
            "Amnon Shashua"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.06258v3",
        "title": "Using Fast Weights to Attend to the Recent Past",
        "abstract": "  Until recently, research on artificial neural networks was largely restricted\nto systems with only two types of variable: Neural activities that represent\nthe current or recent input and weights that learn to capture regularities\namong inputs, outputs and payoffs. There is no good reason for this\nrestriction. Synapses have dynamics at many different time-scales and this\nsuggests that artificial neural networks might benefit from variables that\nchange slower than activities but much faster than the standard weights. These\n\"fast weights\" can be used to store temporary memories of the recent past and\nthey provide a neurally plausible way of implementing the type of attention to\nthe past that has recently proved very helpful in sequence-to-sequence models.\nBy using fast weights we can avoid the need to store copies of neural activity\npatterns.\n",
        "published": "2016",
        "authors": [
            "Jimmy Ba",
            "Geoffrey Hinton",
            "Volodymyr Mnih",
            "Joel Z. Leibo",
            "Catalin Ionescu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.07857v1",
        "title": "Hybrid clustering-classification neural network in the medical\n  diagnostics of reactive arthritis",
        "abstract": "  The hybrid clustering-classification neural network is proposed. This network\nallows increasing a quality of information processing under the condition of\noverlapping classes due to the rational choice of a learning rate parameter and\nintroducing a special procedure of fuzzy reasoning in the clustering process,\nwhich occurs both with an external learning signal (supervised) and without the\none (unsupervised). As similarity measure neighborhood function or membership\none, cosine structures are used, which allow to provide a high flexibility due\nto self-learning-learning process and to provide some new useful properties.\nMany realized experiments have confirmed the efficiency of proposed hybrid\nclustering-classification neural network; also, this network was used for\nsolving diagnostics task of reactive arthritis.\n",
        "published": "2016",
        "authors": [
            "Yevgeniy Bodyanskiy",
            "Olena Vynokurova",
            "Volodymyr Savvo",
            "Tatiana Tverdokhlib",
            "Pavlo Mulesa"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.09887v3",
        "title": "Depth-Width Tradeoffs in Approximating Natural Functions with Neural\n  Networks",
        "abstract": "  We provide several new depth-based separation results for feed-forward neural\nnetworks, proving that various types of simple and natural functions can be\nbetter approximated using deeper networks than shallower ones, even if the\nshallower networks are much larger. This includes indicators of balls and\nellipses; non-linear functions which are radial with respect to the $L_1$ norm;\nand smooth non-linear functions. We also show that these gaps can be observed\nexperimentally: Increasing the depth indeed allows better learning than\nincreasing width, when training neural networks to learn an indicator of a unit\nball.\n",
        "published": "2016",
        "authors": [
            "Itay Safran",
            "Ohad Shamir"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1610.10087v1",
        "title": "Tensor Switching Networks",
        "abstract": "  We present a novel neural network algorithm, the Tensor Switching (TS)\nnetwork, which generalizes the Rectified Linear Unit (ReLU) nonlinearity to\ntensor-valued hidden units. The TS network copies its entire input vector to\ndifferent locations in an expanded representation, with the location determined\nby its hidden unit activity. In this way, even a simple linear readout from the\nTS representation can implement a highly expressive deep-network-like function.\nThe TS network hence avoids the vanishing gradient problem by construction, at\nthe cost of larger representation size. We develop several methods to train the\nTS network, including equivalent kernels for infinitely wide and deep TS\nnetworks, a one-pass linear learning algorithm, and two\nbackpropagation-inspired representation learning algorithms. Our experimental\nresults demonstrate that the TS network is indeed more expressive and\nconsistently learns faster than standard ReLU networks.\n",
        "published": "2016",
        "authors": [
            "Chuan-Yung Tsai",
            "Andrew Saxe",
            "David Cox"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.00035v1",
        "title": "Full-Capacity Unitary Recurrent Neural Networks",
        "abstract": "  Recurrent neural networks are powerful models for processing sequential data,\nbut they are generally plagued by vanishing and exploding gradient problems.\nUnitary recurrent neural networks (uRNNs), which use unitary recurrence\nmatrices, have recently been proposed as a means to avoid these issues.\nHowever, in previous experiments, the recurrence matrices were restricted to be\na product of parameterized unitary matrices, and an open question remains: when\ndoes such a parameterization fail to represent all unitary matrices, and how\ndoes this restricted representational capacity limit what can be learned? To\naddress this question, we propose full-capacity uRNNs that optimize their\nrecurrence matrix over all unitary matrices, leading to significantly improved\nperformance over uRNNs that use a restricted-capacity recurrence matrix. Our\ncontribution consists of two main components. First, we provide a theoretical\nargument to determine if a unitary parameterization has restricted capacity.\nUsing this argument, we show that a recently proposed unitary parameterization\nhas restricted capacity for hidden state dimension greater than 7. Second, we\nshow how a complete, full-capacity unitary recurrence matrix can be optimized\nover the differentiable manifold of unitary matrices. The resulting\nmultiplicative gradient step is very simple and does not require gradient\nclipping or learning rate adaptation. We confirm the utility of our claims by\nempirically evaluating our new full-capacity uRNNs on both synthetic and\nnatural data, achieving superior performance compared to both LSTMs and the\noriginal restricted-capacity uRNNs.\n",
        "published": "2016",
        "authors": [
            "Scott Wisdom",
            "Thomas Powers",
            "John R. Hershey",
            "Jonathan Le Roux",
            "Les Atlas"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.01186v2",
        "title": "Demystifying ResNet",
        "abstract": "  The Residual Network (ResNet), proposed in He et al. (2015), utilized\nshortcut connections to significantly reduce the difficulty of training, which\nresulted in great performance boosts in terms of both training and\ngeneralization error.\n  It was empirically observed in He et al. (2015) that stacking more layers of\nresidual blocks with shortcut 2 results in smaller training error, while it is\nnot true for shortcut of length 1 or 3. We provide a theoretical explanation\nfor the uniqueness of shortcut 2.\n  We show that with or without nonlinearities, by adding shortcuts that have\ndepth two, the condition number of the Hessian of the loss function at the zero\ninitial point is depth-invariant, which makes training very deep models no more\ndifficult than shallow ones. Shortcuts of higher depth result in an extremely\nflat (high-order) stationary point initially, from which the optimization\nalgorithm is hard to escape. The shortcut 1, however, is essentially equivalent\nto no shortcuts, which has a condition number exploding to infinity as the\nnumber of layers grows. We further argue that as the number of layers tends to\ninfinity, it suffices to only look at the loss function at the zero initial\npoint.\n  Extensive experiments are provided accompanying our theoretical results. We\nshow that initializing the network to small weights with shortcut 2 achieves\nsignificantly better results than random Gaussian (Xavier) initialization,\northogonal initialization, and shortcuts of deeper depth, from various\nperspectives ranging from final loss, learning dynamics and stability, to the\nbehavior of the Hessian along the learning process.\n",
        "published": "2016",
        "authors": [
            "Sihan Li",
            "Jiantao Jiao",
            "Yanjun Han",
            "Tsachy Weissman"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.01211v8",
        "title": "Combating Reinforcement Learning's Sisyphean Curse with Intrinsic Fear",
        "abstract": "  Many practical environments contain catastrophic states that an optimal agent\nwould visit infrequently or never. Even on toy problems, Deep Reinforcement\nLearning (DRL) agents tend to periodically revisit these states upon forgetting\ntheir existence under a new policy. We introduce intrinsic fear (IF), a learned\nreward shaping that guards DRL agents against periodic catastrophes. IF agents\npossess a fear model trained to predict the probability of imminent\ncatastrophe. This score is then used to penalize the Q-learning objective. Our\ntheoretical analysis bounds the reduction in average return due to learning on\nthe perturbed objective. We also prove robustness to classification errors. As\na bonus, IF models tend to learn faster, owing to reward shaping. Experiments\ndemonstrate that intrinsic-fear DQNs solve otherwise pathological environments\nand improve on several Atari games.\n",
        "published": "2016",
        "authors": [
            "Zachary C. Lipton",
            "Kamyar Azizzadenesheli",
            "Abhishek Kumar",
            "Lihong Li",
            "Jianfeng Gao",
            "Li Deng"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.02320v3",
        "title": "Adversarial Ladder Networks",
        "abstract": "  The use of unsupervised data in addition to supervised data in training\ndiscriminative neural networks has improved the performance of this clas-\nsification scheme. However, the best results were achieved with a training\nprocess that is divided in two parts: first an unsupervised pre-training step\nis done for initializing the weights of the network and after these weights are\nrefined with the use of supervised data. On the other hand adversarial noise\nhas improved the results of clas- sical supervised learning. Recently, a new\nneural network topology called Ladder Network, where the key idea is based in\nsome properties of hierar- chichal latent variable models, has been proposed as\na technique to train a neural network using supervised and unsupervised data at\nthe same time with what is called semi-supervised learning. This technique has\nreached state of the art classification. In this work we add adversarial noise\nto the ladder network and get state of the art classification, with several\nimportant conclusions on how adversarial noise can help in addition with new\npossible lines of investi- gation. We also propose an alternative to add\nadversarial noise to unsu- pervised data.\n",
        "published": "2016",
        "authors": [
            "Juan Maro\u00f1as Molano",
            "Alberto Albiol Colomer",
            "Roberto Paredes Palacios"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.02345v3",
        "title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier\n  Networks",
        "abstract": "  Modern convolutional networks, incorporating rectifiers and max-pooling, are\nneither smooth nor convex; standard guarantees therefore do not apply.\nNevertheless, methods from convex optimization such as gradient descent and\nAdam are widely used as building blocks for deep learning algorithms. This\npaper provides the first convergence guarantee applicable to modern convnets,\nwhich furthermore matches a lower bound for convex nonsmooth functions. The key\ntechnical tool is the neural Taylor approximation -- a straightforward\napplication of Taylor expansions to neural networks -- and the associated\nTaylor loss. Experiments on a range of optimizers, layers, and tasks provide\nevidence that the analysis accurately captures the dynamics of neural\noptimization. The second half of the paper applies the Taylor approximation to\nisolate the main difficulty in training rectifier nets -- that gradients are\nshattered -- and investigates the hypothesis that, by exploring the space of\nactivation configurations more thoroughly, adaptive optimizers such as RMSProp\nand Adam are able to converge to better solutions.\n",
        "published": "2016",
        "authors": [
            "David Balduzzi",
            "Brian McWilliams",
            "Tony Butler-Yeoman"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.02648v2",
        "title": "Deep Unsupervised Clustering with Gaussian Mixture Variational\n  Autoencoders",
        "abstract": "  We study a variant of the variational autoencoder model (VAE) with a Gaussian\nmixture as a prior distribution, with the goal of performing unsupervised\nclustering through deep generative models. We observe that the known problem of\nover-regularisation that has been shown to arise in regular VAEs also manifests\nitself in our model and leads to cluster degeneracy. We show that a heuristic\ncalled minimum information constraint that has been shown to mitigate this\neffect in VAEs can also be applied to improve unsupervised clustering\nperformance with our model. Furthermore we analyse the effect of this heuristic\nand provide an intuition of the various processes with the help of\nvisualizations. Finally, we demonstrate the performance of our model on\nsynthetic data, MNIST and SVHN, showing that the obtained clusters are\ndistinct, interpretable and result in achieving competitive performance on\nunsupervised clustering to the state-of-the-art results.\n",
        "published": "2016",
        "authors": [
            "Nat Dilokthanakul",
            "Pedro A. M. Mediano",
            "Marta Garnelo",
            "Matthew C. H. Lee",
            "Hugh Salimbeni",
            "Kai Arulkumaran",
            "Murray Shanahan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.04231v3",
        "title": "Identity Matters in Deep Learning",
        "abstract": "  An emerging design principle in deep learning is that each layer of a deep\nartificial neural network should be able to easily express the identity\ntransformation. This idea not only motivated various normalization techniques,\nsuch as \\emph{batch normalization}, but was also key to the immense success of\n\\emph{residual networks}.\n  In this work, we put the principle of \\emph{identity parameterization} on a\nmore solid theoretical footing alongside further empirical progress. We first\ngive a strikingly simple proof that arbitrarily deep linear residual networks\nhave no spurious local optima. The same result for linear feed-forward networks\nin their standard parameterization is substantially more delicate. Second, we\nshow that residual networks with ReLu activations have universal finite-sample\nexpressivity in the sense that the network can represent any function of its\nsample provided that the model has more parameters than the sample size.\n  Directly inspired by our theory, we experiment with a radically simple\nresidual architecture consisting of only residual convolutional layers and ReLu\nactivations, but no batch normalization, dropout, or max pool. Our model\nimproves significantly on previous all-convolutional networks on the CIFAR10,\nCIFAR100, and ImageNet classification benchmarks.\n",
        "published": "2016",
        "authors": [
            "Moritz Hardt",
            "Tengyu Ma"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.04500v3",
        "title": "Deep Learning with Sets and Point Clouds",
        "abstract": "  We introduce a simple permutation equivariant layer for deep learning with\nset structure.This type of layer, obtained by parameter-sharing, has a simple\nimplementation and linear-time complexity in the size of each set. We use deep\npermutation-invariant networks to perform point-could classification and\nMNIST-digit summation, where in both cases the output is invariant to\npermutations of the input. In a semi-supervised setting, where the goal is make\npredictions for each instance within a set, we demonstrate the usefulness of\nthis type of layer in set-outlier detection as well as semi-supervised learning\nwith clustering side-information.\n",
        "published": "2016",
        "authors": [
            "Siamak Ravanbakhsh",
            "Jeff Schneider",
            "Barnabas Poczos"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.06148v2",
        "title": "Compacting Neural Network Classifiers via Dropout Training",
        "abstract": "  We introduce dropout compaction, a novel method for training feed-forward\nneural networks which realizes the performance gains of training a large model\nwith dropout regularization, yet extracts a compact neural network for run-time\nefficiency. In the proposed method, we introduce a sparsity-inducing prior on\nthe per unit dropout retention probability so that the optimizer can\neffectively prune hidden units during training. By changing the prior\nhyperparameters, we can control the size of the resulting network. We performed\na systematic comparison of dropout compaction and competing methods on several\nreal-world speech recognition tasks and found that dropout compaction achieved\ncomparable accuracy with fewer than 50% of the hidden units, translating to a\n2.5x speedup in run-time.\n",
        "published": "2016",
        "authors": [
            "Yotaro Kubo",
            "George Tucker",
            "Simon Wiesler"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.06245v1",
        "title": "Spikes as regularizers",
        "abstract": "  We present a confidence-based single-layer feed-forward learning algorithm\nSPIRAL (Spike Regularized Adaptive Learning) relying on an encoding of\nactivation spikes. We adaptively update a weight vector relying on confidence\nestimates and activation offsets relative to previous activity. We regularize\nupdates proportionally to item-level confidence and weight-specific support,\nloosely inspired by the observation from neurophysiology that high spike rates\nare sometimes accompanied by low temporal precision. Our experiments suggest\nthat the new learning algorithm SPIRAL is more robust and less prone to\noverfitting than both the averaged perceptron and AROW.\n",
        "published": "2016",
        "authors": [
            "Anders S\u00f8gaard"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.06310v2",
        "title": "Local minima in training of neural networks",
        "abstract": "  There has been a lot of recent interest in trying to characterize the error\nsurface of deep models. This stems from a long standing question. Given that\ndeep networks are highly nonlinear systems optimized by local gradient methods,\nwhy do they not seem to be affected by bad local minima? It is widely believed\nthat training of deep models using gradient methods works so well because the\nerror surface either has no local minima, or if they exist they need to be\nclose in value to the global minimum. It is known that such results hold under\nvery strong assumptions which are not satisfied by real models. In this paper\nwe present examples showing that for such theorem to be true additional\nassumptions on the data, initialization schemes and/or the model classes have\nto be made. We look at the particular case of finite size datasets. We\ndemonstrate that in this scenario one can construct counter-examples (datasets\nor initialization schemes) when the network does become susceptible to bad\nlocal minima over the weight space.\n",
        "published": "2016",
        "authors": [
            "Grzegorz Swirszcz",
            "Wojciech Marian Czarnecki",
            "Razvan Pascanu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.06455v4",
        "title": "Time Series Classification from Scratch with Deep Neural Networks: A\n  Strong Baseline",
        "abstract": "  We propose a simple but strong baseline for time series classification from\nscratch with deep neural networks. Our proposed baseline models are pure\nend-to-end without any heavy preprocessing on the raw data or feature crafting.\nThe proposed Fully Convolutional Network (FCN) achieves premium performance to\nother state-of-the-art approaches and our exploration of the very deep neural\nnetworks with the ResNet structure is also competitive. The global average\npooling in our convolutional model enables the exploitation of the Class\nActivation Map (CAM) to find out the contributing region in the raw data for\nthe specific labels. Our models provides a simple choice for the real world\napplication and a good starting point for the future research. An overall\nanalysis is provided to discuss the generalization capability of our models,\nlearned features, network structures and the classification semantics.\n",
        "published": "2016",
        "authors": [
            "Zhiguang Wang",
            "Weizhong Yan",
            "Tim Oates"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.07743v1",
        "title": "Tunable Sensitivity to Large Errors in Neural Network Training",
        "abstract": "  When humans learn a new concept, they might ignore examples that they cannot\nmake sense of at first, and only later focus on such examples, when they are\nmore useful for learning. We propose incorporating this idea of tunable\nsensitivity for hard examples in neural network learning, using a new\ngeneralization of the cross-entropy gradient step, which can be used in place\nof the gradient in any gradient-based training method. The generalized gradient\nis parameterized by a value that controls the sensitivity of the training\nprocess to harder training examples. We tested our method on several benchmark\ndatasets. We propose, and corroborate in our experiments, that the optimal\nlevel of sensitivity to hard example is positively correlated with the depth of\nthe network. Moreover, the test prediction error obtained by our method is\ngenerally lower than that of the vanilla cross-entropy gradient learner. We\ntherefore conclude that tunable sensitivity can be helpful for neural network\nlearning.\n",
        "published": "2016",
        "authors": [
            "Gil Keren",
            "Sivan Sabato",
            "Bj\u00f6rn Schuller"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.08083v1",
        "title": "Survey of Expressivity in Deep Neural Networks",
        "abstract": "  We survey results on neural network expressivity described in \"On the\nExpressive Power of Deep Neural Networks\". The paper motivates and develops\nthree natural measures of expressiveness, which all display an exponential\ndependence on the depth of the network. In fact, all of these measures are\nrelated to a fourth quantity, trajectory length. This quantity grows\nexponentially in the depth of the network, and is responsible for the depth\nsensitivity observed. These results translate to consequences for networks\nduring and after training. They suggest that parameters earlier in a network\nhave greater influence on its expressive power -- in particular, given a layer,\nits influence on expressivity is determined by the remaining depth of the\nnetwork after that layer. This is verified with experiments on MNIST and\nCIFAR-10. We also explore the effect of training on the input-output map, and\nfind that it trades off between the stability and expressivity.\n",
        "published": "2016",
        "authors": [
            "Maithra Raghu",
            "Ben Poole",
            "Jon Kleinberg",
            "Surya Ganguli",
            "Jascha Sohl-Dickstein"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1611.09232v1",
        "title": "Efficient Convolutional Auto-Encoding via Random Convexification and\n  Frequency-Domain Minimization",
        "abstract": "  The omnipresence of deep learning architectures such as deep convolutional\nneural networks (CNN)s is fueled by the synergistic combination of\never-increasing labeled datasets and specialized hardware. Despite the\nindisputable success, the reliance on huge amounts of labeled data and\nspecialized hardware can be a limiting factor when approaching new\napplications. To help alleviating these limitations, we propose an efficient\nlearning strategy for layer-wise unsupervised training of deep CNNs on\nconventional hardware in acceptable time. Our proposed strategy consists of\nrandomly convexifying the reconstruction contractive auto-encoding (RCAE)\nlearning objective and solving the resulting large-scale convex minimization\nproblem in the frequency domain via coordinate descent (CD). The main\nadvantages of our proposed learning strategy are: (1) single tunable\noptimization parameter; (2) fast and guaranteed convergence; (3) possibilities\nfor full parallelization. Numerical experiments show that our proposed learning\nstrategy scales (in the worst case) linearly with image size, number of filters\nand filter size.\n",
        "published": "2016",
        "authors": [
            "Meshia C\u00e9dric Oveneke",
            "Mitchel Aliosha-Perez",
            "Yong Zhao",
            "Dongmei Jiang",
            "Hichem Sahli"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.00962v1",
        "title": "Positive blood culture detection in time series data using a BiLSTM\n  network",
        "abstract": "  The presence of bacteria or fungi in the bloodstream of patients is abnormal\nand can lead to life-threatening conditions. A computational model based on a\nbidirectional long short-term memory artificial neural network, is explored to\nassist doctors in the intensive care unit to predict whether examination of\nblood cultures of patients will return positive. As input it uses nine\nmonitored clinical parameters, presented as time series data, collected from\n2177 ICU admissions at the Ghent University Hospital. Our main goal is to\ndetermine if general machine learning methods and more specific, temporal\nmodels, can be used to create an early detection system. This preliminary\nresearch obtains an area of 71.95% under the precision recall curve, proving\nthe potential of temporal neural networks in this context.\n",
        "published": "2016",
        "authors": [
            "Leen De Baets",
            "Joeri Ruyssinck",
            "Thomas Peiffer",
            "Johan Decruyenaere",
            "Filip De Turck",
            "Femke Ongenae",
            "Tom Dhaene"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.01251v2",
        "title": "Known Unknowns: Uncertainty Quality in Bayesian Neural Networks",
        "abstract": "  We evaluate the uncertainty quality in neural networks using anomaly\ndetection. We extract uncertainty measures (e.g. entropy) from the predictions\nof candidate models, use those measures as features for an anomaly detector,\nand gauge how well the detector differentiates known from unknown classes. We\nassign higher uncertainty quality to candidate models that lead to better\ndetectors. We also propose a novel method for sampling a variational\napproximation of a Bayesian neural network, called One-Sample Bayesian\nApproximation (OSBA). We experiment on two datasets, MNIST and CIFAR10. We\ncompare the following candidate neural network models: Maximum Likelihood,\nBayesian Dropout, OSBA, and --- for MNIST --- the standard variational\napproximation. We show that Bayesian Dropout and OSBA provide better\nuncertainty information than Maximum Likelihood, and are essentially equivalent\nto the standard variational approximation, but much faster.\n",
        "published": "2016",
        "authors": [
            "Ramon Oliveira",
            "Pedro Tabacof",
            "Eduardo Valle"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.01936v1",
        "title": "A Probabilistic Framework for Deep Learning",
        "abstract": "  We develop a probabilistic framework for deep learning based on the Deep\nRendering Mixture Model (DRMM), a new generative probabilistic model that\nexplicitly capture variations in data due to latent task nuisance variables. We\ndemonstrate that max-sum inference in the DRMM yields an algorithm that exactly\nreproduces the operations in deep convolutional neural networks (DCNs),\nproviding a first principles derivation. Our framework provides new insights\ninto the successes and shortcomings of DCNs as well as a principled route to\ntheir improvement. DRMM training via the Expectation-Maximization (EM)\nalgorithm is a powerful alternative to DCN back-propagation, and initial\ntraining results are promising. Classification based on the DRMM and other\nvariants outperforms DCNs in supervised digit classification, training 2-3x\nfaster while achieving similar accuracy. Moreover, the DRMM is applicable to\nsemi-supervised and unsupervised learning tasks, achieving results that are\nstate-of-the-art in several categories on the MNIST benchmark and comparable to\nstate of the art on the CIFAR10 benchmark.\n",
        "published": "2016",
        "authors": [
            "Ankit B. Patel",
            "Tan Nguyen",
            "Richard G. Baraniuk"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.01942v1",
        "title": "Semi-Supervised Learning with the Deep Rendering Mixture Model",
        "abstract": "  Semi-supervised learning algorithms reduce the high cost of acquiring labeled\ntraining data by using both labeled and unlabeled data during learning. Deep\nConvolutional Networks (DCNs) have achieved great success in supervised tasks\nand as such have been widely employed in the semi-supervised learning. In this\npaper we leverage the recently developed Deep Rendering Mixture Model (DRMM), a\nprobabilistic generative model that models latent nuisance variation, and whose\ninference algorithm yields DCNs. We develop an EM algorithm for the DRMM to\nlearn from both labeled and unlabeled data. Guided by the theory of the DRMM,\nwe introduce a novel non-negativity constraint and a variational inference\nterm. We report state-of-the-art performance on MNIST and SVHN and competitive\nresults on CIFAR10. We also probe deeper into how a DRMM trained in a\nsemi-supervised setting represents latent nuisance variation using\nsynthetically rendered images. Taken together, our work provides a unified\nframework for supervised, unsupervised, and semi-supervised learning.\n",
        "published": "2016",
        "authors": [
            "Tan Nguyen",
            "Wanjia Liu",
            "Ethan Perez",
            "Richard G. Baraniuk",
            "Ankit B. Patel"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.03480v1",
        "title": "Self-calibrating Neural Networks for Dimensionality Reduction",
        "abstract": "  Recently, a novel family of biologically plausible online algorithms for\nreducing the dimensionality of streaming data has been derived from the\nsimilarity matching principle. In these algorithms, the number of output\ndimensions can be determined adaptively by thresholding the singular values of\nthe input data matrix. However, setting such threshold requires knowing the\nmagnitude of the desired singular values in advance. Here we propose online\nalgorithms where the threshold is self-calibrating based on the singular values\ncomputed from the existing observations. To derive these algorithms from the\nsimilarity matching cost function we propose novel regularizers. As before,\nthese online algorithms can be implemented by Hebbian/anti-Hebbian neural\nnetworks in which the learning rule depends on the chosen regularizer. We\ndemonstrate both mathematically and via simulation the effectiveness of these\nonline algorithms in various settings.\n",
        "published": "2016",
        "authors": [
            "Yuansi Chen",
            "Cengiz Pehlevan",
            "Dmitri B. Chklovskii"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.03770v2",
        "title": "Neurogenesis Deep Learning",
        "abstract": "  Neural machine learning methods, such as deep neural networks (DNN), have\nachieved remarkable success in a number of complex data processing tasks. These\nmethods have arguably had their strongest impact on tasks such as image and\naudio processing - data processing domains in which humans have long held clear\nadvantages over conventional algorithms. In contrast to biological neural\nsystems, which are capable of learning continuously, deep artificial networks\nhave a limited ability for incorporating new information in an already trained\nnetwork. As a result, methods for continuous learning are potentially highly\nimpactful in enabling the application of deep networks to dynamic data sets.\nHere, inspired by the process of adult neurogenesis in the hippocampus, we\nexplore the potential for adding new neurons to deep layers of artificial\nneural networks in order to facilitate their acquisition of novel information\nwhile preserving previously trained data representations. Our results on the\nMNIST handwritten digit dataset and the NIST SD 19 dataset, which includes\nlower and upper case letters and digits, demonstrate that neurogenesis is well\nsuited for addressing the stability-plasticity dilemma that has long challenged\nadaptive machine learning algorithms.\n",
        "published": "2016",
        "authors": [
            "Timothy J. Draelos",
            "Nadine E. Miner",
            "Christopher C. Lamb",
            "Jonathan A. Cox",
            "Craig M. Vineyard",
            "Kristofor D. Carlson",
            "William M. Severa",
            "Conrad D. James",
            "James B. Aimone"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1612.05231v3",
        "title": "Tunable Efficient Unitary Neural Networks (EUNN) and their application\n  to RNNs",
        "abstract": "  Using unitary (instead of general) matrices in artificial neural networks\n(ANNs) is a promising way to solve the gradient explosion/vanishing problem, as\nwell as to enable ANNs to learn long-term correlations in the data. This\napproach appears particularly promising for Recurrent Neural Networks (RNNs).\nIn this work, we present a new architecture for implementing an Efficient\nUnitary Neural Network (EUNNs); its main advantages can be summarized as\nfollows. Firstly, the representation capacity of the unitary space in an EUNN\nis fully tunable, ranging from a subspace of SU(N) to the entire unitary space.\nSecondly, the computational complexity for training an EUNN is merely\n$\\mathcal{O}(1)$ per parameter. Finally, we test the performance of EUNNs on\nthe standard copying task, the pixel-permuted MNIST digit recognition benchmark\nas well as the Speech Prediction Test (TIMIT). We find that our architecture\nsignificantly outperforms both other state-of-the-art unitary RNNs and the LSTM\narchitecture, in terms of the final performance and/or the wall-clock training\nspeed. EUNNs are thus promising alternatives to RNNs and LSTMs for a wide\nvariety of applications.\n",
        "published": "2016",
        "authors": [
            "Li Jing",
            "Yichen Shen",
            "Tena Dub\u010dek",
            "John Peurifoy",
            "Scott Skirlo",
            "Yann LeCun",
            "Max Tegmark",
            "Marin Solja\u010di\u0107"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.03477v4",
        "title": "A Neural Representation of Sketch Drawings",
        "abstract": "  We present sketch-rnn, a recurrent neural network (RNN) able to construct\nstroke-based drawings of common objects. The model is trained on thousands of\ncrude human-drawn images representing hundreds of classes. We outline a\nframework for conditional and unconditional sketch generation, and describe new\nrobust training methods for generating coherent sketch drawings in a vector\nformat.\n",
        "published": "2017",
        "authors": [
            "David Ha",
            "Douglas Eck"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1704.05420v2",
        "title": "Diagonal RNNs in Symbolic Music Modeling",
        "abstract": "  In this paper, we propose a new Recurrent Neural Network (RNN) architecture.\nThe novelty is simple: We use diagonal recurrent matrices instead of full. This\nresults in better test likelihood and faster convergence compared to regular\nfull RNNs in most of our experiments. We show the benefits of using diagonal\nrecurrent matrices with popularly used LSTM and GRU architectures as well as\nwith the vanilla RNN architecture, on four standard symbolic music datasets.\n",
        "published": "2017",
        "authors": [
            "Y. Cem Subakan",
            "Paris Smaragdis"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.02975v3",
        "title": "Anomaly Detection on Graph Time Series",
        "abstract": "  In this paper, we use variational recurrent neural network to investigate the\nanomaly detection problem on graph time series. The temporal correlation is\nmodeled by the combination of recurrent neural network (RNN) and variational\ninference (VI), while the spatial information is captured by the graph\nconvolutional network. In order to incorporate external factors, we use feature\nextractor to augment the transition of latent variables, which can learn the\ninfluence of external factors. With the target function as accumulative ELBO,\nit is easy to extend this model to on-line method. The experimental study on\ntraffic flow data shows the detection capability of the proposed method.\n",
        "published": "2017",
        "authors": [
            "Daniel Hsu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.02979v1",
        "title": "Tikhonov Regularization for Long Short-Term Memory Networks",
        "abstract": "  It is a well-known fact that adding noise to the input data often improves\nnetwork performance. While the dropout technique may be a cause of memory loss,\nwhen it is applied to recurrent connections, Tikhonov regularization, which can\nbe regarded as the training with additive noise, avoids this issue naturally,\nthough it implies regularizer derivation for different architectures. In case\nof feedforward neural networks this is straightforward, while for networks with\nrecurrent connections and complicated layers it leads to some difficulties. In\nthis paper, a Tikhonov regularizer is derived for Long-Short Term Memory (LSTM)\nnetworks. Although it is independent of time for simplicity, it considers\ninteraction between weights of the LSTM unit, which in theory makes it possible\nto regularize the unit with complicated dependences by using only one parameter\nthat measures the input data perturbation. The regularizer that is proposed in\nthis paper has three parameters: one to control the regularization process, and\nother two to maintain computation stability while the network is being trained.\nThe theory developed in this paper can be applied to get such regularizers for\ndifferent recurrent neural networks with Hadamard products and Lipschitz\ncontinuous functions.\n",
        "published": "2017",
        "authors": [
            "Andrei Turkin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.03498v2",
        "title": "Neural Expectation Maximization",
        "abstract": "  Many real world tasks such as reasoning and physical interaction require\nidentification and manipulation of conceptual entities. A first step towards\nsolving these tasks is the automated discovery of distributed symbol-like\nrepresentations. In this paper, we explicitly formalize this problem as\ninference in a spatial mixture model where each component is parametrized by a\nneural network. Based on the Expectation Maximization framework we then derive\na differentiable clustering method that simultaneously learns how to group and\nrepresent individual entities. We evaluate our method on the (sequential)\nperceptual grouping task and find that it is able to accurately recover the\nconstituent objects. We demonstrate that the learned representations are useful\nfor next-step prediction.\n",
        "published": "2017",
        "authors": [
            "Klaus Greff",
            "Sjoerd van Steenkiste",
            "J\u00fcrgen Schmidhuber"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.07147v1",
        "title": "Classification via Tensor Decompositions of Echo State Networks",
        "abstract": "  This work introduces a tensor-based method to perform supervised\nclassification on spatiotemporal data processed in an echo state network.\nTypically when performing supervised classification tasks on data processed in\nan echo state network, the entire collection of hidden layer node states from\nthe training dataset is shaped into a matrix, allowing one to use standard\nlinear algebra techniques to train the output layer. However, the collection of\nhidden layer states is multidimensional in nature, and representing it as a\nmatrix may lead to undesirable numerical conditions or loss of spatial and\ntemporal correlations in the data.\n  This work proposes a tensor-based supervised classification method on echo\nstate network data that preserves and exploits the multidimensional nature of\nthe hidden layer states. The method, which is based on orthogonal Tucker\ndecompositions of tensors, is compared with the standard linear output weight\napproach in several numerical experiments on both synthetic and natural data.\nThe results show that the tensor-based approach tends to outperform the\nstandard approach in terms of classification accuracy.\n",
        "published": "2017",
        "authors": [
            "Ashley Prater"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.08012v3",
        "title": "Deep learning with convolutional neural networks for decoding and\n  visualization of EEG pathology",
        "abstract": "  We apply convolutional neural networks (ConvNets) to the task of\ndistinguishing pathological from normal EEG recordings in the Temple University\nHospital EEG Abnormal Corpus. We use two basic, shallow and deep ConvNet\narchitectures recently shown to decode task-related information from EEG at\nleast as well as established algorithms designed for this purpose. In decoding\nEEG pathology, both ConvNets reached substantially better accuracies (about 6%\nbetter, ~85% vs. ~79%) than the only published result for this dataset, and\nwere still better when using only 1 minute of each recording for training and\nonly six seconds of each recording for testing. We used automated methods to\noptimize architectural hyperparameters and found intriguingly different ConvNet\narchitectures, e.g., with max pooling as the only nonlinearity. Visualizations\nof the ConvNet decoding behavior showed that they used spectral power changes\nin the delta (0-4 Hz) and theta (4-8 Hz) frequency range, possibly alongside\nother features, consistent with expectations derived from spectral analysis of\nthe EEG data and from the textual medical reports. Analysis of the textual\nmedical reports also highlighted the potential for accuracy increases by\nintegrating contextual information, such as the age of subjects. In summary,\nthe ConvNets and visualization techniques used in this study constitute a next\nstep towards clinically useful automated EEG diagnosis and establish a new\nbaseline for future work on this topic.\n",
        "published": "2017",
        "authors": [
            "Robin Tibor Schirrmeister",
            "Lukas Gemein",
            "Katharina Eggensperger",
            "Frank Hutter",
            "Tonio Ball"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1708.08282v4",
        "title": "A New Learning Paradigm for Random Vector Functional-Link Network: RVFL+",
        "abstract": "  In school, a teacher plays an important role in various classroom teaching\npatterns. Likewise to this human learning activity, the learning using\nprivileged information (LUPI) paradigm provides additional information\ngenerated by the teacher to 'teach' learning models during the training stage.\nTherefore, this novel learning paradigm is a typical Teacher-Student\nInteraction mechanism. This paper is the first to present a random vector\nfunctional link network based on the LUPI paradigm, called RVFL+. Rather than\nsimply combining two existing approaches, the newly-derived RVFL+ fills the gap\nbetween classical randomized neural networks and the newfashioned LUPI\nparadigm, which offers an alternative way to train RVFL networks. Moreover, the\nproposed RVFL+ can perform in conjunction with the kernel trick for highly\ncomplicated nonlinear feature learning, which is termed KRVFL+. Furthermore,\nthe statistical property of the proposed RVFL+ is investigated, and we present\na sharp and high-quality generalization error bound based on the Rademacher\ncomplexity. Competitive experimental results on 14 real-world datasets\nillustrate the great effectiveness and efficiency of the novel RVFL+ and\nKRVFL+, which can achieve better generalization performance than\nstate-of-the-art methods.\n",
        "published": "2017",
        "authors": [
            "Peng-Bo Zhang",
            "Zhi-Xin Yang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.00486v2",
        "title": "DeepSafe: A Data-driven Approach for Checking Adversarial Robustness in\n  Neural Networks",
        "abstract": "  Deep neural networks have become widely used, obtaining remarkable results in\ndomains such as computer vision, speech recognition, natural language\nprocessing, audio recognition, social network filtering, machine translation,\nand bio-informatics, where they have produced results comparable to human\nexperts. However, these networks can be easily fooled by adversarial\nperturbations: minimal changes to correctly-classified inputs, that cause the\nnetwork to mis-classify them. This phenomenon represents a concern for both\nsafety and security, but it is currently unclear how to measure a network's\nrobustness against such perturbations. Existing techniques are limited to\nchecking robustness around a few individual input points, providing only very\nlimited guarantees. We propose a novel approach for automatically identifying\nsafe regions of the input space, within which the network is robust against\nadversarial perturbations. The approach is data-guided, relying on clustering\nto identify well-defined geometric regions as candidate safe regions. We then\nutilize verification techniques to confirm that these regions are safe or to\nprovide counter-examples showing that they are not safe. We also introduce the\nnotion of targeted robustness which, for a given target label and region,\nensures that a NN does not map any input in the region to the target label. We\nevaluated our technique on the MNIST dataset and on a neural network\nimplementation of a controller for the next-generation Airborne Collision\nAvoidance System for unmanned aircraft (ACAS Xu). For these networks, our\napproach identified multiple regions which were completely safe as well as some\nwhich were only safe for specific labels. It also discovered several\nadversarial perturbations of interest.\n",
        "published": "2017",
        "authors": [
            "Divya Gopinath",
            "Guy Katz",
            "Corina S. Pasareanu",
            "Clark Barrett"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.00811v2",
        "title": "Deep Learning for Unsupervised Insider Threat Detection in Structured\n  Cybersecurity Data Streams",
        "abstract": "  Analysis of an organization's computer network activity is a key component of\nearly detection and mitigation of insider threat, a growing concern for many\norganizations. Raw system logs are a prototypical example of streaming data\nthat can quickly scale beyond the cognitive power of a human analyst. As a\nprospective filter for the human analyst, we present an online unsupervised\ndeep learning approach to detect anomalous network activity from system logs in\nreal time. Our models decompose anomaly scores into the contributions of\nindividual user behavior features for increased interpretability to aid\nanalysts reviewing potential cases of insider threat. Using the CERT Insider\nThreat Dataset v6.2 and threat detection recall as our performance metric, our\nnovel deep and recurrent neural network models outperform Principal Component\nAnalysis, Support Vector Machine and Isolation Forest based anomaly detection\nbaselines. For our best model, the events labeled as insider threat activity in\nour dataset had an average anomaly score in the 95.53 percentile, demonstrating\nour approach's potential to greatly reduce analyst workloads.\n",
        "published": "2017",
        "authors": [
            "Aaron Tuor",
            "Samuel Kaplan",
            "Brian Hutchinson",
            "Nicole Nichols",
            "Sean Robinson"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.01013v1",
        "title": "Training Feedforward Neural Networks with Standard Logistic Activations\n  is Feasible",
        "abstract": "  Training feedforward neural networks with standard logistic activations is\nconsidered difficult because of the intrinsic properties of these sigmoidal\nfunctions. This work aims at showing that these networks can be trained to\nachieve generalization performance comparable to those based on hyperbolic\ntangent activations. The solution consists on applying a set of conditions in\nparameter initialization, which have been derived from the study of the\nproperties of a single neuron from an information-theoretic perspective. The\nproposed initialization is validated through an extensive experimental\nanalysis.\n",
        "published": "2017",
        "authors": [
            "Emanuele Sansone",
            "Francesco G. B. De Natale"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.03070v1",
        "title": "full-FORCE: A Target-Based Method for Training Recurrent Networks",
        "abstract": "  Trained recurrent networks are powerful tools for modeling dynamic neural\ncomputations. We present a target-based method for modifying the full\nconnectivity matrix of a recurrent network to train it to perform tasks\ninvolving temporally complex input/output transformations. The method\nintroduces a second network during training to provide suitable \"target\"\ndynamics useful for performing the task. Because it exploits the full recurrent\nconnectivity, the method produces networks that perform tasks with fewer\nneurons and greater noise robustness than traditional least-squares (FORCE)\napproaches. In addition, we show how introducing additional input signals into\nthe target-generating network, which act as task hints, greatly extends the\nrange of tasks that can be learned and provides control over the complexity and\nnature of the dynamics of the trained, task-performing network.\n",
        "published": "2017",
        "authors": [
            "Brian DePasquale",
            "Christopher J. Cueva",
            "Kanaka Rajan",
            "G. Sean Escola",
            "L. F. Abbott"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.04211v2",
        "title": "StackSeq2Seq: Dual Encoder Seq2Seq Recurrent Networks",
        "abstract": "  A widely studied non-deterministic polynomial time (NP) hard problem lies in\nfinding a route between the two nodes of a graph. Often meta-heuristics\nalgorithms such as $A^{*}$ are employed on graphs with a large number of nodes.\nHere, we propose a deep recurrent neural network architecture based on the\nSequence-2-Sequence (Seq2Seq) model, widely used, for instance in text\ntranslation. Particularly, we illustrate that utilising a context vector that\nhas been learned from two different recurrent networks enables increased\naccuracies in learning the shortest route of a graph. Additionally, we show\nthat one can boost the performance of the Seq2Seq network by smoothing the loss\nfunction using a homotopy continuation of the decoder's loss function.\n",
        "published": "2017",
        "authors": [
            "Alessandro Bay",
            "Biswa Sengupta"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.04404v3",
        "title": "Sum-Product-Quotient Networks",
        "abstract": "  We present a novel tractable generative model that extends Sum-Product\nNetworks (SPNs) and significantly boosts their power. We call it\nSum-Product-Quotient Networks (SPQNs), whose core concept is to incorporate\nconditional distributions into the model by direct computation using quotient\nnodes, e.g. $P(A|B) = \\frac{P(A,B)}{P(B)}$. We provide sufficient conditions\nfor the tractability of SPQNs that generalize and relax the decomposable and\ncomplete tractability conditions of SPNs. These relaxed conditions give rise to\nan exponential boost to the expressive efficiency of our model, i.e. we prove\nthat there are distributions which SPQNs can compute efficiently but require\nSPNs to be of exponential size. Thus, we narrow the gap in expressivity between\ntractable graphical models and other Neural Network-based generative models.\n",
        "published": "2017",
        "authors": [
            "Or Sharir",
            "Amnon Shashua"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.04874v1",
        "title": "A Method of Generating Random Weights and Biases in Feedforward Neural\n  Networks with Random Hidden Nodes",
        "abstract": "  Neural networks with random hidden nodes have gained increasing interest from\nresearchers and practical applications. This is due to their unique features\nsuch as very fast training and universal approximation property. In these\nnetworks the weights and biases of hidden nodes determining the nonlinear\nfeature mapping are set randomly and are not learned. Appropriate selection of\nthe intervals from which weights and biases are selected is extremely\nimportant. This topic has not yet been sufficiently explored in the literature.\nIn this work a method of generating random weights and biases is proposed. This\nmethod generates the parameters of the hidden nodes in such a way that\nnonlinear fragments of the activation functions are located in the input space\nregions with data and can be used to construct the surface approximating a\nnonlinear target function. The weights and biases are dependent on the input\ndata range and activation function type. The proposed methods allows us to\ncontrol the generalization degree of the model. These all lead to improvement\nin approximation performance of the network. Several experiments show very\npromising results.\n",
        "published": "2017",
        "authors": [
            "Grzegorz Dudek"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.07547v1",
        "title": "Learning compressed representations of blood samples time series with\n  missing data",
        "abstract": "  Clinical measurements collected over time are naturally represented as\nmultivariate time series (MTS), which often contain missing data. An\nautoencoder can learn low dimensional vectorial representations of MTS that\npreserve important data characteristics, but cannot deal explicitly with\nmissing data. In this work, we propose a new framework that combines an\nautoencoder with the Time series Cluster Kernel (TCK), a kernel that accounts\nfor missingness patterns in MTS. Via kernel alignment, we incorporate TCK in\nthe autoencoder to improve the learned representations in presence of missing\ndata. We consider a classification problem of MTS with missing values,\nrepresenting blood samples of patients with surgical site infection. With our\napproach, rather than with a standard autoencoder, we learn representations in\nlow dimensions that can be classified better.\n",
        "published": "2017",
        "authors": [
            "Filippo Maria Bianchi",
            "Karl \u00d8yvind Mikalsen",
            "Robert Jenssen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1710.09537v1",
        "title": "Rotational Unit of Memory",
        "abstract": "  The concepts of unitary evolution matrices and associative memory have\nboosted the field of Recurrent Neural Networks (RNN) to state-of-the-art\nperformance in a variety of sequential tasks. However, RNN still have a limited\ncapacity to manipulate long-term memory. To bypass this weakness the most\nsuccessful applications of RNN use external techniques such as attention\nmechanisms. In this paper we propose a novel RNN model that unifies the\nstate-of-the-art approaches: Rotational Unit of Memory (RUM). The core of RUM\nis its rotational operation, which is, naturally, a unitary matrix, providing\narchitectures with the power to learn long-term dependencies by overcoming the\nvanishing and exploding gradients problem. Moreover, the rotational unit also\nserves as associative memory. We evaluate our model on synthetic memorization,\nquestion answering and language modeling tasks. RUM learns the Copying Memory\ntask completely and improves the state-of-the-art result in the Recall task.\nRUM's performance in the bAbI Question Answering task is comparable to that of\nmodels with attention mechanism. We also improve the state-of-the-art result to\n1.189 bits-per-character (BPC) loss in the Character Level Penn Treebank (PTB)\ntask, which is to signify the applications of RUM to real-world sequential\ndata. The universality of our construction, at the core of RNN, establishes RUM\nas a promising approach to language modeling, speech recognition and machine\ntranslation.\n",
        "published": "2017",
        "authors": [
            "Rumen Dangovski",
            "Li Jing",
            "Marin Soljacic"
        ]
    }
]