[
    {
        "id": "http://arxiv.org/abs/2309.14032v2",
        "title": "DeepACO: Neural-enhanced Ant Systems for Combinatorial Optimization",
        "abstract": "  Ant Colony Optimization (ACO) is a meta-heuristic algorithm that has been\nsuccessfully applied to various Combinatorial Optimization Problems (COPs).\nTraditionally, customizing ACO for a specific problem requires the expert\ndesign of knowledge-driven heuristics. In this paper, we propose DeepACO, a\ngeneric framework that leverages deep reinforcement learning to automate\nheuristic designs. DeepACO serves to strengthen the heuristic measures of\nexisting ACO algorithms and dispense with laborious manual design in future ACO\napplications. As a neural-enhanced meta-heuristic, DeepACO consistently\noutperforms its ACO counterparts on eight COPs using a single neural\narchitecture and a single set of hyperparameters. As a Neural Combinatorial\nOptimization method, DeepACO performs better than or on par with\nproblem-specific methods on canonical routing problems. Our code is publicly\navailable at https://github.com/henry-yeh/DeepACO.\n",
        "published": "2023",
        "authors": [
            "Haoran Ye",
            "Jiarui Wang",
            "Zhiguang Cao",
            "Helan Liang",
            "Yong Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2309.15803v1",
        "title": "ANNCRIPS: Artificial Neural Networks for Cancer Research In Prediction &\n  Survival",
        "abstract": "  Prostate cancer is a prevalent malignancy among men aged 50 and older.\nCurrent diagnostic methods primarily rely on blood tests, PSA:Prostate-Specific\nAntigen levels, and Digital Rectal Examinations (DRE). However, these methods\nsuffer from a significant rate of false positive results. This study focuses on\nthe development and validation of an intelligent mathematical model utilizing\nArtificial Neural Networks (ANNs) to enhance the early detection of prostate\ncancer. The primary objective of this research paper is to present a novel\nmathematical model designed to aid in the early detection of prostate cancer,\nfacilitating prompt intervention by healthcare professionals. The model's\nimplementation demonstrates promising potential in reducing the incidence of\nfalse positives, thereby improving patient outcomes. Furthermore, we envision\nthat, with further refinement, extensive testing, and validation, this model\ncan evolve into a robust, marketable solution for prostate cancer detection.\nThe long-term goal is to make this solution readily available for deployment in\nvarious screening centers, hospitals, and research institutions, ultimately\ncontributing to more effective cancer screening and patient care.\n",
        "published": "2023",
        "authors": [
            "Amit Mathapati"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2309.15946v1",
        "title": "Unified Long-Term Time-Series Forecasting Benchmark",
        "abstract": "  In order to support the advancement of machine learning methods for\npredicting time-series data, we present a comprehensive dataset designed\nexplicitly for long-term time-series forecasting. We incorporate a collection\nof datasets obtained from diverse, dynamic systems and real-life records. Each\ndataset is standardized by dividing it into training and test trajectories with\npredetermined lookback lengths. We include trajectories of length up to $2000$\nto ensure a reliable evaluation of long-term forecasting capabilities. To\ndetermine the most effective model in diverse scenarios, we conduct an\nextensive benchmarking analysis using classical and state-of-the-art models,\nnamely LSTM, DeepAR, NLinear, N-Hits, PatchTST, and LatentODE. Our findings\nreveal intriguing performance comparisons among these models, highlighting the\ndataset-dependent nature of model effectiveness. Notably, we introduce a custom\nlatent NLinear model and enhance DeepAR with a curriculum learning phase. Both\nconsistently outperform their vanilla counterparts.\n",
        "published": "2023",
        "authors": [
            "Jacek Cyranka",
            "Szymon Haponiuk"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.00337v1",
        "title": "Quantization of Deep Neural Networks to facilitate self-correction of\n  weights on Phase Change Memory-based analog hardware",
        "abstract": "  In recent years, hardware-accelerated neural networks have gained significant\nattention for edge computing applications. Among various hardware options,\ncrossbar arrays, offer a promising avenue for efficient storage and\nmanipulation of neural network weights. However, the transition from trained\nfloating-point models to hardware-constrained analog architectures remains a\nchallenge. In this work, we combine a quantization technique specifically\ndesigned for such architectures with a novel self-correcting mechanism. By\nutilizing dual crossbar connections to represent both the positive and negative\nparts of a single weight, we develop an algorithm to approximate a set of\nmultiplicative weights. These weights, along with their differences, aim to\nrepresent the original network's weights with minimal loss in performance. We\nimplement the models using IBM's aihwkit and evaluate their efficacy over time.\nOur results demonstrate that, when paired with an on-chip pulse generator, our\nself-correcting neural network performs comparably to those trained with\nanalog-aware algorithms.\n",
        "published": "2023",
        "authors": [
            "Arseni Ivanov"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.01180v1",
        "title": "Evolutionary Neural Architecture Search for Transformer in Knowledge\n  Tracing",
        "abstract": "  Knowledge tracing (KT) aims to trace students' knowledge states by predicting\nwhether students answer correctly on exercises. Despite the excellent\nperformance of existing Transformer-based KT approaches, they are criticized\nfor the manually selected input features for fusion and the defect of single\nglobal context modelling to directly capture students' forgetting behavior in\nKT, when the related records are distant from the current record in terms of\ntime. To address the issues, this paper first considers adding convolution\noperations to the Transformer to enhance its local context modelling ability\nused for students' forgetting behavior, then proposes an evolutionary neural\narchitecture search approach to automate the input feature selection and\nautomatically determine where to apply which operation for achieving the\nbalancing of the local/global context modelling. In the search space, the\noriginal global path containing the attention module in Transformer is replaced\nwith the sum of a global path and a local path that could contain different\nconvolutions, and the selection of input features is also considered. To search\nthe best architecture, we employ an effective evolutionary algorithm to explore\nthe search space and also suggest a search space reduction strategy to\naccelerate the convergence of the algorithm. Experimental results on the two\nlargest and most challenging education datasets demonstrate the effectiveness\nof the architecture found by the proposed approach.\n",
        "published": "2023",
        "authors": [
            "Shangshang Yang",
            "Xiaoshan Yu",
            "Ye Tian",
            "Xueming Yan",
            "Haiping Ma",
            "Xingyi Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.02430v1",
        "title": "Episodic Memory Theory for the Mechanistic Interpretation of Recurrent\n  Neural Networks",
        "abstract": "  Understanding the intricate operations of Recurrent Neural Networks (RNNs)\nmechanistically is pivotal for advancing their capabilities and applications.\nIn this pursuit, we propose the Episodic Memory Theory (EMT), illustrating that\nRNNs can be conceptualized as discrete-time analogs of the recently proposed\nGeneral Sequential Episodic Memory Model. To substantiate EMT, we introduce a\nnovel set of algorithmic tasks tailored to probe the variable binding behavior\nin RNNs. Utilizing the EMT, we formulate a mathematically rigorous circuit that\nfacilitates variable binding in these tasks. Our empirical investigations\nreveal that trained RNNs consistently converge to the variable binding circuit,\nthus indicating universality in the dynamics of RNNs. Building on these\nfindings, we devise an algorithm to define a privileged basis, which reveals\nhidden neurons instrumental in the temporal storage and composition of\nvariables, a mechanism vital for the successful generalization in these tasks.\nWe show that the privileged basis enhances the interpretability of the learned\nparameters and hidden states of RNNs. Our work represents a step toward\ndemystifying the internal mechanisms of RNNs and, for computational\nneuroscience, serves to bridge the gap between artificial neural networks and\nneural memory models.\n",
        "published": "2023",
        "authors": [
            "Arjun Karuvally",
            "Peter Delmastro",
            "Hava T. Siegelmann"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.03052v1",
        "title": "Memoria: Hebbian Memory Architecture for Human-Like Sequential\n  Processing",
        "abstract": "  Transformers have demonstrated their success in various domains and tasks.\nHowever, Transformers struggle with long input sequences due to their limited\ncapacity. While one solution is to increase input length, endlessly stretching\nthe length is unrealistic. Furthermore, humans selectively remember and use\nonly relevant information from inputs, unlike Transformers which process all\nraw data from start to end. We introduce Memoria, a general memory network that\napplies Hebbian theory which is a major theory explaining human memory\nformulation to enhance long-term dependencies in neural networks. Memoria\nstores and retrieves information called engram at multiple memory levels of\nworking memory, short-term memory, and long-term memory, using connection\nweights that change according to Hebb's rule. Through experiments with popular\nTransformer-based models like BERT and GPT, we present that Memoria\nsignificantly improves the ability to consider long-term dependencies in\nvarious tasks. Results show that Memoria outperformed existing methodologies in\nsorting and language modeling, and long text classification.\n",
        "published": "2023",
        "authors": [
            "Sangjun Park",
            "JinYeong Bak"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.03195v1",
        "title": "Deep reinforcement learning for machine scheduling: Methodology, the\n  state-of-the-art, and future directions",
        "abstract": "  Machine scheduling aims to optimize job assignments to machines while\nadhering to manufacturing rules and job specifications. This optimization leads\nto reduced operational costs, improved customer demand fulfillment, and\nenhanced production efficiency. However, machine scheduling remains a\nchallenging combinatorial problem due to its NP-hard nature. Deep Reinforcement\nLearning (DRL), a key component of artificial general intelligence, has shown\npromise in various domains like gaming and robotics. Researchers have explored\napplying DRL to machine scheduling problems since 1995. This paper offers a\ncomprehensive review and comparison of DRL-based approaches, highlighting their\nmethodology, applications, advantages, and limitations. It categorizes these\napproaches based on computational components: conventional neural networks,\nencoder-decoder architectures, graph neural networks, and metaheuristic\nalgorithms. Our review concludes that DRL-based methods outperform exact\nsolvers, heuristics, and tabular reinforcement learning algorithms in terms of\ncomputation speed and generating near-global optimal solutions. These DRL-based\napproaches have been successfully applied to static and dynamic scheduling\nacross diverse machine environments and job characteristics. However, DRL-based\nschedulers face limitations in handling complex operational constraints,\nconfigurable multi-objective optimization, generalization, scalability,\ninterpretability, and robustness. Addressing these challenges will be a crucial\nfocus for future research in this field. This paper serves as a valuable\nresource for researchers to assess the current state of DRL-based machine\nscheduling and identify research gaps. It also aids experts and practitioners\nin selecting the appropriate DRL approach for production scheduling.\n",
        "published": "2023",
        "authors": [
            "Maziyar Khadivi",
            "Todd Charter",
            "Marjan Yaghoubi",
            "Masoud Jalayer",
            "Maryam Ahang",
            "Ardeshir Shojaeinasab",
            "Homayoun Najjaran"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.04424v1",
        "title": "Stability Analysis of Non-Linear Classifiers using Gene Regulatory\n  Neural Network for Biological AI",
        "abstract": "  The Gene Regulatory Network (GRN) of biological cells governs a number of key\nfunctionalities that enables them to adapt and survive through different\nenvironmental conditions. Close observation of the GRN shows that the structure\nand operational principles resembles an Artificial Neural Network (ANN), which\ncan pave the way for the development of Biological Artificial Intelligence. In\nparticular, a gene's transcription and translation process resembles a\nsigmoidal-like property based on transcription factor inputs. In this paper, we\ndevelop a mathematical model of gene-perceptron using a dual-layered\ntranscription-translation chemical reaction model, enabling us to transform a\nGRN into a Gene Regulatory Neural Network (GRNN). We perform stability analysis\nfor each gene-perceptron within the fully-connected GRNN sub network to\ndetermine temporal as well as stable concentration outputs that will result in\nreliable computing performance. We focus on a non-linear classifier application\nfor the GRNN, where we analyzed generic multi-layer GRNNs as well as E.Coli\nGRNN that is derived from trans-omic experimental data. Our analysis found that\nvarying the parameters of the chemical reactions can allow us shift the\nboundaries of the classification region, laying the platform for programmable\nGRNNs that suit diverse application requirements.\n",
        "published": "2023",
        "authors": [
            "Adrian Ratwatte",
            "Samitha Somathilaka",
            "Sasitharan Balasubramaniam",
            "Assaf A. Gilad"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.05343v1",
        "title": "Investigating Continuous Learning in Spiking Neural Networks",
        "abstract": "  In this paper, the use of third-generation machine learning, also known as\nspiking neural network architecture, for continuous learning was investigated\nand compared to conventional models. The experimentation was divided into three\nseparate phases. The first phase focused on training the conventional models\nvia transfer learning. The second phase trains a Nengo model from their\nlibrary. Lastly, each conventional model is converted into a spiking neural\nnetwork and trained. Initial results from phase 1 are inline with known\nknowledge about continuous learning within current machine learning literature.\nAll models were able to correctly identify the current classes, but they would\nimmediately see a sharp performance drop in previous classes due to\ncatastrophic forgetting. However, the SNN models were able to retain some\ninformation about previous classes. Although many of the previous classes were\nstill identified as the current trained classes, the output probabilities\nshowed a higher than normal value to the actual class. This indicates that the\nSNN models do have potential to overcome catastrophic forgetting but much work\nis still needed.\n",
        "published": "2023",
        "authors": [
            "C. Tanner Fredieu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.06648v2",
        "title": "Diversity from Human Feedback",
        "abstract": "  Diversity plays a significant role in many problems, such as ensemble\nlearning, reinforcement learning, and combinatorial optimization. How to define\nthe diversity measure is a longstanding problem. Many methods rely on expert\nexperience to define a proper behavior space and then obtain the diversity\nmeasure, which is, however, challenging in many scenarios. In this paper, we\npropose the problem of learning a behavior space from human feedback and\npresent a general method called Diversity from Human Feedback (DivHF) to solve\nit. DivHF learns a behavior descriptor consistent with human preference by\nquerying human feedback. The learned behavior descriptor can be combined with\nany distance measure to define a diversity measure. We demonstrate the\neffectiveness of DivHF by integrating it with the Quality-Diversity\noptimization algorithm MAP-Elites and conducting experiments on the QDax suite.\nThe results show that DivHF learns a behavior space that aligns better with\nhuman requirements compared to direct data-driven approaches and leads to more\ndiverse solutions under human preference. Our contributions include formulating\nthe problem, proposing the DivHF method, and demonstrating its effectiveness\nthrough experiments.\n",
        "published": "2023",
        "authors": [
            "Ren-Jian Wang",
            "Ke Xue",
            "Yutong Wang",
            "Peng Yang",
            "Haobo Fu",
            "Qiang Fu",
            "Chao Qian"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.07711v1",
        "title": "Growing Brains: Co-emergence of Anatomical and Functional Modularity in\n  Recurrent Neural Networks",
        "abstract": "  Recurrent neural networks (RNNs) trained on compositional tasks can exhibit\nfunctional modularity, in which neurons can be clustered by activity similarity\nand participation in shared computational subtasks. Unlike brains, these RNNs\ndo not exhibit anatomical modularity, in which functional clustering is\ncorrelated with strong recurrent coupling and spatial localization of\nfunctional clusters. Contrasting with functional modularity, which can be\nephemerally dependent on the input, anatomically modular networks form a robust\nsubstrate for solving the same subtasks in the future. To examine whether it is\npossible to grow brain-like anatomical modularity, we apply a recent machine\nlearning method, brain-inspired modular training (BIMT), to a network being\ntrained to solve a set of compositional cognitive tasks. We find that\nfunctional and anatomical clustering emerge together, such that functionally\nsimilar neurons also become spatially localized and interconnected. Moreover,\ncompared to standard $L_1$ or no regularization settings, the model exhibits\nsuperior performance by optimally balancing task performance and network\nsparsity. In addition to achieving brain-like organization in RNNs, our\nfindings also suggest that BIMT holds promise for applications in neuromorphic\ncomputing and enhancing the interpretability of neural network architectures.\n",
        "published": "2023",
        "authors": [
            "Ziming Liu",
            "Mikail Khona",
            "Ila R. Fiete",
            "Max Tegmark"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.08252v2",
        "title": "MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with\n  Reinforcement Learning",
        "abstract": "  Recently, Meta-Black-Box Optimization with Reinforcement Learning\n(MetaBBO-RL) has showcased the power of leveraging RL at the meta-level to\nmitigate manual fine-tuning of low-level black-box optimizers. However, this\nfield is hindered by the lack of a unified benchmark. To fill this gap, we\nintroduce MetaBox, the first benchmark platform expressly tailored for\ndeveloping and evaluating MetaBBO-RL methods. MetaBox offers a flexible\nalgorithmic template that allows users to effortlessly implement their unique\ndesigns within the platform. Moreover, it provides a broad spectrum of over 300\nproblem instances, collected from synthetic to realistic scenarios, and an\nextensive library of 19 baseline methods, including both traditional black-box\noptimizers and recent MetaBBO-RL methods. Besides, MetaBox introduces three\nstandardized performance metrics, enabling a more thorough assessment of the\nmethods. In a bid to illustrate the utility of MetaBox for facilitating\nrigorous evaluation and in-depth analysis, we carry out a wide-ranging\nbenchmarking study on existing MetaBBO-RL methods. Our MetaBox is open-source\nand accessible at: https://github.com/GMC-DRL/MetaBox.\n",
        "published": "2023",
        "authors": [
            "Zeyuan Ma",
            "Hongshu Guo",
            "Jiacheng Chen",
            "Zhenrui Li",
            "Guojun Peng",
            "Yue-Jiao Gong",
            "Yining Ma",
            "Zhiguang Cao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.10685v1",
        "title": "PS-AAS: Portfolio Selection for Automated Algorithm Selection in\n  Black-Box Optimization",
        "abstract": "  The performance of automated algorithm selection (AAS) strongly depends on\nthe portfolio of algorithms to choose from. Selecting the portfolio is a\nnon-trivial task that requires balancing the trade-off between the higher\nflexibility of large portfolios with the increased complexity of the AAS task.\nIn practice, probably the most common way to choose the algorithms for the\nportfolio is a greedy selection of the algorithms that perform well in some\nreference tasks of interest.\n  We set out in this work to investigate alternative, data-driven portfolio\nselection techniques. Our proposed method creates algorithm behavior\nmeta-representations, constructs a graph from a set of algorithms based on\ntheir meta-representation similarity, and applies a graph algorithm to select a\nfinal portfolio of diverse, representative, and non-redundant algorithms. We\nevaluate two distinct meta-representation techniques (SHAP and performance2vec)\nfor selecting complementary portfolios from a total of 324 different variants\nof CMA-ES for the task of optimizing the BBOB single-objective problems in\ndimensionalities 5 and 30 with different cut-off budgets. We test two types of\nportfolios: one related to overall algorithm behavior and the `personalized'\none (related to algorithm behavior per each problem separately). We observe\nthat the approach built on the performance2vec-based representations favors\nsmall portfolios with negligible error in the AAS task relative to the virtual\nbest solver from the selected portfolio, whereas the portfolios built from the\nSHAP-based representations gain from higher flexibility at the cost of\ndecreased performance of the AAS. Across most considered scenarios,\npersonalized portfolios yield comparable or slightly better performance than\nthe classical greedy approach. They outperform the full portfolio in all\nscenarios.\n",
        "published": "2023",
        "authors": [
            "Ana Kostovska",
            "Gjorgjina Cenikj",
            "Diederick Vermetten",
            "Anja Jankovic",
            "Ana Nikolikj",
            "Urban Skvorc",
            "Peter Korosec",
            "Carola Doerr",
            "Tome Eftimov"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.13018v2",
        "title": "Getting aligned on representational alignment",
        "abstract": "  Biological and artificial information processing systems form representations\nthat they can use to categorize, reason, plan, navigate, and make decisions.\nHow can we measure the extent to which the representations formed by these\ndiverse systems agree? Do similarities in representations then translate into\nsimilar behavior? How can a system's representations be modified to better\nmatch those of another system? These questions pertaining to the study of\nrepresentational alignment are at the heart of some of the most active research\nareas in cognitive science, neuroscience, and machine learning. For example,\ncognitive scientists measure the representational alignment of multiple\nindividuals to identify shared cognitive priors, neuroscientists align fMRI\nresponses from multiple individuals into a shared representational space for\ngroup-level analyses, and ML researchers distill knowledge from teacher models\ninto student models by increasing their alignment. Unfortunately, there is\nlimited knowledge transfer between research communities interested in\nrepresentational alignment, so progress in one field often ends up being\nrediscovered independently in another. Thus, greater cross-field communication\nwould be advantageous. To improve communication between these fields, we\npropose a unifying framework that can serve as a common language between\nresearchers studying representational alignment. We survey the literature from\nall three fields and demonstrate how prior work fits into this framework.\nFinally, we lay out open problems in representational alignment where progress\ncan benefit all three of these fields. We hope that our work can catalyze\ncross-disciplinary collaboration and accelerate progress for all communities\nstudying and developing information processing systems. We note that this is a\nworking paper and encourage readers to reach out with their suggestions for\nfuture revisions.\n",
        "published": "2023",
        "authors": [
            "Ilia Sucholutsky",
            "Lukas Muttenthaler",
            "Adrian Weller",
            "Andi Peng",
            "Andreea Bobu",
            "Been Kim",
            "Bradley C. Love",
            "Erin Grant",
            "Iris Groen",
            "Jascha Achterberg",
            "Joshua B. Tenenbaum",
            "Katherine M. Collins",
            "Katherine L. Hermann",
            "Kerem Oktar",
            "Klaus Greff",
            "Martin N. Hebart",
            "Nori Jacoby",
            "Qiuyi Zhang",
            "Raja Marjieh",
            "Robert Geirhos",
            "Sherol Chen",
            "Simon Kornblith",
            "Sunayana Rane",
            "Talia Konkle",
            "Thomas P. O'Connell",
            "Thomas Unterthiner",
            "Andrew K. Lampinen",
            "Klaus-Robert M\u00fcller",
            "Mariya Toneva",
            "Thomas L. Griffiths"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.13391v1",
        "title": "Learning Successor Representations with Distributed Hebbian Temporal\n  Memory",
        "abstract": "  This paper presents a novel approach to address the challenge of online\nhidden representation learning for decision-making under uncertainty in\nnon-stationary, partially observable environments. The proposed algorithm,\nDistributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism\nand a multicomponent neuron model. DHTM aims to capture sequential data\nrelationships and make cumulative predictions about future observations,\nforming Successor Representation (SR). Inspired by neurophysiological models of\nthe neocortex, the algorithm utilizes distributed representations, sparse\ntransition matrices, and local Hebbian-like learning rules to overcome the\ninstability and slow learning process of traditional temporal memory algorithms\nlike RNN and HMM. Experimental results demonstrate that DHTM outperforms\nclassical LSTM and performs comparably to more advanced RNN-like algorithms,\nspeeding up Temporal Difference learning for SR in changing environments.\nAdditionally, we compare the SRs produced by DHTM to another biologically\ninspired HMM-like algorithm, CSCG. Our findings suggest that DHTM is a\npromising approach for addressing the challenges of online hidden\nrepresentation learning in dynamic environments.\n",
        "published": "2023",
        "authors": [
            "Evgenii Dzhivelikian",
            "Petr Kuderov",
            "Aleksandr I. Panov"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.15195v1",
        "title": "Neural Multi-Objective Combinatorial Optimization with Diversity\n  Enhancement",
        "abstract": "  Most of existing neural methods for multi-objective combinatorial\noptimization (MOCO) problems solely rely on decomposition, which often leads to\nrepetitive solutions for the respective subproblems, thus a limited Pareto set.\nBeyond decomposition, we propose a novel neural heuristic with diversity\nenhancement (NHDE) to produce more Pareto solutions from two perspectives. On\nthe one hand, to hinder duplicated solutions for different subproblems, we\npropose an indicator-enhanced deep reinforcement learning method to guide the\nmodel, and design a heterogeneous graph attention mechanism to capture the\nrelations between the instance graph and the Pareto front graph. On the other\nhand, to excavate more solutions in the neighborhood of each subproblem, we\npresent a multiple Pareto optima strategy to sample and preserve desirable\nsolutions. Experimental results on classic MOCO problems show that our NHDE is\nable to generate a Pareto front with higher diversity, thereby achieving\nsuperior overall performance. Moreover, our NHDE is generic and can be applied\nto different neural methods for MOCO.\n",
        "published": "2023",
        "authors": [
            "Jinbiao Chen",
            "Zizhen Zhang",
            "Zhiguang Cao",
            "Yaoxin Wu",
            "Yining Ma",
            "Te Ye",
            "Jiahai Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.17132v1",
        "title": "Unleashing the potential of GNNs via Bi-directional Knowledge Transfer",
        "abstract": "  Based on the message-passing paradigm, there has been an amount of research\nproposing diverse and impressive feature propagation mechanisms to improve the\nperformance of GNNs. However, less focus has been put on feature\ntransformation, another major operation of the message-passing framework. In\nthis paper, we first empirically investigate the performance of the feature\ntransformation operation in several typical GNNs. Unexpectedly, we notice that\nGNNs do not completely free up the power of the inherent feature transformation\noperation. By this observation, we propose the Bi-directional Knowledge\nTransfer (BiKT), a plug-and-play approach to unleash the potential of the\nfeature transformation operations without modifying the original architecture.\nTaking the feature transformation operation as a derived representation\nlearning model that shares parameters with the original GNN, the direct\nprediction by this model provides a topological-agnostic knowledge feedback\nthat can further instruct the learning of GNN and the feature transformations\ntherein. On this basis, BiKT not only allows us to acquire knowledge from both\nthe GNN and its derived model but promotes each other by injecting the\nknowledge into the other. In addition, a theoretical analysis is further\nprovided to demonstrate that BiKT improves the generalization bound of the GNNs\nfrom the perspective of domain adaption. An extensive group of experiments on\nup to 7 datasets with 5 typical GNNs demonstrates that BiKT brings up to 0.5% -\n4% performance gain over the original GNN, which means a boosted GNN is\nobtained. Meanwhile, the derived model also shows a powerful performance to\ncompete with or even surpass the original GNN, enabling us to flexibly apply it\nindependently to some other specific downstream tasks.\n",
        "published": "2023",
        "authors": [
            "Shuai Zheng",
            "Zhizhe Liu",
            "Zhenfeng Zhu",
            "Xingxing Zhang",
            "Jianxin Li",
            "Yao Zhao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.17250v1",
        "title": "IDENAS: Internal Dependency Exploration for Neural Architecture Search",
        "abstract": "  Machine learning is a powerful tool for extracting valuable information and\nmaking various predictions from diverse datasets. Traditional algorithms rely\non well-defined input and output variables however, there are scenarios where\nthe distinction between the input and output variables and the underlying,\nassociated (input and output) layers of the model, are unknown. Neural\nArchitecture Search (NAS) and Feature Selection have emerged as promising\nsolutions in such scenarios. This research proposes IDENAS, an Internal\nDependency-based Exploration for Neural Architecture Search, integrating NAS\nwith feature selection. The methodology explores internal dependencies in the\ncomplete parameter space for classification involving 1D sensor and 2D image\ndata as well. IDENAS employs a modified encoder-decoder model and the\nSequential Forward Search (SFS) algorithm, combining input-output configuration\nsearch with embedded feature selection. Experimental results demonstrate\nIDENASs superior performance in comparison to other algorithms, showcasing its\neffectiveness in model development pipelines and automated machine learning. On\naverage, IDENAS achieved significant modelling improvements, underscoring its\nsignificant contribution to advancing the state-of-the-art in neural\narchitecture search and feature selection integration.\n",
        "published": "2023",
        "authors": [
            "Anh T. Hoang",
            "Zsolt J. Viharos"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.17404v1",
        "title": "Invariance Measures for Neural Networks",
        "abstract": "  Invariances in neural networks are useful and necessary for many tasks.\nHowever, the representation of the invariance of most neural network models has\nnot been characterized. We propose measures to quantify the invariance of\nneural networks in terms of their internal representation. The measures are\nefficient and interpretable, and can be applied to any neural network model.\nThey are also more sensitive to invariance than previously defined measures. We\nvalidate the measures and their properties in the domain of affine\ntransformations and the CIFAR10 and MNIST datasets, including their stability\nand interpretability. Using the measures, we perform a first analysis of CNN\nmodels and show that their internal invariance is remarkably stable to random\nweight initializations, but not to changes in dataset or transformation. We\nbelieve the measures will enable new avenues of research in invariance\nrepresentation.\n",
        "published": "2023",
        "authors": [
            "Facundo Manuel Quiroga",
            "Jordina Torrents-Barrena",
            "Laura Cristina Lanzarini",
            "Domenec Puig-Valls"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.18893v2",
        "title": "Ever Evolving Evaluator (EV3): Towards Flexible and Reliable\n  Meta-Optimization for Knowledge Distillation",
        "abstract": "  We introduce EV3, a novel meta-optimization framework designed to efficiently\ntrain scalable machine learning models through an intuitive\nexplore-assess-adapt protocol. In each iteration of EV3, we explore various\nmodel parameter updates, assess them using pertinent evaluation methods, and\nthen adapt the model based on the optimal updates and previous progress\nhistory. EV3 offers substantial flexibility without imposing stringent\nconstraints like differentiability on the key objectives relevant to the tasks\nof interest, allowing for exploratory updates with intentionally-biased\ngradients and through a diversity of losses and optimizers. Additionally, the\nassessment phase provides reliable safety controls to ensure robust\ngeneralization, and can dynamically prioritize tasks in scenarios with multiple\nobjectives. With inspiration drawn from evolutionary algorithms, meta-learning,\nand neural architecture search, we investigate an application of EV3 to\nknowledge distillation. Our experimental results illustrate EV3's capability to\nsafely explore the modeling landscape, while hinting at its potential\napplicability across numerous domains due to its inherent flexibility and\nadaptability. Finally, we provide a JAX implementation of EV3, along with\nsource code for experiments, available at:\nhttps://github.com/google-research/google-research/tree/master/ev3.\n",
        "published": "2023",
        "authors": [
            "Li Ding",
            "Masrour Zoghi",
            "Guy Tennenholtz",
            "Maryam Karimzadehgan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.19225v1",
        "title": "Stochastic Configuration Machines: FPGA Implementation",
        "abstract": "  Neural networks for industrial applications generally have additional\nconstraints such as response speed, memory size and power usage. Randomized\nlearners can address some of these issues. However, hardware solutions can\nprovide better resource reduction whilst maintaining the model's performance.\nStochastic configuration networks (SCNs) are a prime choice in industrial\napplications due to their merits and feasibility for data modelling. Stochastic\nConfiguration Machines (SCMs) extend this to focus on reducing the memory\nconstraints by limiting the randomized weights to a binary value with a scalar\nfor each node and using a mechanism model to improve the learning performance\nand result interpretability. This paper aims to implement SCM models on a field\nprogrammable gate array (FPGA) and introduce binary-coded inputs to the\nalgorithm. Results are reported for two benchmark and two industrial datasets,\nincluding SCM with single-layer and deep architectures.\n",
        "published": "2023",
        "authors": [
            "Matthew J. Felicetti",
            "Dianhui Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.19813v1",
        "title": "Enhancing Genetic Improvement Mutations Using Large Language Models",
        "abstract": "  Large language models (LLMs) have been successfully applied to software\nengineering tasks, including program repair. However, their application in\nsearch-based techniques such as Genetic Improvement (GI) is still largely\nunexplored. In this paper, we evaluate the use of LLMs as mutation operators\nfor GI to improve the search process. We expand the Gin Java GI toolkit to call\nOpenAI's API to generate edits for the JCodec tool. We randomly sample the\nspace of edits using 5 different edit types. We find that the number of patches\npassing unit tests is up to 75% higher with LLM-based edits than with standard\nInsert edits. Further, we observe that the patches found with LLMs are\ngenerally less diverse compared to standard edits. We ran GI with local search\nto find runtime improvements. Although many improving patches are found by\nLLM-enhanced GI, the best improving patch was found by standard GI.\n",
        "published": "2023",
        "authors": [
            "Alexander E. I. Brownlee",
            "James Callan",
            "Karine Even-Mendoza",
            "Alina Geiger",
            "Carol Hanna",
            "Justyna Petke",
            "Federica Sarro",
            "Dominik Sobania"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.19815v1",
        "title": "Training binary neural networks without floating point precision",
        "abstract": "  The main goal of this work is to improve the efficiency of training binary\nneural networks, which are low latency and low energy networks. The main\ncontribution of this work is the proposal of two solutions comprised of\ntopology changes and strategy training that allow the network to achieve near\nthe state-of-the-art performance and efficient training. The time required for\ntraining and the memory required in the process are two factors that contribute\nto efficient training.\n",
        "published": "2023",
        "authors": [
            "Federico Fontana"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2310.19843v1",
        "title": "Modeling the Telemarketing Process using Genetic Algorithms and Extreme\n  Boosting: Feature Selection and Cost-Sensitive Analytical Approach",
        "abstract": "  Currently, almost all direct marketing activities take place virtually rather\nthan in person, weakening interpersonal skills at an alarming pace.\nFurthermore, businesses have been striving to sense and foster the tendency of\ntheir clients to accept a marketing offer. The digital transformation and the\nincreased virtual presence forced firms to seek novel marketing research\napproaches. This research aims at leveraging the power of telemarketing data in\nmodeling the willingness of clients to make a term deposit and finding the most\nsignificant characteristics of the clients. Real-world data from a Portuguese\nbank and national socio-economic metrics are used to model the telemarketing\ndecision-making process. This research makes two key contributions. First,\npropose a novel genetic algorithm-based classifier to select the best\ndiscriminating features and tune classifier parameters simultaneously. Second,\nbuild an explainable prediction model. The best-generated classification models\nwere intensively validated using 50 times repeated 10-fold stratified\ncross-validation and the selected features have been analyzed. The models\nsignificantly outperform the related works in terms of class of interest\naccuracy, they attained an average of 89.07\\% and 0.059 in terms of geometric\nmean and type I error respectively. The model is expected to maximize the\npotential profit margin at the least possible cost and provide more insights to\nsupport marketing decision-making.\n",
        "published": "2023",
        "authors": [
            "Nazeeh Ghatasheh",
            "Ismail Altaharwa",
            "Khaled Aldebei"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.01205v1",
        "title": "Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go\n  Indifferent",
        "abstract": "  Prior attacks on graph neural networks have mostly focused on graph poisoning\nand evasion, neglecting the network's weights and biases. Traditional\nweight-based fault injection attacks, such as bit flip attacks used for\nconvolutional neural networks, do not consider the unique properties of graph\nneural networks. We propose the Injectivity Bit Flip Attack, the first bit flip\nattack designed specifically for graph neural networks. Our attack targets the\nlearnable neighborhood aggregation functions in quantized message passing\nneural networks, degrading their ability to distinguish graph structures and\nlosing the expressivity of the Weisfeiler-Lehman test. Our findings suggest\nthat exploiting mathematical properties specific to certain graph neural\nnetwork architectures can significantly increase their vulnerability to bit\nflip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive\nGraph Isomorphism Networks trained on various graph property prediction\ndatasets to random output by flipping only a small fraction of the network's\nbits, demonstrating its higher destructive power compared to a bit flip attack\ntransferred from convolutional neural networks. Our attack is transparent and\nmotivated by theoretical insights which are confirmed by extensive empirical\nresults.\n",
        "published": "2023",
        "authors": [
            "Lorenz Kummer",
            "Samir Moustafa",
            "Nils N. Kriege",
            "Wilfried N. Gansterer"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.03408v1",
        "title": "Training Multi-layer Neural Networks on Ising Machine",
        "abstract": "  As a dedicated quantum device, Ising machines could solve large-scale binary\noptimization problems in milliseconds. There is emerging interest in utilizing\nIsing machines to train feedforward neural networks due to the prosperity of\ngenerative artificial intelligence. However, existing methods can only train\nsingle-layer feedforward networks because of the complex nonlinear network\ntopology. This paper proposes an Ising learning algorithm to train quantized\nneural network (QNN), by incorporating two essential techinques, namely binary\nrepresentation of topological network and order reduction of loss function. As\nfar as we know, this is the first algorithm to train multi-layer feedforward\nnetworks on Ising machines, providing an alternative to gradient-based\nbackpropagation. Firstly, training QNN is formulated as a quadratic constrained\nbinary optimization (QCBO) problem by representing neuron connection and\nactivation function as equality constraints. All quantized variables are\nencoded by binary bits based on binary encoding protocol. Secondly, QCBO is\nconverted to a quadratic unconstrained binary optimization (QUBO) problem, that\ncan be efficiently solved on Ising machines. The conversion leverages both\npenalty function and Rosenberg order reduction, who together eliminate equality\nconstraints and reduce high-order loss function into a quadratic one. With some\nassumptions, theoretical analysis shows the space complexity of our algorithm\nis $\\mathcal{O}(H^2L + HLN\\log H)$, quantifying the required number of Ising\nspins. Finally, the algorithm effectiveness is validated with a simulated Ising\nmachine on MNIST dataset. After annealing 700 ms, the classification accuracy\nachieves 98.3%. Among 100 runs, the success probability of finding the optimal\nsolution is 72%. Along with the increasing number of spins on Ising machine,\nour algorithm has the potential to train deeper neural networks.\n",
        "published": "2023",
        "authors": [
            "Xujie Song",
            "Tong Liu",
            "Shengbo Eben Li",
            "Jingliang Duan",
            "Wenxuan Wang",
            "Keqiang Li"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.07705v1",
        "title": "Robust and Scalable Hyperdimensional Computing With Brain-Like Neural\n  Adaptations",
        "abstract": "  The Internet of Things (IoT) has facilitated many applications utilizing\nedge-based machine learning (ML) methods to analyze locally collected data.\nUnfortunately, popular ML algorithms often require intensive computations\nbeyond the capabilities of today's IoT devices. Brain-inspired hyperdimensional\ncomputing (HDC) has been introduced to address this issue. However, existing\nHDCs use static encoders, requiring extremely high dimensionality and hundreds\nof training iterations to achieve reasonable accuracy. This results in a huge\nefficiency loss, severely impeding the application of HDCs in IoT systems. We\nobserved that a main cause is that the encoding module of existing HDCs lacks\nthe capability to utilize and adapt to information learned during training. In\ncontrast, neurons in human brains dynamically regenerate all the time and\nprovide more useful functionalities when learning new information. While the\ngoal of HDC is to exploit the high-dimensionality of randomly generated base\nhypervectors to represent the information as a pattern of neural activity, it\nremains challenging for existing HDCs to support a similar behavior as brain\nneural regeneration. In this work, we present dynamic HDC learning frameworks\nthat identify and regenerate undesired dimensions to provide adequate accuracy\nwith significantly lowered dimensionalities, thereby accelerating both the\ntraining and inference.\n",
        "published": "2023",
        "authors": [
            "Junyao Wang",
            "Mohammad Abdullah Al Faruque"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.09266v1",
        "title": "Adversarially Robust Spiking Neural Networks Through Conversion",
        "abstract": "  Spiking neural networks (SNNs) provide an energy-efficient alternative to a\nvariety of artificial neural network (ANN) based AI applications. As the\nprogress in neuromorphic computing with SNNs expands their use in applications,\nthe problem of adversarial robustness of SNNs becomes more pronounced. To the\ncontrary of the widely explored end-to-end adversarial training based\nsolutions, we address the limited progress in scalable robust SNN training\nmethods by proposing an adversarially robust ANN-to-SNN conversion algorithm.\nOur method provides an efficient approach to embrace various computationally\ndemanding robust learning objectives that have been proposed for ANNs. During a\npost-conversion robust finetuning phase, our method adversarially optimizes\nboth layer-wise firing thresholds and synaptic connectivity weights of the SNN\nto maintain transferred robustness gains from the pre-trained ANN. We perform\nexperimental evaluations in numerous adaptive adversarial settings that account\nfor the spike-based operation dynamics of SNNs, and show that our approach\nyields a scalable state-of-the-art solution for adversarially robust deep SNNs\nwith low-latency.\n",
        "published": "2023",
        "authors": [
            "Ozan \u00d6zdenizci",
            "Robert Legenstein"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.10025v1",
        "title": "A Novel Neural Network-Based Federated Learning System for Imbalanced\n  and Non-IID Data",
        "abstract": "  With the growth of machine learning techniques, privacy of data of users has\nbecome a major concern. Most of the machine learning algorithms rely heavily on\nlarge amount of data which may be collected from various sources. Collecting\nthese data yet maintaining privacy policies has become one of the most\nchallenging tasks for the researchers. To combat this issue, researchers have\nintroduced federated learning, where a prediction model is learnt by ensuring\nthe privacy of data of clients data. However, the prevalent federated learning\nalgorithms possess an accuracy and efficiency trade-off, especially for non-IID\ndata. In this research, we propose a centralized, neural network-based\nfederated learning system. The centralized algorithm incorporates micro-level\nparallel processing inspired by the traditional mini-batch algorithm where the\nclient devices and the server handle the forward and backward propagation\nrespectively. We also devise a semi-centralized version of our proposed\nalgorithm. This algorithm takes advantage of edge computing for minimizing the\nload from the central server, where clients handle both the forward and\nbackward propagation while sacrificing the overall train time to some extent.\nWe evaluate our proposed systems on five well-known benchmark datasets and\nachieve satisfactory performance in a reasonable time across various data\ndistribution settings as compared to some existing benchmark algorithms.\n",
        "published": "2023",
        "authors": [
            "Mahfuzur Rahman Chowdhury",
            "Muhammad Ibrahim"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.12304v2",
        "title": "Discovering Effective Policies for Land-Use Planning",
        "abstract": "  How areas of land are allocated for different uses, such as forests, urban,\nand agriculture, has a large effect on carbon balance, and therefore climate\nchange. Based on available historical data on changes in land use and a\nsimulation of carbon emissions/absorption, a surrogate model can be learned\nthat makes it possible to evaluate the different options available to\ndecision-makers efficiently. An evolutionary search process can then be used to\ndiscover effective land-use policies for specific locations. Such a system was\nbuilt on the Project Resilience platform and evaluated with the Land-Use\nHarmonization dataset and the BLUE simulator. It generates Pareto fronts that\ntrade off carbon impact and amount of change customized to different locations,\nthus providing a potentially useful tool for land-use planning.\n",
        "published": "2023",
        "authors": [
            "Risto Miikkulainen",
            "Olivier Francon",
            "Daniel Young",
            "Elliot Meyerson",
            "Jacob Bieker",
            "Hugo Cunha",
            "Babak Hodjat"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.12944v1",
        "title": "DroneOptiNet: A Framework for Optimal Drone-based Load Redistribution\n  Mechanism for 5G and Beyond Solar Small Cell Networks",
        "abstract": "  The power requirements posed by the fifth-generation and beyond cellular\nnetworks are an important constraint in network deployment and require\nenergy-efficient solutions. In this work, we propose a novel user load transfer\napproach using airborne base stations (BS), mounted on drones, for reliable and\nsecure power redistribution across the micro-grid network comprising green\nsmall cell BSs. Depending on the user density and the availability of an aerial\nBS, the energy requirement of a cell with an energy deficit is accommodated by\nmigrating the aerial BS from a high-energy to a low-energy cell. The proposed\nhybrid drone-based framework integrates long short-term memory with unique cost\nfunctions using an evolutionary neural network for drones and BSs, and\nefficiently manages energy and load redistribution. The proposed algorithm\nreduces power outages at BSs and maintains consistent throughput stability,\nthereby demonstrating its capability to boost the reliability and robustness of\nwireless communication systems.\n",
        "published": "2023",
        "authors": [
            "Daksh Dave",
            "Vinay Chamola",
            "Sandeep Joshi",
            "Sherali Zeadally"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.13038v1",
        "title": "Synaptic Sampling of Neural Networks",
        "abstract": "  Probabilistic artificial neural networks offer intriguing prospects for\nenabling the uncertainty of artificial intelligence methods to be described\nexplicitly in their function; however, the development of techniques that\nquantify uncertainty by well-understood methods such as Monte Carlo sampling\nhas been limited by the high costs of stochastic sampling on deterministic\ncomputing hardware. Emerging computing systems that are amenable to\nhardware-level probabilistic computing, such as those that leverage stochastic\ndevices, may make probabilistic neural networks more feasible in the\nnot-too-distant future. This paper describes the scANN technique --\n\\textit{sampling (by coinflips) artificial neural networks} -- which enables\nneural networks to be sampled directly by treating the weights as Bernoulli\ncoin flips. This method is natively well suited for probabilistic computing\ntechniques that focus on tunable stochastic devices, nearly matches fully\ndeterministic performance while also describing the uncertainty of correct and\nincorrect neural network outputs.\n",
        "published": "2023",
        "authors": [
            "James B. Aimone",
            "William Severa",
            "J. Darby Smith"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.15249v1",
        "title": "Algorithm Evolution Using Large Language Model",
        "abstract": "  Optimization can be found in many real-life applications. Designing an\neffective algorithm for a specific optimization problem typically requires a\ntedious amount of effort from human experts with domain knowledge and algorithm\ndesign skills. In this paper, we propose a novel approach called Algorithm\nEvolution using Large Language Model (AEL). It utilizes a large language model\n(LLM) to automatically generate optimization algorithms via an evolutionary\nframework. AEL does algorithm-level evolution without model training. Human\neffort and requirements for domain knowledge can be significantly reduced. We\ntake constructive methods for the salesman traveling problem as a test example,\nwe show that the constructive algorithm obtained by AEL outperforms simple\nhand-crafted and LLM-generated heuristics. Compared with other domain deep\nlearning model-based algorithms, these methods exhibit excellent scalability\nacross different problem sizes. AEL is also very different from previous\nattempts that utilize LLMs as search operators in algorithms.\n",
        "published": "2023",
        "authors": [
            "Fei Liu",
            "Xialiang Tong",
            "Mingxuan Yuan",
            "Qingfu Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.16112v1",
        "title": "Co-learning synaptic delays, weights and adaptation in spiking neural\n  networks",
        "abstract": "  Spiking neural networks (SNN) distinguish themselves from artificial neural\nnetworks (ANN) because of their inherent temporal processing and spike-based\ncomputations, enabling a power-efficient implementation in neuromorphic\nhardware. In this paper, we demonstrate that data processing with spiking\nneurons can be enhanced by co-learning the connection weights with two other\nbiologically inspired neuronal features: 1) a set of parameters describing\nneuronal adaptation processes and 2) synaptic propagation delays. The former\nallows the spiking neuron to learn how to specifically react to incoming spikes\nbased on its past. The trained adaptation parameters result in neuronal\nheterogeneity, which is found in the brain and also leads to a greater variety\nin available spike patterns. The latter enables to learn to explicitly\ncorrelate patterns that are temporally distanced. Synaptic delays reflect the\ntime an action potential requires to travel from one neuron to another. We show\nthat each of the co-learned features separately leads to an improvement over\nthe baseline SNN and that the combination of both leads to state-of-the-art SNN\nresults on all speech recognition datasets investigated with a simple 2-hidden\nlayer feed-forward network. Our SNN outperforms the ANN on the neuromorpic\ndatasets (Spiking Heidelberg Digits and Spiking Speech Commands), even with\nfewer trainable parameters. On the 35-class Google Speech Commands dataset, our\nSNN also outperforms a GRU of similar size. Our work presents brain-inspired\nimprovements to SNN that enable them to excel over an equivalent ANN of similar\nsize on tasks with rich temporal dynamics.\n",
        "published": "2023",
        "authors": [
            "Lucas Deckers",
            "Laurens Van Damme",
            "Ing Jyh Tsang",
            "Werner Van Leekwijck",
            "Steven Latr\u00e9"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2311.16172v1",
        "title": "Evolutionary Machine Learning and Games",
        "abstract": "  Evolutionary machine learning (EML) has been applied to games in multiple\nways, and for multiple different purposes. Importantly, AI research in games is\nnot only about playing games; it is also about generating game content,\nmodeling players, and many other applications. Many of these applications pose\ninteresting problems for EML. We will structure this chapter on EML for games\nbased on whether evolution is used to augment machine learning (ML) or ML is\nused to augment evolution. For completeness, we also briefly discuss the usage\nof ML and evolution separately in games.\n",
        "published": "2023",
        "authors": [
            "Julian Togelius",
            "Ahmed Khalifa",
            "Sam Earle",
            "Michael Cerny Green",
            "Lisa Soros"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.03038v3",
        "title": "Sample-based Dynamic Hierarchical Transformer with Layer and Head\n  Flexibility via Contextual Bandit",
        "abstract": "  Transformer requires a fixed number of layers and heads which makes them\ninflexible to the complexity of individual samples and expensive in training\nand inference. To address this, we propose a sample-based Dynamic Hierarchical\nTransformer (DHT) model whose layers and heads can be dynamically configured\nwith single data samples via solving contextual bandit problems. To determine\nthe number of layers and heads, we use the Uniform Confidence Bound while we\ndeploy combinatorial Thompson Sampling in order to select specific head\ncombinations given their number. Different from previous work that focuses on\ncompressing trained networks for inference only, DHT is not only advantageous\nfor adaptively optimizing the underlying network architecture during training\nbut also has a flexible network for efficient inference. To the best of our\nknowledge, this is the first comprehensive data-driven dynamic transformer\nwithout any additional auxiliary neural networks that implement the dynamic\nsystem. According to the experiment results, we achieve up to 74% computational\nsavings for both training and inference with a minimal loss of accuracy.\n",
        "published": "2023",
        "authors": [
            "Fanfei Meng",
            "Lele Zhang",
            "Yu Chen",
            "Yuxin Wang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.03051v1",
        "title": "Generating Interpretable Networks using Hypernetworks",
        "abstract": "  An essential goal in mechanistic interpretability to decode a network, i.e.,\nto convert a neural network's raw weights to an interpretable algorithm. Given\nthe difficulty of the decoding problem, progress has been made to understand\nthe easier encoding problem, i.e., to convert an interpretable algorithm into\nnetwork weights. Previous works focus on encoding existing algorithms into\nnetworks, which are interpretable by definition. However, focusing on encoding\nlimits the possibility of discovering new algorithms that humans have never\nstumbled upon, but that are nevertheless interpretable. In this work, we\nexplore the possibility of using hypernetworks to generate interpretable\nnetworks whose underlying algorithms are not yet known. The hypernetwork is\ncarefully designed such that it can control network complexity, leading to a\ndiverse family of interpretable algorithms ranked by their complexity. All of\nthem are interpretable in hindsight, although some of them are less intuitive\nto humans, hence providing new insights regarding how to \"think\" like a neural\nnetwork. For the task of computing L1 norms, hypernetworks find three\nalgorithms: (a) the double-sided algorithm, (b) the convexity algorithm, (c)\nthe pudding algorithm, although only the first algorithm was expected by the\nauthors before experiments. We automatically classify these algorithms and\nanalyze how these algorithmic phases develop during training, as well as how\nthey are affected by complexity control. Furthermore, we show that a trained\nhypernetwork can correctly construct models for input dimensions not seen in\ntraining, demonstrating systematic generalization.\n",
        "published": "2023",
        "authors": [
            "Isaac Liao",
            "Ziming Liu",
            "Max Tegmark"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.03096v1",
        "title": "Incidental Polysemanticity",
        "abstract": "  Polysemantic neurons (neurons that activate for a set of unrelated features)\nhave been seen as a significant obstacle towards interpretability of\ntask-optimized deep networks, with implications for AI safety. The classic\norigin story of polysemanticity is that the data contains more \"features\" than\nneurons, such that learning to perform a task forces the network to co-allocate\nmultiple unrelated features to the same neuron, endangering our ability to\nunderstand the network's internal processing. In this work, we present a second\nand non-mutually exclusive origin story of polysemanticity. We show that\npolysemanticity can arise incidentally, even when there are ample neurons to\nrepresent all features in the data, using a combination of theory and\nexperiments. This second type of polysemanticity occurs because random\ninitialization can, by chance alone, initially assign multiple features to the\nsame neuron, and the training dynamics then strengthen such overlap. Due to its\norigin, we term this \\textit{incidental polysemanticity}.\n",
        "published": "2023",
        "authors": [
            "Victor Lecomte",
            "Kushal Thaman",
            "Trevor Chow",
            "Rylan Schaeffer",
            "Sanmi Koyejo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.04574v1",
        "title": "Differentiable Visual Computing for Inverse Problems and Machine\n  Learning",
        "abstract": "  Originally designed for applications in computer graphics, visual computing\n(VC) methods synthesize information about physical and virtual worlds, using\nprescribed algorithms optimized for spatial computing. VC is used to analyze\ngeometry, physically simulate solids, fluids, and other media, and render the\nworld via optical techniques. These fine-tuned computations that operate\nexplicitly on a given input solve so-called forward problems, VC excels at. By\ncontrast, deep learning (DL) allows for the construction of general algorithmic\nmodels, side stepping the need for a purely first principles-based approach to\nproblem solving. DL is powered by highly parameterized neural network\narchitectures -- universal function approximators -- and gradient-based search\nalgorithms which can efficiently search that large parameter space for optimal\nmodels. This approach is predicated by neural network differentiability, the\nrequirement that analytic derivatives of a given problem's task metric can be\ncomputed with respect to neural network's parameters. Neural networks excel\nwhen an explicit model is not known, and neural network training solves an\ninverse problem in which a model is computed from data.\n",
        "published": "2023",
        "authors": [
            "Andrew Spielberg",
            "Fangcheng Zhong",
            "Konstantinos Rematas",
            "Krishna Murthy Jatavallabhula",
            "Cengiz Oztireli",
            "Tzu-Mao Li",
            "Derek Nowrouzezahrai"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.04840v1",
        "title": "Analysis on Effects of Fault Elements in Memristive Neuromorphic Systems",
        "abstract": "  Nowadays, neuromorphic systems based on Spiking Neural Networks (SNNs)\nattract attentions of many researchers. There are many studies to improve\nperformances of neuromorphic systems. These studies have been showing\nsatisfactory results. To magnify performances of neuromorphic systems,\ndeveloping actual neuromorphic systems is essential. For developing them,\nmemristors play key role due to their useful characteristics. Although\nmemristors are essential for actual neuromorphic systems, they are vulnerable\nto faults. However, there are few studies analyzing effects of fault elements\nin neuromorphic systems using memristors. To solve this problem, we analyze\nperformance of a memristive neuromorphic system with fault elements changing\nfault ratios, types, and positions. We choose neurons and synapses to inject\nfaults. We inject two types of faults to synapses: SA0 and SA1 faults. The\nfault synapses appear in random and important positions. Through our analysis,\nwe discover the following four interesting points. First, memristive\ncharacteristics increase vulnerability of neuromorphic systems to fault\nelements. Second, fault neuron ratios reducing performance sharply exist.\nThird, performance degradation by fault synapses depends on fault types.\nFinally, SA1 fault synapses improve performance when they appear in important\npositions.\n",
        "published": "2023",
        "authors": [
            "Hyun-Jong Lee",
            "Jae-Han Lim"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.06182v1",
        "title": "Why \"classic\" Transformers are shallow and how to make them go deep",
        "abstract": "  Since its introduction in 2017, Transformer has emerged as the leading neural\nnetwork architecture, catalyzing revolutionary advancements in many AI\ndisciplines. The key innovation in Transformer is a Self-Attention (SA)\nmechanism designed to capture contextual information. However, extending the\noriginal Transformer design to models of greater depth has proven exceedingly\nchallenging, if not impossible. Even though various modifications have been\nproposed in order to stack more layers of SA mechanism into deeper models, a\nfull understanding of this depth problem remains elusive. In this paper, we\nconduct a comprehensive investigation, both theoretically and empirically, to\nsubstantiate the claim that the depth problem is caused by \\emph{token\nsimilarity escalation}; that is, tokens grow increasingly alike after repeated\napplications of the SA mechanism. Our analysis reveals that, driven by the\ninvariant leading eigenspace and large spectral gaps of attention matrices,\ntoken similarity provably escalates at a linear rate. Based on the gained\ninsight, we propose a simple strategy that, unlike most existing methods,\nsurgically removes excessive similarity without discounting the SA mechanism as\na whole. Preliminary experimental results confirm the effectiveness of the\nproposed approach on moderate-scale post-norm Transformer models.\n",
        "published": "2023",
        "authors": [
            "Yueyao Yu",
            "Yin Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.06336v1",
        "title": "Vehicle Lane Change Prediction based on Knowledge Graph Embeddings and\n  Bayesian Inference",
        "abstract": "  Prediction of vehicle lane change maneuvers has gained a lot of momentum in\nthe last few years. Some recent works focus on predicting a vehicle's intention\nby predicting its trajectory first. This is not enough, as it ignores the\ncontext of the scene and the state of the surrounding vehicles (as they might\nbe risky to the target vehicle). Other works assessed the risk made by the\nsurrounding vehicles only by considering their existence around the target\nvehicle, or by considering the distance and relative velocities between them\nand the target vehicle as two separate numerical features. In this work, we\npropose a solution that leverages Knowledge Graphs (KGs) to anticipate lane\nchanges based on linguistic contextual information in a way that goes well\nbeyond the capabilities of current perception systems. Our solution takes the\nTime To Collision (TTC) with surrounding vehicles as input to assess the risk\non the target vehicle. Moreover, our KG is trained on the HighD dataset using\nthe TransE model to obtain the Knowledge Graph Embeddings (KGE). Then, we apply\nBayesian inference on top of the KG using the embeddings learned during\ntraining. Finally, the model can predict lane changes two seconds ahead with\n97.95% f1-score, which surpassed the state of the art, and three seconds before\nchanging lanes with 93.60% f1-score.\n",
        "published": "2023",
        "authors": [
            "M. Manzour",
            "A. Ballardini",
            "R. Izquierdo",
            "M. A. Sotelo"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.06695v1",
        "title": "Evolving Reservoirs for Meta Reinforcement Learning",
        "abstract": "  Animals often demonstrate a remarkable ability to adapt to their environments\nduring their lifetime. They do so partly due to the evolution of morphological\nand neural structures. These structures capture features of environments shared\nbetween generations to bias and speed up lifetime learning. In this work, we\npropose a computational model for studying a mechanism that can enable such a\nprocess. We adopt a computational framework based on meta reinforcement\nlearning as a model of the interplay between evolution and development. At the\nevolutionary scale, we evolve reservoirs, a family of recurrent neural networks\nthat differ from conventional networks in that one optimizes not the weight\nvalues but hyperparameters of the architecture: the later control macro-level\nproperties, such as memory and dynamics. At the developmental scale, we employ\nthese evolved reservoirs to facilitate the learning of a behavioral policy\nthrough Reinforcement Learning (RL). Within an RL agent, a reservoir encodes\nthe environment state before providing it to an action policy. We evaluate our\napproach on several 2D and 3D simulated environments. Our results show that the\nevolution of reservoirs can improve the learning of diverse challenging tasks.\nWe study in particular three hypotheses: the use of an architecture combining\nreservoirs and reinforcement learning could enable (1) solving tasks with\npartial observability, (2) generating oscillatory dynamics that facilitate the\nlearning of locomotion tasks, and (3) facilitating the generalization of\nlearned behaviors to new tasks unknown during the evolution phase.\n",
        "published": "2023",
        "authors": [
            "Corentin L\u00e9ger",
            "Gautier Hamon",
            "Eleni Nisioti",
            "Xavier Hinaut",
            "Cl\u00e9ment Moulin-Frier"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.09971v1",
        "title": "GreenLightningAI: An Efficient AI System with Decoupled Structural and\n  Quantitative Knowledge",
        "abstract": "  The number and complexity of artificial intelligence (AI) applications is\ngrowing relentlessly. As a result, even with the many algorithmic and\nmathematical advances experienced over past decades as well as the impressive\nenergy efficiency and computational capacity of current hardware accelerators,\ntraining the most powerful and popular deep neural networks comes at very high\neconomic and environmental costs. Recognising that additional optimisations of\nconventional neural network training is very difficult, this work takes a\nradically different approach by proposing GreenLightningAI, a new AI system\ndesign consisting of a linear model that is capable of emulating the behaviour\nof deep neural networks by subsetting the model for each particular sample. The\nnew AI system stores the information required to select the system subset for a\ngiven sample (referred to as structural information) separately from the linear\nmodel parameters (referred to as quantitative knowledge). In this paper we\npresent a proof of concept, showing that the structural information stabilises\nfar earlier than the quantitative knowledge. Additionally, we show\nexperimentally that the structural information can be kept unmodified when\nre-training the AI system with new samples while still achieving a validation\naccuracy similar to that obtained when re-training a neural network with\nsimilar size. Since the proposed AI system is based on a linear model, multiple\ncopies of the model, trained with different datasets, can be easily combined.\nThis enables faster and greener (re)-training algorithms, including incremental\nre-training and federated incremental re-training.\n",
        "published": "2023",
        "authors": [
            "Jose Duato",
            "Jose I. Mestre",
            "Manuel F. Dolz",
            "Enrique S. Quintana-Ort\u00ed"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.11560v1",
        "title": "Emergence Learning: A Rising Direction from Emergent Abilities and a\n  Monosemanticity-Based Study",
        "abstract": "  In the past 20 years, artificial neural networks have become dominant in\nvarious areas, continually growing in scale. However, the current analysis of\nlarge models has mainly focused on functionality, overlooking the influence of\nscale differences on their properties. To address this, we propose the concept\nof Emergence Learning, which emphasizes the significance of scale. By studying\nmodels of different scales, we have identified a key factor in achieving higher\nperformance in large models: the decrease of monosemantic neurons. Building on\nthis insight, we propose a proactive approach to inhibit monosemanticity for\nimproved performance. Our solution involves a two-phase process that includes\nmonosemantic neuron detection and inhibition, supported by theoretical\nanalysis. Experimental results on various tasks and neural networks demonstrate\nthe effectiveness of our proposed method.\n  Following the idea of Emergence Learning, though drawing inspiration from\nscaling phenomena, the applicability of our method is not restricted to large\nscale alone. Therefore, the experiment is self-contained. However, extending\nthis research to very large-scale datasets is appealing yet impossible for\nresearch departments due to limited resources. We are delighted to share the\nfirst co-authorship and eagerly await collaboration from any AI company before\nsubmission.\n",
        "published": "2023",
        "authors": [
            "Jiachuan Wang",
            "Shimin Di",
            "Lei Chen",
            "Charles Wang Wai Ng"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.14217v1",
        "title": "Adversarial Infrared Curves: An Attack on Infrared Pedestrian Detectors\n  in the Physical World",
        "abstract": "  Deep neural network security is a persistent concern, with considerable\nresearch on visible light physical attacks but limited exploration in the\ninfrared domain. Existing approaches, like white-box infrared attacks using\nbulb boards and QR suits, lack realism and stealthiness. Meanwhile, black-box\nmethods with cold and hot patches often struggle to ensure robustness. To\nbridge these gaps, we propose Adversarial Infrared Curves (AdvIC). Using\nParticle Swarm Optimization, we optimize two Bezier curves and employ cold\npatches in the physical realm to introduce perturbations, creating infrared\ncurve patterns for physical sample generation. Our extensive experiments\nconfirm AdvIC's effectiveness, achieving 94.8\\% and 67.2\\% attack success rates\nfor digital and physical attacks, respectively. Stealthiness is demonstrated\nthrough a comparative analysis, and robustness assessments reveal AdvIC's\nsuperiority over baseline methods. When deployed against diverse advanced\ndetectors, AdvIC achieves an average attack success rate of 76.8\\%, emphasizing\nits robust nature. we explore adversarial defense strategies against AdvIC and\nexamine its impact under various defense mechanisms. Given AdvIC's substantial\nsecurity implications for real-world vision-based applications, urgent\nattention and mitigation efforts are warranted.\n",
        "published": "2023",
        "authors": [
            "Chengyin Hu",
            "Weiwen Shi"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.14948v1",
        "title": "An Evolving Population Approach to Data-Stream Classification with\n  Extreme Verification Latency",
        "abstract": "  Recognising and reacting to change in non-stationary data-streams is a\nchallenging task. The majority of research in this area assumes that the true\nclass label of incoming points are available, either at each time step or\nintermittently with some latency. In the worse case this latency approaches\ninfinity and we can assume that no labels are available beyond the initial\ntraining set. When change is expected and no further training labels are\nprovided the challenge of maintaining a high classification accuracy is very\ngreat. The challenge is to propagate the original training information through\nseveral timesteps, possibly indefinitely, while adapting to underlying change\nin the data-stream. In this paper we conduct an initial study into the\neffectiveness of using an evolving, population-based approach as the mechanism\nfor adapting to change. An ensemble of one-class-classifiers is maintained for\neach class. Each classifier is considered as an agent in the sub-population and\nis subject to selection pressure to find interesting areas of the feature\nspace. This selection pressure forces the ensemble to adapt to the underlying\nchange in the data-stream.\n",
        "published": "2023",
        "authors": [
            "Conor Fahy",
            "Shengxiang Yang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.14954v1",
        "title": "Neuromorphic Co-Design as a Game",
        "abstract": "  Co-design is a prominent topic presently in computing, speaking to the mutual\nbenefit of coordinating design choices of several layers in the technology\nstack. For example, this may be designing algorithms which can most efficiently\ntake advantage of the acceleration properties of a given architecture, while\nsimultaneously designing the hardware to support the structural needs of a\nclass of computation. The implications of these design decisions are\ninfluential enough to be deemed a lottery, enabling an idea to win out over\nothers irrespective of the individual merits. Coordination is a well studied\ntopic in the mathematics of game theory, where in many cases without a\ncoordination mechanism the outcome is sub-optimal. Here we consider what\ninsights game theoretic analysis can offer for computer architecture co-design.\nIn particular, we consider the interplay between algorithm and architecture\nadvances in the field of neuromorphic computing. Analyzing developments of\nspiking neural network algorithms and neuromorphic hardware as a co-design game\nwe use the Stag Hunt model to illustrate challenges for spiking algorithms or\narchitectures to advance the field independently and advocate for a strategic\npursuit to advance neuromorphic computing.\n",
        "published": "2023",
        "authors": [
            "Craig M. Vineyard",
            "William M. Severa",
            "James B. Aimone"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.14963v1",
        "title": "Optimizing Mario Adventures in a Constrained Environment",
        "abstract": "  This project proposes and compares a new way to optimise Super Mario Bros.\n(SMB) environment where the control is in hand of two approaches, namely,\nGenetic Algorithm (MarioGA) and NeuroEvolution (MarioNE). Not only we learn\nplaying SMB using these techniques, but also optimise it with constrains of\ncollection of coins and finishing levels. Firstly, we formalise the SMB agent\nto maximize the total value of collected coins (reward) and maximising the\ntotal distance traveled (reward) in order to finish the level faster (time\npenalty) for both the algorithms. Secondly, we study MarioGA and its evaluation\nfunction (fitness criteria) including its representation methods, crossover\nused, mutation operator formalism, selection method used, MarioGA loop, and few\nother parameters. Thirdly, MarioNE is applied on SMB where a population of ANNs\nwith random weights is generated, and these networks control Marios actions in\nthe game. Fourth, SMB is further constrained to complete the task within the\nspecified time, rebirths (deaths) within the limit, and performs actions or\nmoves within the maximum allowed moves, while seeking to maximize the total\ncoin value collected. This ensures an efficient way of finishing SMB levels.\nFinally, we provide a fivefold comparative analysis by plotting fitness plots,\nability to finish different levels of world 1, and domain adaptation (transfer\nlearning) of the trained models.\n",
        "published": "2023",
        "authors": [
            "Sanyam Jain"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.14978v1",
        "title": "On Quantifying Sentiments of Financial News -- Are We Doing the Right\n  Things?",
        "abstract": "  Typical investors start off the day by going through the daily news to get an\nintuition about the performance of the market. The speculations based on the\ntone of the news ultimately shape their responses towards the market. Today,\ncomputers are being trained to compute the news sentiment so that it can be\nused as a variable to predict stock market movements and returns. Some\nresearchers have even developed news-based market indices to forecast stock\nmarket returns. Majority of the research in the field of news sentiment\nanalysis has focussed on using libraries like Vader, Loughran-McDonald (LM),\nHarvard IV and Pattern. However, are the popular approaches for measuring\nfinancial news sentiment really approaching the problem of sentiment analysis\ncorrectly? Our experiments suggest that measuring sentiments using these\nlibraries, especially for financial news, fails to depict the true picture and\nhence may not be very reliable. Therefore, the question remains: What is the\nmost effective and accurate approach to measure financial news sentiment? Our\npaper explores these questions and attempts to answer them through SENTInews: a\none-of-its-kind financial news sentiment analyzer customized to the Indian\ncontext\n",
        "published": "2023",
        "authors": [
            "Gourab Nath",
            "Arav Sood",
            "Aanchal Khanna",
            "Savi Wilson",
            "Karan Manot",
            "Sree Kavya Durbaka"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.16071v1",
        "title": "Event-based Shape from Polarization with Spiking Neural Networks",
        "abstract": "  Recent advances in event-based shape determination from polarization offer a\ntransformative approach that tackles the trade-off between speed and accuracy\nin capturing surface geometries. In this paper, we investigate event-based\nshape from polarization using Spiking Neural Networks (SNNs), introducing the\nSingle-Timestep and Multi-Timestep Spiking UNets for effective and efficient\nsurface normal estimation. Specificially, the Single-Timestep model processes\nevent-based shape as a non-temporal task, updating the membrane potential of\neach spiking neuron only once, thereby reducing computational and energy\ndemands. In contrast, the Multi-Timestep model exploits temporal dynamics for\nenhanced data extraction. Extensive evaluations on synthetic and real-world\ndatasets demonstrate that our models match the performance of state-of-the-art\nArtifical Neural Networks (ANNs) in estimating surface normals, with the added\nadvantage of superior energy efficiency. Our work not only contributes to the\nadvancement of SNNs in event-based sensing but also sets the stage for future\nexplorations in optimizing SNN architectures, integrating multi-modal data, and\nscaling for applications on neuromorphic hardware.\n",
        "published": "2023",
        "authors": [
            "Peng Kang",
            "Srutarshi Banerjee",
            "Henry Chopp",
            "Aggelos Katsaggelos",
            "Oliver Cossairt"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2312.17286v2",
        "title": "Comparative study of clustering models for multivariate time series from\n  connected medical devices",
        "abstract": "  In healthcare, patient data is often collected as multivariate time series,\nproviding a comprehensive view of a patient's health status over time. While\nthis data can be sparse, connected devices may enhance its frequency. The goal\nis to create patient profiles from these time series. In the absence of labels,\na predictive model can be used to predict future values while forming a latent\ncluster space, evaluated based on predictive performance. We compare two models\non Withing's datasets, M AGMAC LUST which clusters entire time series and\nDGM${}^2$ which allows the group affiliation of an individual to change over\ntime (dynamic clustering).\n",
        "published": "2023",
        "authors": [
            "Violaine Courrier",
            "Christophe Biernacki",
            "Cristian Preda",
            "Benjamin Vittrant"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.01364v1",
        "title": "Multi-Modal Cognitive Maps based on Neural Networks trained on Successor\n  Representations",
        "abstract": "  Cognitive maps are a proposed concept on how the brain efficiently organizes\nmemories and retrieves context out of them. The entorhinal-hippocampal complex\nis heavily involved in episodic and relational memory processing, as well as\nspatial navigation and is thought to built cognitive maps via place and grid\ncells. To make use of the promising properties of cognitive maps, we set up a\nmulti-modal neural network using successor representations which is able to\nmodel place cell dynamics and cognitive map representations. Here, we use\nmulti-modal inputs consisting of images and word embeddings. The network learns\nthe similarities between novel inputs and the training database and therefore\nthe representation of the cognitive map successfully. Subsequently, the\nprediction of the network can be used to infer from one modality to another\nwith over $90\\%$ accuracy. The proposed method could therefore be a building\nblock to improve current AI systems for better understanding of the environment\nand the different modalities in which objects appear. The association of\nspecific modalities with certain encounters can therefore lead to context\nawareness in novel situations when similar encounters with less information\noccur and additional information can be inferred from the learned cognitive\nmap. Cognitive maps, as represented by the entorhinal-hippocampal complex in\nthe brain, organize and retrieve context from memories, suggesting that large\nlanguage models (LLMs) like ChatGPT could harness similar architectures to\nfunction as a high-level processing center, akin to how the hippocampus\noperates within the cortex hierarchy. Finally, by utilizing multi-modal inputs,\nLLMs can potentially bridge the gap between different forms of data (like\nimages and words), paving the way for context-awareness and grounding of\nabstract concepts through learned associations, addressing the grounding\nproblem in AI.\n",
        "published": "2023",
        "authors": [
            "Paul Stoewer",
            "Achim Schilling",
            "Andreas Maier",
            "Patrick Krauss"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.01732v1",
        "title": "Task and Explanation Network",
        "abstract": "  Explainability in deep networks has gained increased importance in recent\nyears. We argue herein that an AI must be tasked not just with a task but also\nwith an explanation of why said task was accomplished as such. We present a\nbasic framework -- Task and Explanation Network (TENet) -- which fully\nintegrates task completion and its explanation. We believe that the field of AI\nas a whole should insist -- quite emphatically -- on explainability.\n",
        "published": "2024",
        "authors": [
            "Moshe Sipper"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.02429v1",
        "title": "Brain-Inspired Spiking Neural Networks for Industrial Fault Diagnosis: A\n  Survey, Challenges, and Opportunities",
        "abstract": "  In recent decades, Industrial Fault Diagnosis (IFD) has emerged as a crucial\ndiscipline concerned with detecting and gathering vital information about\nindustrial equipment's health condition, thereby facilitating the\nidentification of failure types and severities. The pursuit of precise and\neffective fault recognition has garnered substantial attention, culminating in\na focus on automating equipment monitoring to preclude safety accidents and\nreduce reliance on human labor. The advent of artificial neural networks (ANNs)\nhas been instrumental in augmenting intelligent IFD algorithms, particularly in\nthe context of big data. Despite these advancements, ANNs, being a simplified\nbiomimetic neural network model, exhibit inherent limitations such as resource\nand data dependencies and restricted cognitive capabilities. To address these\nlimitations, the third-generation Spiking Neural Network (SNN), founded on\nprinciples of Brain-inspired computing, has surfaced as a promising\nalternative. The SNN, characterized by its biological neuron dynamics and\nspiking information encoding, demonstrates exceptional potential in\nrepresenting spatiotemporal features. Consequently, developing SNN-based IFD\nmodels has gained momentum, displaying encouraging performance. Nevertheless,\nthis field lacks systematic surveys to illustrate the current situation,\nchallenges, and future directions. Therefore, this paper systematically reviews\nthe theoretical progress of SNN-based models to answer the question of what SNN\nis. Subsequently, it reviews and analyzes existing SNN-based IFD models to\nexplain why SNN needs to be used and how to use it. More importantly, this\npaper systematically answers the challenges, solutions, and opportunities of\nSNN in IFD.\n",
        "published": "2023",
        "authors": [
            "Huan Wang",
            "Yan-Fu Li",
            "Konstantinos Gryllias"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.02576v1",
        "title": "t-DGR: A Trajectory-Based Deep Generative Replay Method for Continual\n  Learning in Decision Making",
        "abstract": "  Deep generative replay has emerged as a promising approach for continual\nlearning in decision-making tasks. This approach addresses the problem of\ncatastrophic forgetting by leveraging the generation of trajectories from\npreviously encountered tasks to augment the current dataset. However, existing\ndeep generative replay methods for continual learning rely on autoregressive\nmodels, which suffer from compounding errors in the generated trajectories. In\nthis paper, we propose a simple, scalable, and non-autoregressive method for\ncontinual learning in decision-making tasks using a generative model that\ngenerates task samples conditioned on the trajectory timestep. We evaluate our\nmethod on Continual World benchmarks and find that our approach achieves\nstate-of-the-art performance on the average success rate metric among continual\nlearning methods. Code is available at https://github.com/WilliamYue37/t-DGR .\n",
        "published": "2024",
        "authors": [
            "William Yue",
            "Bo Liu",
            "Peter Stone"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.03319v1",
        "title": "Comparison of Microservice Call Rate Predictions for Replication in the\n  Cloud",
        "abstract": "  Today, many users deploy their microservice-based applications with various\ninterconnections on a cluster of Cloud machines, subject to stochastic changes\ndue to dynamic user requirements. To address this problem, we compare three\nmachine learning (ML) models for predicting the microservice call rates based\non the microservice times and aiming at estimating the scalability\nrequirements. We apply the linear regression (LR), multilayer perception (MLP),\nand gradient boosting regression (GBR) models on the Alibaba microservice\ntraces. The prediction results reveal that the LR model reaches a lower\ntraining time than the GBR and MLP models. However, the GBR reduces the mean\nabsolute error and the mean absolute percentage error compared to LR and MLP\nmodels. Moreover, the prediction results show that the required number of\nreplicas for each microservice by the gradient boosting model is close to the\nactual test data without any prediction.\n",
        "published": "2023",
        "authors": [
            "Narges Mehran",
            "Arman Haghighi",
            "Pedram Aminharati",
            "Nikolay Nikolov",
            "Ahmet Soylu",
            "Dumitru Roman",
            "Radu Prodan"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.05350v1",
        "title": "Adaptive operator selection utilising generalised experience",
        "abstract": "  Optimisation problems, particularly combinatorial optimisation problems, are\ndifficult to solve due to their complexity and hardness. Such problems have\nbeen successfully solved by evolutionary and swarm intelligence algorithms,\nespecially in binary format. However, the approximation may suffer due to the\nthe issues in balance between exploration and exploitation activities (EvE),\nwhich remain as the major challenge in this context. Although the complementary\nusage of multiple operators is becoming more popular for managing EvE with\nadaptive operator selection schemes, a bespoke adaptive selection system is\nstill an important topic in research. Reinforcement Learning (RL) has recently\nbeen proposed as a way to customise and shape up a highly effective adaptive\nselection system. However, it is still challenging to handle the problem in\nterms of scalability. This paper proposes and assesses a RL-based novel\napproach to help develop a generalised framework for gaining, processing, and\nutilising the experiences for both the immediate and future use. The\nexperimental results support the proposed approach with a certain level of\nsuccess.\n",
        "published": "2023",
        "authors": [
            "Mehmet Emin Aydin",
            "Rafet Durgut",
            "Abdur Rakib"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.05373v1",
        "title": "Dynamic Spiking Graph Neural Networks",
        "abstract": "  The integration of Spiking Neural Networks (SNNs) and Graph Neural Networks\n(GNNs) is gradually attracting attention due to the low power consumption and\nhigh efficiency in processing the non-Euclidean data represented by graphs.\nHowever, as a common problem, dynamic graph representation learning faces\nchallenges such as high complexity and large memory overheads. Current work\noften uses SNNs instead of Recurrent Neural Networks (RNNs) by using binary\nfeatures instead of continuous ones for efficient training, which would\noverlooks graph structure information and leads to the loss of details during\npropagation. Additionally, optimizing dynamic spiking models typically requires\npropagation of information across time steps, which increases memory\nrequirements. To address these challenges, we present a framework named\n\\underline{Dy}namic \\underline{S}p\\underline{i}king \\underline{G}raph\n\\underline{N}eural Networks (\\method{}). To mitigate the information loss\nproblem, \\method{} propagates early-layer information directly to the last\nlayer for information compensation. To accommodate the memory requirements, we\napply the implicit differentiation on the equilibrium state, which does not\nrely on the exact reverse of the forward computation. While traditional\nimplicit differentiation methods are usually used for static situations,\n\\method{} extends it to the dynamic graph setting. Extensive experiments on\nthree large-scale real-world dynamic graph datasets validate the effectiveness\nof \\method{} on dynamic node classification tasks with lower computational\ncosts.\n",
        "published": "2023",
        "authors": [
            "Nan Yin",
            "Mengzhu Wang",
            "Zhenghan Chen",
            "Giulia De Masi",
            "Bin Gu",
            "Huan Xiong"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.05444v1",
        "title": "Fully Spiking Actor Network with Intra-layer Connections for\n  Reinforcement Learning",
        "abstract": "  With the help of special neuromorphic hardware, spiking neural networks\n(SNNs) are expected to realize artificial intelligence (AI) with less energy\nconsumption. It provides a promising energy-efficient way for realistic control\ntasks by combining SNNs with deep reinforcement learning (DRL). In this paper,\nwe focus on the task where the agent needs to learn multi-dimensional\ndeterministic policies to control, which is very common in real scenarios.\nRecently, the surrogate gradient method has been utilized for training\nmulti-layer SNNs, which allows SNNs to achieve comparable performance with the\ncorresponding deep networks in this task. Most existing spike-based RL methods\ntake the firing rate as the output of SNNs, and convert it to represent\ncontinuous action space (i.e., the deterministic policy) through a\nfully-connected (FC) layer. However, the decimal characteristic of the firing\nrate brings the floating-point matrix operations to the FC layer, making the\nwhole SNN unable to deploy on the neuromorphic hardware directly. To develop a\nfully spiking actor network without any floating-point matrix operations, we\ndraw inspiration from the non-spiking interneurons found in insects and employ\nthe membrane voltage of the non-spiking neurons to represent the action. Before\nthe non-spiking neurons, multiple population neurons are introduced to decode\ndifferent dimensions of actions. Since each population is used to decode a\ndimension of action, we argue that the neurons in each population should be\nconnected in time domain and space domain. Hence, the intra-layer connections\nare used in output populations to enhance the representation capacity. Finally,\nwe propose a fully spiking actor network with intra-layer connections\n(ILC-SAN).\n",
        "published": "2024",
        "authors": [
            "Ding Chen",
            "Peixi Peng",
            "Tiejun Huang",
            "Yonghong Tian"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.05680v1",
        "title": "Use of Graph Neural Networks in Aiding Defensive Cyber Operations",
        "abstract": "  In an increasingly interconnected world, where information is the lifeblood\nof modern society, regular cyber-attacks sabotage the confidentiality,\nintegrity, and availability of digital systems and information. Additionally,\ncyber-attacks differ depending on the objective and evolve rapidly to disguise\ndefensive systems. However, a typical cyber-attack demonstrates a series of\nstages from attack initiation to final resolution, called an attack life cycle.\nThese diverse characteristics and the relentless evolution of cyber attacks\nhave led cyber defense to adopt modern approaches like Machine Learning to\nbolster defensive measures and break the attack life cycle. Among the adopted\nML approaches, Graph Neural Networks have emerged as a promising approach for\nenhancing the effectiveness of defensive measures due to their ability to\nprocess and learn from heterogeneous cyber threat data. In this paper, we look\ninto the application of GNNs in aiding to break each stage of one of the most\nrenowned attack life cycles, the Lockheed Martin Cyber Kill Chain. We address\neach phase of CKC and discuss how GNNs contribute to preparing and preventing\nan attack from a defensive standpoint. Furthermore, We also discuss open\nresearch areas and further improvement scopes.\n",
        "published": "2024",
        "authors": [
            "Shaswata Mitra",
            "Trisha Chakraborty",
            "Subash Neupane",
            "Aritran Piplai",
            "Sudip Mittal"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.06137v1",
        "title": "QuasiNet: a neural network with trainable product layers",
        "abstract": "  Classical neural networks achieve only limited convergence in hard problems\nsuch as XOR or parity when the number of hidden neurons is small. With the\nmotivation to improve the success rate of neural networks in these problems, we\npropose a new neural network model inspired by existing neural network models\nwith so called product neurons and a learning rule derived from classical error\nbackpropagation, which elegantly solves the problem of mutually exclusive\nsituations. Unlike existing product neurons, which have weights that are preset\nand not adaptable, our product layers of neurons also do learn. We tested the\nmodel and compared its success rate to a classical multilayer perceptron in the\naforementioned problems as well as in other hard problems such as the two\nspirals. Our results indicate that our model is clearly more successful than\nthe classical MLP and has the potential to be used in many tasks and\napplications.\n",
        "published": "2023",
        "authors": [
            "Krist\u00edna Malinovsk\u00e1",
            "Slavom\u00edr Holenda",
            "\u013dudov\u00edt Malinovsk\u00fd"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.06195v1",
        "title": "NeuSpin: Design of a Reliable Edge Neuromorphic System Based on\n  Spintronics for Green AI",
        "abstract": "  Internet of Things (IoT) and smart wearable devices for personalized\nhealthcare will require storing and computing ever-increasing amounts of data.\nThe key requirements for these devices are ultra-low-power, high-processing\ncapabilities, autonomy at low cost, as well as reliability and accuracy to\nenable Green AI at the edge. Artificial Intelligence (AI) models, especially\nBayesian Neural Networks (BayNNs) are resource-intensive and face challenges\nwith traditional computing architectures due to the memory wall problem.\nComputing-in-Memory (CIM) with emerging resistive memories offers a solution by\ncombining memory blocks and computing units for higher efficiency and lower\npower consumption. However, implementing BayNNs on CIM hardware, particularly\nwith spintronic technologies, presents technical challenges due to variability\nand manufacturing defects. The NeuSPIN project aims to address these challenges\nthrough full-stack hardware and software co-design, developing novel\nalgorithmic and circuit design approaches to enhance the performance,\nenergy-efficiency and robustness of BayNNs on sprintronic-based CIM platforms.\n",
        "published": "2024",
        "authors": [
            "Soyed Tuhin Ahmed",
            "Kamal Danouchi",
            "Guillaume Prenat",
            "Lorena Anghel",
            "Mehdi B. Tahoori"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2401.07387v1",
        "title": "Optimising network interactions through device agnostic models",
        "abstract": "  Physically implemented neural networks hold the potential to achieve the\nperformance of deep learning models by exploiting the innate physical\nproperties of devices as computational tools. This exploration of physical\nprocesses for computation requires to also consider their intrinsic dynamics,\nwhich can serve as valuable resources to process information. However, existing\ncomputational methods are unable to extend the success of deep learning\ntechniques to parameters influencing device dynamics, which often lack a\nprecise mathematical description. In this work, we formulate a universal\nframework to optimise interactions with dynamic physical systems in a fully\ndata-driven fashion. The framework adopts neural stochastic differential\nequations as differentiable digital twins, effectively capturing both\ndeterministic and stochastic behaviours of devices. Employing differentiation\nthrough the trained models provides the essential mathematical estimates for\noptimizing a physical neural network, harnessing the intrinsic temporal\ncomputation abilities of its physical nodes. To accurately model real devices'\nbehaviours, we formulated neural-SDE variants that can operate under a variety\nof experimental settings. Our work demonstrates the framework's applicability\nthrough simulations and physical implementations of interacting dynamic\ndevices, while highlighting the importance of accurately capturing system\nstochasticity for the successful deployment of a physically defined neural\nnetwork.\n",
        "published": "2024",
        "authors": [
            "Luca Manneschi",
            "Ian T. Vidamour",
            "Kilian D. Stenning",
            "Jack C. Gartside",
            "Charles Swindells",
            "Guru Venkat",
            "David Griffin",
            "Susan Stepney",
            "Will R. Branford",
            "Thomas Hayward",
            "Matt O Ellis",
            "Eleni Vasilaki"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2103.15798v2",
        "title": "Rethinking Neural Operations for Diverse Tasks",
        "abstract": "  An important goal of AutoML is to automate-away the design of neural networks\non new tasks in under-explored domains. Motivated by this goal, we study the\nproblem of enabling users to discover the right neural operations given data\nfrom their specific domain. We introduce a search space of operations called\nXD-Operations that mimic the inductive bias of standard multi-channel\nconvolutions while being much more expressive: we prove that it includes many\nnamed operations across multiple application areas. Starting with any standard\nbackbone such as ResNet, we show how to transform it into a search space over\nXD-operations and how to traverse the space using a simple weight-sharing\nscheme. On a diverse set of tasks -- solving PDEs, distance prediction for\nprotein folding, and music modeling -- our approach consistently yields models\nwith lower error than baseline networks and often even lower error than\nexpert-designed domain-specific approaches.\n",
        "published": "2021",
        "authors": [
            "Nicholas Roberts",
            "Mikhail Khodak",
            "Tri Dao",
            "Liam Li",
            "Christopher R\u00e9",
            "Ameet Talwalkar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2210.17020v2",
        "title": "A Law of Data Separation in Deep Learning",
        "abstract": "  While deep learning has enabled significant advances in many areas of\nscience, its black-box nature hinders architecture design for future artificial\nintelligence applications and interpretation for high-stakes decision makings.\nWe addressed this issue by studying the fundamental question of how deep neural\nnetworks process data in the intermediate layers. Our finding is a simple and\nquantitative law that governs how deep neural networks separate data according\nto class membership throughout all layers for classification. This law shows\nthat each layer improves data separation at a constant geometric rate, and its\nemergence is observed in a collection of network architectures and datasets\nduring training. This law offers practical guidelines for designing\narchitectures, improving model robustness and out-of-sample performance, as\nwell as interpreting the predictions.\n",
        "published": "2022",
        "authors": [
            "Hangfeng He",
            "Weijie J. Su"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2304.07689v3",
        "title": "Learning Empirical Bregman Divergence for Uncertain Distance\n  Representation",
        "abstract": "  Deep metric learning techniques have been used for visual representation in\nvarious supervised and unsupervised learning tasks through learning embeddings\nof samples with deep networks. However, classic approaches, which employ a\nfixed distance metric as a similarity function between two embeddings, may lead\nto suboptimal performance for capturing the complex data distribution. The\nBregman divergence generalizes measures of various distance metrics and arises\nthroughout many fields of deep metric learning. In this paper, we first show\nhow deep metric learning loss can arise from the Bregman divergence. We then\nintroduce a novel method for learning empirical Bregman divergence directly\nfrom data based on parameterizing the convex function underlying the Bregman\ndivergence with a deep learning setting. We further experimentally show that\nour approach performs effectively on five popular public datasets compared to\nother SOTA deep metric learning methods, particularly for pattern recognition\nproblems.\n",
        "published": "2023",
        "authors": [
            "Zhiyuan Li",
            "Ziru Liu",
            "Anna Zou",
            "Anca L. Ralescu"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1910.00101v1",
        "title": "Risk-Aware Planning by Confidence Estimation using Deep Learning-Based\n  Perception",
        "abstract": "  This work proposes the use of Bayesian approximations of uncertainty from\ndeep learning in a robot planner, showing that this produces more cautious\nactions in safety-critical scenarios. The case study investigated is motivated\nby a setup where an aerial robot acts as a \"scout\" for a ground robot. This is\nuseful when the below area is unknown or dangerous, with applications in space\nexploration, military, or search-and-rescue. Images taken from the aerial view\nare used to provide a less obstructed map to guide the navigation of the robot\non the ground. Experiments are conducted using a deep learning semantic image\nsegmentation, followed by a path planner based on the resulting cost map, to\nprovide an empirical analysis of the proposed method. A comparison with similar\napproaches is presented to portray the usefulness of certain techniques, or\nvariations within a technique, in similar experimental settings. The method is\nanalyzed to assess the impact of variations in the uncertainty extraction, as\nwell as the absence of an uncertainty metric, on the overall system with the\nuse of a defined metric which measures surprise to the planner. The analysis is\nperformed on multiple datasets, showing a similar trend of lower surprise when\nuncertainty information is incorporated in the planning, given threshold values\nof the hyperparameters in the uncertainty extraction have been met. We find\nthat taking uncertainty into account leads to paths that could be 18% less\nrisky on an average.\n",
        "published": "2019",
        "authors": [
            "Maymoonah Toubeh",
            "Pratap Tokekar"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2010.00482v2",
        "title": "Physical Exercise Recommendation and Success Prediction Using\n  Interconnected Recurrent Neural Networks",
        "abstract": "  Unhealthy behaviors, e.g., physical inactivity and unhealthful food choice,\nare the primary healthcare cost drivers in developed countries. Pervasive\ncomputational, sensing, and communication technology provided by smartphones\nand smartwatches have made it possible to support individuals in their everyday\nlives to develop healthier lifestyles. In this paper, we propose an exercise\nrecommendation system that also predicts individual success rates. The system,\nconsisting of two inter-connected recurrent neural networks (RNNs), uses the\nhistory of workouts to recommend the next workout activity for each individual.\nThe system then predicts the probability of successful completion of the\npredicted activity by the individual. The prediction accuracy of this\ninterconnected-RNN model is assessed on previously published data from a\nfour-week mobile health experiment and is shown to improve upon previous\npredictions from a computational cognitive model.\n",
        "published": "2020",
        "authors": [
            "Arash Mahyari",
            "Peter Pirolli"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2107.01152v1",
        "title": "Simpler, Faster, Stronger: Breaking The log-K Curse On Contrastive\n  Learners With FlatNCE",
        "abstract": "  InfoNCE-based contrastive representation learners, such as SimCLR, have been\ntremendously successful in recent years. However, these contrastive schemes are\nnotoriously resource demanding, as their effectiveness breaks down with\nsmall-batch training (i.e., the log-K curse, whereas K is the batch-size). In\nthis work, we reveal mathematically why contrastive learners fail in the\nsmall-batch-size regime, and present a novel simple, non-trivial contrastive\nobjective named FlatNCE, which fixes this issue. Unlike InfoNCE, our FlatNCE no\nlonger explicitly appeals to a discriminative classification goal for\ncontrastive learning. Theoretically, we show FlatNCE is the mathematical dual\nformulation of InfoNCE, thus bridging the classical literature on energy\nmodeling; and empirically, we demonstrate that, with minimal modification of\ncode, FlatNCE enables immediate performance boost independent of the\nsubject-matter engineering efforts. The significance of this work is furthered\nby the powerful generalization of contrastive learning techniques, and the\nintroduction of new tools to monitor and diagnose contrastive training. We\nsubstantiate our claims with empirical evidence on CIFAR10, ImageNet, and other\ndatasets, where FlatNCE consistently outperforms InfoNCE.\n",
        "published": "2021",
        "authors": [
            "Junya Chen",
            "Zhe Gan",
            "Xuan Li",
            "Qing Guo",
            "Liqun Chen",
            "Shuyang Gao",
            "Tagyoung Chung",
            "Yi Xu",
            "Belinda Zeng",
            "Wenlian Lu",
            "Fan Li",
            "Lawrence Carin",
            "Chenyang Tao"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2302.05881v4",
        "title": "Exploring Numerical Priors for Low-Rank Tensor Completion with\n  Generalized CP Decomposition",
        "abstract": "  Tensor completion is important to many areas such as computer vision, data\nanalysis, and signal processing. Enforcing low-rank structures on completed\ntensors, a category of methods known as low-rank tensor completion, has\nrecently been studied extensively. Whilst such methods attained great success,\nnone considered exploiting numerical priors of tensor elements. Ignoring\nnumerical priors causes loss of important information regarding the data, and\ntherefore prevents the algorithms from reaching optimal accuracy. This work\nattempts to construct a new methodological framework called GCDTC (Generalized\nCP Decomposition Tensor Completion) for leveraging numerical priors and\nachieving higher accuracy in tensor completion. In this newly introduced\nframework, a generalized form of CP Decomposition is applied to low-rank tensor\ncompletion. This paper also proposes an algorithm known as SPTC (Smooth Poisson\nTensor Completion) for nonnegative integer tensor completion as an\ninstantiation of the GCDTC framework. A series of experiments on real-world\ndata indicate that SPTC could produce results superior in completion accuracy\nto current state-of-the-art methods. Related code is available in the\nsupplemental materials.\n",
        "published": "2023",
        "authors": [
            "Shiran Yuan",
            "Kaizhu Huang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2309.07332v1",
        "title": "Reliability-based cleaning of noisy training labels with inductive\n  conformal prediction in multi-modal biomedical data mining",
        "abstract": "  Accurately labeling biomedical data presents a challenge. Traditional\nsemi-supervised learning methods often under-utilize available unlabeled data.\nTo address this, we propose a novel reliability-based training data cleaning\nmethod employing inductive conformal prediction (ICP). This method capitalizes\non a small set of accurately labeled training data and leverages ICP-calculated\nreliability metrics to rectify mislabeled data and outliers within vast\nquantities of noisy training data. The efficacy of the method is validated\nacross three classification tasks within distinct modalities: filtering\ndrug-induced-liver-injury (DILI) literature with title and abstract, predicting\nICU admission of COVID-19 patients through CT radiomics and electronic health\nrecords, and subtyping breast cancer using RNA-sequencing data. Varying levels\nof noise to the training labels were introduced through label permutation.\nResults show significant enhancements in classification performance: accuracy\nenhancement in 86 out of 96 DILI experiments (up to 11.4%), AUROC and AUPRC\nenhancements in all 48 COVID-19 experiments (up to 23.8% and 69.8%), and\naccuracy and macro-average F1 score improvements in 47 out of 48 RNA-sequencing\nexperiments (up to 74.6% and 89.0%). Our method offers the potential to\nsubstantially boost classification performance in multi-modal biomedical\nmachine learning tasks. Importantly, it accomplishes this without necessitating\nan excessive volume of meticulously curated training data.\n",
        "published": "2023",
        "authors": [
            "Xianghao Zhan",
            "Qinmei Xu",
            "Yuanning Zheng",
            "Guangming Lu",
            "Olivier Gevaert"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2009.00802v1",
        "title": "Estimating the Brittleness of AI: Safety Integrity Levels and the Need\n  for Testing Out-Of-Distribution Performance",
        "abstract": "  Test, Evaluation, Verification, and Validation (TEVV) for Artificial\nIntelligence (AI) is a challenge that threatens to limit the economic and\nsocietal rewards that AI researchers have devoted themselves to producing. A\ncentral task of TEVV for AI is estimating brittleness, where brittleness\nimplies that the system functions well within some bounds and poorly outside of\nthose bounds. This paper argues that neither of those criteria are certain of\nDeep Neural Networks. First, highly touted AI successes (eg. image\nclassification and speech recognition) are orders of magnitude more\nfailure-prone than are typically certified in critical systems even within\ndesign bounds (perfectly in-distribution sampling). Second, performance falls\noff only gradually as inputs become further Out-Of-Distribution (OOD). Enhanced\nemphasis is needed on designing systems that are resilient despite\nfailure-prone AI components as well as on evaluating and improving OOD\nperformance in order to get AI to where it can clear the challenging hurdles of\nTEVV and certification.\n",
        "published": "2020",
        "authors": [
            "Andrew J. Lohn"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2303.11536v1",
        "title": "Indeterminate Probability Neural Network",
        "abstract": "  We propose a new general model called IPNN - Indeterminate Probability Neural\nNetwork, which combines neural network and probability theory together. In the\nclassical probability theory, the calculation of probability is based on the\noccurrence of events, which is hardly used in current neural networks. In this\npaper, we propose a new general probability theory, which is an extension of\nclassical probability theory, and makes classical probability theory a special\ncase to our theory. Besides, for our proposed neural network framework, the\noutput of neural network is defined as probability events, and based on the\nstatistical analysis of these events, the inference model for classification\ntask is deduced. IPNN shows new property: It can perform unsupervised\nclustering while doing classification. Besides, IPNN is capable of making very\nlarge classification with very small neural network, e.g. model with 100 output\nnodes can classify 10 billion categories. Theoretical advantages are reflected\nin experimental results.\n",
        "published": "2023",
        "authors": [
            "Tao Yang",
            "Chuang Liu",
            "Xiaofeng Ma",
            "Weijia Lu",
            "Ning Wu",
            "Bingyang Li",
            "Zhifei Yang",
            "Peng Liu",
            "Lin Sun",
            "Xiaodong Zhang",
            "Can Zhang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2003.00203v2",
        "title": "Contextual Policy Transfer in Reinforcement Learning Domains via Deep\n  Mixtures-of-Experts",
        "abstract": "  In reinforcement learning, agents that consider the context, or current\nstate, when selecting source policies for transfer have been shown to\noutperform context-free approaches. However, none of the existing approaches\ntransfer knowledge contextually from model-based learners to a model-free\nlearner. This could be useful, for instance, when source policies are\nintentionally learned on diverse simulations with plentiful data but\ntransferred to a real-world setting with limited data. In this paper, we assume\nknowledge of estimated source task dynamics and policies, and common sub-goals\nbut different dynamics. We introduce a novel deep mixture-of-experts\nformulation for learning state-dependent beliefs over source task dynamics that\nmatch the target dynamics using state trajectories collected from the target\ntask. The mixture model is easy to interpret, demonstrates robustness to\nestimation errors in dynamics, and is compatible with most learning algorithms.\nWe then show how this model can be incorporated into standard policy reuse\nframeworks, and demonstrate its effectiveness on benchmarks from OpenAI-Gym.\n",
        "published": "2020",
        "authors": [
            "Michael Gimelfarb",
            "Scott Sanner",
            "Chi-Guhn Lee"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2201.05098v2",
        "title": "Neural Koopman Lyapunov Control",
        "abstract": "  Learning and synthesizing stabilizing controllers for unknown nonlinear\ncontrol systems is a challenging problem for real-world and industrial\napplications. Koopman operator theory allows one to analyze nonlinear systems\nthrough the lens of linear systems and nonlinear control systems through the\nlens of bilinear control systems. The key idea of these methods lies in the\ntransformation of the coordinates of the nonlinear system into the Koopman\nobservables, which are coordinates that allow the representation of the\noriginal system (control system) as a higher dimensional linear (bilinear\ncontrol) system. However, for nonlinear control systems, the bilinear control\nmodel obtained by applying Koopman operator based learning methods is not\nnecessarily stabilizable. Simultaneous identification of stabilizable lifted\nbilinear control systems as well as the associated Koopman observables is still\nan open problem. In this paper, we propose a framework to construct these\nstabilizable bilinear models and identify its associated observables from data\nby simultaneously learning a bilinear Koopman embedding for the underlying\nunknown control affine nonlinear system as well as a Control Lyapunov Function\n(CLF) for the Koopman based bilinear model using a learner and falsifier. Our\nproposed approach thereby provides provable guarantees of asymptotic stability\nfor the Koopman based representation of the unknown control affine nonlinear\ncontrol system as a bilinear system. Numerical simulations are provided to\nvalidate the efficacy of our proposed class of stabilizing feedback controllers\nfor unknown control-affine nonlinear systems.\n",
        "published": "2022",
        "authors": [
            "Vrushabh Zinage",
            "Efstathios Bakolas"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2302.00773v3",
        "title": "Toward Physically Plausible Data-Driven Models: A Novel Neural Network\n  Approach to Symbolic Regression",
        "abstract": "  Many real-world systems can be described by mathematical models that are\nhuman-comprehensible, easy to analyze and help explain the system's behavior.\nSymbolic regression is a method that can automatically generate such models\nfrom data. Historically, symbolic regression has been predominantly realized by\ngenetic programming, a method that evolves populations of candidate solutions\nthat are subsequently modified by genetic operators crossover and mutation.\nHowever, this approach suffers from several deficiencies: it does not scale\nwell with the number of variables and samples in the training data - models\ntend to grow in size and complexity without an adequate accuracy gain, and it\nis hard to fine-tune the model coefficients using just genetic operators.\nRecently, neural networks have been applied to learn the whole analytic model,\ni.e., its structure and the coefficients, using gradient-based optimization\nalgorithms. This paper proposes a novel neural network-based symbolic\nregression method that constructs physically plausible models based on even\nvery small training data sets and prior knowledge about the system. The method\nemploys an adaptive weighting scheme to effectively deal with multiple loss\nfunction terms and an epoch-wise learning process to reduce the chance of\ngetting stuck in poor local optima. Furthermore, we propose a parameter-free\nmethod for choosing the model with the best interpolation and extrapolation\nperformance out of all the models generated throughout the whole learning\nprocess. We experimentally evaluate the approach on four test systems: the\nTurtleBot 2 mobile robot, the magnetic manipulation system, the equivalent\nresistance of two resistors in parallel, and the longitudinal force of the\nanti-lock braking system. The results clearly show the potential of the method\nto find parsimonious models that comply with the prior knowledge provided.\n",
        "published": "2023",
        "authors": [
            "Ji\u0159\u00ed Kubal\u00edk",
            "Erik Derner",
            "Robert Babu\u0161ka"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0712.4153v2",
        "title": "Biology of Applied Digital Ecosystems",
        "abstract": "  A primary motivation for our research in Digital Ecosystems is the desire to\nexploit the self-organising properties of biological ecosystems. Ecosystems are\nthought to be robust, scalable architectures that can automatically solve\ncomplex, dynamic problems. However, the biological processes that contribute to\nthese properties have not been made explicit in Digital Ecosystems research.\nHere, we discuss how biological properties contribute to the self-organising\nfeatures of biological ecosystems, including population dynamics, evolution, a\ncomplex dynamic environment, and spatial distributions for generating local\ninteractions. The potential for exploiting these properties in artificial\nsystems is then considered. We suggest that several key features of biological\necosystems have not been fully explored in existing digital ecosystems, and\ndiscuss how mimicking these features may assist in developing robust, scalable\nself-organising architectures. An example architecture, the Digital Ecosystem,\nis considered in detail. The Digital Ecosystem is then measured experimentally\nthrough simulations, with measures originating from theoretical ecology, to\nconfirm its likeness to a biological ecosystem. Including the responsiveness to\nrequests for applications from the user base, as a measure of the 'ecological\nsuccession' (development).\n",
        "published": "2007",
        "authors": [
            "G. Briscoe",
            "S. Sadedin",
            "G. Paperin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0803.1596v1",
        "title": "Using Intelligent Agents to understand organisational behaviour",
        "abstract": "  This paper introduces two ongoing research projects which seek to apply\ncomputer modelling techniques in order to simulate human behaviour within\norganisations. Previous research in other disciplines has suggested that\ncomplex social behaviours are governed by relatively simple rules which, when\nidentified, can be used to accurately model such processes using computer\ntechnology. The broad objective of our research is to develop a similar\ncapability within organisational psychology.\n",
        "published": "2008",
        "authors": [
            "Helen Celia",
            "Christopher Clegg",
            "Mark Robinson",
            "Peer-Olaf Siebers",
            "Uwe Aickelin",
            "Christine Sprigg"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0803.3905v1",
        "title": "Introduction to Multi-Agent Simulation",
        "abstract": "  When designing systems that are complex, dynamic and stochastic in nature,\nsimulation is generally recognised as one of the best design support\ntechnologies, and a valuable aid in the strategic and tactical decision making\nprocess. A simulation model consists of a set of rules that define how a system\nchanges over time, given its current state. Unlike analytical models, a\nsimulation model is not solved but is run and the changes of system states can\nbe observed at any point in time. This provides an insight into system dynamics\nrather than just predicting the output of a system based on specific inputs.\nSimulation is not a decision making tool but a decision support tool, allowing\nbetter informed decisions to be made. Due to the complexity of the real world,\na simulation model can only be an approximation of the target system. The\nessence of the art of simulation modelling is abstraction and simplification.\nOnly those characteristics that are important for the study and analysis of the\ntarget system should be included in the simulation model.\n",
        "published": "2008",
        "authors": [
            "Peer-Olaf Siebers",
            "Uwe Aickelin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0901.1610v1",
        "title": "Towards a Framework for Observing Artificial Evolutionary Systems",
        "abstract": "  Establishing the emergence of evolutionary behavior as a defining\ncharacteristic of 'life' is a major step in the Artificial life (ALife)\nstudies. We present here an abstract formal framework for this aim based upon\nthe notion of high-level observations made on the ALife model at hand during\nits simulations. An observation process is defined as a computable\ntransformation from the underlying dynamic structure of the model universe to a\ntuple consisting of abstract components needed to establish the evolutionary\nprocesses in the model. Starting with defining entities and their evolutionary\nrelationships observed during the simulations of the model, the framework\nprescribes a series of definitions, followed by the axioms (conditions) that\nmust be met in order to establish the level of evolutionary behavior in the\nmodel. The examples of Cellular Automata based Langton Loops and Lambda\ncalculus based Algorithmic Chemistry are used to illustrate the framework.\nGeneric design suggestions for the ALife research are also drawn based upon the\nframework design and case study analysis.\n",
        "published": "2009",
        "authors": [
            "Janardan Misra"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0909.3423v2",
        "title": "Digital Ecosystems",
        "abstract": "  We view Digital Ecosystems to be the digital counterparts of biological\necosystems, which are considered to be robust, self-organising and scalable\narchitectures that can automatically solve complex, dynamic problems. So, this\nwork is concerned with the creation, investigation, and optimisation of Digital\nEcosystems, exploiting the self-organising properties of biological ecosystems.\nFirst, we created the Digital Ecosystem, a novel optimisation technique\ninspired by biological ecosystems, where the optimisation works at two levels:\na first optimisation, migration of agents which are distributed in a\ndecentralised peer-to-peer network, operating continuously in time; this\nprocess feeds a second optimisation based on evolutionary computing that\noperates locally on single peers and is aimed at finding solutions to satisfy\nlocally relevant constraints. We then investigated its self-organising aspects,\nstarting with an extension to the definition of Physical Complexity to include\nevolving agent populations. Next, we established stability of evolving agent\npopulations over time, by extending the Chli-DeWilde definition of agent\nstability to include evolutionary dynamics. Further, we evaluated the diversity\nof the software agents within evolving agent populations. To conclude, we\nconsidered alternative augmentations to optimise and accelerate our Digital\nEcosystem, by studying the accelerating effect of a clustering catalyst on the\nevolutionary dynamics. We also studied the optimising effect of targeted\nmigration on the ecological dynamics, through the indirect and emergent\noptimisation of the agent migration patterns. Overall, we have advanced the\nunderstanding of creating Digital Ecosystems, the self-organisation that occurs\nwithin them, and the optimisation of their Ecosystem-Oriented Architecture.\n",
        "published": "2009",
        "authors": [
            "Gerard Briscoe"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0910.0674v1",
        "title": "Computing of Applied Digital Ecosystems",
        "abstract": "  A primary motivation for our research in digital ecosystems is the desire to\nexploit the self-organising properties of biological ecosystems. Ecosystems are\nthought to be robust, scalable architectures that can automatically solve\ncomplex, dynamic problems. However, the computing technologies that contribute\nto these properties have not been made explicit in digital ecosystems research.\nHere, we discuss how different computing technologies can contribute to\nproviding the necessary self-organising features, including Multi-Agent\nSystems, Service-Oriented Architectures, and distributed evolutionary\ncomputing. The potential for exploiting these properties in digital ecosystems\nis considered, suggesting how several key features of biological ecosystems can\nbe exploited in Digital Ecosystems, and discussing how mimicking these features\nmay assist in developing robust, scalable self-organising architectures. An\nexample architecture, the Digital Ecosystem, is considered in detail. The\nDigital Ecosystem is then measured experimentally through simulations,\nconsidering the self-organised diversity of its evolving agent populations\nrelative to the user request behaviour.\n",
        "published": "2009",
        "authors": [
            "G. Briscoe",
            "P. De Wilde"
        ]
    },
    {
        "id": "http://arxiv.org/abs/0910.2029v1",
        "title": "A Framework For Intelligent Multi Agent System Based Neural Network\n  Classification Model",
        "abstract": "  TIntelligent multi agent systems have great potentials to use in different\npurposes and research areas. One of the important issues to apply intelligent\nmulti agent systems in real world and virtual environment is to develop a\nframework that support machine learning model to reflect the whole complexity\nof the real world. In this paper, we proposed a framework of intelligent agent\nbased neural network classification model to solve the problem of gap between\ntwo applicable flows of intelligent multi agent technology and learning model\nfrom real environment. We consider the new Supervised Multilayers Feed Forward\nNeural Network (SMFFNN) model as an intelligent classification for learning\nmodel in the framework. The framework earns the information from the respective\nenvironment and its behavior can be recognized by the weights. Therefore, the\nSMFFNN model that lies in the framework will give more benefits in finding the\nsuitable information and the real weights from the environment which result for\nbetter recognition. The framework is applicable to different domains\nsuccessfully and for the potential case study, the clinical organization and\nits domain is considered for the proposed framework\n",
        "published": "2009",
        "authors": [
            "Roya Asadi",
            "Norwati Mustapha",
            "Nasir Sulaiman"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1111.7033v1",
        "title": "Stability of Evolving Multi-Agent Systems",
        "abstract": "  A Multi-Agent System is a distributed system where the agents or nodes\nperform complex functions that cannot be written down in analytic form.\nMulti-Agent Systems are highly connected, and the information they contain is\nmostly stored in the connections. When agents update their state, they take\ninto account the state of the other agents, and they have access to those\nstates via the connections. There is also external, user-generated input into\nthe Multi-Agent System. As so much information is stored in the connections,\nagents are often memory-less. This memory-less property, together with the\nrandomness of the external input, has allowed us to model Multi-Agent Systems\nusing Markov chains. In this paper, we look at Multi-Agent Systems that evolve,\ni.e. the number of agents varies according to the fitness of the individual\nagents. We extend our Markov chain model, and define stability. This is the\nstart of a methodology to control Multi-Agent Systems. We then build upon this\nto construct an entropy-based definition for the degree of instability (entropy\nof the limit probabilities), which we used to perform a stability analysis. We\nthen investigated the stability of evolving agent populations through\nsimulation, and show that the results are consistent with the original\ndefinition of stability in non-evolving Multi-Agent Systems, proposed by Chli\nand De Wilde. This paper forms the theoretical basis for the construction of\nDigital Business Ecosystems, and applications have been reported elsewhere.\n",
        "published": "2011",
        "authors": [
            "Philippe De Wilde",
            "Gerard Briscoe"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1304.4051v1",
        "title": "Coordinating metaheuristic agents with swarm intelligence",
        "abstract": "  Coordination of multi agent systems remains as a problem since there is no\nprominent method to completely solve this problem. Metaheuristic agents are\nspecific implementations of multi-agent systems, which imposes working together\nto solve optimisation problems with metaheuristic algorithms. The idea borrowed\nfrom swarm intelligence seems working much better than those implementations\nsuggested before. This paper reports the performance of swarms of simulated\nannealing agents collaborating with particle swarm optimization algorithm. The\nproposed approach is implemented for multidimensional knapsack problem and has\nresulted much better than some other works published before.\n",
        "published": "2013",
        "authors": [
            "Mehmet Emin Aydin"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1309.7524v3",
        "title": "Meme and Variations: A Computer Model of Cultural Evolution",
        "abstract": "  Holland's (1975) genetic algorithm is a minimal computer model of natural\nselection that made it possible to investigate the effect of manipulating\nspecific parameters on the evolutionary process. If culture is, like biology, a\nform of evolution, it should be possible to similarly abstract the underlying\nskeleton of the process and develop a minimal model of it. Meme and Variations,\nor MAV, is a computational model, inspired by the genetic algorithm, of how\nideas evolve in a society of interacting individuals (Gabora 1995). The name is\na pun on the classical music form 'theme and variations', because it is based\non the premise that novel ideas are variations of old ones; they result from\ntweaking or combining existing ideas in new ways (Holland et al. 1981). MAV\nexplores the impact of biological phenomena such as over-dominance and\nepistasis as well as cognitive and social phenomena such as the ability to\nlearn generalizations or imitate others on the fitness and diversity of\ncultural transmissible actions.\n",
        "published": "2013",
        "authors": [
            "Liane Gabora"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1310.0522v2",
        "title": "EVOC: A Computer Model of the Evolution of Culture",
        "abstract": "  EVOC is a computer model of the EVOlution of Culture. It consists of neural\nnetwork based agents that invent ideas for actions, and imitate neighbors'\nactions. EVOC replicates using a different fitness function the results\nobtained with an earlier model (MAV), including (1) an increase in mean fitness\nof actions, and (2) an increase and then decrease in the diversity of actions.\nDiversity of actions is positively correlated with number of needs, population\nsize and density, and with the erosion of borders between populations. Slowly\neroding borders maximize diversity, fostering specialization followed by\nsharing of fit actions. Square (as opposed to toroidal) worlds also exhibit\nhigher diversity. Introducing a leader that broadcasts its actions throughout\nthe population increases the fitness of actions but reduces diversity; these\neffects diminish the more leaders there are. Low density populations have less\nfit ideas but broadcasting diminishes this effect.\n",
        "published": "2013",
        "authors": [
            "Liane Gabora"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1407.0576v1",
        "title": "Novelty Search in Competitive Coevolution",
        "abstract": "  One of the main motivations for the use of competitive coevolution systems is\ntheir ability to capitalise on arms races between competing species to evolve\nincreasingly sophisticated solutions. Such arms races can, however, be hard to\nsustain, and it has been shown that the competing species often converge\nprematurely to certain classes of behaviours. In this paper, we investigate if\nand how novelty search, an evolutionary technique driven by behavioural\nnovelty, can overcome convergence in coevolution. We propose three methods for\napplying novelty search to coevolutionary systems with two species: (i) score\nboth populations according to behavioural novelty; (ii) score one population\naccording to novelty, and the other according to fitness; and (iii) score both\npopulations with a combination of novelty and fitness. We evaluate the methods\nin a predator-prey pursuit task. Our results show that novelty-based approaches\ncan evolve a significantly more diverse set of solutions, when compared to\ntraditional fitness-based coevolution.\n",
        "published": "2014",
        "authors": [
            "Jorge Gomes",
            "Pedro Mariano",
            "Anders Lyhne Christensen"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1407.0698v1",
        "title": "Continuous On-line Evolution of Agent Behaviours with Cartesian Genetic\n  Programming",
        "abstract": "  Evolutionary Computation has been successfully used to synthesise controllers\nfor embodied agents and multi-agent systems in general. Notwithstanding this,\ncontinuous on-line adaptation by the means of evolutionary algorithms is still\nunder-explored, especially outside the evolutionary robotics domain. In this\npaper, we present an on-line evolutionary programming algorithm that searches\nin the agent design space for the appropriate behavioural policies to cope with\nthe underlying environment. We discuss the current problems of continuous agent\nadaptation, present our on-line evolution testbed for evolutionary simulation.\n",
        "published": "2014",
        "authors": [
            "Davide Nunes",
            "Luis Antunes"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1407.5719v1",
        "title": "Artificial Life and the Web: WebAL Comes of Age",
        "abstract": "  A brief survey is presented of the first 18 years of web-based Artificial\nLife (\"WebAL\") research and applications, covering the period 1995-2013. The\nsurvey is followed by a short discussion of common methodologies employed and\ncurrent technologies relevant to WebAL research. The paper concludes with a\nquick look at what the future may hold for work in this exciting area.\n",
        "published": "2014",
        "authors": [
            "Tim Taylor"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1501.06721v2",
        "title": "Massively-concurrent Agent-based Evolutionary Computing",
        "abstract": "  The fusion of the multi-agent paradigm with evolutionary computation yielded\npromising results in many optimization problems. Evolutionary multi-agent\nsystem (EMAS) are more similar to biological evolution than classical\nevolutionary algorithms. However, technological limitations prevented the use\nof fully asynchronous agents in previous EMAS implementations. In this paper we\npresent a new algorithm for agent-based evolutionary computations. The\nindividuals are represented as fully autonomous and asynchronous agents. An\nefficient implementation of this algorithm was possible through the use of\nmodern technologies based on functional languages (namely Erlang and Scala),\nwhich natively support lightweight processes and asynchronous communication.\nOur experiments show that such an asynchronous approach is both faster and more\nefficient in solving common optimization problems.\n",
        "published": "2015",
        "authors": [
            "D. Krzywicki",
            "W. Turek",
            "A. Byrski",
            "M. Kisiel-Dorohinicki"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2004.10558v1",
        "title": "Evolving Dyadic Strategies for a Cooperative Physical Task",
        "abstract": "  Many cooperative physical tasks require that individuals play specialized\nroles (e.g., leader-follower). Humans are adept cooperators, negotiating these\nroles and transitions between roles innately. Yet how roles are delegated and\nreassigned is not well understood. Using a genetic algorithm, we evolve\nsimulated agents to explore a space of feasible role-switching policies.\nApplying these switching policies in a cooperative manual task, agents process\nvisual and haptic cues to decide when to switch roles. We then analyze the\nevolved virtual population for attributes typically associated with\ncooperation: load sharing and temporal coordination. We find that the best\nperforming dyads exhibit high temporal coordination (anti-synchrony). And in\nturn, anti-synchrony is correlated to symmetry between the parameters of the\ncooperative agents. These simulations furnish hypotheses as to how human\ncooperators might mediate roles in dyadic tasks.\n",
        "published": "2020",
        "authors": [
            "Saber Sheybani",
            "Eduardo J. Izquierdo",
            "Eatai Roth"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1406.2507v4",
        "title": "WebAL-1: Workshop on Artificial Life and the Web 2014 Proceedings",
        "abstract": "  Proceedings of WebAL-1: Workshop on Artificial Life and the Web 2014, held at\nthe 14th International Conference on the Synthesis and Simulation of Living\nSystems (ALIFE 14), New York, NY, 31 July 2014.\n",
        "published": "2014",
        "authors": [
            "Tim Taylor"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2101.07540v1",
        "title": "A synthetic biology approach for the design of genetic algorithms with\n  bacterial agents",
        "abstract": "  Bacteria have been a source of inspiration for the design of evolutionary\nalgorithms. At the beginning of the 20th century synthetic biology was born, a\ndiscipline whose goal is the design of biological systems that do not exist in\nnature, for example, programmable synthetic bacteria. In this paper, we\nintroduce as a novelty the designing of evolutionary algorithms where all the\nsteps are conducted by synthetic bacteria. To this end, we designed a genetic\nalgorithm, which we have named BAGA, illustrating its utility solving simple\ninstances of optimization problems such as function optimization, 0/1 knapsack\nproblem, Hamiltonian path problem. The results obtained open the possibility of\nconceiving evolutionary algorithms inspired by principles, mechanisms and\ngenetic circuits from synthetic biology. In summary, we can conclude that\nsynthetic biology is a source of inspiration either for the design of\nevolutionary algorithms or for some of their steps, as shown by the results\nobtained in our simulation experiments.\n",
        "published": "2021",
        "authors": [
            "A. Gargantilla Becerra",
            "M. Guti\u00e9rrez",
            "R. Lahoz-Beltra"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1906.05616v1",
        "title": "Decentralised Multi-Demic Evolutionary Approach to the Dynamic\n  Multi-Agent Travelling Salesman Problem",
        "abstract": "  The Travelling Salesman and its variations are some of the most well known NP\nhard optimisation problems. This paper looks to use both centralised and\ndecentralised implementations of Evolutionary Algorithms (EA) to solve a\ndynamic variant of the Multi-Agent Travelling Salesman Problem (MATSP). The\nproblem is dynamic, requiring an on-line solution, whereby tasks are completed\nduring simulation with new tasks added and completed ones removed. The problem\nis allocating an active set of tasks to a set of agents whilst simultaneously\nplanning the route for each agent. The allocation and routing are closely\ncoupled parts of the same problem making it difficult to decompose, instead\nthis paper uses multiple populations with well defined interactions to exploit\nthe problem structure. This work attempts to align the real world\nimplementation demands of a decentralised solution, where agents are far apart\nand have communication limits, to that of the structure of the multi-demic EA\nsolution process, ultimately allowing decentralised parts of the problem to be\nsolved `on board' agents and allow for robust communication and exchange of\ntasks.\n",
        "published": "2019",
        "authors": [
            "Thomas E. Kent",
            "Arthur G. Richards"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1909.06037v1",
        "title": "Optimisation of Air-Ground Swarm Teaming for Target Search, using\n  Differential Evolution",
        "abstract": "  This paper presents a swarm teaming perspective that enhances the scope of\nclassic investigations on survivable networks. A target searching generic\ncontext is considered as test-bed, in which a swarm of ground agents and a\nswarm of UAVs cooperate so that the ground agents reach as many targets as\npossible in the field while also remaining connected as much as possible at all\ntimes. To optimise the system against both these objectives in the same time,\nwe use an evolutionary computation approach in the form of a differential\nevolution algorithm. Results are encouraging, showing a good evolution of the\nfitness function used as part of the differential evolution, and a good\nperformance of the evolved dual-swarm system, which exhibits an optimal\ntrade-off between target reaching and connectivity.\n",
        "published": "2019",
        "authors": [
            "Jiangjun Tang",
            "George Leu",
            "Yu-Bin Yang"
        ]
    },
    {
        "id": "http://arxiv.org/abs/1909.06254v4",
        "title": "AED: An Anytime Evolutionary DCOP Algorithm",
        "abstract": "  Evolutionary optimization is a generic population-based metaheuristic that\ncan be adapted to solve a wide variety of optimization problems and has proven\nvery effective for combinatorial optimization problems. However, the potential\nof this metaheuristic has not been utilized in Distributed Constraint\nOptimization Problems (DCOPs), a well-known class of combinatorial optimization\nproblems prevalent in Multi-Agent Systems. In this paper, we present a novel\npopulation-based algorithm, Anytime Evolutionary DCOP (AED), that uses\nevolutionary optimization to solve DCOPs. In AED, the agents cooperatively\nconstruct an initial set of random solutions and gradually improve them through\na new mechanism that considers an optimistic approximation of local benefits.\nMoreover, we present a new anytime update mechanism for AED that identifies the\nbest among a distributed set of candidate solutions and notifies all the agents\nwhen a new best is found. In our theoretical analysis, we prove that AED is\nanytime. Finally, we present empirical results indicating AED outperforms the\nstate-of-the-art DCOP algorithms in terms of solution quality.\n",
        "published": "2019",
        "authors": [
            "Saaduddin Mahmud",
            "Moumita Choudhury",
            "Md. Mosaddek Khan",
            "Long Tran-Thanh",
            "Nicholas R. Jennings"
        ]
    },
    {
        "id": "http://arxiv.org/abs/2201.07977v2",
        "title": "Adaptability of Improved NEAT in Variable Environments",
        "abstract": "  A large challenge in Artificial Intelligence (AI) is training control agents\nthat can properly adapt to variable environments. Environments in which the\nconditions change can cause issues for agents trying to operate in them.\nBuilding algorithms that can train agents to operate in these environments and\nproperly deal with the changing conditions is therefore important.\nNeuroEvolution of Augmenting Topologies (NEAT) was a novel Genetic Algorithm\n(GA) when it was created, but has fallen aside with newer GAs outperforming it.\nThis paper furthers the research on this subject by implementing various\nversions of improved NEAT in a variable environment to determine if NEAT can\nperform well in these environments. The improvements included, in every\ncombination, are: recurrent connections, automatic feature selection, and\nincreasing population size. The recurrent connections improvement performed\nextremely well. The automatic feature selection improvement was found to be\ndetrimental to performance, and the increasing population size improvement\nlowered performance a small amount, but decreased computation requirements\nnoticeably.\n",
        "published": "2021",
        "authors": [
            "Destiny Bailey"
        ]
    }
]